{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working_dir='c:\\\\Users\\\\amitmils\\\\Documents\\\\Repo\\\\Text2BGAudio'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from audio_dataset import audio_segment\n",
    "import numpy as np\n",
    "\n",
    "working_dir = os.path.join(os.getcwd().split('Text2BGAudio')[0],'Text2BGAudio')\n",
    "os.chdir(working_dir)\n",
    "print(f\"{working_dir=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_data_raw_folder = r\"_Data\\Music\\train\"\n",
    "save_folder = r\"_Data/Music\"\n",
    "SR = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "Processing label: Angry\n",
      "Created 10 segments\n",
      "#######################\n",
      "\n",
      "\n",
      "#####################\n",
      "Processing label: Joy\n",
      "Created 21 segments\n",
      "#####################\n",
      "\n",
      "\n",
      "######################\n",
      "Processing label: Love\n",
      "Created 10 segments\n",
      "######################\n",
      "\n",
      "\n",
      "#####################\n",
      "Processing label: Sad\n",
      "Created 51 segments\n",
      "#####################\n",
      "\n",
      "\n",
      "#######################\n",
      "Processing label: Scary\n",
      "Created 26 segments\n",
      "#######################\n",
      "\n",
      "\n",
      "##########################\n",
      "Processing label: Surprise\n",
      "Created 10 segments\n",
      "##########################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "for label in os.listdir(music_data_raw_folder):\n",
    "    curr_size = len(data_set)\n",
    "    title = f\"Processing label: {label}\"\n",
    "    print(\"#\" * len(title))\n",
    "    print(title)\n",
    "    label_folder_path = os.path.join(music_data_raw_folder, label)\n",
    "    for audio_file in os.listdir(label_folder_path):\n",
    "        audio_file_path = os.path.join(label_folder_path, audio_file)\n",
    "        waveform, orig_sample_rate = librosa.load(audio_file_path)\n",
    "        waveform = torch.tensor(waveform)\n",
    "        if SR != orig_sample_rate:\n",
    "            waveform = torchaudio.transforms.Resample(orig_sample_rate, SR)(waveform)\n",
    "        segment_length = 10 * SR\n",
    "        batches = waveform.split(segment_length)\n",
    "        for batch_seg in batches:\n",
    "            if len(batch_seg) < segment_length:\n",
    "                continue\n",
    "            data_set.append((batch_seg.numpy().astype(np.float32),SR,label,audio_file_path))\n",
    "    print(f\"Created {len(data_set) - curr_size} segments\")\n",
    "    print(\"#\" * len(title)  + \"\\n\\n\")\n",
    "\n",
    "torch.save(data_set, os.path.join(save_folder, f\"music_dataset_{os.path.basename(music_data_raw_folder)}_size{len(data_set)}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "Processing label: Angry\n",
      "Created 1131 segments\n",
      "#######################\n",
      "\n",
      "\n",
      "#####################\n",
      "Processing label: Joy\n",
      "Created 1662 segments\n",
      "#####################\n",
      "\n",
      "\n",
      "######################\n",
      "Processing label: Love\n",
      "Created 1939 segments\n",
      "######################\n",
      "\n",
      "\n",
      "#####################\n",
      "Processing label: Sad\n",
      "Created 1233 segments\n",
      "#####################\n",
      "\n",
      "\n",
      "#######################\n",
      "Processing label: Scary\n",
      "Created 1231 segments\n",
      "#######################\n",
      "\n",
      "\n",
      "##########################\n",
      "Processing label: Surprise\n",
      "Created 360 segments\n",
      "##########################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "output_folder = r\"_Data/Music/train_segments\"\n",
    "for label in os.listdir(music_data_raw_folder):\n",
    "    num_segments = 0\n",
    "    title = f\"Processing label: {label}\"\n",
    "    print(\"#\" * len(title))\n",
    "    print(title)\n",
    "    label_folder_path = os.path.join(music_data_raw_folder, label)\n",
    "    output_label_folder = os.path.join(output_folder, label)\n",
    "    for audio_file in os.listdir(label_folder_path):\n",
    "        audio_file_path = os.path.join(label_folder_path, audio_file)\n",
    "        waveform, orig_sample_rate = librosa.load(audio_file_path)\n",
    "        waveform = torch.tensor(waveform)\n",
    "        if SR != orig_sample_rate:\n",
    "            waveform = torchaudio.transforms.Resample(orig_sample_rate, SR)(waveform)\n",
    "        segment_length = 10 * SR\n",
    "        batches = waveform.split(segment_length)\n",
    "\n",
    "        for i,batch_seg in enumerate(batches):\n",
    "            if len(batch_seg) < segment_length:\n",
    "                continue\n",
    "            segment_name = os.path.join(output_label_folder,f\"{audio_file.split('.')[0]}_{i}.wav\")\n",
    "            os.makedirs(output_label_folder, exist_ok=True)\n",
    "            sf.write(segment_name, batch_seg.numpy().astype(np.float32), SR)\n",
    "        num_segments+=i+1\n",
    "    print(f\"Created {num_segments} segments\")\n",
    "    print(\"#\" * len(title)  + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tsv = list()\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\amitmils\\Documents\\Repo\\Text2BGAudio\\_Data\\Music\\train_segments\"):\n",
    "    for file in files:\n",
    "        data_tsv.append(\n",
    "            {\n",
    "                \"name\": file.split(\".\")[0],\n",
    "                \"dataset\": \"MoodAudio\",\n",
    "                \"caption\": os.path.basename(root).lower(),\n",
    "                \"audio_path\": os.path.join(\"/content/drive/MyDrive/Colab Notebooks/AmitM/Make-An-Audio/data\",root.split('Music\\\\')[-1], file).replace('\\\\','/'),\n",
    "            }\n",
    "        )\n",
    "random.shuffle(data_tsv)\n",
    "df = pd.DataFrame(data_tsv)\n",
    "df.to_csv(r\"C:\\Users\\amitmils\\Documents\\Repo\\Text2BGAudio\\_Data\\Music\\train_segments.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
