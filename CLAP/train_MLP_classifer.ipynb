{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "working_dir = os.path.join(os.getcwd().split(\"Text2BGAudio\")[0],'Text2BGAudio')\n",
    "sys.path.append(working_dir)\n",
    "os.chdir(working_dir)\n",
    "from datasets import load_dataset\n",
    "from transformers import ClapModel, ClapProcessor\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter,defaultdict\n",
    "from tqdm import tqdm\n",
    "from Dataset_Creation import audio_dataset\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(DEVICE))\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Device Name: CPU\")\n",
    "\n",
    "CLAP_ARCH = \"laion/larger_clap_music\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"_Data\\Music\\Music Data New\\music_dataset_fixed_Music Data New_tr3141_val390_te398.pt\"\n",
    "clap_model_path = r\"CLAP\\models\\new_fixed\\clap_fine_tunned_Fixeed_BatchSize_32_LR_1e-05_Epochs_400_VAL_LOSS_26.47.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddedDataset(Dataset):\n",
    "    def __init__(self, embedded_data):\n",
    "        self.embedded_data = embedded_data\n",
    "    def __len__(self):\n",
    "        return len(self.embedded_data)\n",
    "    def __getitem__(self, idx):\n",
    "        x,y= self.embedded_data[idx]\n",
    "        return x,y\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "class MLPHead(torch.nn.Module):\n",
    "    def __init__(self, input_dim=512, output_dim=6, hidden_dim=256):\n",
    "        super(MLPHead, self).__init__()\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, output_dim),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "label_to_index  = {'anger' : 0, 'joy' : 1, 'love' : 2, 'sadness' : 3, 'fear' : 4, 'surprise' : 5}\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedded_ds_v2(dataset,clap_model,processor):\n",
    "    embedded_data = list()\n",
    "    with torch.no_grad():\n",
    "        data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        for batch in tqdm(data_loader,desc=\"Batches\"):\n",
    "            audio = batch[0]\n",
    "            labels = list(batch[1])\n",
    "            unique_labels = list(set(labels))\n",
    "            inputs = processor(\n",
    "                text=unique_labels,\n",
    "                audios=audio.numpy(),\n",
    "                return_tensors=\"pt\",\n",
    "                sampling_rate=48000,\n",
    "                padding=True,\n",
    "            )\n",
    "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "            outputs = clap_model(**inputs)\n",
    "            audio_embeds = outputs.audio_embeds\n",
    "            embedded_data.extend([(audio_embed.cpu().detach(), label_to_index[label]) for audio_embed, label in zip(audio_embeds, labels)])\n",
    "    return EmbeddedDataset(embedded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = list(torch.load(data_path, weights_only=False).values())\n",
    "train_dataset = audio_dataset.AudioDataset(train_data)\n",
    "val_dataset = audio_dataset.AudioDataset(val_data)\n",
    "test_dataset = audio_dataset.AudioDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clap_model = ClapModel.from_pretrained(CLAP_ARCH).to(DEVICE)\n",
    "processor = ClapProcessor.from_pretrained(CLAP_ARCH)\n",
    "if clap_model_path is not None:\n",
    "    clap_model.load_state_dict(torch.load(clap_model_path,weights_only=False)['model_state_dict'])\n",
    "classification_head = MLPHead().to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP Head on CLAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embedded DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 99/99 [00:53<00:00,  1.85it/s]\n",
      "Batches: 100%|██████████| 13/13 [00:06<00:00,  1.95it/s]\n",
      "Batches: 100%|██████████| 13/13 [00:06<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_embedded = create_embedded_ds_v2(train_dataset,clap_model,processor)\n",
    "val_dataset_embedded = create_embedded_ds_v2(val_dataset,clap_model,processor)\n",
    "test_dataset_embedded = create_embedded_ds_v2(test_dataset,clap_model,processor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Loss: 1.7907419204711914, Train Acc : 0.16109519261381725 , Val Acc : 0.16923076923076924\n",
      "Epoch 2/10000, Loss: 1.7895835638046265, Train Acc : 0.23559375994906082 , Val Acc : 0.24102564102564103\n",
      "Epoch 3/10000, Loss: 1.7893081903457642, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 4/10000, Loss: 1.7896015644073486, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 5/10000, Loss: 1.789014220237732, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 6/10000, Loss: 1.7888131141662598, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 7/10000, Loss: 1.7889841794967651, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 8/10000, Loss: 1.7874435186386108, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 9/10000, Loss: 1.7877782583236694, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 10/10000, Loss: 1.789236307144165, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 11/10000, Loss: 1.7913787364959717, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 12/10000, Loss: 1.7860629558563232, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 13/10000, Loss: 1.7882047891616821, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 14/10000, Loss: 1.786948561668396, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 15/10000, Loss: 1.7835602760314941, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 16/10000, Loss: 1.7829610109329224, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 17/10000, Loss: 1.7896485328674316, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 18/10000, Loss: 1.7852447032928467, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 19/10000, Loss: 1.7815719842910767, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 20/10000, Loss: 1.786730170249939, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 21/10000, Loss: 1.7842779159545898, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 22/10000, Loss: 1.7826695442199707, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 23/10000, Loss: 1.7885445356369019, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 24/10000, Loss: 1.7756993770599365, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 25/10000, Loss: 1.7812788486480713, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 26/10000, Loss: 1.7828257083892822, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 27/10000, Loss: 1.787966251373291, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 28/10000, Loss: 1.7762707471847534, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 29/10000, Loss: 1.7873880863189697, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 30/10000, Loss: 1.7759038209915161, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 31/10000, Loss: 1.7810113430023193, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 32/10000, Loss: 1.7806015014648438, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 33/10000, Loss: 1.7756469249725342, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 34/10000, Loss: 1.7827588319778442, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 35/10000, Loss: 1.7768911123275757, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 36/10000, Loss: 1.7759896516799927, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 37/10000, Loss: 1.7683476209640503, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 38/10000, Loss: 1.768951416015625, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 39/10000, Loss: 1.7769545316696167, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 40/10000, Loss: 1.7819416522979736, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 41/10000, Loss: 1.7576178312301636, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 42/10000, Loss: 1.7605648040771484, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 43/10000, Loss: 1.777550220489502, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 44/10000, Loss: 1.7786539793014526, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 45/10000, Loss: 1.7748743295669556, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 46/10000, Loss: 1.7844727039337158, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 47/10000, Loss: 1.765358805656433, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 48/10000, Loss: 1.774741291999817, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 49/10000, Loss: 1.7824782133102417, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 50/10000, Loss: 1.7584295272827148, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 51/10000, Loss: 1.757714033126831, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 52/10000, Loss: 1.7746649980545044, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 53/10000, Loss: 1.762336015701294, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 54/10000, Loss: 1.7759177684783936, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 55/10000, Loss: 1.7644500732421875, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 56/10000, Loss: 1.7675071954727173, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 57/10000, Loss: 1.7752659320831299, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 58/10000, Loss: 1.7732867002487183, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 59/10000, Loss: 1.7739887237548828, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 60/10000, Loss: 1.7660973072052002, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 61/10000, Loss: 1.7497692108154297, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 62/10000, Loss: 1.7707922458648682, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 63/10000, Loss: 1.7747000455856323, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 64/10000, Loss: 1.7658659219741821, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 65/10000, Loss: 1.7728009223937988, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 66/10000, Loss: 1.7687913179397583, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 67/10000, Loss: 1.7594056129455566, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 68/10000, Loss: 1.7713596820831299, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 69/10000, Loss: 1.775916576385498, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 70/10000, Loss: 1.7729485034942627, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 71/10000, Loss: 1.776762843132019, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 72/10000, Loss: 1.7841510772705078, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 73/10000, Loss: 1.7510924339294434, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 74/10000, Loss: 1.7644509077072144, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 75/10000, Loss: 1.7457900047302246, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 76/10000, Loss: 1.759696364402771, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 77/10000, Loss: 1.795750617980957, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 78/10000, Loss: 1.766389012336731, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 79/10000, Loss: 1.770125389099121, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 80/10000, Loss: 1.751246690750122, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 81/10000, Loss: 1.7793002128601074, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 82/10000, Loss: 1.7537801265716553, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 83/10000, Loss: 1.7681546211242676, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 84/10000, Loss: 1.7642323970794678, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 85/10000, Loss: 1.7427703142166138, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 86/10000, Loss: 1.763569951057434, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 87/10000, Loss: 1.7741315364837646, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 88/10000, Loss: 1.7543364763259888, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 89/10000, Loss: 1.7761039733886719, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 90/10000, Loss: 1.746815800666809, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 91/10000, Loss: 1.7226719856262207, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 92/10000, Loss: 1.775740385055542, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 93/10000, Loss: 1.7460212707519531, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 94/10000, Loss: 1.7787854671478271, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 95/10000, Loss: 1.737830400466919, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 96/10000, Loss: 1.7626780271530151, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 97/10000, Loss: 1.7682759761810303, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 98/10000, Loss: 1.7564963102340698, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 99/10000, Loss: 1.766108512878418, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 100/10000, Loss: 1.7686659097671509, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 101/10000, Loss: 1.7489237785339355, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 102/10000, Loss: 1.7285572290420532, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 103/10000, Loss: 1.7467851638793945, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 104/10000, Loss: 1.7827775478363037, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 105/10000, Loss: 1.7487571239471436, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 106/10000, Loss: 1.745726466178894, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 107/10000, Loss: 1.752912163734436, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 108/10000, Loss: 1.7400754690170288, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 109/10000, Loss: 1.6993588209152222, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 110/10000, Loss: 1.7149940729141235, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 111/10000, Loss: 1.7258659601211548, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 112/10000, Loss: 1.7967544794082642, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 113/10000, Loss: 1.7769585847854614, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 114/10000, Loss: 1.779058575630188, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 115/10000, Loss: 1.7337753772735596, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 116/10000, Loss: 1.7628036737442017, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 117/10000, Loss: 1.7372370958328247, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 118/10000, Loss: 1.7604516744613647, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 119/10000, Loss: 1.767100214958191, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 120/10000, Loss: 1.7654038667678833, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 121/10000, Loss: 1.7572826147079468, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 122/10000, Loss: 1.7852821350097656, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 123/10000, Loss: 1.7644888162612915, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 124/10000, Loss: 1.749559760093689, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 125/10000, Loss: 1.7863370180130005, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 126/10000, Loss: 1.7827858924865723, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 127/10000, Loss: 1.7331629991531372, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 128/10000, Loss: 1.7559500932693481, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 129/10000, Loss: 1.7313709259033203, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 130/10000, Loss: 1.7278251647949219, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 131/10000, Loss: 1.772321105003357, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 132/10000, Loss: 1.800203800201416, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 133/10000, Loss: 1.7446393966674805, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 134/10000, Loss: 1.7642990350723267, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 135/10000, Loss: 1.7518644332885742, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 136/10000, Loss: 1.743808388710022, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 137/10000, Loss: 1.779162883758545, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 138/10000, Loss: 1.7826775312423706, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 139/10000, Loss: 1.7424108982086182, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 140/10000, Loss: 1.721320390701294, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 141/10000, Loss: 1.7573789358139038, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 142/10000, Loss: 1.7339661121368408, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 143/10000, Loss: 1.7375682592391968, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 144/10000, Loss: 1.7676173448562622, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 145/10000, Loss: 1.7516536712646484, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 146/10000, Loss: 1.7484021186828613, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 147/10000, Loss: 1.7587695121765137, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 148/10000, Loss: 1.7337969541549683, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 149/10000, Loss: 1.7259197235107422, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 150/10000, Loss: 1.752138614654541, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 151/10000, Loss: 1.7305893898010254, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 152/10000, Loss: 1.7822346687316895, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 153/10000, Loss: 1.7685948610305786, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 154/10000, Loss: 1.7772068977355957, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 155/10000, Loss: 1.7599318027496338, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 156/10000, Loss: 1.768545389175415, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 157/10000, Loss: 1.7470015287399292, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 158/10000, Loss: 1.782235026359558, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 159/10000, Loss: 1.7511628866195679, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 160/10000, Loss: 1.7777161598205566, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 161/10000, Loss: 1.7381361722946167, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 162/10000, Loss: 1.7643136978149414, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 163/10000, Loss: 1.7728937864303589, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 164/10000, Loss: 1.7525765895843506, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 165/10000, Loss: 1.7909095287322998, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 166/10000, Loss: 1.7595056295394897, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 167/10000, Loss: 1.7705931663513184, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 168/10000, Loss: 1.7789281606674194, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 169/10000, Loss: 1.753479242324829, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 170/10000, Loss: 1.772170066833496, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 171/10000, Loss: 1.7616328001022339, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 172/10000, Loss: 1.721845030784607, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 173/10000, Loss: 1.7376048564910889, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 174/10000, Loss: 1.7576597929000854, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 175/10000, Loss: 1.7139219045639038, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 176/10000, Loss: 1.7747472524642944, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 177/10000, Loss: 1.7711769342422485, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 178/10000, Loss: 1.767038106918335, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 179/10000, Loss: 1.763267159461975, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 180/10000, Loss: 1.7168887853622437, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 181/10000, Loss: 1.791593313217163, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 182/10000, Loss: 1.7381428480148315, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 183/10000, Loss: 1.7543022632598877, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 184/10000, Loss: 1.7610712051391602, Train Acc : 0.24036930913721744 , Val Acc : 0.24102564102564103\n",
      "Epoch 185/10000, Loss: 1.747788667678833, Train Acc : 0.24068767908309455 , Val Acc : 0.24102564102564103\n",
      "Epoch 186/10000, Loss: 1.7321420907974243, Train Acc : 0.24068767908309455 , Val Acc : 0.24102564102564103\n",
      "Epoch 187/10000, Loss: 1.719935417175293, Train Acc : 0.24068767908309455 , Val Acc : 0.24102564102564103\n",
      "Epoch 188/10000, Loss: 1.7426174879074097, Train Acc : 0.24068767908309455 , Val Acc : 0.24102564102564103\n",
      "Epoch 189/10000, Loss: 1.7668579816818237, Train Acc : 0.24068767908309455 , Val Acc : 0.24102564102564103\n",
      "Epoch 190/10000, Loss: 1.7382739782333374, Train Acc : 0.24100604902897166 , Val Acc : 0.24102564102564103\n",
      "Epoch 191/10000, Loss: 1.7629977464675903, Train Acc : 0.24164278892072588 , Val Acc : 0.24102564102564103\n",
      "Epoch 192/10000, Loss: 1.7724822759628296, Train Acc : 0.24259789875835722 , Val Acc : 0.24102564102564103\n",
      "Epoch 193/10000, Loss: 1.7544347047805786, Train Acc : 0.24323463865011144 , Val Acc : 0.24358974358974358\n",
      "Epoch 194/10000, Loss: 1.7675864696502686, Train Acc : 0.24450811843361986 , Val Acc : 0.24358974358974358\n",
      "Epoch 195/10000, Loss: 1.7735546827316284, Train Acc : 0.24514485832537408 , Val Acc : 0.24615384615384617\n",
      "Epoch 196/10000, Loss: 1.7489097118377686, Train Acc : 0.24641833810888253 , Val Acc : 0.24871794871794872\n",
      "Epoch 197/10000, Loss: 1.7429121732711792, Train Acc : 0.24705507800063675 , Val Acc : 0.24871794871794872\n",
      "Epoch 198/10000, Loss: 1.7101869583129883, Train Acc : 0.24832855778414517 , Val Acc : 0.24871794871794872\n",
      "Epoch 199/10000, Loss: 1.7508715391159058, Train Acc : 0.24960203756765362 , Val Acc : 0.24871794871794872\n",
      "Epoch 200/10000, Loss: 1.7277839183807373, Train Acc : 0.2502387774594078 , Val Acc : 0.24871794871794872\n",
      "Epoch 201/10000, Loss: 1.7474920749664307, Train Acc : 0.25151225724291626 , Val Acc : 0.24871794871794872\n",
      "Epoch 202/10000, Loss: 1.748049259185791, Train Acc : 0.2527857370264247 , Val Acc : 0.24871794871794872\n",
      "Epoch 203/10000, Loss: 1.7797629833221436, Train Acc : 0.25405921680993315 , Val Acc : 0.24871794871794872\n",
      "Epoch 204/10000, Loss: 1.7834612131118774, Train Acc : 0.2553326965934416 , Val Acc : 0.24871794871794872\n",
      "Epoch 205/10000, Loss: 1.7686946392059326, Train Acc : 0.2562878064310729 , Val Acc : 0.24871794871794872\n",
      "Epoch 206/10000, Loss: 1.7397069931030273, Train Acc : 0.2572429162687042 , Val Acc : 0.2512820512820513\n",
      "Epoch 207/10000, Loss: 1.7651230096817017, Train Acc : 0.25756128621458135 , Val Acc : 0.2564102564102564\n",
      "Epoch 208/10000, Loss: 1.7380073070526123, Train Acc : 0.25787965616045844 , Val Acc : 0.2564102564102564\n",
      "Epoch 209/10000, Loss: 1.7176636457443237, Train Acc : 0.2581980261063356 , Val Acc : 0.2564102564102564\n",
      "Epoch 210/10000, Loss: 1.7252949476242065, Train Acc : 0.25851639605221266 , Val Acc : 0.26153846153846155\n",
      "Epoch 211/10000, Loss: 1.7487434148788452, Train Acc : 0.2588347659980898 , Val Acc : 0.26153846153846155\n",
      "Epoch 212/10000, Loss: 1.740835428237915, Train Acc : 0.2588347659980898 , Val Acc : 0.2641025641025641\n",
      "Epoch 213/10000, Loss: 1.7434115409851074, Train Acc : 0.2591531359439669 , Val Acc : 0.2641025641025641\n",
      "Epoch 214/10000, Loss: 1.7624059915542603, Train Acc : 0.259471505889844 , Val Acc : 0.2641025641025641\n",
      "Epoch 215/10000, Loss: 1.7353156805038452, Train Acc : 0.2601082457815982 , Val Acc : 0.26666666666666666\n",
      "Epoch 216/10000, Loss: 1.739931344985962, Train Acc : 0.2607449856733524 , Val Acc : 0.2692307692307692\n",
      "Epoch 217/10000, Loss: 1.762647271156311, Train Acc : 0.26106335561922955 , Val Acc : 0.2692307692307692\n",
      "Epoch 218/10000, Loss: 1.7394859790802002, Train Acc : 0.2617000955109838 , Val Acc : 0.2692307692307692\n",
      "Epoch 219/10000, Loss: 1.7483837604522705, Train Acc : 0.2626552053486151 , Val Acc : 0.2692307692307692\n",
      "Epoch 220/10000, Loss: 1.7094697952270508, Train Acc : 0.26392868513212353 , Val Acc : 0.2692307692307692\n",
      "Epoch 221/10000, Loss: 1.715079665184021, Train Acc : 0.26488379496975484 , Val Acc : 0.2692307692307692\n",
      "Epoch 222/10000, Loss: 1.7741771936416626, Train Acc : 0.26552053486150906 , Val Acc : 0.2692307692307692\n",
      "Epoch 223/10000, Loss: 1.7442437410354614, Train Acc : 0.26711238459089465 , Val Acc : 0.2692307692307692\n",
      "Epoch 224/10000, Loss: 1.728824496269226, Train Acc : 0.26806749442852595 , Val Acc : 0.2743589743589744\n",
      "Epoch 225/10000, Loss: 1.752442479133606, Train Acc : 0.2696593441579115 , Val Acc : 0.27692307692307694\n",
      "Epoch 226/10000, Loss: 1.749011754989624, Train Acc : 0.2699777141037886 , Val Acc : 0.27692307692307694\n",
      "Epoch 227/10000, Loss: 1.7503547668457031, Train Acc : 0.271251193887297 , Val Acc : 0.2794871794871795\n",
      "Epoch 228/10000, Loss: 1.7722008228302002, Train Acc : 0.271251193887297 , Val Acc : 0.2794871794871795\n",
      "Epoch 229/10000, Loss: 1.7389944791793823, Train Acc : 0.2734797835084368 , Val Acc : 0.2794871794871795\n",
      "Epoch 230/10000, Loss: 1.7205551862716675, Train Acc : 0.2737981534543139 , Val Acc : 0.2794871794871795\n",
      "Epoch 231/10000, Loss: 1.7219645977020264, Train Acc : 0.27443489334606813 , Val Acc : 0.28205128205128205\n",
      "Epoch 232/10000, Loss: 1.7587777376174927, Train Acc : 0.27507163323782235 , Val Acc : 0.28205128205128205\n",
      "Epoch 233/10000, Loss: 1.7106435298919678, Train Acc : 0.27539000318369944 , Val Acc : 0.28205128205128205\n",
      "Epoch 234/10000, Loss: 1.7543336153030396, Train Acc : 0.2757083731295766 , Val Acc : 0.28205128205128205\n",
      "Epoch 235/10000, Loss: 1.733391523361206, Train Acc : 0.2763451130213308 , Val Acc : 0.28205128205128205\n",
      "Epoch 236/10000, Loss: 1.73900306224823, Train Acc : 0.2766634829672079 , Val Acc : 0.28205128205128205\n",
      "Epoch 237/10000, Loss: 1.7384254932403564, Train Acc : 0.27793696275071633 , Val Acc : 0.28205128205128205\n",
      "Epoch 238/10000, Loss: 1.7637110948562622, Train Acc : 0.27857370264247056 , Val Acc : 0.28205128205128205\n",
      "Epoch 239/10000, Loss: 1.7950385808944702, Train Acc : 0.2792104425342248 , Val Acc : 0.2846153846153846\n",
      "Epoch 240/10000, Loss: 1.7521941661834717, Train Acc : 0.2804839223177332 , Val Acc : 0.28717948717948716\n",
      "Epoch 241/10000, Loss: 1.7015998363494873, Train Acc : 0.28112066220948745 , Val Acc : 0.28717948717948716\n",
      "Epoch 242/10000, Loss: 1.704611897468567, Train Acc : 0.2817574021012416 , Val Acc : 0.28717948717948716\n",
      "Epoch 243/10000, Loss: 1.751037359237671, Train Acc : 0.282712511938873 , Val Acc : 0.28717948717948716\n",
      "Epoch 244/10000, Loss: 1.7213917970657349, Train Acc : 0.282712511938873 , Val Acc : 0.28717948717948716\n",
      "Epoch 245/10000, Loss: 1.7537600994110107, Train Acc : 0.282712511938873 , Val Acc : 0.28974358974358977\n",
      "Epoch 246/10000, Loss: 1.7002302408218384, Train Acc : 0.2833492518306272 , Val Acc : 0.28974358974358977\n",
      "Epoch 247/10000, Loss: 1.7351596355438232, Train Acc : 0.2843043616682585 , Val Acc : 0.28974358974358977\n",
      "Epoch 248/10000, Loss: 1.7737783193588257, Train Acc : 0.2843043616682585 , Val Acc : 0.28974358974358977\n",
      "Epoch 249/10000, Loss: 1.7251672744750977, Train Acc : 0.28494110156001273 , Val Acc : 0.28974358974358977\n",
      "Epoch 250/10000, Loss: 1.7702369689941406, Train Acc : 0.28494110156001273 , Val Acc : 0.28974358974358977\n",
      "Epoch 251/10000, Loss: 1.7449676990509033, Train Acc : 0.2852594715058898 , Val Acc : 0.28974358974358977\n",
      "Epoch 252/10000, Loss: 1.7052873373031616, Train Acc : 0.2862145813435212 , Val Acc : 0.28974358974358977\n",
      "Epoch 253/10000, Loss: 1.7688041925430298, Train Acc : 0.2871696911811525 , Val Acc : 0.2923076923076923\n",
      "Epoch 254/10000, Loss: 1.7281768321990967, Train Acc : 0.2874880611270296 , Val Acc : 0.2923076923076923\n",
      "Epoch 255/10000, Loss: 1.7939246892929077, Train Acc : 0.2874880611270296 , Val Acc : 0.2923076923076923\n",
      "Epoch 256/10000, Loss: 1.7386163473129272, Train Acc : 0.2874880611270296 , Val Acc : 0.2923076923076923\n",
      "Epoch 257/10000, Loss: 1.7065485715866089, Train Acc : 0.2878064310729067 , Val Acc : 0.2923076923076923\n",
      "Epoch 258/10000, Loss: 1.745764136314392, Train Acc : 0.28812480101878385 , Val Acc : 0.2923076923076923\n",
      "Epoch 259/10000, Loss: 1.7552359104156494, Train Acc : 0.28812480101878385 , Val Acc : 0.2948717948717949\n",
      "Epoch 260/10000, Loss: 1.7303667068481445, Train Acc : 0.2887615409105381 , Val Acc : 0.2948717948717949\n",
      "Epoch 261/10000, Loss: 1.7374404668807983, Train Acc : 0.28907991085641516 , Val Acc : 0.2948717948717949\n",
      "Epoch 262/10000, Loss: 1.6941945552825928, Train Acc : 0.28907991085641516 , Val Acc : 0.2948717948717949\n",
      "Epoch 263/10000, Loss: 1.7094489336013794, Train Acc : 0.28907991085641516 , Val Acc : 0.2948717948717949\n",
      "Epoch 264/10000, Loss: 1.6972250938415527, Train Acc : 0.28939828080229224 , Val Acc : 0.2948717948717949\n",
      "Epoch 265/10000, Loss: 1.728850245475769, Train Acc : 0.2897166507481694 , Val Acc : 0.2948717948717949\n",
      "Epoch 266/10000, Loss: 1.7270933389663696, Train Acc : 0.2903533906399236 , Val Acc : 0.29743589743589743\n",
      "Epoch 267/10000, Loss: 1.715333342552185, Train Acc : 0.2913085004775549 , Val Acc : 0.29743589743589743\n",
      "Epoch 268/10000, Loss: 1.7607842683792114, Train Acc : 0.29162687042343205 , Val Acc : 0.29743589743589743\n",
      "Epoch 269/10000, Loss: 1.7453986406326294, Train Acc : 0.29162687042343205 , Val Acc : 0.3\n",
      "Epoch 270/10000, Loss: 1.7447272539138794, Train Acc : 0.2913085004775549 , Val Acc : 0.3\n",
      "Epoch 271/10000, Loss: 1.7496458292007446, Train Acc : 0.29194524036930913 , Val Acc : 0.3\n",
      "Epoch 272/10000, Loss: 1.681931495666504, Train Acc : 0.2922636103151863 , Val Acc : 0.3\n",
      "Epoch 273/10000, Loss: 1.6946723461151123, Train Acc : 0.29290035020694044 , Val Acc : 0.3\n",
      "Epoch 274/10000, Loss: 1.7456690073013306, Train Acc : 0.29290035020694044 , Val Acc : 0.3\n",
      "Epoch 275/10000, Loss: 1.7879678010940552, Train Acc : 0.2932187201528176 , Val Acc : 0.3\n",
      "Epoch 276/10000, Loss: 1.7228888273239136, Train Acc : 0.29290035020694044 , Val Acc : 0.30256410256410254\n",
      "Epoch 277/10000, Loss: 1.740757703781128, Train Acc : 0.2932187201528176 , Val Acc : 0.30256410256410254\n",
      "Epoch 278/10000, Loss: 1.749096393585205, Train Acc : 0.2938554600445718 , Val Acc : 0.30256410256410254\n",
      "Epoch 279/10000, Loss: 1.7538325786590576, Train Acc : 0.2938554600445718 , Val Acc : 0.30256410256410254\n",
      "Epoch 280/10000, Loss: 1.7066813707351685, Train Acc : 0.2938554600445718 , Val Acc : 0.30256410256410254\n",
      "Epoch 281/10000, Loss: 1.7123335599899292, Train Acc : 0.2938554600445718 , Val Acc : 0.30256410256410254\n",
      "Epoch 282/10000, Loss: 1.7677052021026611, Train Acc : 0.2938554600445718 , Val Acc : 0.30256410256410254\n",
      "Epoch 283/10000, Loss: 1.7057958841323853, Train Acc : 0.294492199936326 , Val Acc : 0.30256410256410254\n",
      "Epoch 284/10000, Loss: 1.737521767616272, Train Acc : 0.294492199936326 , Val Acc : 0.30256410256410254\n",
      "Epoch 285/10000, Loss: 1.7334048748016357, Train Acc : 0.2948105698822031 , Val Acc : 0.30256410256410254\n",
      "Epoch 286/10000, Loss: 1.6915451288223267, Train Acc : 0.2948105698822031 , Val Acc : 0.30256410256410254\n",
      "Epoch 287/10000, Loss: 1.7268089056015015, Train Acc : 0.2948105698822031 , Val Acc : 0.30256410256410254\n",
      "Epoch 288/10000, Loss: 1.728783369064331, Train Acc : 0.2948105698822031 , Val Acc : 0.30256410256410254\n",
      "Epoch 289/10000, Loss: 1.721206545829773, Train Acc : 0.29512893982808025 , Val Acc : 0.30256410256410254\n",
      "Epoch 290/10000, Loss: 1.7261617183685303, Train Acc : 0.29512893982808025 , Val Acc : 0.30256410256410254\n",
      "Epoch 291/10000, Loss: 1.6510227918624878, Train Acc : 0.29512893982808025 , Val Acc : 0.30256410256410254\n",
      "Epoch 292/10000, Loss: 1.7578208446502686, Train Acc : 0.29544730977395733 , Val Acc : 0.30256410256410254\n",
      "Epoch 293/10000, Loss: 1.702666163444519, Train Acc : 0.29544730977395733 , Val Acc : 0.30256410256410254\n",
      "Epoch 294/10000, Loss: 1.7496169805526733, Train Acc : 0.29544730977395733 , Val Acc : 0.30256410256410254\n",
      "Epoch 295/10000, Loss: 1.7073135375976562, Train Acc : 0.29544730977395733 , Val Acc : 0.30256410256410254\n",
      "Epoch 296/10000, Loss: 1.6825000047683716, Train Acc : 0.2957656797198345 , Val Acc : 0.30256410256410254\n",
      "Epoch 297/10000, Loss: 1.7300920486450195, Train Acc : 0.2957656797198345 , Val Acc : 0.30256410256410254\n",
      "Epoch 298/10000, Loss: 1.6865477561950684, Train Acc : 0.2957656797198345 , Val Acc : 0.30256410256410254\n",
      "Epoch 299/10000, Loss: 1.7231172323226929, Train Acc : 0.2957656797198345 , Val Acc : 0.30256410256410254\n",
      "Epoch 300/10000, Loss: 1.7130087614059448, Train Acc : 0.2957656797198345 , Val Acc : 0.30256410256410254\n",
      "Epoch 301/10000, Loss: 1.6871587038040161, Train Acc : 0.29608404966571156 , Val Acc : 0.30256410256410254\n",
      "Epoch 302/10000, Loss: 1.6818876266479492, Train Acc : 0.29640241961158864 , Val Acc : 0.30256410256410254\n",
      "Epoch 303/10000, Loss: 1.6986039876937866, Train Acc : 0.29640241961158864 , Val Acc : 0.30256410256410254\n",
      "Epoch 304/10000, Loss: 1.705487847328186, Train Acc : 0.2967207895574658 , Val Acc : 0.30256410256410254\n",
      "Epoch 305/10000, Loss: 1.7308003902435303, Train Acc : 0.2967207895574658 , Val Acc : 0.30256410256410254\n",
      "Epoch 306/10000, Loss: 1.7555313110351562, Train Acc : 0.2967207895574658 , Val Acc : 0.30256410256410254\n",
      "Epoch 307/10000, Loss: 1.7408910989761353, Train Acc : 0.29735752944922 , Val Acc : 0.30256410256410254\n",
      "Epoch 308/10000, Loss: 1.7476222515106201, Train Acc : 0.2976758993950971 , Val Acc : 0.30256410256410254\n",
      "Epoch 309/10000, Loss: 1.70420503616333, Train Acc : 0.2976758993950971 , Val Acc : 0.30256410256410254\n",
      "Epoch 310/10000, Loss: 1.7122617959976196, Train Acc : 0.2976758993950971 , Val Acc : 0.30256410256410254\n",
      "Epoch 311/10000, Loss: 1.755326271057129, Train Acc : 0.2979942693409742 , Val Acc : 0.30256410256410254\n",
      "Epoch 312/10000, Loss: 1.7163736820220947, Train Acc : 0.2979942693409742 , Val Acc : 0.30512820512820515\n",
      "Epoch 313/10000, Loss: 1.737159252166748, Train Acc : 0.2979942693409742 , Val Acc : 0.30512820512820515\n",
      "Epoch 314/10000, Loss: 1.7659555673599243, Train Acc : 0.2979942693409742 , Val Acc : 0.30512820512820515\n",
      "Epoch 315/10000, Loss: 1.738574504852295, Train Acc : 0.2979942693409742 , Val Acc : 0.30512820512820515\n",
      "Epoch 316/10000, Loss: 1.6982309818267822, Train Acc : 0.2983126392868513 , Val Acc : 0.30512820512820515\n",
      "Epoch 317/10000, Loss: 1.7747471332550049, Train Acc : 0.29863100923272845 , Val Acc : 0.30512820512820515\n",
      "Epoch 318/10000, Loss: 1.7116209268569946, Train Acc : 0.29863100923272845 , Val Acc : 0.30512820512820515\n",
      "Epoch 319/10000, Loss: 1.6842457056045532, Train Acc : 0.29894937917860553 , Val Acc : 0.30512820512820515\n",
      "Epoch 320/10000, Loss: 1.7493361234664917, Train Acc : 0.29894937917860553 , Val Acc : 0.30512820512820515\n",
      "Epoch 321/10000, Loss: 1.752112865447998, Train Acc : 0.29894937917860553 , Val Acc : 0.30512820512820515\n",
      "Epoch 322/10000, Loss: 1.720102310180664, Train Acc : 0.29894937917860553 , Val Acc : 0.30512820512820515\n",
      "Epoch 323/10000, Loss: 1.7118607759475708, Train Acc : 0.29894937917860553 , Val Acc : 0.30512820512820515\n",
      "Epoch 324/10000, Loss: 1.6458874940872192, Train Acc : 0.2992677491244827 , Val Acc : 0.3076923076923077\n",
      "Epoch 325/10000, Loss: 1.745814561843872, Train Acc : 0.2992677491244827 , Val Acc : 0.3076923076923077\n",
      "Epoch 326/10000, Loss: 1.6940134763717651, Train Acc : 0.2992677491244827 , Val Acc : 0.3076923076923077\n",
      "Epoch 327/10000, Loss: 1.7469017505645752, Train Acc : 0.29958611907035976 , Val Acc : 0.3076923076923077\n",
      "Epoch 328/10000, Loss: 1.7118666172027588, Train Acc : 0.29990448901623684 , Val Acc : 0.31025641025641026\n",
      "Epoch 329/10000, Loss: 1.6935514211654663, Train Acc : 0.300222858962114 , Val Acc : 0.31025641025641026\n",
      "Epoch 330/10000, Loss: 1.7216261625289917, Train Acc : 0.300222858962114 , Val Acc : 0.31025641025641026\n",
      "Epoch 331/10000, Loss: 1.731092095375061, Train Acc : 0.300222858962114 , Val Acc : 0.31025641025641026\n",
      "Epoch 332/10000, Loss: 1.6820158958435059, Train Acc : 0.300222858962114 , Val Acc : 0.31025641025641026\n",
      "Epoch 333/10000, Loss: 1.7224810123443604, Train Acc : 0.3008595988538682 , Val Acc : 0.3128205128205128\n",
      "Epoch 334/10000, Loss: 1.709887981414795, Train Acc : 0.3011779687997453 , Val Acc : 0.3128205128205128\n",
      "Epoch 335/10000, Loss: 1.7269484996795654, Train Acc : 0.3014963387456224 , Val Acc : 0.3128205128205128\n",
      "Epoch 336/10000, Loss: 1.7039419412612915, Train Acc : 0.3014963387456224 , Val Acc : 0.3128205128205128\n",
      "Epoch 337/10000, Loss: 1.7099087238311768, Train Acc : 0.3014963387456224 , Val Acc : 0.3128205128205128\n",
      "Epoch 338/10000, Loss: 1.6933249235153198, Train Acc : 0.3018147086914995 , Val Acc : 0.3128205128205128\n",
      "Epoch 339/10000, Loss: 1.6634355783462524, Train Acc : 0.3018147086914995 , Val Acc : 0.3128205128205128\n",
      "Epoch 340/10000, Loss: 1.7672207355499268, Train Acc : 0.3018147086914995 , Val Acc : 0.3128205128205128\n",
      "Epoch 341/10000, Loss: 1.7236778736114502, Train Acc : 0.30213307863737665 , Val Acc : 0.3128205128205128\n",
      "Epoch 342/10000, Loss: 1.6939996480941772, Train Acc : 0.3018147086914995 , Val Acc : 0.3128205128205128\n",
      "Epoch 343/10000, Loss: 1.7259209156036377, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 344/10000, Loss: 1.7446529865264893, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 345/10000, Loss: 1.7068926095962524, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 346/10000, Loss: 1.7611116170883179, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 347/10000, Loss: 1.6861518621444702, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 348/10000, Loss: 1.6745145320892334, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 349/10000, Loss: 1.7312393188476562, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 350/10000, Loss: 1.6731759309768677, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 351/10000, Loss: 1.6923054456710815, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 352/10000, Loss: 1.6758977174758911, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 353/10000, Loss: 1.7485198974609375, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 354/10000, Loss: 1.7584457397460938, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 355/10000, Loss: 1.7588963508605957, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 356/10000, Loss: 1.6939353942871094, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 357/10000, Loss: 1.7498204708099365, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 358/10000, Loss: 1.6984264850616455, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 359/10000, Loss: 1.7374180555343628, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 360/10000, Loss: 1.7031282186508179, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 361/10000, Loss: 1.7297325134277344, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 362/10000, Loss: 1.7385523319244385, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 363/10000, Loss: 1.7059203386306763, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 364/10000, Loss: 1.707404613494873, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 365/10000, Loss: 1.7042704820632935, Train Acc : 0.3018147086914995 , Val Acc : 0.3153846153846154\n",
      "Epoch 366/10000, Loss: 1.7225052118301392, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 367/10000, Loss: 1.7187085151672363, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 368/10000, Loss: 1.6438031196594238, Train Acc : 0.30213307863737665 , Val Acc : 0.3153846153846154\n",
      "Epoch 369/10000, Loss: 1.759944200515747, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 370/10000, Loss: 1.7084345817565918, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 371/10000, Loss: 1.7483735084533691, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 372/10000, Loss: 1.7257764339447021, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 373/10000, Loss: 1.6868782043457031, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 374/10000, Loss: 1.7383872270584106, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 375/10000, Loss: 1.7355955839157104, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 376/10000, Loss: 1.6908012628555298, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 377/10000, Loss: 1.689151406288147, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 378/10000, Loss: 1.7273283004760742, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 379/10000, Loss: 1.6686385869979858, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 380/10000, Loss: 1.6968594789505005, Train Acc : 0.3027698185291309 , Val Acc : 0.3153846153846154\n",
      "Epoch 381/10000, Loss: 1.7662092447280884, Train Acc : 0.30245144858325373 , Val Acc : 0.3153846153846154\n",
      "Epoch 382/10000, Loss: 1.6812777519226074, Train Acc : 0.3027698185291309 , Val Acc : 0.3153846153846154\n",
      "Epoch 383/10000, Loss: 1.6997170448303223, Train Acc : 0.3027698185291309 , Val Acc : 0.3153846153846154\n",
      "Epoch 384/10000, Loss: 1.7257773876190186, Train Acc : 0.3027698185291309 , Val Acc : 0.3153846153846154\n",
      "Epoch 385/10000, Loss: 1.7116752862930298, Train Acc : 0.3027698185291309 , Val Acc : 0.3153846153846154\n",
      "Epoch 386/10000, Loss: 1.7187868356704712, Train Acc : 0.30308818847500796 , Val Acc : 0.3153846153846154\n",
      "Epoch 387/10000, Loss: 1.6878342628479004, Train Acc : 0.30404329831263927 , Val Acc : 0.3153846153846154\n",
      "Epoch 388/10000, Loss: 1.7094906568527222, Train Acc : 0.30340655842088504 , Val Acc : 0.3153846153846154\n",
      "Epoch 389/10000, Loss: 1.6871426105499268, Train Acc : 0.3037249283667622 , Val Acc : 0.3153846153846154\n",
      "Epoch 390/10000, Loss: 1.6735825538635254, Train Acc : 0.30340655842088504 , Val Acc : 0.3153846153846154\n",
      "Epoch 391/10000, Loss: 1.7610410451889038, Train Acc : 0.30404329831263927 , Val Acc : 0.3153846153846154\n",
      "Epoch 392/10000, Loss: 1.690020203590393, Train Acc : 0.30404329831263927 , Val Acc : 0.3153846153846154\n",
      "Epoch 393/10000, Loss: 1.7392926216125488, Train Acc : 0.3037249283667622 , Val Acc : 0.3153846153846154\n",
      "Epoch 394/10000, Loss: 1.726154088973999, Train Acc : 0.30404329831263927 , Val Acc : 0.3153846153846154\n",
      "Epoch 395/10000, Loss: 1.7511558532714844, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 396/10000, Loss: 1.7422999143600464, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 397/10000, Loss: 1.7358993291854858, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 398/10000, Loss: 1.727403998374939, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 399/10000, Loss: 1.7136622667312622, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 400/10000, Loss: 1.7256073951721191, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 401/10000, Loss: 1.7543599605560303, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 402/10000, Loss: 1.7141692638397217, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 403/10000, Loss: 1.6920982599258423, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 404/10000, Loss: 1.6937183141708374, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 405/10000, Loss: 1.7183117866516113, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 406/10000, Loss: 1.6821647882461548, Train Acc : 0.3043616682585164 , Val Acc : 0.3153846153846154\n",
      "Epoch 407/10000, Loss: 1.7411437034606934, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 408/10000, Loss: 1.6730849742889404, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 409/10000, Loss: 1.7229920625686646, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 410/10000, Loss: 1.702860713005066, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 411/10000, Loss: 1.6828694343566895, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 412/10000, Loss: 1.6904857158660889, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 413/10000, Loss: 1.7122290134429932, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 414/10000, Loss: 1.70448899269104, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 415/10000, Loss: 1.7564722299575806, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 416/10000, Loss: 1.7028594017028809, Train Acc : 0.3046800382043935 , Val Acc : 0.31794871794871793\n",
      "Epoch 417/10000, Loss: 1.6752296686172485, Train Acc : 0.3046800382043935 , Val Acc : 0.31794871794871793\n",
      "Epoch 418/10000, Loss: 1.749538779258728, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 419/10000, Loss: 1.7006375789642334, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 420/10000, Loss: 1.6937402486801147, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 421/10000, Loss: 1.7458561658859253, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 422/10000, Loss: 1.7204267978668213, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 423/10000, Loss: 1.6899477243423462, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 424/10000, Loss: 1.6952261924743652, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 425/10000, Loss: 1.7216819524765015, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 426/10000, Loss: 1.7274881601333618, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 427/10000, Loss: 1.7082712650299072, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 428/10000, Loss: 1.643491506576538, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 429/10000, Loss: 1.7295643091201782, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 430/10000, Loss: 1.685546636581421, Train Acc : 0.3046800382043935 , Val Acc : 0.31794871794871793\n",
      "Epoch 431/10000, Loss: 1.7634466886520386, Train Acc : 0.3043616682585164 , Val Acc : 0.31794871794871793\n",
      "Epoch 432/10000, Loss: 1.714219093322754, Train Acc : 0.3046800382043935 , Val Acc : 0.31794871794871793\n",
      "Epoch 433/10000, Loss: 1.683976173400879, Train Acc : 0.30499840815027063 , Val Acc : 0.31794871794871793\n",
      "Epoch 434/10000, Loss: 1.68215012550354, Train Acc : 0.30499840815027063 , Val Acc : 0.31794871794871793\n",
      "Epoch 435/10000, Loss: 1.724669337272644, Train Acc : 0.3053167780961477 , Val Acc : 0.31794871794871793\n",
      "Epoch 436/10000, Loss: 1.7670866250991821, Train Acc : 0.3053167780961477 , Val Acc : 0.32051282051282054\n",
      "Epoch 437/10000, Loss: 1.7344932556152344, Train Acc : 0.3053167780961477 , Val Acc : 0.31794871794871793\n",
      "Epoch 438/10000, Loss: 1.728893518447876, Train Acc : 0.3053167780961477 , Val Acc : 0.32051282051282054\n",
      "Epoch 439/10000, Loss: 1.655699372291565, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 440/10000, Loss: 1.7377080917358398, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 441/10000, Loss: 1.6867256164550781, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 442/10000, Loss: 1.7813392877578735, Train Acc : 0.3053167780961477 , Val Acc : 0.32051282051282054\n",
      "Epoch 443/10000, Loss: 1.7122563123703003, Train Acc : 0.3053167780961477 , Val Acc : 0.32051282051282054\n",
      "Epoch 444/10000, Loss: 1.7312405109405518, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 445/10000, Loss: 1.7158809900283813, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 446/10000, Loss: 1.7604080438613892, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 447/10000, Loss: 1.7320395708084106, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 448/10000, Loss: 1.7382198572158813, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 449/10000, Loss: 1.744935154914856, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 450/10000, Loss: 1.7105342149734497, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 451/10000, Loss: 1.6600005626678467, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 452/10000, Loss: 1.666650414466858, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 453/10000, Loss: 1.6864324808120728, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 454/10000, Loss: 1.6865603923797607, Train Acc : 0.30563514804202485 , Val Acc : 0.32051282051282054\n",
      "Epoch 455/10000, Loss: 1.8232628107070923, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 456/10000, Loss: 1.730940818786621, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 457/10000, Loss: 1.695114254951477, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 458/10000, Loss: 1.6705107688903809, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 459/10000, Loss: 1.704116702079773, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 460/10000, Loss: 1.7293678522109985, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 461/10000, Loss: 1.657859444618225, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 462/10000, Loss: 1.6881023645401, Train Acc : 0.30595351798790194 , Val Acc : 0.32051282051282054\n",
      "Epoch 463/10000, Loss: 1.733211636543274, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 464/10000, Loss: 1.755746841430664, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 465/10000, Loss: 1.7223775386810303, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 466/10000, Loss: 1.6885470151901245, Train Acc : 0.30659025787965616 , Val Acc : 0.32051282051282054\n",
      "Epoch 467/10000, Loss: 1.6859452724456787, Train Acc : 0.30659025787965616 , Val Acc : 0.32051282051282054\n",
      "Epoch 468/10000, Loss: 1.687964677810669, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 469/10000, Loss: 1.7243163585662842, Train Acc : 0.30659025787965616 , Val Acc : 0.32051282051282054\n",
      "Epoch 470/10000, Loss: 1.7549662590026855, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 471/10000, Loss: 1.6944600343704224, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 472/10000, Loss: 1.7344781160354614, Train Acc : 0.30659025787965616 , Val Acc : 0.32051282051282054\n",
      "Epoch 473/10000, Loss: 1.6712355613708496, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 474/10000, Loss: 1.7003803253173828, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 475/10000, Loss: 1.7086950540542603, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 476/10000, Loss: 1.6891562938690186, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 477/10000, Loss: 1.7127223014831543, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 478/10000, Loss: 1.7023227214813232, Train Acc : 0.30659025787965616 , Val Acc : 0.32051282051282054\n",
      "Epoch 479/10000, Loss: 1.6708533763885498, Train Acc : 0.30659025787965616 , Val Acc : 0.32051282051282054\n",
      "Epoch 480/10000, Loss: 1.7621418237686157, Train Acc : 0.30659025787965616 , Val Acc : 0.32051282051282054\n",
      "Epoch 481/10000, Loss: 1.733720302581787, Train Acc : 0.30659025787965616 , Val Acc : 0.32051282051282054\n",
      "Epoch 482/10000, Loss: 1.6708166599273682, Train Acc : 0.30659025787965616 , Val Acc : 0.32051282051282054\n",
      "Epoch 483/10000, Loss: 1.7368125915527344, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 484/10000, Loss: 1.7147598266601562, Train Acc : 0.3062718879337791 , Val Acc : 0.32051282051282054\n",
      "Epoch 485/10000, Loss: 1.6165151596069336, Train Acc : 0.30690862782553324 , Val Acc : 0.32051282051282054\n",
      "Epoch 486/10000, Loss: 1.6496821641921997, Train Acc : 0.30690862782553324 , Val Acc : 0.32051282051282054\n",
      "Epoch 487/10000, Loss: 1.692012071609497, Train Acc : 0.30690862782553324 , Val Acc : 0.32051282051282054\n",
      "Epoch 488/10000, Loss: 1.6856575012207031, Train Acc : 0.3072269977714104 , Val Acc : 0.32051282051282054\n",
      "Epoch 489/10000, Loss: 1.717139482498169, Train Acc : 0.3072269977714104 , Val Acc : 0.32051282051282054\n",
      "Epoch 490/10000, Loss: 1.687347173690796, Train Acc : 0.30754536771728747 , Val Acc : 0.32051282051282054\n",
      "Epoch 491/10000, Loss: 1.7068990468978882, Train Acc : 0.3072269977714104 , Val Acc : 0.32051282051282054\n",
      "Epoch 492/10000, Loss: 1.736020565032959, Train Acc : 0.3072269977714104 , Val Acc : 0.3230769230769231\n",
      "Epoch 493/10000, Loss: 1.722387433052063, Train Acc : 0.3072269977714104 , Val Acc : 0.3230769230769231\n",
      "Epoch 494/10000, Loss: 1.6693129539489746, Train Acc : 0.30754536771728747 , Val Acc : 0.3230769230769231\n",
      "Epoch 495/10000, Loss: 1.6997368335723877, Train Acc : 0.30754536771728747 , Val Acc : 0.3230769230769231\n",
      "Epoch 496/10000, Loss: 1.7125036716461182, Train Acc : 0.30754536771728747 , Val Acc : 0.3230769230769231\n",
      "Epoch 497/10000, Loss: 1.7165251970291138, Train Acc : 0.30754536771728747 , Val Acc : 0.3230769230769231\n",
      "Epoch 498/10000, Loss: 1.7006099224090576, Train Acc : 0.30754536771728747 , Val Acc : 0.3230769230769231\n",
      "Epoch 499/10000, Loss: 1.6751000881195068, Train Acc : 0.30754536771728747 , Val Acc : 0.3230769230769231\n",
      "Epoch 500/10000, Loss: 1.679992437362671, Train Acc : 0.30754536771728747 , Val Acc : 0.3230769230769231\n",
      "Epoch 501/10000, Loss: 1.7059822082519531, Train Acc : 0.3078637376631646 , Val Acc : 0.32564102564102565\n",
      "Epoch 502/10000, Loss: 1.6564966440200806, Train Acc : 0.3078637376631646 , Val Acc : 0.3230769230769231\n",
      "Epoch 503/10000, Loss: 1.7380725145339966, Train Acc : 0.3081821076090417 , Val Acc : 0.32564102564102565\n",
      "Epoch 504/10000, Loss: 1.6490898132324219, Train Acc : 0.3081821076090417 , Val Acc : 0.32564102564102565\n",
      "Epoch 505/10000, Loss: 1.722019076347351, Train Acc : 0.3078637376631646 , Val Acc : 0.32564102564102565\n",
      "Epoch 506/10000, Loss: 1.725666880607605, Train Acc : 0.3081821076090417 , Val Acc : 0.32564102564102565\n",
      "Epoch 507/10000, Loss: 1.7052085399627686, Train Acc : 0.3081821076090417 , Val Acc : 0.32564102564102565\n",
      "Epoch 508/10000, Loss: 1.709168553352356, Train Acc : 0.3081821076090417 , Val Acc : 0.32564102564102565\n",
      "Epoch 509/10000, Loss: 1.7130438089370728, Train Acc : 0.3081821076090417 , Val Acc : 0.32564102564102565\n",
      "Epoch 510/10000, Loss: 1.711419939994812, Train Acc : 0.30754536771728747 , Val Acc : 0.32564102564102565\n",
      "Epoch 511/10000, Loss: 1.689507007598877, Train Acc : 0.30850047755491883 , Val Acc : 0.32564102564102565\n",
      "Epoch 512/10000, Loss: 1.7062684297561646, Train Acc : 0.3081821076090417 , Val Acc : 0.32564102564102565\n",
      "Epoch 513/10000, Loss: 1.7156212329864502, Train Acc : 0.30850047755491883 , Val Acc : 0.32564102564102565\n",
      "Epoch 514/10000, Loss: 1.6978578567504883, Train Acc : 0.3081821076090417 , Val Acc : 0.32564102564102565\n",
      "Epoch 515/10000, Loss: 1.768270492553711, Train Acc : 0.30850047755491883 , Val Acc : 0.3282051282051282\n",
      "Epoch 516/10000, Loss: 1.7372450828552246, Train Acc : 0.30913721744667305 , Val Acc : 0.3282051282051282\n",
      "Epoch 517/10000, Loss: 1.720948338508606, Train Acc : 0.30945558739255014 , Val Acc : 0.3282051282051282\n",
      "Epoch 518/10000, Loss: 1.7060010433197021, Train Acc : 0.30850047755491883 , Val Acc : 0.3282051282051282\n",
      "Epoch 519/10000, Loss: 1.7343823909759521, Train Acc : 0.30850047755491883 , Val Acc : 0.3282051282051282\n",
      "Epoch 520/10000, Loss: 1.690941333770752, Train Acc : 0.30913721744667305 , Val Acc : 0.3282051282051282\n",
      "Epoch 521/10000, Loss: 1.6816775798797607, Train Acc : 0.3088188475007959 , Val Acc : 0.3282051282051282\n",
      "Epoch 522/10000, Loss: 1.7217061519622803, Train Acc : 0.3097739573384273 , Val Acc : 0.3282051282051282\n",
      "Epoch 523/10000, Loss: 1.7006542682647705, Train Acc : 0.31009232728430436 , Val Acc : 0.3282051282051282\n",
      "Epoch 524/10000, Loss: 1.6933542490005493, Train Acc : 0.30945558739255014 , Val Acc : 0.3282051282051282\n",
      "Epoch 525/10000, Loss: 1.6461080312728882, Train Acc : 0.3097739573384273 , Val Acc : 0.3282051282051282\n",
      "Epoch 526/10000, Loss: 1.6932249069213867, Train Acc : 0.3097739573384273 , Val Acc : 0.3282051282051282\n",
      "Epoch 527/10000, Loss: 1.7069377899169922, Train Acc : 0.31009232728430436 , Val Acc : 0.3282051282051282\n",
      "Epoch 528/10000, Loss: 1.7025933265686035, Train Acc : 0.31009232728430436 , Val Acc : 0.3282051282051282\n",
      "Epoch 529/10000, Loss: 1.719773769378662, Train Acc : 0.3104106972301815 , Val Acc : 0.3282051282051282\n",
      "Epoch 530/10000, Loss: 1.723528265953064, Train Acc : 0.3104106972301815 , Val Acc : 0.3282051282051282\n",
      "Epoch 531/10000, Loss: 1.7241904735565186, Train Acc : 0.3104106972301815 , Val Acc : 0.3282051282051282\n",
      "Epoch 532/10000, Loss: 1.7066643238067627, Train Acc : 0.3097739573384273 , Val Acc : 0.3282051282051282\n",
      "Epoch 533/10000, Loss: 1.7181326150894165, Train Acc : 0.3104106972301815 , Val Acc : 0.3282051282051282\n",
      "Epoch 534/10000, Loss: 1.6754705905914307, Train Acc : 0.3107290671760586 , Val Acc : 0.3282051282051282\n",
      "Epoch 535/10000, Loss: 1.6131072044372559, Train Acc : 0.3107290671760586 , Val Acc : 0.32564102564102565\n",
      "Epoch 536/10000, Loss: 1.7067294120788574, Train Acc : 0.31104743712193567 , Val Acc : 0.32564102564102565\n",
      "Epoch 537/10000, Loss: 1.7006069421768188, Train Acc : 0.31104743712193567 , Val Acc : 0.3282051282051282\n",
      "Epoch 538/10000, Loss: 1.6729164123535156, Train Acc : 0.3113658070678128 , Val Acc : 0.32564102564102565\n",
      "Epoch 539/10000, Loss: 1.7080711126327515, Train Acc : 0.3113658070678128 , Val Acc : 0.32564102564102565\n",
      "Epoch 540/10000, Loss: 1.707718014717102, Train Acc : 0.3107290671760586 , Val Acc : 0.32564102564102565\n",
      "Epoch 541/10000, Loss: 1.66900634765625, Train Acc : 0.3113658070678128 , Val Acc : 0.32564102564102565\n",
      "Epoch 542/10000, Loss: 1.7709240913391113, Train Acc : 0.3113658070678128 , Val Acc : 0.32564102564102565\n",
      "Epoch 543/10000, Loss: 1.7460941076278687, Train Acc : 0.3116841770136899 , Val Acc : 0.32564102564102565\n",
      "Epoch 544/10000, Loss: 1.6709550619125366, Train Acc : 0.3116841770136899 , Val Acc : 0.32564102564102565\n",
      "Epoch 545/10000, Loss: 1.6924588680267334, Train Acc : 0.3116841770136899 , Val Acc : 0.32564102564102565\n",
      "Epoch 546/10000, Loss: 1.647115707397461, Train Acc : 0.3123209169054441 , Val Acc : 0.32564102564102565\n",
      "Epoch 547/10000, Loss: 1.6554847955703735, Train Acc : 0.3116841770136899 , Val Acc : 0.32564102564102565\n",
      "Epoch 548/10000, Loss: 1.7009341716766357, Train Acc : 0.31200254695956703 , Val Acc : 0.32564102564102565\n",
      "Epoch 549/10000, Loss: 1.7085188627243042, Train Acc : 0.31200254695956703 , Val Acc : 0.32564102564102565\n",
      "Epoch 550/10000, Loss: 1.638318657875061, Train Acc : 0.3116841770136899 , Val Acc : 0.32564102564102565\n",
      "Epoch 551/10000, Loss: 1.7338831424713135, Train Acc : 0.31263928685132125 , Val Acc : 0.32564102564102565\n",
      "Epoch 552/10000, Loss: 1.790614128112793, Train Acc : 0.31200254695956703 , Val Acc : 0.32564102564102565\n",
      "Epoch 553/10000, Loss: 1.7010570764541626, Train Acc : 0.3123209169054441 , Val Acc : 0.32564102564102565\n",
      "Epoch 554/10000, Loss: 1.676643967628479, Train Acc : 0.31295765679719834 , Val Acc : 0.32564102564102565\n",
      "Epoch 555/10000, Loss: 1.7277778387069702, Train Acc : 0.31295765679719834 , Val Acc : 0.32564102564102565\n",
      "Epoch 556/10000, Loss: 1.7244179248809814, Train Acc : 0.3139127666348297 , Val Acc : 0.3282051282051282\n",
      "Epoch 557/10000, Loss: 1.6779736280441284, Train Acc : 0.3142311365807068 , Val Acc : 0.32564102564102565\n",
      "Epoch 558/10000, Loss: 1.6818304061889648, Train Acc : 0.3142311365807068 , Val Acc : 0.3282051282051282\n",
      "Epoch 559/10000, Loss: 1.7317918539047241, Train Acc : 0.314867876472461 , Val Acc : 0.3282051282051282\n",
      "Epoch 560/10000, Loss: 1.6430295705795288, Train Acc : 0.31454950652658387 , Val Acc : 0.3282051282051282\n",
      "Epoch 561/10000, Loss: 1.6871099472045898, Train Acc : 0.314867876472461 , Val Acc : 0.3282051282051282\n",
      "Epoch 562/10000, Loss: 1.7001689672470093, Train Acc : 0.3142311365807068 , Val Acc : 0.3282051282051282\n",
      "Epoch 563/10000, Loss: 1.732627272605896, Train Acc : 0.31454950652658387 , Val Acc : 0.3282051282051282\n",
      "Epoch 564/10000, Loss: 1.6288303136825562, Train Acc : 0.31359439668895256 , Val Acc : 0.3282051282051282\n",
      "Epoch 565/10000, Loss: 1.7821160554885864, Train Acc : 0.314867876472461 , Val Acc : 0.3282051282051282\n",
      "Epoch 566/10000, Loss: 1.6973587274551392, Train Acc : 0.3151862464183381 , Val Acc : 0.3282051282051282\n",
      "Epoch 567/10000, Loss: 1.6610689163208008, Train Acc : 0.314867876472461 , Val Acc : 0.3282051282051282\n",
      "Epoch 568/10000, Loss: 1.6672604084014893, Train Acc : 0.3151862464183381 , Val Acc : 0.3282051282051282\n",
      "Epoch 569/10000, Loss: 1.6594958305358887, Train Acc : 0.314867876472461 , Val Acc : 0.3282051282051282\n",
      "Epoch 570/10000, Loss: 1.61758553981781, Train Acc : 0.31550461636421523 , Val Acc : 0.3282051282051282\n",
      "Epoch 571/10000, Loss: 1.6457027196884155, Train Acc : 0.31550461636421523 , Val Acc : 0.3282051282051282\n",
      "Epoch 572/10000, Loss: 1.7267760038375854, Train Acc : 0.31550461636421523 , Val Acc : 0.3282051282051282\n",
      "Epoch 573/10000, Loss: 1.6837985515594482, Train Acc : 0.3167780961477237 , Val Acc : 0.3333333333333333\n",
      "Epoch 574/10000, Loss: 1.6772023439407349, Train Acc : 0.31645972620184654 , Val Acc : 0.3333333333333333\n",
      "Epoch 575/10000, Loss: 1.7007864713668823, Train Acc : 0.31614135625596945 , Val Acc : 0.33076923076923076\n",
      "Epoch 576/10000, Loss: 1.6519725322723389, Train Acc : 0.3158229863100923 , Val Acc : 0.33076923076923076\n",
      "Epoch 577/10000, Loss: 1.6438536643981934, Train Acc : 0.31550461636421523 , Val Acc : 0.33076923076923076\n",
      "Epoch 578/10000, Loss: 1.7135473489761353, Train Acc : 0.31709646609360076 , Val Acc : 0.3333333333333333\n",
      "Epoch 579/10000, Loss: 1.7141668796539307, Train Acc : 0.31709646609360076 , Val Acc : 0.33589743589743587\n",
      "Epoch 580/10000, Loss: 1.7299919128417969, Train Acc : 0.31645972620184654 , Val Acc : 0.3333333333333333\n",
      "Epoch 581/10000, Loss: 1.6947580575942993, Train Acc : 0.31645972620184654 , Val Acc : 0.3333333333333333\n",
      "Epoch 582/10000, Loss: 1.7399566173553467, Train Acc : 0.31645972620184654 , Val Acc : 0.3333333333333333\n",
      "Epoch 583/10000, Loss: 1.6745381355285645, Train Acc : 0.31645972620184654 , Val Acc : 0.3333333333333333\n",
      "Epoch 584/10000, Loss: 1.7297049760818481, Train Acc : 0.31709646609360076 , Val Acc : 0.3333333333333333\n",
      "Epoch 585/10000, Loss: 1.7328158617019653, Train Acc : 0.31709646609360076 , Val Acc : 0.3333333333333333\n",
      "Epoch 586/10000, Loss: 1.7406482696533203, Train Acc : 0.3167780961477237 , Val Acc : 0.3333333333333333\n",
      "Epoch 587/10000, Loss: 1.7257124185562134, Train Acc : 0.31709646609360076 , Val Acc : 0.3333333333333333\n",
      "Epoch 588/10000, Loss: 1.7696716785430908, Train Acc : 0.3167780961477237 , Val Acc : 0.3333333333333333\n",
      "Epoch 589/10000, Loss: 1.7230859994888306, Train Acc : 0.31805157593123207 , Val Acc : 0.3333333333333333\n",
      "Epoch 590/10000, Loss: 1.6820417642593384, Train Acc : 0.31805157593123207 , Val Acc : 0.3333333333333333\n",
      "Epoch 591/10000, Loss: 1.7476494312286377, Train Acc : 0.3212352753900032 , Val Acc : 0.3333333333333333\n",
      "Epoch 592/10000, Loss: 1.6607747077941895, Train Acc : 0.3212352753900032 , Val Acc : 0.3333333333333333\n",
      "Epoch 593/10000, Loss: 1.7391977310180664, Train Acc : 0.3202801655523719 , Val Acc : 0.3333333333333333\n",
      "Epoch 594/10000, Loss: 1.7301599979400635, Train Acc : 0.3221903852276345 , Val Acc : 0.3384615384615385\n",
      "Epoch 595/10000, Loss: 1.7219289541244507, Train Acc : 0.32250875517351163 , Val Acc : 0.33589743589743587\n",
      "Epoch 596/10000, Loss: 1.662301778793335, Train Acc : 0.3256924546322827 , Val Acc : 0.33589743589743587\n",
      "Epoch 597/10000, Loss: 1.6986161470413208, Train Acc : 0.3247373447946514 , Val Acc : 0.33589743589743587\n",
      "Epoch 598/10000, Loss: 1.681946039199829, Train Acc : 0.3237822349570201 , Val Acc : 0.33589743589743587\n",
      "Epoch 599/10000, Loss: 1.6787281036376953, Train Acc : 0.32410060490289716 , Val Acc : 0.33589743589743587\n",
      "Epoch 600/10000, Loss: 1.7279108762741089, Train Acc : 0.3253740846864056 , Val Acc : 0.33589743589743587\n",
      "Epoch 601/10000, Loss: 1.7040382623672485, Train Acc : 0.32314549506526585 , Val Acc : 0.3384615384615385\n",
      "Epoch 602/10000, Loss: 1.7293096780776978, Train Acc : 0.3253740846864056 , Val Acc : 0.33589743589743587\n",
      "Epoch 603/10000, Loss: 1.7113345861434937, Train Acc : 0.3263291945240369 , Val Acc : 0.33589743589743587\n",
      "Epoch 604/10000, Loss: 1.689296841621399, Train Acc : 0.3263291945240369 , Val Acc : 0.33589743589743587\n",
      "Epoch 605/10000, Loss: 1.7309499979019165, Train Acc : 0.32601082457815983 , Val Acc : 0.33589743589743587\n",
      "Epoch 606/10000, Loss: 1.7103781700134277, Train Acc : 0.3228271251193887 , Val Acc : 0.33589743589743587\n",
      "Epoch 607/10000, Loss: 1.7160861492156982, Train Acc : 0.32601082457815983 , Val Acc : 0.33589743589743587\n",
      "Epoch 608/10000, Loss: 1.7221115827560425, Train Acc : 0.3263291945240369 , Val Acc : 0.33589743589743587\n",
      "Epoch 609/10000, Loss: 1.6997219324111938, Train Acc : 0.3291945240369309 , Val Acc : 0.33589743589743587\n",
      "Epoch 610/10000, Loss: 1.712445855140686, Train Acc : 0.3326965934415791 , Val Acc : 0.33589743589743587\n",
      "Epoch 611/10000, Loss: 1.711387276649475, Train Acc : 0.32951289398280803 , Val Acc : 0.33589743589743587\n",
      "Epoch 612/10000, Loss: 1.6896685361862183, Train Acc : 0.32664756446991405 , Val Acc : 0.33589743589743587\n",
      "Epoch 613/10000, Loss: 1.7302430868148804, Train Acc : 0.32346386501114294 , Val Acc : 0.3384615384615385\n",
      "Epoch 614/10000, Loss: 1.6538411378860474, Train Acc : 0.32760267430754536 , Val Acc : 0.33589743589743587\n",
      "Epoch 615/10000, Loss: 1.7376857995986938, Train Acc : 0.3298312639286851 , Val Acc : 0.33589743589743587\n",
      "Epoch 616/10000, Loss: 1.6478523015975952, Train Acc : 0.3314231136580707 , Val Acc : 0.33589743589743587\n",
      "Epoch 617/10000, Loss: 1.7022383213043213, Train Acc : 0.3317414836039478 , Val Acc : 0.33589743589743587\n",
      "Epoch 618/10000, Loss: 1.6737723350524902, Train Acc : 0.3320598535498249 , Val Acc : 0.33589743589743587\n",
      "Epoch 619/10000, Loss: 1.6898761987686157, Train Acc : 0.33301496338745623 , Val Acc : 0.33589743589743587\n",
      "Epoch 620/10000, Loss: 1.7118734121322632, Train Acc : 0.33397007322508754 , Val Acc : 0.33589743589743587\n",
      "Epoch 621/10000, Loss: 1.695148229598999, Train Acc : 0.33365170327921045 , Val Acc : 0.33589743589743587\n",
      "Epoch 622/10000, Loss: 1.6692121028900146, Train Acc : 0.3317414836039478 , Val Acc : 0.33589743589743587\n",
      "Epoch 623/10000, Loss: 1.6923043727874756, Train Acc : 0.3320598535498249 , Val Acc : 0.33589743589743587\n",
      "Epoch 624/10000, Loss: 1.6580476760864258, Train Acc : 0.33365170327921045 , Val Acc : 0.33589743589743587\n",
      "Epoch 625/10000, Loss: 1.7139859199523926, Train Acc : 0.3368354027379815 , Val Acc : 0.34102564102564104\n",
      "Epoch 626/10000, Loss: 1.7094048261642456, Train Acc : 0.33651703279210443 , Val Acc : 0.33589743589743587\n",
      "Epoch 627/10000, Loss: 1.6807748079299927, Train Acc : 0.33651703279210443 , Val Acc : 0.3435897435897436\n",
      "Epoch 628/10000, Loss: 1.637151837348938, Train Acc : 0.33810888252148996 , Val Acc : 0.3435897435897436\n",
      "Epoch 629/10000, Loss: 1.7140464782714844, Train Acc : 0.3368354027379815 , Val Acc : 0.33589743589743587\n",
      "Epoch 630/10000, Loss: 1.6813819408416748, Train Acc : 0.33747214262973574 , Val Acc : 0.34615384615384615\n",
      "Epoch 631/10000, Loss: 1.688307523727417, Train Acc : 0.33810888252148996 , Val Acc : 0.34615384615384615\n",
      "Epoch 632/10000, Loss: 1.7871040105819702, Train Acc : 0.3403374721426297 , Val Acc : 0.3487179487179487\n",
      "Epoch 633/10000, Loss: 1.7100156545639038, Train Acc : 0.3377905125756129 , Val Acc : 0.3435897435897436\n",
      "Epoch 634/10000, Loss: 1.744666337966919, Train Acc : 0.34065584208850685 , Val Acc : 0.3487179487179487\n",
      "Epoch 635/10000, Loss: 1.7440509796142578, Train Acc : 0.3384272524673671 , Val Acc : 0.34615384615384615\n",
      "Epoch 636/10000, Loss: 1.7104504108428955, Train Acc : 0.3390639923591213 , Val Acc : 0.34615384615384615\n",
      "Epoch 637/10000, Loss: 1.7156776189804077, Train Acc : 0.3390639923591213 , Val Acc : 0.34615384615384615\n",
      "Epoch 638/10000, Loss: 1.656907320022583, Train Acc : 0.34001910219675263 , Val Acc : 0.3487179487179487\n",
      "Epoch 639/10000, Loss: 1.7745980024337769, Train Acc : 0.33651703279210443 , Val Acc : 0.33589743589743587\n",
      "Epoch 640/10000, Loss: 1.7093311548233032, Train Acc : 0.3368354027379815 , Val Acc : 0.34615384615384615\n",
      "Epoch 641/10000, Loss: 1.6772880554199219, Train Acc : 0.34065584208850685 , Val Acc : 0.3487179487179487\n",
      "Epoch 642/10000, Loss: 1.7641475200653076, Train Acc : 0.3390639923591213 , Val Acc : 0.34615384615384615\n",
      "Epoch 643/10000, Loss: 1.6157433986663818, Train Acc : 0.3377905125756129 , Val Acc : 0.34615384615384615\n",
      "Epoch 644/10000, Loss: 1.7257447242736816, Train Acc : 0.34065584208850685 , Val Acc : 0.34615384615384615\n",
      "Epoch 645/10000, Loss: 1.7590585947036743, Train Acc : 0.34161095192613816 , Val Acc : 0.3487179487179487\n",
      "Epoch 646/10000, Loss: 1.6796588897705078, Train Acc : 0.3403374721426297 , Val Acc : 0.34615384615384615\n",
      "Epoch 647/10000, Loss: 1.7127872705459595, Train Acc : 0.3397007322508755 , Val Acc : 0.3487179487179487\n",
      "Epoch 648/10000, Loss: 1.735862135887146, Train Acc : 0.34065584208850685 , Val Acc : 0.3487179487179487\n",
      "Epoch 649/10000, Loss: 1.713124394416809, Train Acc : 0.3397007322508755 , Val Acc : 0.34615384615384615\n",
      "Epoch 650/10000, Loss: 1.671964406967163, Train Acc : 0.3422476918178924 , Val Acc : 0.3487179487179487\n",
      "Epoch 651/10000, Loss: 1.6577409505844116, Train Acc : 0.34161095192613816 , Val Acc : 0.34615384615384615\n",
      "Epoch 652/10000, Loss: 1.6163935661315918, Train Acc : 0.34065584208850685 , Val Acc : 0.34615384615384615\n",
      "Epoch 653/10000, Loss: 1.7031848430633545, Train Acc : 0.34001910219675263 , Val Acc : 0.3487179487179487\n",
      "Epoch 654/10000, Loss: 1.742378830909729, Train Acc : 0.3419293218720153 , Val Acc : 0.3487179487179487\n",
      "Epoch 655/10000, Loss: 1.738167405128479, Train Acc : 0.3432028016555237 , Val Acc : 0.3487179487179487\n",
      "Epoch 656/10000, Loss: 1.678443193435669, Train Acc : 0.34352117160140083 , Val Acc : 0.3487179487179487\n",
      "Epoch 657/10000, Loss: 1.7308604717254639, Train Acc : 0.3432028016555237 , Val Acc : 0.3487179487179487\n",
      "Epoch 658/10000, Loss: 1.6705405712127686, Train Acc : 0.3432028016555237 , Val Acc : 0.3487179487179487\n",
      "Epoch 659/10000, Loss: 1.7235136032104492, Train Acc : 0.3432028016555237 , Val Acc : 0.3487179487179487\n",
      "Epoch 660/10000, Loss: 1.7052539587020874, Train Acc : 0.34415791149315506 , Val Acc : 0.3487179487179487\n",
      "Epoch 661/10000, Loss: 1.6411041021347046, Train Acc : 0.3467048710601719 , Val Acc : 0.3487179487179487\n",
      "Epoch 662/10000, Loss: 1.6578792333602905, Train Acc : 0.3457497612225406 , Val Acc : 0.3487179487179487\n",
      "Epoch 663/10000, Loss: 1.6607584953308105, Train Acc : 0.3473416109519261 , Val Acc : 0.3487179487179487\n",
      "Epoch 664/10000, Loss: 1.670794129371643, Train Acc : 0.3473416109519261 , Val Acc : 0.3487179487179487\n",
      "Epoch 665/10000, Loss: 1.6494022607803345, Train Acc : 0.34797835084368034 , Val Acc : 0.3487179487179487\n",
      "Epoch 666/10000, Loss: 1.6796765327453613, Train Acc : 0.3467048710601719 , Val Acc : 0.3487179487179487\n",
      "Epoch 667/10000, Loss: 1.6618763208389282, Train Acc : 0.35052531041069723 , Val Acc : 0.35128205128205126\n",
      "Epoch 668/10000, Loss: 1.669589877128601, Train Acc : 0.3489334606813117 , Val Acc : 0.35128205128205126\n",
      "Epoch 669/10000, Loss: 1.6731065511703491, Train Acc : 0.3489334606813117 , Val Acc : 0.35128205128205126\n",
      "Epoch 670/10000, Loss: 1.6931043863296509, Train Acc : 0.34765998089780326 , Val Acc : 0.3487179487179487\n",
      "Epoch 671/10000, Loss: 1.6829826831817627, Train Acc : 0.3492518306271888 , Val Acc : 0.3487179487179487\n",
      "Epoch 672/10000, Loss: 1.761179804801941, Train Acc : 0.3517987901942057 , Val Acc : 0.35128205128205126\n",
      "Epoch 673/10000, Loss: 1.7171040773391724, Train Acc : 0.3495702005730659 , Val Acc : 0.3487179487179487\n",
      "Epoch 674/10000, Loss: 1.7033799886703491, Train Acc : 0.3495702005730659 , Val Acc : 0.35128205128205126\n",
      "Epoch 675/10000, Loss: 1.661569356918335, Train Acc : 0.3517987901942057 , Val Acc : 0.35128205128205126\n",
      "Epoch 676/10000, Loss: 1.7236851453781128, Train Acc : 0.349888570518943 , Val Acc : 0.35128205128205126\n",
      "Epoch 677/10000, Loss: 1.6384268999099731, Train Acc : 0.3502069404648201 , Val Acc : 0.35128205128205126\n",
      "Epoch 678/10000, Loss: 1.6720740795135498, Train Acc : 0.35148042024832854 , Val Acc : 0.35128205128205126\n",
      "Epoch 679/10000, Loss: 1.6396589279174805, Train Acc : 0.3495702005730659 , Val Acc : 0.35128205128205126\n",
      "Epoch 680/10000, Loss: 1.7050235271453857, Train Acc : 0.3524355300859599 , Val Acc : 0.35128205128205126\n",
      "Epoch 681/10000, Loss: 1.6932759284973145, Train Acc : 0.35148042024832854 , Val Acc : 0.35128205128205126\n",
      "Epoch 682/10000, Loss: 1.6601903438568115, Train Acc : 0.3492518306271888 , Val Acc : 0.35128205128205126\n",
      "Epoch 683/10000, Loss: 1.683275818824768, Train Acc : 0.349888570518943 , Val Acc : 0.35128205128205126\n",
      "Epoch 684/10000, Loss: 1.6615327596664429, Train Acc : 0.3492518306271888 , Val Acc : 0.35128205128205126\n",
      "Epoch 685/10000, Loss: 1.6256182193756104, Train Acc : 0.35052531041069723 , Val Acc : 0.35128205128205126\n",
      "Epoch 686/10000, Loss: 1.6888350248336792, Train Acc : 0.3502069404648201 , Val Acc : 0.35128205128205126\n",
      "Epoch 687/10000, Loss: 1.6536006927490234, Train Acc : 0.3502069404648201 , Val Acc : 0.35128205128205126\n",
      "Epoch 688/10000, Loss: 1.5670305490493774, Train Acc : 0.3502069404648201 , Val Acc : 0.35128205128205126\n",
      "Epoch 689/10000, Loss: 1.66334867477417, Train Acc : 0.3524355300859599 , Val Acc : 0.35128205128205126\n",
      "Epoch 690/10000, Loss: 1.714484691619873, Train Acc : 0.3524355300859599 , Val Acc : 0.35128205128205126\n",
      "Epoch 691/10000, Loss: 1.61894953250885, Train Acc : 0.3530722699777141 , Val Acc : 0.35128205128205126\n",
      "Epoch 692/10000, Loss: 1.6794888973236084, Train Acc : 0.3502069404648201 , Val Acc : 0.35128205128205126\n",
      "Epoch 693/10000, Loss: 1.6764873266220093, Train Acc : 0.3533906399235912 , Val Acc : 0.35384615384615387\n",
      "Epoch 694/10000, Loss: 1.6896144151687622, Train Acc : 0.35402737981534543 , Val Acc : 0.35384615384615387\n",
      "Epoch 695/10000, Loss: 1.6975990533828735, Train Acc : 0.3578478191658707 , Val Acc : 0.3564102564102564\n",
      "Epoch 696/10000, Loss: 1.7083125114440918, Train Acc : 0.35848455905762494 , Val Acc : 0.35384615384615387\n",
      "Epoch 697/10000, Loss: 1.6891841888427734, Train Acc : 0.35752944921999363 , Val Acc : 0.35384615384615387\n",
      "Epoch 698/10000, Loss: 1.6967462301254272, Train Acc : 0.3568927093282394 , Val Acc : 0.35384615384615387\n",
      "Epoch 699/10000, Loss: 1.5943671464920044, Train Acc : 0.3565743393823623 , Val Acc : 0.3564102564102564\n",
      "Epoch 700/10000, Loss: 1.7279548645019531, Train Acc : 0.35848455905762494 , Val Acc : 0.35384615384615387\n",
      "Epoch 701/10000, Loss: 1.6199679374694824, Train Acc : 0.3559375994906081 , Val Acc : 0.35384615384615387\n",
      "Epoch 702/10000, Loss: 1.6779836416244507, Train Acc : 0.3562559694364852 , Val Acc : 0.35384615384615387\n",
      "Epoch 703/10000, Loss: 1.6845074892044067, Train Acc : 0.3597580388411334 , Val Acc : 0.358974358974359\n",
      "Epoch 704/10000, Loss: 1.7422828674316406, Train Acc : 0.3597580388411334 , Val Acc : 0.3564102564102564\n",
      "Epoch 705/10000, Loss: 1.6455098390579224, Train Acc : 0.3578478191658707 , Val Acc : 0.35384615384615387\n",
      "Epoch 706/10000, Loss: 1.6688575744628906, Train Acc : 0.3565743393823623 , Val Acc : 0.35384615384615387\n",
      "Epoch 707/10000, Loss: 1.701914668083191, Train Acc : 0.3597580388411334 , Val Acc : 0.3641025641025641\n",
      "Epoch 708/10000, Loss: 1.7124855518341064, Train Acc : 0.3600764087870105 , Val Acc : 0.36153846153846153\n",
      "Epoch 709/10000, Loss: 1.6649209260940552, Train Acc : 0.36453358802929003 , Val Acc : 0.36666666666666664\n",
      "Epoch 710/10000, Loss: 1.6773895025253296, Train Acc : 0.3667621776504298 , Val Acc : 0.36666666666666664\n",
      "Epoch 711/10000, Loss: 1.7119591236114502, Train Acc : 0.36612543775867556 , Val Acc : 0.36666666666666664\n",
      "Epoch 712/10000, Loss: 1.650202751159668, Train Acc : 0.36612543775867556 , Val Acc : 0.36666666666666664\n",
      "Epoch 713/10000, Loss: 1.7429131269454956, Train Acc : 0.36517032792104426 , Val Acc : 0.36666666666666664\n",
      "Epoch 714/10000, Loss: 1.6622990369796753, Train Acc : 0.36453358802929003 , Val Acc : 0.36666666666666664\n",
      "Epoch 715/10000, Loss: 1.6805336475372314, Train Acc : 0.36517032792104426 , Val Acc : 0.36666666666666664\n",
      "Epoch 716/10000, Loss: 1.6911864280700684, Train Acc : 0.36803565743393823 , Val Acc : 0.36666666666666664\n",
      "Epoch 717/10000, Loss: 1.6798346042633057, Train Acc : 0.3667621776504298 , Val Acc : 0.36666666666666664\n",
      "Epoch 718/10000, Loss: 1.6870942115783691, Train Acc : 0.3664438077045527 , Val Acc : 0.36666666666666664\n",
      "Epoch 719/10000, Loss: 1.6988352537155151, Train Acc : 0.3670805475963069 , Val Acc : 0.36666666666666664\n",
      "Epoch 720/10000, Loss: 1.6630430221557617, Train Acc : 0.36612543775867556 , Val Acc : 0.36666666666666664\n",
      "Epoch 721/10000, Loss: 1.6610690355300903, Train Acc : 0.36517032792104426 , Val Acc : 0.36666666666666664\n",
      "Epoch 722/10000, Loss: 1.7275713682174683, Train Acc : 0.36612543775867556 , Val Acc : 0.36666666666666664\n",
      "Epoch 723/10000, Loss: 1.642177700996399, Train Acc : 0.3635784781916587 , Val Acc : 0.36666666666666664\n",
      "Epoch 724/10000, Loss: 1.6888782978057861, Train Acc : 0.3667621776504298 , Val Acc : 0.36666666666666664\n",
      "Epoch 725/10000, Loss: 1.7598375082015991, Train Acc : 0.36771728748806115 , Val Acc : 0.36666666666666664\n",
      "Epoch 726/10000, Loss: 1.6927597522735596, Train Acc : 0.36612543775867556 , Val Acc : 0.36666666666666664\n",
      "Epoch 727/10000, Loss: 1.6655046939849854, Train Acc : 0.36612543775867556 , Val Acc : 0.36666666666666664\n",
      "Epoch 728/10000, Loss: 1.7199280261993408, Train Acc : 0.36166825851639606 , Val Acc : 0.3641025641025641\n",
      "Epoch 729/10000, Loss: 1.711403489112854, Train Acc : 0.36517032792104426 , Val Acc : 0.36666666666666664\n",
      "Epoch 730/10000, Loss: 1.697432041168213, Train Acc : 0.3667621776504298 , Val Acc : 0.36666666666666664\n",
      "Epoch 731/10000, Loss: 1.6583049297332764, Train Acc : 0.3667621776504298 , Val Acc : 0.36666666666666664\n",
      "Epoch 732/10000, Loss: 1.7184476852416992, Train Acc : 0.36803565743393823 , Val Acc : 0.36666666666666664\n",
      "Epoch 733/10000, Loss: 1.739068627357483, Train Acc : 0.36803565743393823 , Val Acc : 0.36666666666666664\n",
      "Epoch 734/10000, Loss: 1.6955162286758423, Train Acc : 0.36803565743393823 , Val Acc : 0.36923076923076925\n",
      "Epoch 735/10000, Loss: 1.7029610872268677, Train Acc : 0.36771728748806115 , Val Acc : 0.36923076923076925\n",
      "Epoch 736/10000, Loss: 1.71017587184906, Train Acc : 0.36771728748806115 , Val Acc : 0.36923076923076925\n",
      "Epoch 737/10000, Loss: 1.747760534286499, Train Acc : 0.3670805475963069 , Val Acc : 0.36923076923076925\n",
      "Epoch 738/10000, Loss: 1.6723830699920654, Train Acc : 0.367398917542184 , Val Acc : 0.36923076923076925\n",
      "Epoch 739/10000, Loss: 1.7260761260986328, Train Acc : 0.3683540273798153 , Val Acc : 0.36923076923076925\n",
      "Epoch 740/10000, Loss: 1.6735244989395142, Train Acc : 0.367398917542184 , Val Acc : 0.36923076923076925\n",
      "Epoch 741/10000, Loss: 1.627640962600708, Train Acc : 0.36803565743393823 , Val Acc : 0.36923076923076925\n",
      "Epoch 742/10000, Loss: 1.7230186462402344, Train Acc : 0.3683540273798153 , Val Acc : 0.36923076923076925\n",
      "Epoch 743/10000, Loss: 1.7092941999435425, Train Acc : 0.3693091372174467 , Val Acc : 0.36923076923076925\n",
      "Epoch 744/10000, Loss: 1.6251517534255981, Train Acc : 0.36899076727156954 , Val Acc : 0.36923076923076925\n",
      "Epoch 745/10000, Loss: 1.7292835712432861, Train Acc : 0.370264247055078 , Val Acc : 0.37435897435897436\n",
      "Epoch 746/10000, Loss: 1.6534233093261719, Train Acc : 0.3693091372174467 , Val Acc : 0.37435897435897436\n",
      "Epoch 747/10000, Loss: 1.7120211124420166, Train Acc : 0.36962750716332377 , Val Acc : 0.3717948717948718\n",
      "Epoch 748/10000, Loss: 1.6553657054901123, Train Acc : 0.3683540273798153 , Val Acc : 0.36923076923076925\n",
      "Epoch 749/10000, Loss: 1.6960480213165283, Train Acc : 0.3693091372174467 , Val Acc : 0.36923076923076925\n",
      "Epoch 750/10000, Loss: 1.7585132122039795, Train Acc : 0.3693091372174467 , Val Acc : 0.37435897435897436\n",
      "Epoch 751/10000, Loss: 1.7285346984863281, Train Acc : 0.3693091372174467 , Val Acc : 0.36923076923076925\n",
      "Epoch 752/10000, Loss: 1.7003390789031982, Train Acc : 0.3693091372174467 , Val Acc : 0.37435897435897436\n",
      "Epoch 753/10000, Loss: 1.7036734819412231, Train Acc : 0.3699458771092009 , Val Acc : 0.36923076923076925\n",
      "Epoch 754/10000, Loss: 1.7145252227783203, Train Acc : 0.36899076727156954 , Val Acc : 0.36923076923076925\n",
      "Epoch 755/10000, Loss: 1.7207995653152466, Train Acc : 0.36962750716332377 , Val Acc : 0.36923076923076925\n",
      "Epoch 756/10000, Loss: 1.6782751083374023, Train Acc : 0.3699458771092009 , Val Acc : 0.37435897435897436\n",
      "Epoch 757/10000, Loss: 1.715503215789795, Train Acc : 0.3709009869468322 , Val Acc : 0.3717948717948718\n",
      "Epoch 758/10000, Loss: 1.6839191913604736, Train Acc : 0.3728112066220949 , Val Acc : 0.37435897435897436\n",
      "Epoch 759/10000, Loss: 1.6781326532363892, Train Acc : 0.3728112066220949 , Val Acc : 0.37435897435897436\n",
      "Epoch 760/10000, Loss: 1.6945815086364746, Train Acc : 0.37217446673034066 , Val Acc : 0.37435897435897436\n",
      "Epoch 761/10000, Loss: 1.7192479372024536, Train Acc : 0.37217446673034066 , Val Acc : 0.3717948717948718\n",
      "Epoch 762/10000, Loss: 1.6862547397613525, Train Acc : 0.37153772683858644 , Val Acc : 0.37435897435897436\n",
      "Epoch 763/10000, Loss: 1.684938907623291, Train Acc : 0.37217446673034066 , Val Acc : 0.37435897435897436\n",
      "Epoch 764/10000, Loss: 1.641484260559082, Train Acc : 0.37249283667621774 , Val Acc : 0.37435897435897436\n",
      "Epoch 765/10000, Loss: 1.6442527770996094, Train Acc : 0.37217446673034066 , Val Acc : 0.37435897435897436\n",
      "Epoch 766/10000, Loss: 1.6654655933380127, Train Acc : 0.37312957656797197 , Val Acc : 0.37948717948717947\n",
      "Epoch 767/10000, Loss: 1.6874806880950928, Train Acc : 0.37217446673034066 , Val Acc : 0.3717948717948718\n",
      "Epoch 768/10000, Loss: 1.6127513647079468, Train Acc : 0.37153772683858644 , Val Acc : 0.37435897435897436\n",
      "Epoch 769/10000, Loss: 1.7122063636779785, Train Acc : 0.37153772683858644 , Val Acc : 0.37435897435897436\n",
      "Epoch 770/10000, Loss: 1.6735126972198486, Train Acc : 0.37121935689270935 , Val Acc : 0.37435897435897436\n",
      "Epoch 771/10000, Loss: 1.6955422163009644, Train Acc : 0.3718560967844635 , Val Acc : 0.37435897435897436\n",
      "Epoch 772/10000, Loss: 1.6776069402694702, Train Acc : 0.37217446673034066 , Val Acc : 0.37435897435897436\n",
      "Epoch 773/10000, Loss: 1.7221145629882812, Train Acc : 0.37153772683858644 , Val Acc : 0.37435897435897436\n",
      "Epoch 774/10000, Loss: 1.6831035614013672, Train Acc : 0.37153772683858644 , Val Acc : 0.3717948717948718\n",
      "Epoch 775/10000, Loss: 1.6382025480270386, Train Acc : 0.3728112066220949 , Val Acc : 0.37435897435897436\n",
      "Epoch 776/10000, Loss: 1.7415118217468262, Train Acc : 0.3718560967844635 , Val Acc : 0.3717948717948718\n",
      "Epoch 777/10000, Loss: 1.6741125583648682, Train Acc : 0.37249283667621774 , Val Acc : 0.37948717948717947\n",
      "Epoch 778/10000, Loss: 1.6837486028671265, Train Acc : 0.3734479465138491 , Val Acc : 0.37435897435897436\n",
      "Epoch 779/10000, Loss: 1.6858727931976318, Train Acc : 0.3728112066220949 , Val Acc : 0.37435897435897436\n",
      "Epoch 780/10000, Loss: 1.6722826957702637, Train Acc : 0.3734479465138491 , Val Acc : 0.382051282051282\n",
      "Epoch 781/10000, Loss: 1.691182255744934, Train Acc : 0.3734479465138491 , Val Acc : 0.382051282051282\n",
      "Epoch 782/10000, Loss: 1.6636378765106201, Train Acc : 0.37312957656797197 , Val Acc : 0.382051282051282\n",
      "Epoch 783/10000, Loss: 1.6928722858428955, Train Acc : 0.3734479465138491 , Val Acc : 0.382051282051282\n",
      "Epoch 784/10000, Loss: 1.671810507774353, Train Acc : 0.3737663164597262 , Val Acc : 0.382051282051282\n",
      "Epoch 785/10000, Loss: 1.6931957006454468, Train Acc : 0.37408468640560333 , Val Acc : 0.37948717948717947\n",
      "Epoch 786/10000, Loss: 1.6971782445907593, Train Acc : 0.37408468640560333 , Val Acc : 0.382051282051282\n",
      "Epoch 787/10000, Loss: 1.7240346670150757, Train Acc : 0.3734479465138491 , Val Acc : 0.382051282051282\n",
      "Epoch 788/10000, Loss: 1.7306585311889648, Train Acc : 0.3744030563514804 , Val Acc : 0.38461538461538464\n",
      "Epoch 789/10000, Loss: 1.6315494775772095, Train Acc : 0.37408468640560333 , Val Acc : 0.382051282051282\n",
      "Epoch 790/10000, Loss: 1.6925102472305298, Train Acc : 0.3753581661891118 , Val Acc : 0.38461538461538464\n",
      "Epoch 791/10000, Loss: 1.7087528705596924, Train Acc : 0.3753581661891118 , Val Acc : 0.382051282051282\n",
      "Epoch 792/10000, Loss: 1.719967246055603, Train Acc : 0.37408468640560333 , Val Acc : 0.38461538461538464\n",
      "Epoch 793/10000, Loss: 1.7052990198135376, Train Acc : 0.37503979624323464 , Val Acc : 0.382051282051282\n",
      "Epoch 794/10000, Loss: 1.6566108465194702, Train Acc : 0.37567653613498886 , Val Acc : 0.382051282051282\n",
      "Epoch 795/10000, Loss: 1.672912836074829, Train Acc : 0.37503979624323464 , Val Acc : 0.38461538461538464\n",
      "Epoch 796/10000, Loss: 1.69630765914917, Train Acc : 0.37567653613498886 , Val Acc : 0.382051282051282\n",
      "Epoch 797/10000, Loss: 1.6613937616348267, Train Acc : 0.3763132760267431 , Val Acc : 0.382051282051282\n",
      "Epoch 798/10000, Loss: 1.6900641918182373, Train Acc : 0.3753581661891118 , Val Acc : 0.382051282051282\n",
      "Epoch 799/10000, Loss: 1.6570976972579956, Train Acc : 0.3753581661891118 , Val Acc : 0.382051282051282\n",
      "Epoch 800/10000, Loss: 1.7238659858703613, Train Acc : 0.37599490608086594 , Val Acc : 0.382051282051282\n",
      "Epoch 801/10000, Loss: 1.6985924243927002, Train Acc : 0.3763132760267431 , Val Acc : 0.382051282051282\n",
      "Epoch 802/10000, Loss: 1.6514629125595093, Train Acc : 0.37663164597262017 , Val Acc : 0.38461538461538464\n",
      "Epoch 803/10000, Loss: 1.697801113128662, Train Acc : 0.3772683858643744 , Val Acc : 0.38461538461538464\n",
      "Epoch 804/10000, Loss: 1.680780053138733, Train Acc : 0.37663164597262017 , Val Acc : 0.38461538461538464\n",
      "Epoch 805/10000, Loss: 1.6580023765563965, Train Acc : 0.37663164597262017 , Val Acc : 0.38461538461538464\n",
      "Epoch 806/10000, Loss: 1.707702398300171, Train Acc : 0.37758675581025153 , Val Acc : 0.38461538461538464\n",
      "Epoch 807/10000, Loss: 1.7014445066452026, Train Acc : 0.37567653613498886 , Val Acc : 0.382051282051282\n",
      "Epoch 808/10000, Loss: 1.6796351671218872, Train Acc : 0.37599490608086594 , Val Acc : 0.382051282051282\n",
      "Epoch 809/10000, Loss: 1.6813163757324219, Train Acc : 0.37567653613498886 , Val Acc : 0.382051282051282\n",
      "Epoch 810/10000, Loss: 1.6864079236984253, Train Acc : 0.37599490608086594 , Val Acc : 0.38461538461538464\n",
      "Epoch 811/10000, Loss: 1.6447539329528809, Train Acc : 0.3772683858643744 , Val Acc : 0.38461538461538464\n",
      "Epoch 812/10000, Loss: 1.7160176038742065, Train Acc : 0.3763132760267431 , Val Acc : 0.38461538461538464\n",
      "Epoch 813/10000, Loss: 1.6403805017471313, Train Acc : 0.3772683858643744 , Val Acc : 0.382051282051282\n",
      "Epoch 814/10000, Loss: 1.696351408958435, Train Acc : 0.37663164597262017 , Val Acc : 0.38461538461538464\n",
      "Epoch 815/10000, Loss: 1.6677398681640625, Train Acc : 0.37822349570200575 , Val Acc : 0.38461538461538464\n",
      "Epoch 816/10000, Loss: 1.6907055377960205, Train Acc : 0.37758675581025153 , Val Acc : 0.38461538461538464\n",
      "Epoch 817/10000, Loss: 1.7549301385879517, Train Acc : 0.37886023559376 , Val Acc : 0.38461538461538464\n",
      "Epoch 818/10000, Loss: 1.6957682371139526, Train Acc : 0.3804520853231455 , Val Acc : 0.38461538461538464\n",
      "Epoch 819/10000, Loss: 1.7276362180709839, Train Acc : 0.37917860553963706 , Val Acc : 0.38461538461538464\n",
      "Epoch 820/10000, Loss: 1.647229790687561, Train Acc : 0.3807704552690226 , Val Acc : 0.38461538461538464\n",
      "Epoch 821/10000, Loss: 1.6427881717681885, Train Acc : 0.3807704552690226 , Val Acc : 0.38461538461538464\n",
      "Epoch 822/10000, Loss: 1.6756858825683594, Train Acc : 0.3807704552690226 , Val Acc : 0.38461538461538464\n",
      "Epoch 823/10000, Loss: 1.6722837686538696, Train Acc : 0.3807704552690226 , Val Acc : 0.38461538461538464\n",
      "Epoch 824/10000, Loss: 1.6853904724121094, Train Acc : 0.38013371537726837 , Val Acc : 0.38461538461538464\n",
      "Epoch 825/10000, Loss: 1.7004871368408203, Train Acc : 0.38013371537726837 , Val Acc : 0.38461538461538464\n",
      "Epoch 826/10000, Loss: 1.6962753534317017, Train Acc : 0.38108882521489973 , Val Acc : 0.38461538461538464\n",
      "Epoch 827/10000, Loss: 1.6913127899169922, Train Acc : 0.3807704552690226 , Val Acc : 0.3871794871794872\n",
      "Epoch 828/10000, Loss: 1.6299444437026978, Train Acc : 0.3807704552690226 , Val Acc : 0.38974358974358975\n",
      "Epoch 829/10000, Loss: 1.7273426055908203, Train Acc : 0.38172556510665395 , Val Acc : 0.3871794871794872\n",
      "Epoch 830/10000, Loss: 1.6597439050674438, Train Acc : 0.3804520853231455 , Val Acc : 0.3871794871794872\n",
      "Epoch 831/10000, Loss: 1.6528196334838867, Train Acc : 0.38013371537726837 , Val Acc : 0.3871794871794872\n",
      "Epoch 832/10000, Loss: 1.6633821725845337, Train Acc : 0.3814071951607768 , Val Acc : 0.3871794871794872\n",
      "Epoch 833/10000, Loss: 1.659957766532898, Train Acc : 0.3804520853231455 , Val Acc : 0.38461538461538464\n",
      "Epoch 834/10000, Loss: 1.6883989572525024, Train Acc : 0.3807704552690226 , Val Acc : 0.3871794871794872\n",
      "Epoch 835/10000, Loss: 1.655690312385559, Train Acc : 0.38108882521489973 , Val Acc : 0.38461538461538464\n",
      "Epoch 836/10000, Loss: 1.6685277223587036, Train Acc : 0.38204393505253104 , Val Acc : 0.38461538461538464\n",
      "Epoch 837/10000, Loss: 1.6724591255187988, Train Acc : 0.38172556510665395 , Val Acc : 0.3871794871794872\n",
      "Epoch 838/10000, Loss: 1.679425835609436, Train Acc : 0.3814071951607768 , Val Acc : 0.3871794871794872\n",
      "Epoch 839/10000, Loss: 1.6603721380233765, Train Acc : 0.3833174148360395 , Val Acc : 0.38974358974358975\n",
      "Epoch 840/10000, Loss: 1.731284260749817, Train Acc : 0.38299904489016234 , Val Acc : 0.38974358974358975\n",
      "Epoch 841/10000, Loss: 1.7380237579345703, Train Acc : 0.3839541547277937 , Val Acc : 0.3871794871794872\n",
      "Epoch 842/10000, Loss: 1.707969307899475, Train Acc : 0.38268067494428526 , Val Acc : 0.3871794871794872\n",
      "Epoch 843/10000, Loss: 1.6592155694961548, Train Acc : 0.38299904489016234 , Val Acc : 0.3871794871794872\n",
      "Epoch 844/10000, Loss: 1.716072678565979, Train Acc : 0.38172556510665395 , Val Acc : 0.3871794871794872\n",
      "Epoch 845/10000, Loss: 1.724419116973877, Train Acc : 0.3833174148360395 , Val Acc : 0.38974358974358975\n",
      "Epoch 846/10000, Loss: 1.7171989679336548, Train Acc : 0.3833174148360395 , Val Acc : 0.3871794871794872\n",
      "Epoch 847/10000, Loss: 1.641675591468811, Train Acc : 0.38459089461954793 , Val Acc : 0.3871794871794872\n",
      "Epoch 848/10000, Loss: 1.6516166925430298, Train Acc : 0.3839541547277937 , Val Acc : 0.38974358974358975\n",
      "Epoch 849/10000, Loss: 1.6650023460388184, Train Acc : 0.38299904489016234 , Val Acc : 0.38974358974358975\n",
      "Epoch 850/10000, Loss: 1.6130356788635254, Train Acc : 0.38363578478191657 , Val Acc : 0.38974358974358975\n",
      "Epoch 851/10000, Loss: 1.6403918266296387, Train Acc : 0.3842725246736708 , Val Acc : 0.38974358974358975\n",
      "Epoch 852/10000, Loss: 1.6585991382598877, Train Acc : 0.38459089461954793 , Val Acc : 0.38974358974358975\n",
      "Epoch 853/10000, Loss: 1.6650216579437256, Train Acc : 0.3842725246736708 , Val Acc : 0.38974358974358975\n",
      "Epoch 854/10000, Loss: 1.7040059566497803, Train Acc : 0.38522763451130215 , Val Acc : 0.38974358974358975\n",
      "Epoch 855/10000, Loss: 1.6864972114562988, Train Acc : 0.384909264565425 , Val Acc : 0.38974358974358975\n",
      "Epoch 856/10000, Loss: 1.6629438400268555, Train Acc : 0.38459089461954793 , Val Acc : 0.3871794871794872\n",
      "Epoch 857/10000, Loss: 1.762316107749939, Train Acc : 0.38459089461954793 , Val Acc : 0.3871794871794872\n",
      "Epoch 858/10000, Loss: 1.6538500785827637, Train Acc : 0.38459089461954793 , Val Acc : 0.38974358974358975\n",
      "Epoch 859/10000, Loss: 1.683334231376648, Train Acc : 0.38363578478191657 , Val Acc : 0.38974358974358975\n",
      "Epoch 860/10000, Loss: 1.6642035245895386, Train Acc : 0.3842725246736708 , Val Acc : 0.38974358974358975\n",
      "Epoch 861/10000, Loss: 1.6523082256317139, Train Acc : 0.3842725246736708 , Val Acc : 0.38974358974358975\n",
      "Epoch 862/10000, Loss: 1.6583375930786133, Train Acc : 0.3842725246736708 , Val Acc : 0.38974358974358975\n",
      "Epoch 863/10000, Loss: 1.6333229541778564, Train Acc : 0.38459089461954793 , Val Acc : 0.38974358974358975\n",
      "Epoch 864/10000, Loss: 1.5819483995437622, Train Acc : 0.38459089461954793 , Val Acc : 0.3923076923076923\n",
      "Epoch 865/10000, Loss: 1.7015655040740967, Train Acc : 0.38554600445717924 , Val Acc : 0.3923076923076923\n",
      "Epoch 866/10000, Loss: 1.6285450458526611, Train Acc : 0.38459089461954793 , Val Acc : 0.3923076923076923\n",
      "Epoch 867/10000, Loss: 1.7100902795791626, Train Acc : 0.38459089461954793 , Val Acc : 0.3923076923076923\n",
      "Epoch 868/10000, Loss: 1.7739830017089844, Train Acc : 0.38522763451130215 , Val Acc : 0.3923076923076923\n",
      "Epoch 869/10000, Loss: 1.6310713291168213, Train Acc : 0.38459089461954793 , Val Acc : 0.3923076923076923\n",
      "Epoch 870/10000, Loss: 1.6944094896316528, Train Acc : 0.3858643744030564 , Val Acc : 0.38974358974358975\n",
      "Epoch 871/10000, Loss: 1.7020072937011719, Train Acc : 0.38554600445717924 , Val Acc : 0.3923076923076923\n",
      "Epoch 872/10000, Loss: 1.6903297901153564, Train Acc : 0.384909264565425 , Val Acc : 0.3923076923076923\n",
      "Epoch 873/10000, Loss: 1.6293660402297974, Train Acc : 0.3858643744030564 , Val Acc : 0.3923076923076923\n",
      "Epoch 874/10000, Loss: 1.6957138776779175, Train Acc : 0.38522763451130215 , Val Acc : 0.3923076923076923\n",
      "Epoch 875/10000, Loss: 1.6826025247573853, Train Acc : 0.38522763451130215 , Val Acc : 0.3923076923076923\n",
      "Epoch 876/10000, Loss: 1.6841590404510498, Train Acc : 0.38522763451130215 , Val Acc : 0.3923076923076923\n",
      "Epoch 877/10000, Loss: 1.7016657590866089, Train Acc : 0.38554600445717924 , Val Acc : 0.3923076923076923\n",
      "Epoch 878/10000, Loss: 1.699800729751587, Train Acc : 0.38618274434893346 , Val Acc : 0.3923076923076923\n",
      "Epoch 879/10000, Loss: 1.6686478853225708, Train Acc : 0.38522763451130215 , Val Acc : 0.3923076923076923\n",
      "Epoch 880/10000, Loss: 1.680200219154358, Train Acc : 0.3858643744030564 , Val Acc : 0.3923076923076923\n",
      "Epoch 881/10000, Loss: 1.661242961883545, Train Acc : 0.38618274434893346 , Val Acc : 0.3923076923076923\n",
      "Epoch 882/10000, Loss: 1.6744061708450317, Train Acc : 0.38554600445717924 , Val Acc : 0.38974358974358975\n",
      "Epoch 883/10000, Loss: 1.6843260526657104, Train Acc : 0.3858643744030564 , Val Acc : 0.3923076923076923\n",
      "Epoch 884/10000, Loss: 1.6607342958450317, Train Acc : 0.384909264565425 , Val Acc : 0.3923076923076923\n",
      "Epoch 885/10000, Loss: 1.6702618598937988, Train Acc : 0.38522763451130215 , Val Acc : 0.3923076923076923\n",
      "Epoch 886/10000, Loss: 1.6879615783691406, Train Acc : 0.38618274434893346 , Val Acc : 0.3923076923076923\n",
      "Epoch 887/10000, Loss: 1.6676063537597656, Train Acc : 0.38459089461954793 , Val Acc : 0.3923076923076923\n",
      "Epoch 888/10000, Loss: 1.7186486721038818, Train Acc : 0.38618274434893346 , Val Acc : 0.3923076923076923\n",
      "Epoch 889/10000, Loss: 1.6586681604385376, Train Acc : 0.3874562241324419 , Val Acc : 0.3923076923076923\n",
      "Epoch 890/10000, Loss: 1.682904839515686, Train Acc : 0.387774594078319 , Val Acc : 0.3923076923076923\n",
      "Epoch 891/10000, Loss: 1.675522804260254, Train Acc : 0.38650111429481054 , Val Acc : 0.3923076923076923\n",
      "Epoch 892/10000, Loss: 1.6383800506591797, Train Acc : 0.3874562241324419 , Val Acc : 0.3923076923076923\n",
      "Epoch 893/10000, Loss: 1.6393890380859375, Train Acc : 0.38650111429481054 , Val Acc : 0.3923076923076923\n",
      "Epoch 894/10000, Loss: 1.6818249225616455, Train Acc : 0.3858643744030564 , Val Acc : 0.39487179487179486\n",
      "Epoch 895/10000, Loss: 1.656657099723816, Train Acc : 0.3858643744030564 , Val Acc : 0.39487179487179486\n",
      "Epoch 896/10000, Loss: 1.7275886535644531, Train Acc : 0.38650111429481054 , Val Acc : 0.39487179487179486\n",
      "Epoch 897/10000, Loss: 1.6407387256622314, Train Acc : 0.3858643744030564 , Val Acc : 0.3923076923076923\n",
      "Epoch 898/10000, Loss: 1.717810034751892, Train Acc : 0.3858643744030564 , Val Acc : 0.39487179487179486\n",
      "Epoch 899/10000, Loss: 1.7380032539367676, Train Acc : 0.3858643744030564 , Val Acc : 0.3974358974358974\n",
      "Epoch 900/10000, Loss: 1.742052435874939, Train Acc : 0.38618274434893346 , Val Acc : 0.3974358974358974\n",
      "Epoch 901/10000, Loss: 1.660652756690979, Train Acc : 0.3858643744030564 , Val Acc : 0.3871794871794872\n",
      "Epoch 902/10000, Loss: 1.6894270181655884, Train Acc : 0.38522763451130215 , Val Acc : 0.39487179487179486\n",
      "Epoch 903/10000, Loss: 1.6388359069824219, Train Acc : 0.38522763451130215 , Val Acc : 0.38974358974358975\n",
      "Epoch 904/10000, Loss: 1.6439335346221924, Train Acc : 0.38713785418656477 , Val Acc : 0.3974358974358974\n",
      "Epoch 905/10000, Loss: 1.6605513095855713, Train Acc : 0.3874562241324419 , Val Acc : 0.3923076923076923\n",
      "Epoch 906/10000, Loss: 1.7275141477584839, Train Acc : 0.38618274434893346 , Val Acc : 0.3923076923076923\n",
      "Epoch 907/10000, Loss: 1.676315426826477, Train Acc : 0.3858643744030564 , Val Acc : 0.38974358974358975\n",
      "Epoch 908/10000, Loss: 1.7132266759872437, Train Acc : 0.38650111429481054 , Val Acc : 0.4\n",
      "Epoch 909/10000, Loss: 1.645459771156311, Train Acc : 0.38713785418656477 , Val Acc : 0.3923076923076923\n",
      "Epoch 910/10000, Loss: 1.6728858947753906, Train Acc : 0.38554600445717924 , Val Acc : 0.4\n",
      "Epoch 911/10000, Loss: 1.7186601161956787, Train Acc : 0.3868194842406877 , Val Acc : 0.3923076923076923\n",
      "Epoch 912/10000, Loss: 1.598595380783081, Train Acc : 0.387774594078319 , Val Acc : 0.39487179487179486\n",
      "Epoch 913/10000, Loss: 1.704874038696289, Train Acc : 0.38650111429481054 , Val Acc : 0.38974358974358975\n",
      "Epoch 914/10000, Loss: 1.709053635597229, Train Acc : 0.38713785418656477 , Val Acc : 0.39487179487179486\n",
      "Epoch 915/10000, Loss: 1.7306267023086548, Train Acc : 0.3868194842406877 , Val Acc : 0.3923076923076923\n",
      "Epoch 916/10000, Loss: 1.6546382904052734, Train Acc : 0.3874562241324419 , Val Acc : 0.38974358974358975\n",
      "Epoch 917/10000, Loss: 1.6964478492736816, Train Acc : 0.387774594078319 , Val Acc : 0.39487179487179486\n",
      "Epoch 918/10000, Loss: 1.6928428411483765, Train Acc : 0.38809296402419613 , Val Acc : 0.3923076923076923\n",
      "Epoch 919/10000, Loss: 1.7107852697372437, Train Acc : 0.3868194842406877 , Val Acc : 0.3923076923076923\n",
      "Epoch 920/10000, Loss: 1.6652843952178955, Train Acc : 0.38809296402419613 , Val Acc : 0.3923076923076923\n",
      "Epoch 921/10000, Loss: 1.6746867895126343, Train Acc : 0.38809296402419613 , Val Acc : 0.3923076923076923\n",
      "Epoch 922/10000, Loss: 1.642950177192688, Train Acc : 0.3884113339700732 , Val Acc : 0.38974358974358975\n",
      "Epoch 923/10000, Loss: 1.6704368591308594, Train Acc : 0.38968481375358166 , Val Acc : 0.3974358974358974\n",
      "Epoch 924/10000, Loss: 1.6457856893539429, Train Acc : 0.3874562241324419 , Val Acc : 0.38974358974358975\n",
      "Epoch 925/10000, Loss: 1.6612457036972046, Train Acc : 0.3874562241324419 , Val Acc : 0.3923076923076923\n",
      "Epoch 926/10000, Loss: 1.6943910121917725, Train Acc : 0.3893664438077046 , Val Acc : 0.3923076923076923\n",
      "Epoch 927/10000, Loss: 1.6367695331573486, Train Acc : 0.38809296402419613 , Val Acc : 0.3923076923076923\n",
      "Epoch 928/10000, Loss: 1.7377946376800537, Train Acc : 0.38904807386182744 , Val Acc : 0.38974358974358975\n",
      "Epoch 929/10000, Loss: 1.7181941270828247, Train Acc : 0.38904807386182744 , Val Acc : 0.38974358974358975\n",
      "Epoch 930/10000, Loss: 1.640056848526001, Train Acc : 0.38809296402419613 , Val Acc : 0.38974358974358975\n",
      "Epoch 931/10000, Loss: 1.7163482904434204, Train Acc : 0.38968481375358166 , Val Acc : 0.39487179487179486\n",
      "Epoch 932/10000, Loss: 1.6397455930709839, Train Acc : 0.3912766634829672 , Val Acc : 0.3974358974358974\n",
      "Epoch 933/10000, Loss: 1.69684898853302, Train Acc : 0.3909582935370901 , Val Acc : 0.3974358974358974\n",
      "Epoch 934/10000, Loss: 1.6359928846359253, Train Acc : 0.3912766634829672 , Val Acc : 0.3923076923076923\n",
      "Epoch 935/10000, Loss: 1.6842061281204224, Train Acc : 0.39000318369945874 , Val Acc : 0.3974358974358974\n",
      "Epoch 936/10000, Loss: 1.6448936462402344, Train Acc : 0.39063992359121297 , Val Acc : 0.3923076923076923\n",
      "Epoch 937/10000, Loss: 1.63870108127594, Train Acc : 0.3912766634829672 , Val Acc : 0.3923076923076923\n",
      "Epoch 938/10000, Loss: 1.6084641218185425, Train Acc : 0.3909582935370901 , Val Acc : 0.3974358974358974\n",
      "Epoch 939/10000, Loss: 1.7002177238464355, Train Acc : 0.3909582935370901 , Val Acc : 0.3974358974358974\n",
      "Epoch 940/10000, Loss: 1.6721611022949219, Train Acc : 0.3919134033747214 , Val Acc : 0.3974358974358974\n",
      "Epoch 941/10000, Loss: 1.6589967012405396, Train Acc : 0.39159503342884433 , Val Acc : 0.3974358974358974\n",
      "Epoch 942/10000, Loss: 1.7012107372283936, Train Acc : 0.3919134033747214 , Val Acc : 0.4\n",
      "Epoch 943/10000, Loss: 1.6695945262908936, Train Acc : 0.39159503342884433 , Val Acc : 0.39487179487179486\n",
      "Epoch 944/10000, Loss: 1.6599576473236084, Train Acc : 0.39063992359121297 , Val Acc : 0.39487179487179486\n",
      "Epoch 945/10000, Loss: 1.6842025518417358, Train Acc : 0.3912766634829672 , Val Acc : 0.4\n",
      "Epoch 946/10000, Loss: 1.7419625520706177, Train Acc : 0.3912766634829672 , Val Acc : 0.3923076923076923\n",
      "Epoch 947/10000, Loss: 1.6561301946640015, Train Acc : 0.3912766634829672 , Val Acc : 0.3923076923076923\n",
      "Epoch 948/10000, Loss: 1.6380133628845215, Train Acc : 0.3903215536453359 , Val Acc : 0.39487179487179486\n",
      "Epoch 949/10000, Loss: 1.6810181140899658, Train Acc : 0.39223177332059855 , Val Acc : 0.4\n",
      "Epoch 950/10000, Loss: 1.6874589920043945, Train Acc : 0.39255014326647564 , Val Acc : 0.4\n",
      "Epoch 951/10000, Loss: 1.6536797285079956, Train Acc : 0.39223177332059855 , Val Acc : 0.3974358974358974\n",
      "Epoch 952/10000, Loss: 1.698468565940857, Train Acc : 0.3919134033747214 , Val Acc : 0.39487179487179486\n",
      "Epoch 953/10000, Loss: 1.684840202331543, Train Acc : 0.39255014326647564 , Val Acc : 0.4\n",
      "Epoch 954/10000, Loss: 1.6663581132888794, Train Acc : 0.39223177332059855 , Val Acc : 0.4\n",
      "Epoch 955/10000, Loss: 1.6969283819198608, Train Acc : 0.3928685132123528 , Val Acc : 0.4\n",
      "Epoch 956/10000, Loss: 1.6892216205596924, Train Acc : 0.3928685132123528 , Val Acc : 0.4\n",
      "Epoch 957/10000, Loss: 1.6707959175109863, Train Acc : 0.39223177332059855 , Val Acc : 0.4\n",
      "Epoch 958/10000, Loss: 1.7062122821807861, Train Acc : 0.39318688315822986 , Val Acc : 0.4\n",
      "Epoch 959/10000, Loss: 1.7183916568756104, Train Acc : 0.39255014326647564 , Val Acc : 0.4\n",
      "Epoch 960/10000, Loss: 1.6525245904922485, Train Acc : 0.39318688315822986 , Val Acc : 0.4\n",
      "Epoch 961/10000, Loss: 1.650044560432434, Train Acc : 0.3928685132123528 , Val Acc : 0.40512820512820513\n",
      "Epoch 962/10000, Loss: 1.7386075258255005, Train Acc : 0.39318688315822986 , Val Acc : 0.4025641025641026\n",
      "Epoch 963/10000, Loss: 1.6402347087860107, Train Acc : 0.39318688315822986 , Val Acc : 0.4025641025641026\n",
      "Epoch 964/10000, Loss: 1.719971776008606, Train Acc : 0.3912766634829672 , Val Acc : 0.3974358974358974\n",
      "Epoch 965/10000, Loss: 1.6999751329421997, Train Acc : 0.39318688315822986 , Val Acc : 0.4025641025641026\n",
      "Epoch 966/10000, Loss: 1.620503544807434, Train Acc : 0.39414199299586117 , Val Acc : 0.4025641025641026\n",
      "Epoch 967/10000, Loss: 1.6460751295089722, Train Acc : 0.3954154727793696 , Val Acc : 0.40512820512820513\n",
      "Epoch 968/10000, Loss: 1.6547685861587524, Train Acc : 0.3944603629417383 , Val Acc : 0.40512820512820513\n",
      "Epoch 969/10000, Loss: 1.714104413986206, Train Acc : 0.3938236230499841 , Val Acc : 0.40512820512820513\n",
      "Epoch 970/10000, Loss: 1.655670404434204, Train Acc : 0.39414199299586117 , Val Acc : 0.40512820512820513\n",
      "Epoch 971/10000, Loss: 1.685134768486023, Train Acc : 0.3947787328876154 , Val Acc : 0.40512820512820513\n",
      "Epoch 972/10000, Loss: 1.6523537635803223, Train Acc : 0.39573384272524675 , Val Acc : 0.4025641025641026\n",
      "Epoch 973/10000, Loss: 1.6523842811584473, Train Acc : 0.39350525310410694 , Val Acc : 0.4025641025641026\n",
      "Epoch 974/10000, Loss: 1.6640658378601074, Train Acc : 0.39414199299586117 , Val Acc : 0.4025641025641026\n",
      "Epoch 975/10000, Loss: 1.726965069770813, Train Acc : 0.3938236230499841 , Val Acc : 0.4025641025641026\n",
      "Epoch 976/10000, Loss: 1.6942927837371826, Train Acc : 0.3938236230499841 , Val Acc : 0.4025641025641026\n",
      "Epoch 977/10000, Loss: 1.6592097282409668, Train Acc : 0.3944603629417383 , Val Acc : 0.4025641025641026\n",
      "Epoch 978/10000, Loss: 1.6961818933486938, Train Acc : 0.3947787328876154 , Val Acc : 0.40512820512820513\n",
      "Epoch 979/10000, Loss: 1.691070318222046, Train Acc : 0.39509710283349253 , Val Acc : 0.40512820512820513\n",
      "Epoch 980/10000, Loss: 1.6398497819900513, Train Acc : 0.3947787328876154 , Val Acc : 0.40512820512820513\n",
      "Epoch 981/10000, Loss: 1.7043957710266113, Train Acc : 0.3947787328876154 , Val Acc : 0.40512820512820513\n",
      "Epoch 982/10000, Loss: 1.6515635251998901, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 983/10000, Loss: 1.6422245502471924, Train Acc : 0.3947787328876154 , Val Acc : 0.4025641025641026\n",
      "Epoch 984/10000, Loss: 1.6766464710235596, Train Acc : 0.39414199299586117 , Val Acc : 0.40512820512820513\n",
      "Epoch 985/10000, Loss: 1.7329353094100952, Train Acc : 0.39509710283349253 , Val Acc : 0.40512820512820513\n",
      "Epoch 986/10000, Loss: 1.6175074577331543, Train Acc : 0.3947787328876154 , Val Acc : 0.40512820512820513\n",
      "Epoch 987/10000, Loss: 1.6769163608551025, Train Acc : 0.3954154727793696 , Val Acc : 0.40512820512820513\n",
      "Epoch 988/10000, Loss: 1.7073650360107422, Train Acc : 0.39509710283349253 , Val Acc : 0.40512820512820513\n",
      "Epoch 989/10000, Loss: 1.662270426750183, Train Acc : 0.39573384272524675 , Val Acc : 0.3974358974358974\n",
      "Epoch 990/10000, Loss: 1.6253374814987183, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 991/10000, Loss: 1.6555616855621338, Train Acc : 0.39509710283349253 , Val Acc : 0.40512820512820513\n",
      "Epoch 992/10000, Loss: 1.6669241189956665, Train Acc : 0.3954154727793696 , Val Acc : 0.40512820512820513\n",
      "Epoch 993/10000, Loss: 1.706976294517517, Train Acc : 0.3954154727793696 , Val Acc : 0.40512820512820513\n",
      "Epoch 994/10000, Loss: 1.6937785148620605, Train Acc : 0.39573384272524675 , Val Acc : 0.4025641025641026\n",
      "Epoch 995/10000, Loss: 1.7261720895767212, Train Acc : 0.39509710283349253 , Val Acc : 0.40512820512820513\n",
      "Epoch 996/10000, Loss: 1.6541807651519775, Train Acc : 0.39605221267112384 , Val Acc : 0.4025641025641026\n",
      "Epoch 997/10000, Loss: 1.673706293106079, Train Acc : 0.3954154727793696 , Val Acc : 0.40512820512820513\n",
      "Epoch 998/10000, Loss: 1.6942362785339355, Train Acc : 0.39573384272524675 , Val Acc : 0.4025641025641026\n",
      "Epoch 999/10000, Loss: 1.6866930723190308, Train Acc : 0.3954154727793696 , Val Acc : 0.39487179487179486\n",
      "Epoch 1000/10000, Loss: 1.6573466062545776, Train Acc : 0.3944603629417383 , Val Acc : 0.4025641025641026\n",
      "Epoch 1001/10000, Loss: 1.7194544076919556, Train Acc : 0.39509710283349253 , Val Acc : 0.3974358974358974\n",
      "Epoch 1002/10000, Loss: 1.6811835765838623, Train Acc : 0.39605221267112384 , Val Acc : 0.3974358974358974\n",
      "Epoch 1003/10000, Loss: 1.731823205947876, Train Acc : 0.3973256924546323 , Val Acc : 0.39487179487179486\n",
      "Epoch 1004/10000, Loss: 1.6547728776931763, Train Acc : 0.39668895256287806 , Val Acc : 0.3974358974358974\n",
      "Epoch 1005/10000, Loss: 1.6851921081542969, Train Acc : 0.3970073225087552 , Val Acc : 0.40512820512820513\n",
      "Epoch 1006/10000, Loss: 1.670702338218689, Train Acc : 0.39668895256287806 , Val Acc : 0.4025641025641026\n",
      "Epoch 1007/10000, Loss: 1.6386359930038452, Train Acc : 0.396370582617001 , Val Acc : 0.39487179487179486\n",
      "Epoch 1008/10000, Loss: 1.6737264394760132, Train Acc : 0.39668895256287806 , Val Acc : 0.39487179487179486\n",
      "Epoch 1009/10000, Loss: 1.7380026578903198, Train Acc : 0.3973256924546323 , Val Acc : 0.40512820512820513\n",
      "Epoch 1010/10000, Loss: 1.6661410331726074, Train Acc : 0.39605221267112384 , Val Acc : 0.3974358974358974\n",
      "Epoch 1011/10000, Loss: 1.6951614618301392, Train Acc : 0.39668895256287806 , Val Acc : 0.3974358974358974\n",
      "Epoch 1012/10000, Loss: 1.6491422653198242, Train Acc : 0.3970073225087552 , Val Acc : 0.40512820512820513\n",
      "Epoch 1013/10000, Loss: 1.6490397453308105, Train Acc : 0.3970073225087552 , Val Acc : 0.40512820512820513\n",
      "Epoch 1014/10000, Loss: 1.6350579261779785, Train Acc : 0.39668895256287806 , Val Acc : 0.4\n",
      "Epoch 1015/10000, Loss: 1.7021986246109009, Train Acc : 0.3970073225087552 , Val Acc : 0.39487179487179486\n",
      "Epoch 1016/10000, Loss: 1.611271619796753, Train Acc : 0.396370582617001 , Val Acc : 0.40512820512820513\n",
      "Epoch 1017/10000, Loss: 1.6699377298355103, Train Acc : 0.3973256924546323 , Val Acc : 0.3974358974358974\n",
      "Epoch 1018/10000, Loss: 1.6415916681289673, Train Acc : 0.3970073225087552 , Val Acc : 0.3974358974358974\n",
      "Epoch 1019/10000, Loss: 1.676271677017212, Train Acc : 0.396370582617001 , Val Acc : 0.39487179487179486\n",
      "Epoch 1020/10000, Loss: 1.6447607278823853, Train Acc : 0.396370582617001 , Val Acc : 0.4025641025641026\n",
      "Epoch 1021/10000, Loss: 1.7025038003921509, Train Acc : 0.39668895256287806 , Val Acc : 0.4025641025641026\n",
      "Epoch 1022/10000, Loss: 1.6929349899291992, Train Acc : 0.39668895256287806 , Val Acc : 0.39487179487179486\n",
      "Epoch 1023/10000, Loss: 1.7108997106552124, Train Acc : 0.39668895256287806 , Val Acc : 0.40512820512820513\n",
      "Epoch 1024/10000, Loss: 1.6866039037704468, Train Acc : 0.39668895256287806 , Val Acc : 0.40512820512820513\n",
      "Epoch 1025/10000, Loss: 1.7196273803710938, Train Acc : 0.396370582617001 , Val Acc : 0.39487179487179486\n",
      "Epoch 1026/10000, Loss: 1.6675848960876465, Train Acc : 0.3979624323463865 , Val Acc : 0.40512820512820513\n",
      "Epoch 1027/10000, Loss: 1.661440372467041, Train Acc : 0.39668895256287806 , Val Acc : 0.39487179487179486\n",
      "Epoch 1028/10000, Loss: 1.6384077072143555, Train Acc : 0.396370582617001 , Val Acc : 0.39487179487179486\n",
      "Epoch 1029/10000, Loss: 1.6998436450958252, Train Acc : 0.39668895256287806 , Val Acc : 0.4076923076923077\n",
      "Epoch 1030/10000, Loss: 1.6942224502563477, Train Acc : 0.396370582617001 , Val Acc : 0.3974358974358974\n",
      "Epoch 1031/10000, Loss: 1.6512095928192139, Train Acc : 0.39605221267112384 , Val Acc : 0.3974358974358974\n",
      "Epoch 1032/10000, Loss: 1.6664955615997314, Train Acc : 0.39605221267112384 , Val Acc : 0.4\n",
      "Epoch 1033/10000, Loss: 1.6742753982543945, Train Acc : 0.39573384272524675 , Val Acc : 0.4\n",
      "Epoch 1034/10000, Loss: 1.6327637434005737, Train Acc : 0.396370582617001 , Val Acc : 0.4025641025641026\n",
      "Epoch 1035/10000, Loss: 1.6249265670776367, Train Acc : 0.39573384272524675 , Val Acc : 0.3974358974358974\n",
      "Epoch 1036/10000, Loss: 1.7338865995407104, Train Acc : 0.396370582617001 , Val Acc : 0.3974358974358974\n",
      "Epoch 1037/10000, Loss: 1.6633116006851196, Train Acc : 0.39605221267112384 , Val Acc : 0.4\n",
      "Epoch 1038/10000, Loss: 1.6740330457687378, Train Acc : 0.39605221267112384 , Val Acc : 0.4\n",
      "Epoch 1039/10000, Loss: 1.6362552642822266, Train Acc : 0.39605221267112384 , Val Acc : 0.4025641025641026\n",
      "Epoch 1040/10000, Loss: 1.7211509943008423, Train Acc : 0.3954154727793696 , Val Acc : 0.4025641025641026\n",
      "Epoch 1041/10000, Loss: 1.6882736682891846, Train Acc : 0.396370582617001 , Val Acc : 0.4\n",
      "Epoch 1042/10000, Loss: 1.678771734237671, Train Acc : 0.39509710283349253 , Val Acc : 0.40512820512820513\n",
      "Epoch 1043/10000, Loss: 1.6987221240997314, Train Acc : 0.39605221267112384 , Val Acc : 0.4025641025641026\n",
      "Epoch 1044/10000, Loss: 1.7031832933425903, Train Acc : 0.3947787328876154 , Val Acc : 0.4076923076923077\n",
      "Epoch 1045/10000, Loss: 1.6563811302185059, Train Acc : 0.39509710283349253 , Val Acc : 0.40512820512820513\n",
      "Epoch 1046/10000, Loss: 1.6982611417770386, Train Acc : 0.39509710283349253 , Val Acc : 0.4076923076923077\n",
      "Epoch 1047/10000, Loss: 1.646705985069275, Train Acc : 0.3947787328876154 , Val Acc : 0.4076923076923077\n",
      "Epoch 1048/10000, Loss: 1.6514922380447388, Train Acc : 0.3938236230499841 , Val Acc : 0.4076923076923077\n",
      "Epoch 1049/10000, Loss: 1.6673498153686523, Train Acc : 0.39605221267112384 , Val Acc : 0.4025641025641026\n",
      "Epoch 1050/10000, Loss: 1.6158778667449951, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 1051/10000, Loss: 1.6736128330230713, Train Acc : 0.39605221267112384 , Val Acc : 0.4\n",
      "Epoch 1052/10000, Loss: 1.6916983127593994, Train Acc : 0.39573384272524675 , Val Acc : 0.4025641025641026\n",
      "Epoch 1053/10000, Loss: 1.6122883558273315, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 1054/10000, Loss: 1.739087700843811, Train Acc : 0.39509710283349253 , Val Acc : 0.40512820512820513\n",
      "Epoch 1055/10000, Loss: 1.689205288887024, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 1056/10000, Loss: 1.64718759059906, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 1057/10000, Loss: 1.6992539167404175, Train Acc : 0.3954154727793696 , Val Acc : 0.4025641025641026\n",
      "Epoch 1058/10000, Loss: 1.6431504487991333, Train Acc : 0.39573384272524675 , Val Acc : 0.4076923076923077\n",
      "Epoch 1059/10000, Loss: 1.6518275737762451, Train Acc : 0.3954154727793696 , Val Acc : 0.40512820512820513\n",
      "Epoch 1060/10000, Loss: 1.7022002935409546, Train Acc : 0.39605221267112384 , Val Acc : 0.40512820512820513\n",
      "Epoch 1061/10000, Loss: 1.6940336227416992, Train Acc : 0.396370582617001 , Val Acc : 0.4025641025641026\n",
      "Epoch 1062/10000, Loss: 1.633081316947937, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 1063/10000, Loss: 1.7331758737564087, Train Acc : 0.39509710283349253 , Val Acc : 0.4025641025641026\n",
      "Epoch 1064/10000, Loss: 1.6747781038284302, Train Acc : 0.396370582617001 , Val Acc : 0.40512820512820513\n",
      "Epoch 1065/10000, Loss: 1.747215986251831, Train Acc : 0.39668895256287806 , Val Acc : 0.4025641025641026\n",
      "Epoch 1066/10000, Loss: 1.6313681602478027, Train Acc : 0.39509710283349253 , Val Acc : 0.40512820512820513\n",
      "Epoch 1067/10000, Loss: 1.620376706123352, Train Acc : 0.3954154727793696 , Val Acc : 0.4\n",
      "Epoch 1068/10000, Loss: 1.6882727146148682, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 1069/10000, Loss: 1.6555310487747192, Train Acc : 0.39605221267112384 , Val Acc : 0.4076923076923077\n",
      "Epoch 1070/10000, Loss: 1.6591999530792236, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 1071/10000, Loss: 1.613619327545166, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 1072/10000, Loss: 1.6399017572402954, Train Acc : 0.396370582617001 , Val Acc : 0.40512820512820513\n",
      "Epoch 1073/10000, Loss: 1.70033860206604, Train Acc : 0.39605221267112384 , Val Acc : 0.4025641025641026\n",
      "Epoch 1074/10000, Loss: 1.6196556091308594, Train Acc : 0.3979624323463865 , Val Acc : 0.40512820512820513\n",
      "Epoch 1075/10000, Loss: 1.639815330505371, Train Acc : 0.39605221267112384 , Val Acc : 0.40512820512820513\n",
      "Epoch 1076/10000, Loss: 1.612844705581665, Train Acc : 0.396370582617001 , Val Acc : 0.4076923076923077\n",
      "Epoch 1077/10000, Loss: 1.6835029125213623, Train Acc : 0.39605221267112384 , Val Acc : 0.40512820512820513\n",
      "Epoch 1078/10000, Loss: 1.6930086612701416, Train Acc : 0.396370582617001 , Val Acc : 0.4025641025641026\n",
      "Epoch 1079/10000, Loss: 1.6941500902175903, Train Acc : 0.396370582617001 , Val Acc : 0.4076923076923077\n",
      "Epoch 1080/10000, Loss: 1.614601731300354, Train Acc : 0.39573384272524675 , Val Acc : 0.40512820512820513\n",
      "Epoch 1081/10000, Loss: 1.6833044290542603, Train Acc : 0.396370582617001 , Val Acc : 0.40512820512820513\n",
      "Epoch 1082/10000, Loss: 1.646192193031311, Train Acc : 0.3970073225087552 , Val Acc : 0.4076923076923077\n",
      "Epoch 1083/10000, Loss: 1.6393502950668335, Train Acc : 0.39509710283349253 , Val Acc : 0.4025641025641026\n",
      "Epoch 1084/10000, Loss: 1.6671226024627686, Train Acc : 0.39605221267112384 , Val Acc : 0.40512820512820513\n",
      "Epoch 1085/10000, Loss: 1.6589515209197998, Train Acc : 0.396370582617001 , Val Acc : 0.40512820512820513\n",
      "Epoch 1086/10000, Loss: 1.7410216331481934, Train Acc : 0.39605221267112384 , Val Acc : 0.40512820512820513\n",
      "Epoch 1087/10000, Loss: 1.6663614511489868, Train Acc : 0.39605221267112384 , Val Acc : 0.40512820512820513\n",
      "Epoch 1088/10000, Loss: 1.6616941690444946, Train Acc : 0.39605221267112384 , Val Acc : 0.4025641025641026\n",
      "Epoch 1089/10000, Loss: 1.620369553565979, Train Acc : 0.3970073225087552 , Val Acc : 0.41025641025641024\n",
      "Epoch 1090/10000, Loss: 1.7095918655395508, Train Acc : 0.396370582617001 , Val Acc : 0.40512820512820513\n",
      "Epoch 1091/10000, Loss: 1.6671209335327148, Train Acc : 0.3989175421840178 , Val Acc : 0.40512820512820513\n",
      "Epoch 1092/10000, Loss: 1.6930831670761108, Train Acc : 0.3973256924546323 , Val Acc : 0.40512820512820513\n",
      "Epoch 1093/10000, Loss: 1.6830905675888062, Train Acc : 0.3970073225087552 , Val Acc : 0.40512820512820513\n",
      "Epoch 1094/10000, Loss: 1.6120750904083252, Train Acc : 0.39668895256287806 , Val Acc : 0.4025641025641026\n",
      "Epoch 1095/10000, Loss: 1.713646650314331, Train Acc : 0.3970073225087552 , Val Acc : 0.40512820512820513\n",
      "Epoch 1096/10000, Loss: 1.6717798709869385, Train Acc : 0.39764406240050937 , Val Acc : 0.40512820512820513\n",
      "Epoch 1097/10000, Loss: 1.7067245244979858, Train Acc : 0.3973256924546323 , Val Acc : 0.40512820512820513\n",
      "Epoch 1098/10000, Loss: 1.6905624866485596, Train Acc : 0.3973256924546323 , Val Acc : 0.40512820512820513\n",
      "Epoch 1099/10000, Loss: 1.6323641538619995, Train Acc : 0.3982808022922636 , Val Acc : 0.40512820512820513\n",
      "Epoch 1100/10000, Loss: 1.6463978290557861, Train Acc : 0.3973256924546323 , Val Acc : 0.4025641025641026\n",
      "Epoch 1101/10000, Loss: 1.6849088668823242, Train Acc : 0.3970073225087552 , Val Acc : 0.40512820512820513\n",
      "Epoch 1102/10000, Loss: 1.612502098083496, Train Acc : 0.3973256924546323 , Val Acc : 0.40512820512820513\n",
      "Epoch 1103/10000, Loss: 1.6629221439361572, Train Acc : 0.39764406240050937 , Val Acc : 0.4025641025641026\n",
      "Epoch 1104/10000, Loss: 1.6079304218292236, Train Acc : 0.3979624323463865 , Val Acc : 0.4025641025641026\n",
      "Epoch 1105/10000, Loss: 1.7136887311935425, Train Acc : 0.396370582617001 , Val Acc : 0.4025641025641026\n",
      "Epoch 1106/10000, Loss: 1.65205979347229, Train Acc : 0.39764406240050937 , Val Acc : 0.4025641025641026\n",
      "Epoch 1107/10000, Loss: 1.6703013181686401, Train Acc : 0.39764406240050937 , Val Acc : 0.40512820512820513\n",
      "Epoch 1108/10000, Loss: 1.684796929359436, Train Acc : 0.39764406240050937 , Val Acc : 0.40512820512820513\n",
      "Epoch 1109/10000, Loss: 1.683530569076538, Train Acc : 0.39764406240050937 , Val Acc : 0.4025641025641026\n",
      "Epoch 1110/10000, Loss: 1.6905980110168457, Train Acc : 0.39764406240050937 , Val Acc : 0.4025641025641026\n",
      "Epoch 1111/10000, Loss: 1.7279242277145386, Train Acc : 0.3973256924546323 , Val Acc : 0.4025641025641026\n",
      "Epoch 1112/10000, Loss: 1.6787632703781128, Train Acc : 0.3979624323463865 , Val Acc : 0.4025641025641026\n",
      "Epoch 1113/10000, Loss: 1.6776663064956665, Train Acc : 0.3982808022922636 , Val Acc : 0.4025641025641026\n",
      "Epoch 1114/10000, Loss: 1.6638672351837158, Train Acc : 0.3982808022922636 , Val Acc : 0.4025641025641026\n",
      "Epoch 1115/10000, Loss: 1.7048743963241577, Train Acc : 0.39859917223814073 , Val Acc : 0.40512820512820513\n",
      "Epoch 1116/10000, Loss: 1.6452434062957764, Train Acc : 0.39859917223814073 , Val Acc : 0.40512820512820513\n",
      "Epoch 1117/10000, Loss: 1.6517016887664795, Train Acc : 0.3982808022922636 , Val Acc : 0.40512820512820513\n",
      "Epoch 1118/10000, Loss: 1.6745288372039795, Train Acc : 0.39764406240050937 , Val Acc : 0.40512820512820513\n",
      "Epoch 1119/10000, Loss: 1.6590880155563354, Train Acc : 0.39859917223814073 , Val Acc : 0.40512820512820513\n",
      "Epoch 1120/10000, Loss: 1.6639503240585327, Train Acc : 0.3982808022922636 , Val Acc : 0.4025641025641026\n",
      "Epoch 1121/10000, Loss: 1.6678763628005981, Train Acc : 0.39923591212989495 , Val Acc : 0.4025641025641026\n",
      "Epoch 1122/10000, Loss: 1.6779148578643799, Train Acc : 0.39859917223814073 , Val Acc : 0.4025641025641026\n",
      "Epoch 1123/10000, Loss: 1.691517949104309, Train Acc : 0.39859917223814073 , Val Acc : 0.4025641025641026\n",
      "Epoch 1124/10000, Loss: 1.6646734476089478, Train Acc : 0.39764406240050937 , Val Acc : 0.4025641025641026\n",
      "Epoch 1125/10000, Loss: 1.7509746551513672, Train Acc : 0.39859917223814073 , Val Acc : 0.4025641025641026\n",
      "Epoch 1126/10000, Loss: 1.693927526473999, Train Acc : 0.39923591212989495 , Val Acc : 0.4025641025641026\n",
      "Epoch 1127/10000, Loss: 1.6312263011932373, Train Acc : 0.39859917223814073 , Val Acc : 0.40512820512820513\n",
      "Epoch 1128/10000, Loss: 1.6555836200714111, Train Acc : 0.39923591212989495 , Val Acc : 0.4025641025641026\n",
      "Epoch 1129/10000, Loss: 1.6472816467285156, Train Acc : 0.39923591212989495 , Val Acc : 0.4153846153846154\n",
      "Epoch 1130/10000, Loss: 1.6681195497512817, Train Acc : 0.39955428207577204 , Val Acc : 0.4025641025641026\n",
      "Epoch 1131/10000, Loss: 1.6811389923095703, Train Acc : 0.39955428207577204 , Val Acc : 0.4025641025641026\n",
      "Epoch 1132/10000, Loss: 1.691332221031189, Train Acc : 0.3998726520216492 , Val Acc : 0.4025641025641026\n",
      "Epoch 1133/10000, Loss: 1.6076200008392334, Train Acc : 0.39955428207577204 , Val Acc : 0.40512820512820513\n",
      "Epoch 1134/10000, Loss: 1.6822028160095215, Train Acc : 0.39955428207577204 , Val Acc : 0.4025641025641026\n",
      "Epoch 1135/10000, Loss: 1.6560386419296265, Train Acc : 0.40019102196752626 , Val Acc : 0.4025641025641026\n",
      "Epoch 1136/10000, Loss: 1.6407371759414673, Train Acc : 0.3998726520216492 , Val Acc : 0.4025641025641026\n",
      "Epoch 1137/10000, Loss: 1.7043272256851196, Train Acc : 0.3998726520216492 , Val Acc : 0.4076923076923077\n",
      "Epoch 1138/10000, Loss: 1.7085691690444946, Train Acc : 0.39923591212989495 , Val Acc : 0.4076923076923077\n",
      "Epoch 1139/10000, Loss: 1.654300570487976, Train Acc : 0.3998726520216492 , Val Acc : 0.4025641025641026\n",
      "Epoch 1140/10000, Loss: 1.6341828107833862, Train Acc : 0.40019102196752626 , Val Acc : 0.41025641025641024\n",
      "Epoch 1141/10000, Loss: 1.65851628780365, Train Acc : 0.39955428207577204 , Val Acc : 0.4076923076923077\n",
      "Epoch 1142/10000, Loss: 1.7374627590179443, Train Acc : 0.39955428207577204 , Val Acc : 0.41025641025641024\n",
      "Epoch 1143/10000, Loss: 1.6594280004501343, Train Acc : 0.3998726520216492 , Val Acc : 0.4025641025641026\n",
      "Epoch 1144/10000, Loss: 1.6038212776184082, Train Acc : 0.3989175421840178 , Val Acc : 0.4128205128205128\n",
      "Epoch 1145/10000, Loss: 1.724805474281311, Train Acc : 0.40019102196752626 , Val Acc : 0.4076923076923077\n",
      "Epoch 1146/10000, Loss: 1.6587073802947998, Train Acc : 0.3998726520216492 , Val Acc : 0.4025641025641026\n",
      "Epoch 1147/10000, Loss: 1.6577249765396118, Train Acc : 0.39955428207577204 , Val Acc : 0.40512820512820513\n",
      "Epoch 1148/10000, Loss: 1.7487224340438843, Train Acc : 0.3998726520216492 , Val Acc : 0.4076923076923077\n",
      "Epoch 1149/10000, Loss: 1.6359230279922485, Train Acc : 0.4005093919134034 , Val Acc : 0.4076923076923077\n",
      "Epoch 1150/10000, Loss: 1.6406608819961548, Train Acc : 0.3998726520216492 , Val Acc : 0.4153846153846154\n",
      "Epoch 1151/10000, Loss: 1.666183352470398, Train Acc : 0.4005093919134034 , Val Acc : 0.4076923076923077\n",
      "Epoch 1152/10000, Loss: 1.6525627374649048, Train Acc : 0.40019102196752626 , Val Acc : 0.4128205128205128\n",
      "Epoch 1153/10000, Loss: 1.6599652767181396, Train Acc : 0.4005093919134034 , Val Acc : 0.4153846153846154\n",
      "Epoch 1154/10000, Loss: 1.7350239753723145, Train Acc : 0.40019102196752626 , Val Acc : 0.4128205128205128\n",
      "Epoch 1155/10000, Loss: 1.6362924575805664, Train Acc : 0.3998726520216492 , Val Acc : 0.4076923076923077\n",
      "Epoch 1156/10000, Loss: 1.6228139400482178, Train Acc : 0.40019102196752626 , Val Acc : 0.4076923076923077\n",
      "Epoch 1157/10000, Loss: 1.6277910470962524, Train Acc : 0.40019102196752626 , Val Acc : 0.40512820512820513\n",
      "Epoch 1158/10000, Loss: 1.6163215637207031, Train Acc : 0.4005093919134034 , Val Acc : 0.4128205128205128\n",
      "Epoch 1159/10000, Loss: 1.6786900758743286, Train Acc : 0.3998726520216492 , Val Acc : 0.4128205128205128\n",
      "Epoch 1160/10000, Loss: 1.6446458101272583, Train Acc : 0.40019102196752626 , Val Acc : 0.4128205128205128\n",
      "Epoch 1161/10000, Loss: 1.6295316219329834, Train Acc : 0.4005093919134034 , Val Acc : 0.4128205128205128\n",
      "Epoch 1162/10000, Loss: 1.683301329612732, Train Acc : 0.40019102196752626 , Val Acc : 0.40512820512820513\n",
      "Epoch 1163/10000, Loss: 1.6544609069824219, Train Acc : 0.4005093919134034 , Val Acc : 0.4025641025641026\n",
      "Epoch 1164/10000, Loss: 1.6045016050338745, Train Acc : 0.40114613180515757 , Val Acc : 0.4025641025641026\n",
      "Epoch 1165/10000, Loss: 1.631761074066162, Train Acc : 0.40114613180515757 , Val Acc : 0.4076923076923077\n",
      "Epoch 1166/10000, Loss: 1.7017310857772827, Train Acc : 0.4005093919134034 , Val Acc : 0.4076923076923077\n",
      "Epoch 1167/10000, Loss: 1.6656293869018555, Train Acc : 0.4005093919134034 , Val Acc : 0.4128205128205128\n",
      "Epoch 1168/10000, Loss: 1.6052037477493286, Train Acc : 0.3998726520216492 , Val Acc : 0.41794871794871796\n",
      "Epoch 1169/10000, Loss: 1.6115695238113403, Train Acc : 0.39955428207577204 , Val Acc : 0.4128205128205128\n",
      "Epoch 1170/10000, Loss: 1.7262217998504639, Train Acc : 0.4008277618592805 , Val Acc : 0.4128205128205128\n",
      "Epoch 1171/10000, Loss: 1.6348520517349243, Train Acc : 0.4008277618592805 , Val Acc : 0.4076923076923077\n",
      "Epoch 1172/10000, Loss: 1.6091301441192627, Train Acc : 0.40114613180515757 , Val Acc : 0.4153846153846154\n",
      "Epoch 1173/10000, Loss: 1.700831413269043, Train Acc : 0.4008277618592805 , Val Acc : 0.40512820512820513\n",
      "Epoch 1174/10000, Loss: 1.6493300199508667, Train Acc : 0.40019102196752626 , Val Acc : 0.4153846153846154\n",
      "Epoch 1175/10000, Loss: 1.623165249824524, Train Acc : 0.40019102196752626 , Val Acc : 0.41025641025641024\n",
      "Epoch 1176/10000, Loss: 1.6202867031097412, Train Acc : 0.4008277618592805 , Val Acc : 0.41025641025641024\n",
      "Epoch 1177/10000, Loss: 1.6884890794754028, Train Acc : 0.4005093919134034 , Val Acc : 0.4153846153846154\n",
      "Epoch 1178/10000, Loss: 1.7058615684509277, Train Acc : 0.40114613180515757 , Val Acc : 0.4128205128205128\n",
      "Epoch 1179/10000, Loss: 1.6826330423355103, Train Acc : 0.4005093919134034 , Val Acc : 0.4153846153846154\n",
      "Epoch 1180/10000, Loss: 1.6619811058044434, Train Acc : 0.4008277618592805 , Val Acc : 0.4153846153846154\n",
      "Epoch 1181/10000, Loss: 1.7265737056732178, Train Acc : 0.4017828716969118 , Val Acc : 0.4153846153846154\n",
      "Epoch 1182/10000, Loss: 1.617855191230774, Train Acc : 0.4005093919134034 , Val Acc : 0.41025641025641024\n",
      "Epoch 1183/10000, Loss: 1.697832465171814, Train Acc : 0.40114613180515757 , Val Acc : 0.4153846153846154\n",
      "Epoch 1184/10000, Loss: 1.6602152585983276, Train Acc : 0.4008277618592805 , Val Acc : 0.4153846153846154\n",
      "Epoch 1185/10000, Loss: 1.7341281175613403, Train Acc : 0.4014645017510347 , Val Acc : 0.41025641025641024\n",
      "Epoch 1186/10000, Loss: 1.6212953329086304, Train Acc : 0.40019102196752626 , Val Acc : 0.41794871794871796\n",
      "Epoch 1187/10000, Loss: 1.6739150285720825, Train Acc : 0.4005093919134034 , Val Acc : 0.4153846153846154\n",
      "Epoch 1188/10000, Loss: 1.6870102882385254, Train Acc : 0.4008277618592805 , Val Acc : 0.41025641025641024\n",
      "Epoch 1189/10000, Loss: 1.6685928106307983, Train Acc : 0.4008277618592805 , Val Acc : 0.4153846153846154\n",
      "Epoch 1190/10000, Loss: 1.6162753105163574, Train Acc : 0.4008277618592805 , Val Acc : 0.4153846153846154\n",
      "Epoch 1191/10000, Loss: 1.6954673528671265, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1192/10000, Loss: 1.6655683517456055, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1193/10000, Loss: 1.605034351348877, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1194/10000, Loss: 1.6689070463180542, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1195/10000, Loss: 1.6065526008605957, Train Acc : 0.4008277618592805 , Val Acc : 0.41025641025641024\n",
      "Epoch 1196/10000, Loss: 1.634397268295288, Train Acc : 0.4008277618592805 , Val Acc : 0.41025641025641024\n",
      "Epoch 1197/10000, Loss: 1.7020680904388428, Train Acc : 0.4008277618592805 , Val Acc : 0.4128205128205128\n",
      "Epoch 1198/10000, Loss: 1.6947810649871826, Train Acc : 0.4014645017510347 , Val Acc : 0.4128205128205128\n",
      "Epoch 1199/10000, Loss: 1.6133993864059448, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1200/10000, Loss: 1.6704264879226685, Train Acc : 0.40019102196752626 , Val Acc : 0.41794871794871796\n",
      "Epoch 1201/10000, Loss: 1.5980069637298584, Train Acc : 0.4008277618592805 , Val Acc : 0.4076923076923077\n",
      "Epoch 1202/10000, Loss: 1.6534993648529053, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1203/10000, Loss: 1.6402769088745117, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1204/10000, Loss: 1.6576722860336304, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1205/10000, Loss: 1.727929949760437, Train Acc : 0.40019102196752626 , Val Acc : 0.4205128205128205\n",
      "Epoch 1206/10000, Loss: 1.656720757484436, Train Acc : 0.40019102196752626 , Val Acc : 0.4205128205128205\n",
      "Epoch 1207/10000, Loss: 1.684056043624878, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1208/10000, Loss: 1.6210606098175049, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1209/10000, Loss: 1.7004814147949219, Train Acc : 0.4005093919134034 , Val Acc : 0.4205128205128205\n",
      "Epoch 1210/10000, Loss: 1.6392292976379395, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1211/10000, Loss: 1.723089337348938, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1212/10000, Loss: 1.6616904735565186, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1213/10000, Loss: 1.6863380670547485, Train Acc : 0.40114613180515757 , Val Acc : 0.4205128205128205\n",
      "Epoch 1214/10000, Loss: 1.6946264505386353, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1215/10000, Loss: 1.6167153120040894, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1216/10000, Loss: 1.6862897872924805, Train Acc : 0.4017828716969118 , Val Acc : 0.41025641025641024\n",
      "Epoch 1217/10000, Loss: 1.731140375137329, Train Acc : 0.4014645017510347 , Val Acc : 0.41025641025641024\n",
      "Epoch 1218/10000, Loss: 1.6862038373947144, Train Acc : 0.4008277618592805 , Val Acc : 0.41025641025641024\n",
      "Epoch 1219/10000, Loss: 1.5954318046569824, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1220/10000, Loss: 1.6114847660064697, Train Acc : 0.4008277618592805 , Val Acc : 0.4205128205128205\n",
      "Epoch 1221/10000, Loss: 1.6925560235977173, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1222/10000, Loss: 1.6982885599136353, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1223/10000, Loss: 1.7025309801101685, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1224/10000, Loss: 1.695104956626892, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1225/10000, Loss: 1.6649422645568848, Train Acc : 0.3998726520216492 , Val Acc : 0.4205128205128205\n",
      "Epoch 1226/10000, Loss: 1.6749629974365234, Train Acc : 0.3998726520216492 , Val Acc : 0.41794871794871796\n",
      "Epoch 1227/10000, Loss: 1.5891517400741577, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1228/10000, Loss: 1.6381471157073975, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1229/10000, Loss: 1.6507799625396729, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1230/10000, Loss: 1.7029144763946533, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1231/10000, Loss: 1.6665085554122925, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1232/10000, Loss: 1.6296175718307495, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1233/10000, Loss: 1.6497360467910767, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1234/10000, Loss: 1.6841017007827759, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1235/10000, Loss: 1.6209099292755127, Train Acc : 0.40114613180515757 , Val Acc : 0.4205128205128205\n",
      "Epoch 1236/10000, Loss: 1.6376190185546875, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1237/10000, Loss: 1.6060492992401123, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1238/10000, Loss: 1.6647943258285522, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1239/10000, Loss: 1.694320559501648, Train Acc : 0.40019102196752626 , Val Acc : 0.4205128205128205\n",
      "Epoch 1240/10000, Loss: 1.64530348777771, Train Acc : 0.4008277618592805 , Val Acc : 0.4205128205128205\n",
      "Epoch 1241/10000, Loss: 1.6375136375427246, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1242/10000, Loss: 1.6179757118225098, Train Acc : 0.4008277618592805 , Val Acc : 0.4205128205128205\n",
      "Epoch 1243/10000, Loss: 1.6431094408035278, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1244/10000, Loss: 1.642556071281433, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1245/10000, Loss: 1.688040018081665, Train Acc : 0.4005093919134034 , Val Acc : 0.41794871794871796\n",
      "Epoch 1246/10000, Loss: 1.601118564605713, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1247/10000, Loss: 1.6916285753250122, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1248/10000, Loss: 1.6120949983596802, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1249/10000, Loss: 1.6878331899642944, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1250/10000, Loss: 1.5834742784500122, Train Acc : 0.4014645017510347 , Val Acc : 0.4205128205128205\n",
      "Epoch 1251/10000, Loss: 1.645344853401184, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1252/10000, Loss: 1.6491446495056152, Train Acc : 0.40114613180515757 , Val Acc : 0.4205128205128205\n",
      "Epoch 1253/10000, Loss: 1.7317112684249878, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1254/10000, Loss: 1.6351373195648193, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1255/10000, Loss: 1.5982528924942017, Train Acc : 0.4014645017510347 , Val Acc : 0.4128205128205128\n",
      "Epoch 1256/10000, Loss: 1.6743053197860718, Train Acc : 0.40210124164278893 , Val Acc : 0.4205128205128205\n",
      "Epoch 1257/10000, Loss: 1.6340163946151733, Train Acc : 0.4014645017510347 , Val Acc : 0.4205128205128205\n",
      "Epoch 1258/10000, Loss: 1.6276359558105469, Train Acc : 0.4008277618592805 , Val Acc : 0.41794871794871796\n",
      "Epoch 1259/10000, Loss: 1.667222261428833, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1260/10000, Loss: 1.7392785549163818, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1261/10000, Loss: 1.6435246467590332, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1262/10000, Loss: 1.6983773708343506, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1263/10000, Loss: 1.6718790531158447, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1264/10000, Loss: 1.6664353609085083, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1265/10000, Loss: 1.6619044542312622, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1266/10000, Loss: 1.6122981309890747, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1267/10000, Loss: 1.6786197423934937, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1268/10000, Loss: 1.668176293373108, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1269/10000, Loss: 1.70048189163208, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1270/10000, Loss: 1.6400372982025146, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1271/10000, Loss: 1.5485392808914185, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1272/10000, Loss: 1.6216888427734375, Train Acc : 0.40210124164278893 , Val Acc : 0.4205128205128205\n",
      "Epoch 1273/10000, Loss: 1.6285400390625, Train Acc : 0.40210124164278893 , Val Acc : 0.4205128205128205\n",
      "Epoch 1274/10000, Loss: 1.6646136045455933, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1275/10000, Loss: 1.666346788406372, Train Acc : 0.40210124164278893 , Val Acc : 0.4205128205128205\n",
      "Epoch 1276/10000, Loss: 1.7194716930389404, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1277/10000, Loss: 1.688850998878479, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1278/10000, Loss: 1.6652171611785889, Train Acc : 0.4014645017510347 , Val Acc : 0.4205128205128205\n",
      "Epoch 1279/10000, Loss: 1.6075936555862427, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1280/10000, Loss: 1.6604515314102173, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1281/10000, Loss: 1.6201645135879517, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1282/10000, Loss: 1.6241509914398193, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1283/10000, Loss: 1.6871565580368042, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1284/10000, Loss: 1.6181375980377197, Train Acc : 0.4008277618592805 , Val Acc : 0.4205128205128205\n",
      "Epoch 1285/10000, Loss: 1.6628364324569702, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1286/10000, Loss: 1.6532124280929565, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1287/10000, Loss: 1.6396394968032837, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1288/10000, Loss: 1.6051528453826904, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1289/10000, Loss: 1.674174189567566, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1290/10000, Loss: 1.6441389322280884, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1291/10000, Loss: 1.674006700515747, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1292/10000, Loss: 1.6906683444976807, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1293/10000, Loss: 1.7138336896896362, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1294/10000, Loss: 1.5945371389389038, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1295/10000, Loss: 1.6667276620864868, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1296/10000, Loss: 1.7064231634140015, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1297/10000, Loss: 1.6818244457244873, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1298/10000, Loss: 1.6216751337051392, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1299/10000, Loss: 1.6406806707382202, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1300/10000, Loss: 1.6334741115570068, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1301/10000, Loss: 1.6289538145065308, Train Acc : 0.4014645017510347 , Val Acc : 0.4205128205128205\n",
      "Epoch 1302/10000, Loss: 1.681409478187561, Train Acc : 0.40114613180515757 , Val Acc : 0.41794871794871796\n",
      "Epoch 1303/10000, Loss: 1.6561846733093262, Train Acc : 0.4014645017510347 , Val Acc : 0.4205128205128205\n",
      "Epoch 1304/10000, Loss: 1.6124746799468994, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1305/10000, Loss: 1.6244425773620605, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1306/10000, Loss: 1.678614616394043, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1307/10000, Loss: 1.6851660013198853, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1308/10000, Loss: 1.6584491729736328, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1309/10000, Loss: 1.6874264478683472, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1310/10000, Loss: 1.6952979564666748, Train Acc : 0.40114613180515757 , Val Acc : 0.4205128205128205\n",
      "Epoch 1311/10000, Loss: 1.616529107093811, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1312/10000, Loss: 1.6436529159545898, Train Acc : 0.4014645017510347 , Val Acc : 0.4205128205128205\n",
      "Epoch 1313/10000, Loss: 1.656622052192688, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1314/10000, Loss: 1.6997711658477783, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1315/10000, Loss: 1.6809895038604736, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1316/10000, Loss: 1.6717541217803955, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1317/10000, Loss: 1.66364324092865, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1318/10000, Loss: 1.5952619314193726, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1319/10000, Loss: 1.6073282957077026, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1320/10000, Loss: 1.6166075468063354, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1321/10000, Loss: 1.6449317932128906, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1322/10000, Loss: 1.584602952003479, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1323/10000, Loss: 1.6736124753952026, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1324/10000, Loss: 1.6268677711486816, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1325/10000, Loss: 1.6966526508331299, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1326/10000, Loss: 1.6418966054916382, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1327/10000, Loss: 1.633103609085083, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1328/10000, Loss: 1.6054176092147827, Train Acc : 0.4014645017510347 , Val Acc : 0.4205128205128205\n",
      "Epoch 1329/10000, Loss: 1.6740132570266724, Train Acc : 0.4014645017510347 , Val Acc : 0.4205128205128205\n",
      "Epoch 1330/10000, Loss: 1.6994338035583496, Train Acc : 0.40114613180515757 , Val Acc : 0.4205128205128205\n",
      "Epoch 1331/10000, Loss: 1.711621880531311, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1332/10000, Loss: 1.7125366926193237, Train Acc : 0.4014645017510347 , Val Acc : 0.41794871794871796\n",
      "Epoch 1333/10000, Loss: 1.6640490293502808, Train Acc : 0.402419611588666 , Val Acc : 0.4205128205128205\n",
      "Epoch 1334/10000, Loss: 1.6987107992172241, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1335/10000, Loss: 1.6081985235214233, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1336/10000, Loss: 1.6129570007324219, Train Acc : 0.402419611588666 , Val Acc : 0.4205128205128205\n",
      "Epoch 1337/10000, Loss: 1.549658179283142, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1338/10000, Loss: 1.6484196186065674, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1339/10000, Loss: 1.6958966255187988, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1340/10000, Loss: 1.6535375118255615, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1341/10000, Loss: 1.6723854541778564, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1342/10000, Loss: 1.7250593900680542, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1343/10000, Loss: 1.7126678228378296, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1344/10000, Loss: 1.6805146932601929, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1345/10000, Loss: 1.6471003293991089, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1346/10000, Loss: 1.665109634399414, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1347/10000, Loss: 1.711844801902771, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1348/10000, Loss: 1.6855648756027222, Train Acc : 0.402419611588666 , Val Acc : 0.4205128205128205\n",
      "Epoch 1349/10000, Loss: 1.6879409551620483, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1350/10000, Loss: 1.6531909704208374, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1351/10000, Loss: 1.6870595216751099, Train Acc : 0.40210124164278893 , Val Acc : 0.4205128205128205\n",
      "Epoch 1352/10000, Loss: 1.7296477556228638, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1353/10000, Loss: 1.726124882698059, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1354/10000, Loss: 1.610546588897705, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1355/10000, Loss: 1.6428627967834473, Train Acc : 0.4017828716969118 , Val Acc : 0.41794871794871796\n",
      "Epoch 1356/10000, Loss: 1.6103888750076294, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1357/10000, Loss: 1.6538959741592407, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1358/10000, Loss: 1.6679819822311401, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1359/10000, Loss: 1.7722055912017822, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1360/10000, Loss: 1.628962755203247, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1361/10000, Loss: 1.642408013343811, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1362/10000, Loss: 1.7093842029571533, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1363/10000, Loss: 1.6510252952575684, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1364/10000, Loss: 1.6675550937652588, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1365/10000, Loss: 1.721296787261963, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1366/10000, Loss: 1.6667742729187012, Train Acc : 0.402419611588666 , Val Acc : 0.4205128205128205\n",
      "Epoch 1367/10000, Loss: 1.685509443283081, Train Acc : 0.40210124164278893 , Val Acc : 0.4205128205128205\n",
      "Epoch 1368/10000, Loss: 1.7002222537994385, Train Acc : 0.4017828716969118 , Val Acc : 0.4205128205128205\n",
      "Epoch 1369/10000, Loss: 1.6334091424942017, Train Acc : 0.40210124164278893 , Val Acc : 0.4205128205128205\n",
      "Epoch 1370/10000, Loss: 1.6194416284561157, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1371/10000, Loss: 1.671964406967163, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1372/10000, Loss: 1.603579044342041, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1373/10000, Loss: 1.625487208366394, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1374/10000, Loss: 1.6312247514724731, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1375/10000, Loss: 1.6217557191848755, Train Acc : 0.40210124164278893 , Val Acc : 0.4205128205128205\n",
      "Epoch 1376/10000, Loss: 1.5821384191513062, Train Acc : 0.40210124164278893 , Val Acc : 0.41794871794871796\n",
      "Epoch 1377/10000, Loss: 1.6485857963562012, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1378/10000, Loss: 1.6814939975738525, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1379/10000, Loss: 1.680284857749939, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1380/10000, Loss: 1.6659834384918213, Train Acc : 0.40305635148042024 , Val Acc : 0.4205128205128205\n",
      "Epoch 1381/10000, Loss: 1.7137318849563599, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1382/10000, Loss: 1.6569764614105225, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1383/10000, Loss: 1.6710466146469116, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1384/10000, Loss: 1.658398985862732, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1385/10000, Loss: 1.6760648488998413, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1386/10000, Loss: 1.6553595066070557, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1387/10000, Loss: 1.625432014465332, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1388/10000, Loss: 1.6185259819030762, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1389/10000, Loss: 1.6924763917922974, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1390/10000, Loss: 1.6668531894683838, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1391/10000, Loss: 1.7050068378448486, Train Acc : 0.40369309137217446 , Val Acc : 0.41794871794871796\n",
      "Epoch 1392/10000, Loss: 1.6593605279922485, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1393/10000, Loss: 1.64417564868927, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1394/10000, Loss: 1.619816541671753, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1395/10000, Loss: 1.7082476615905762, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1396/10000, Loss: 1.6626124382019043, Train Acc : 0.40369309137217446 , Val Acc : 0.41794871794871796\n",
      "Epoch 1397/10000, Loss: 1.659424066543579, Train Acc : 0.4033747214262974 , Val Acc : 0.41794871794871796\n",
      "Epoch 1398/10000, Loss: 1.6814067363739014, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1399/10000, Loss: 1.652815818786621, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1400/10000, Loss: 1.6361021995544434, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1401/10000, Loss: 1.6391308307647705, Train Acc : 0.40305635148042024 , Val Acc : 0.4205128205128205\n",
      "Epoch 1402/10000, Loss: 1.5857925415039062, Train Acc : 0.4033747214262974 , Val Acc : 0.4205128205128205\n",
      "Epoch 1403/10000, Loss: 1.665916085243225, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1404/10000, Loss: 1.6748464107513428, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1405/10000, Loss: 1.6416391134262085, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1406/10000, Loss: 1.6813546419143677, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1407/10000, Loss: 1.6833305358886719, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1408/10000, Loss: 1.6626732349395752, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1409/10000, Loss: 1.6309762001037598, Train Acc : 0.4033747214262974 , Val Acc : 0.41794871794871796\n",
      "Epoch 1410/10000, Loss: 1.6707603931427002, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1411/10000, Loss: 1.6822807788848877, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1412/10000, Loss: 1.6629760265350342, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1413/10000, Loss: 1.5668518543243408, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1414/10000, Loss: 1.5825586318969727, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1415/10000, Loss: 1.6171642541885376, Train Acc : 0.40369309137217446 , Val Acc : 0.41794871794871796\n",
      "Epoch 1416/10000, Loss: 1.666401743888855, Train Acc : 0.402419611588666 , Val Acc : 0.41794871794871796\n",
      "Epoch 1417/10000, Loss: 1.660121202468872, Train Acc : 0.4033747214262974 , Val Acc : 0.41794871794871796\n",
      "Epoch 1418/10000, Loss: 1.5946098566055298, Train Acc : 0.40273798153454315 , Val Acc : 0.41794871794871796\n",
      "Epoch 1419/10000, Loss: 1.7024304866790771, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1420/10000, Loss: 1.6446559429168701, Train Acc : 0.40369309137217446 , Val Acc : 0.41794871794871796\n",
      "Epoch 1421/10000, Loss: 1.6807950735092163, Train Acc : 0.4040114613180516 , Val Acc : 0.41794871794871796\n",
      "Epoch 1422/10000, Loss: 1.6896597146987915, Train Acc : 0.4040114613180516 , Val Acc : 0.41794871794871796\n",
      "Epoch 1423/10000, Loss: 1.6992493867874146, Train Acc : 0.4033747214262974 , Val Acc : 0.41794871794871796\n",
      "Epoch 1424/10000, Loss: 1.6358836889266968, Train Acc : 0.4033747214262974 , Val Acc : 0.41794871794871796\n",
      "Epoch 1425/10000, Loss: 1.6306571960449219, Train Acc : 0.4040114613180516 , Val Acc : 0.41794871794871796\n",
      "Epoch 1426/10000, Loss: 1.610004186630249, Train Acc : 0.4033747214262974 , Val Acc : 0.41794871794871796\n",
      "Epoch 1427/10000, Loss: 1.6334419250488281, Train Acc : 0.4043298312639287 , Val Acc : 0.41794871794871796\n",
      "Epoch 1428/10000, Loss: 1.658598780632019, Train Acc : 0.4033747214262974 , Val Acc : 0.41794871794871796\n",
      "Epoch 1429/10000, Loss: 1.6885161399841309, Train Acc : 0.40369309137217446 , Val Acc : 0.41794871794871796\n",
      "Epoch 1430/10000, Loss: 1.6758977174758911, Train Acc : 0.4033747214262974 , Val Acc : 0.41794871794871796\n",
      "Epoch 1431/10000, Loss: 1.6285847425460815, Train Acc : 0.4043298312639287 , Val Acc : 0.41794871794871796\n",
      "Epoch 1432/10000, Loss: 1.6716861724853516, Train Acc : 0.4033747214262974 , Val Acc : 0.4205128205128205\n",
      "Epoch 1433/10000, Loss: 1.6391961574554443, Train Acc : 0.40369309137217446 , Val Acc : 0.41794871794871796\n",
      "Epoch 1434/10000, Loss: 1.651113748550415, Train Acc : 0.4033747214262974 , Val Acc : 0.41794871794871796\n",
      "Epoch 1435/10000, Loss: 1.6852593421936035, Train Acc : 0.40305635148042024 , Val Acc : 0.41794871794871796\n",
      "Epoch 1436/10000, Loss: 1.6430375576019287, Train Acc : 0.40369309137217446 , Val Acc : 0.41794871794871796\n",
      "Epoch 1437/10000, Loss: 1.62339448928833, Train Acc : 0.4043298312639287 , Val Acc : 0.41794871794871796\n",
      "Epoch 1438/10000, Loss: 1.699699878692627, Train Acc : 0.4043298312639287 , Val Acc : 0.41794871794871796\n",
      "Epoch 1439/10000, Loss: 1.6656484603881836, Train Acc : 0.4043298312639287 , Val Acc : 0.41794871794871796\n",
      "Epoch 1440/10000, Loss: 1.6648107767105103, Train Acc : 0.40464820120980577 , Val Acc : 0.41794871794871796\n",
      "Epoch 1441/10000, Loss: 1.6653834581375122, Train Acc : 0.4040114613180516 , Val Acc : 0.41794871794871796\n",
      "Epoch 1442/10000, Loss: 1.6232138872146606, Train Acc : 0.4043298312639287 , Val Acc : 0.41794871794871796\n",
      "Epoch 1443/10000, Loss: 1.61494779586792, Train Acc : 0.4049665711556829 , Val Acc : 0.41794871794871796\n",
      "Epoch 1444/10000, Loss: 1.604098916053772, Train Acc : 0.40464820120980577 , Val Acc : 0.41794871794871796\n",
      "Epoch 1445/10000, Loss: 1.6760088205337524, Train Acc : 0.40464820120980577 , Val Acc : 0.41794871794871796\n",
      "Epoch 1446/10000, Loss: 1.6528611183166504, Train Acc : 0.4049665711556829 , Val Acc : 0.4205128205128205\n",
      "Epoch 1447/10000, Loss: 1.6529395580291748, Train Acc : 0.40528494110156 , Val Acc : 0.41794871794871796\n",
      "Epoch 1448/10000, Loss: 1.6546913385391235, Train Acc : 0.40528494110156 , Val Acc : 0.41794871794871796\n",
      "Epoch 1449/10000, Loss: 1.613795280456543, Train Acc : 0.40528494110156 , Val Acc : 0.41794871794871796\n",
      "Epoch 1450/10000, Loss: 1.6608083248138428, Train Acc : 0.40464820120980577 , Val Acc : 0.41794871794871796\n",
      "Epoch 1451/10000, Loss: 1.640315294265747, Train Acc : 0.40464820120980577 , Val Acc : 0.41794871794871796\n",
      "Epoch 1452/10000, Loss: 1.6348072290420532, Train Acc : 0.40464820120980577 , Val Acc : 0.41794871794871796\n",
      "Epoch 1453/10000, Loss: 1.6662265062332153, Train Acc : 0.40464820120980577 , Val Acc : 0.41794871794871796\n",
      "Epoch 1454/10000, Loss: 1.6906578540802002, Train Acc : 0.4049665711556829 , Val Acc : 0.41794871794871796\n",
      "Epoch 1455/10000, Loss: 1.6072335243225098, Train Acc : 0.4049665711556829 , Val Acc : 0.41794871794871796\n",
      "Epoch 1456/10000, Loss: 1.6660023927688599, Train Acc : 0.4049665711556829 , Val Acc : 0.41794871794871796\n",
      "Epoch 1457/10000, Loss: 1.607860803604126, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1458/10000, Loss: 1.666664481163025, Train Acc : 0.40528494110156 , Val Acc : 0.41794871794871796\n",
      "Epoch 1459/10000, Loss: 1.6889780759811401, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1460/10000, Loss: 1.6383939981460571, Train Acc : 0.40528494110156 , Val Acc : 0.41794871794871796\n",
      "Epoch 1461/10000, Loss: 1.7006880044937134, Train Acc : 0.4059216809933142 , Val Acc : 0.41794871794871796\n",
      "Epoch 1462/10000, Loss: 1.6993685960769653, Train Acc : 0.4059216809933142 , Val Acc : 0.41794871794871796\n",
      "Epoch 1463/10000, Loss: 1.5876667499542236, Train Acc : 0.4059216809933142 , Val Acc : 0.41794871794871796\n",
      "Epoch 1464/10000, Loss: 1.688706874847412, Train Acc : 0.40624005093919136 , Val Acc : 0.41794871794871796\n",
      "Epoch 1465/10000, Loss: 1.668206810951233, Train Acc : 0.40624005093919136 , Val Acc : 0.41794871794871796\n",
      "Epoch 1466/10000, Loss: 1.641128659248352, Train Acc : 0.40624005093919136 , Val Acc : 0.41794871794871796\n",
      "Epoch 1467/10000, Loss: 1.6582036018371582, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1468/10000, Loss: 1.6328476667404175, Train Acc : 0.40624005093919136 , Val Acc : 0.41794871794871796\n",
      "Epoch 1469/10000, Loss: 1.665087342262268, Train Acc : 0.40624005093919136 , Val Acc : 0.41794871794871796\n",
      "Epoch 1470/10000, Loss: 1.6409690380096436, Train Acc : 0.4068767908309456 , Val Acc : 0.41794871794871796\n",
      "Epoch 1471/10000, Loss: 1.6872780323028564, Train Acc : 0.40624005093919136 , Val Acc : 0.41794871794871796\n",
      "Epoch 1472/10000, Loss: 1.6002055406570435, Train Acc : 0.40655842088506844 , Val Acc : 0.41794871794871796\n",
      "Epoch 1473/10000, Loss: 1.6326043605804443, Train Acc : 0.40655842088506844 , Val Acc : 0.41794871794871796\n",
      "Epoch 1474/10000, Loss: 1.6673550605773926, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1475/10000, Loss: 1.6908433437347412, Train Acc : 0.4059216809933142 , Val Acc : 0.41794871794871796\n",
      "Epoch 1476/10000, Loss: 1.6396043300628662, Train Acc : 0.4059216809933142 , Val Acc : 0.41794871794871796\n",
      "Epoch 1477/10000, Loss: 1.6849753856658936, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1478/10000, Loss: 1.6073822975158691, Train Acc : 0.40528494110156 , Val Acc : 0.41794871794871796\n",
      "Epoch 1479/10000, Loss: 1.6504806280136108, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1480/10000, Loss: 1.6464282274246216, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1481/10000, Loss: 1.657252311706543, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1482/10000, Loss: 1.6460864543914795, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1483/10000, Loss: 1.6634052991867065, Train Acc : 0.4068767908309456 , Val Acc : 0.41794871794871796\n",
      "Epoch 1484/10000, Loss: 1.6425625085830688, Train Acc : 0.40560331104743713 , Val Acc : 0.41794871794871796\n",
      "Epoch 1485/10000, Loss: 1.6523996591567993, Train Acc : 0.4068767908309456 , Val Acc : 0.41794871794871796\n",
      "Epoch 1486/10000, Loss: 1.6692566871643066, Train Acc : 0.4075135307226998 , Val Acc : 0.41794871794871796\n",
      "Epoch 1487/10000, Loss: 1.6436882019042969, Train Acc : 0.40655842088506844 , Val Acc : 0.41794871794871796\n",
      "Epoch 1488/10000, Loss: 1.5686639547348022, Train Acc : 0.40655842088506844 , Val Acc : 0.41794871794871796\n",
      "Epoch 1489/10000, Loss: 1.6212390661239624, Train Acc : 0.40719516077682266 , Val Acc : 0.41794871794871796\n",
      "Epoch 1490/10000, Loss: 1.6593581438064575, Train Acc : 0.40719516077682266 , Val Acc : 0.41794871794871796\n",
      "Epoch 1491/10000, Loss: 1.6344890594482422, Train Acc : 0.40624005093919136 , Val Acc : 0.41794871794871796\n",
      "Epoch 1492/10000, Loss: 1.6447995901107788, Train Acc : 0.4075135307226998 , Val Acc : 0.41794871794871796\n",
      "Epoch 1493/10000, Loss: 1.5915135145187378, Train Acc : 0.4068767908309456 , Val Acc : 0.41794871794871796\n",
      "Epoch 1494/10000, Loss: 1.668287992477417, Train Acc : 0.4068767908309456 , Val Acc : 0.41794871794871796\n",
      "Epoch 1495/10000, Loss: 1.6109094619750977, Train Acc : 0.40655842088506844 , Val Acc : 0.41794871794871796\n",
      "Epoch 1496/10000, Loss: 1.650008201599121, Train Acc : 0.4075135307226998 , Val Acc : 0.41794871794871796\n",
      "Epoch 1497/10000, Loss: 1.708383560180664, Train Acc : 0.40719516077682266 , Val Acc : 0.41794871794871796\n",
      "Epoch 1498/10000, Loss: 1.6477566957473755, Train Acc : 0.4075135307226998 , Val Acc : 0.41794871794871796\n",
      "Epoch 1499/10000, Loss: 1.6195154190063477, Train Acc : 0.4075135307226998 , Val Acc : 0.41794871794871796\n",
      "Epoch 1500/10000, Loss: 1.6476070880889893, Train Acc : 0.40719516077682266 , Val Acc : 0.41794871794871796\n",
      "Epoch 1501/10000, Loss: 1.6020214557647705, Train Acc : 0.4078319006685769 , Val Acc : 0.41794871794871796\n",
      "Epoch 1502/10000, Loss: 1.5990715026855469, Train Acc : 0.4078319006685769 , Val Acc : 0.41794871794871796\n",
      "Epoch 1503/10000, Loss: 1.6491737365722656, Train Acc : 0.4068767908309456 , Val Acc : 0.41794871794871796\n",
      "Epoch 1504/10000, Loss: 1.6257774829864502, Train Acc : 0.40719516077682266 , Val Acc : 0.41794871794871796\n",
      "Epoch 1505/10000, Loss: 1.6446104049682617, Train Acc : 0.4078319006685769 , Val Acc : 0.41794871794871796\n",
      "Epoch 1506/10000, Loss: 1.6428499221801758, Train Acc : 0.4075135307226998 , Val Acc : 0.41794871794871796\n",
      "Epoch 1507/10000, Loss: 1.680315375328064, Train Acc : 0.4078319006685769 , Val Acc : 0.41794871794871796\n",
      "Epoch 1508/10000, Loss: 1.5995553731918335, Train Acc : 0.40815027061445397 , Val Acc : 0.41794871794871796\n",
      "Epoch 1509/10000, Loss: 1.6044838428497314, Train Acc : 0.4087870105062082 , Val Acc : 0.41794871794871796\n",
      "Epoch 1510/10000, Loss: 1.6634483337402344, Train Acc : 0.4087870105062082 , Val Acc : 0.41794871794871796\n",
      "Epoch 1511/10000, Loss: 1.6296546459197998, Train Acc : 0.4087870105062082 , Val Acc : 0.41794871794871796\n",
      "Epoch 1512/10000, Loss: 1.6294441223144531, Train Acc : 0.40815027061445397 , Val Acc : 0.41794871794871796\n",
      "Epoch 1513/10000, Loss: 1.6570965051651, Train Acc : 0.4087870105062082 , Val Acc : 0.41794871794871796\n",
      "Epoch 1514/10000, Loss: 1.6015918254852295, Train Acc : 0.4084686405603311 , Val Acc : 0.41794871794871796\n",
      "Epoch 1515/10000, Loss: 1.6651986837387085, Train Acc : 0.4084686405603311 , Val Acc : 0.41794871794871796\n",
      "Epoch 1516/10000, Loss: 1.6185188293457031, Train Acc : 0.4078319006685769 , Val Acc : 0.41794871794871796\n",
      "Epoch 1517/10000, Loss: 1.5663491487503052, Train Acc : 0.4078319006685769 , Val Acc : 0.41794871794871796\n",
      "Epoch 1518/10000, Loss: 1.6527228355407715, Train Acc : 0.4078319006685769 , Val Acc : 0.41794871794871796\n",
      "Epoch 1519/10000, Loss: 1.599515676498413, Train Acc : 0.40815027061445397 , Val Acc : 0.41794871794871796\n",
      "Epoch 1520/10000, Loss: 1.676697015762329, Train Acc : 0.40815027061445397 , Val Acc : 0.4205128205128205\n",
      "Epoch 1521/10000, Loss: 1.6657817363739014, Train Acc : 0.4087870105062082 , Val Acc : 0.4205128205128205\n",
      "Epoch 1522/10000, Loss: 1.5966625213623047, Train Acc : 0.4087870105062082 , Val Acc : 0.4205128205128205\n",
      "Epoch 1523/10000, Loss: 1.6459795236587524, Train Acc : 0.40815027061445397 , Val Acc : 0.4205128205128205\n",
      "Epoch 1524/10000, Loss: 1.6131095886230469, Train Acc : 0.4078319006685769 , Val Acc : 0.4205128205128205\n",
      "Epoch 1525/10000, Loss: 1.6422761678695679, Train Acc : 0.4078319006685769 , Val Acc : 0.4205128205128205\n",
      "Epoch 1526/10000, Loss: 1.6242034435272217, Train Acc : 0.40815027061445397 , Val Acc : 0.4205128205128205\n",
      "Epoch 1527/10000, Loss: 1.6203118562698364, Train Acc : 0.4075135307226998 , Val Acc : 0.4205128205128205\n",
      "Epoch 1528/10000, Loss: 1.626713514328003, Train Acc : 0.4078319006685769 , Val Acc : 0.4205128205128205\n",
      "Epoch 1529/10000, Loss: 1.6178624629974365, Train Acc : 0.40719516077682266 , Val Acc : 0.4205128205128205\n",
      "Epoch 1530/10000, Loss: 1.625877857208252, Train Acc : 0.40719516077682266 , Val Acc : 0.4205128205128205\n",
      "Epoch 1531/10000, Loss: 1.6518051624298096, Train Acc : 0.4075135307226998 , Val Acc : 0.4205128205128205\n",
      "Epoch 1532/10000, Loss: 1.6432467699050903, Train Acc : 0.4075135307226998 , Val Acc : 0.4205128205128205\n",
      "Epoch 1533/10000, Loss: 1.6772706508636475, Train Acc : 0.40815027061445397 , Val Acc : 0.4205128205128205\n",
      "Epoch 1534/10000, Loss: 1.6731199026107788, Train Acc : 0.40719516077682266 , Val Acc : 0.4205128205128205\n",
      "Epoch 1535/10000, Loss: 1.5566202402114868, Train Acc : 0.4075135307226998 , Val Acc : 0.4205128205128205\n",
      "Epoch 1536/10000, Loss: 1.6075611114501953, Train Acc : 0.4078319006685769 , Val Acc : 0.4205128205128205\n",
      "Epoch 1537/10000, Loss: 1.6672645807266235, Train Acc : 0.40719516077682266 , Val Acc : 0.4205128205128205\n",
      "Epoch 1538/10000, Loss: 1.6286342144012451, Train Acc : 0.4078319006685769 , Val Acc : 0.4205128205128205\n",
      "Epoch 1539/10000, Loss: 1.617856502532959, Train Acc : 0.40719516077682266 , Val Acc : 0.4205128205128205\n",
      "Epoch 1540/10000, Loss: 1.6726197004318237, Train Acc : 0.40815027061445397 , Val Acc : 0.4205128205128205\n",
      "Epoch 1541/10000, Loss: 1.618330478668213, Train Acc : 0.4075135307226998 , Val Acc : 0.4205128205128205\n",
      "Epoch 1542/10000, Loss: 1.6591945886611938, Train Acc : 0.4075135307226998 , Val Acc : 0.4230769230769231\n",
      "Epoch 1543/10000, Loss: 1.6746453046798706, Train Acc : 0.4078319006685769 , Val Acc : 0.4230769230769231\n",
      "Epoch 1544/10000, Loss: 1.6696070432662964, Train Acc : 0.4075135307226998 , Val Acc : 0.4230769230769231\n",
      "Epoch 1545/10000, Loss: 1.6425178050994873, Train Acc : 0.4075135307226998 , Val Acc : 0.4230769230769231\n",
      "Epoch 1546/10000, Loss: 1.648132562637329, Train Acc : 0.40815027061445397 , Val Acc : 0.4230769230769231\n",
      "Epoch 1547/10000, Loss: 1.6585379838943481, Train Acc : 0.4078319006685769 , Val Acc : 0.4230769230769231\n",
      "Epoch 1548/10000, Loss: 1.6313637495040894, Train Acc : 0.40815027061445397 , Val Acc : 0.4230769230769231\n",
      "Epoch 1549/10000, Loss: 1.6013267040252686, Train Acc : 0.4078319006685769 , Val Acc : 0.4230769230769231\n",
      "Epoch 1550/10000, Loss: 1.6351691484451294, Train Acc : 0.4075135307226998 , Val Acc : 0.4230769230769231\n",
      "Epoch 1551/10000, Loss: 1.678688883781433, Train Acc : 0.40815027061445397 , Val Acc : 0.4230769230769231\n",
      "Epoch 1552/10000, Loss: 1.6476664543151855, Train Acc : 0.40815027061445397 , Val Acc : 0.4230769230769231\n",
      "Epoch 1553/10000, Loss: 1.6282458305358887, Train Acc : 0.4084686405603311 , Val Acc : 0.4230769230769231\n",
      "Epoch 1554/10000, Loss: 1.6651928424835205, Train Acc : 0.40815027061445397 , Val Acc : 0.4230769230769231\n",
      "Epoch 1555/10000, Loss: 1.6443394422531128, Train Acc : 0.40910538045208533 , Val Acc : 0.4230769230769231\n",
      "Epoch 1556/10000, Loss: 1.6661109924316406, Train Acc : 0.4078319006685769 , Val Acc : 0.4230769230769231\n",
      "Epoch 1557/10000, Loss: 1.7002617120742798, Train Acc : 0.4087870105062082 , Val Acc : 0.4230769230769231\n",
      "Epoch 1558/10000, Loss: 1.5919709205627441, Train Acc : 0.4087870105062082 , Val Acc : 0.4230769230769231\n",
      "Epoch 1559/10000, Loss: 1.6439837217330933, Train Acc : 0.40910538045208533 , Val Acc : 0.4230769230769231\n",
      "Epoch 1560/10000, Loss: 1.671162486076355, Train Acc : 0.4075135307226998 , Val Acc : 0.4256410256410256\n",
      "Epoch 1561/10000, Loss: 1.6348077058792114, Train Acc : 0.4087870105062082 , Val Acc : 0.4230769230769231\n",
      "Epoch 1562/10000, Loss: 1.6148520708084106, Train Acc : 0.40815027061445397 , Val Acc : 0.4256410256410256\n",
      "Epoch 1563/10000, Loss: 1.662880778312683, Train Acc : 0.4084686405603311 , Val Acc : 0.4256410256410256\n",
      "Epoch 1564/10000, Loss: 1.5722906589508057, Train Acc : 0.4084686405603311 , Val Acc : 0.4256410256410256\n",
      "Epoch 1565/10000, Loss: 1.6247450113296509, Train Acc : 0.40815027061445397 , Val Acc : 0.4256410256410256\n",
      "Epoch 1566/10000, Loss: 1.62892746925354, Train Acc : 0.40815027061445397 , Val Acc : 0.4256410256410256\n",
      "Epoch 1567/10000, Loss: 1.6689367294311523, Train Acc : 0.4084686405603311 , Val Acc : 0.4256410256410256\n",
      "Epoch 1568/10000, Loss: 1.5914478302001953, Train Acc : 0.4084686405603311 , Val Acc : 0.4256410256410256\n",
      "Epoch 1569/10000, Loss: 1.5974920988082886, Train Acc : 0.40910538045208533 , Val Acc : 0.4256410256410256\n",
      "Epoch 1570/10000, Loss: 1.6972073316574097, Train Acc : 0.40910538045208533 , Val Acc : 0.4256410256410256\n",
      "Epoch 1571/10000, Loss: 1.6118791103363037, Train Acc : 0.40815027061445397 , Val Acc : 0.4256410256410256\n",
      "Epoch 1572/10000, Loss: 1.6119930744171143, Train Acc : 0.4084686405603311 , Val Acc : 0.4256410256410256\n",
      "Epoch 1573/10000, Loss: 1.6427466869354248, Train Acc : 0.4084686405603311 , Val Acc : 0.4256410256410256\n",
      "Epoch 1574/10000, Loss: 1.661485195159912, Train Acc : 0.4094237503979624 , Val Acc : 0.4256410256410256\n",
      "Epoch 1575/10000, Loss: 1.6593639850616455, Train Acc : 0.4087870105062082 , Val Acc : 0.4256410256410256\n",
      "Epoch 1576/10000, Loss: 1.6195158958435059, Train Acc : 0.4084686405603311 , Val Acc : 0.4256410256410256\n",
      "Epoch 1577/10000, Loss: 1.6934864521026611, Train Acc : 0.40910538045208533 , Val Acc : 0.4256410256410256\n",
      "Epoch 1578/10000, Loss: 1.655545949935913, Train Acc : 0.40910538045208533 , Val Acc : 0.4256410256410256\n",
      "Epoch 1579/10000, Loss: 1.615759015083313, Train Acc : 0.4084686405603311 , Val Acc : 0.4256410256410256\n",
      "Epoch 1580/10000, Loss: 1.608153223991394, Train Acc : 0.4087870105062082 , Val Acc : 0.4256410256410256\n",
      "Epoch 1581/10000, Loss: 1.6693713665008545, Train Acc : 0.4084686405603311 , Val Acc : 0.4256410256410256\n",
      "Epoch 1582/10000, Loss: 1.6900184154510498, Train Acc : 0.4087870105062082 , Val Acc : 0.4256410256410256\n",
      "Epoch 1583/10000, Loss: 1.6655316352844238, Train Acc : 0.40910538045208533 , Val Acc : 0.4256410256410256\n",
      "Epoch 1584/10000, Loss: 1.6877353191375732, Train Acc : 0.40910538045208533 , Val Acc : 0.4230769230769231\n",
      "Epoch 1585/10000, Loss: 1.6148735284805298, Train Acc : 0.4094237503979624 , Val Acc : 0.4256410256410256\n",
      "Epoch 1586/10000, Loss: 1.6412941217422485, Train Acc : 0.4094237503979624 , Val Acc : 0.4230769230769231\n",
      "Epoch 1587/10000, Loss: 1.6744638681411743, Train Acc : 0.41006049028971664 , Val Acc : 0.4230769230769231\n",
      "Epoch 1588/10000, Loss: 1.6665092706680298, Train Acc : 0.40974212034383956 , Val Acc : 0.4230769230769231\n",
      "Epoch 1589/10000, Loss: 1.648566484451294, Train Acc : 0.41006049028971664 , Val Acc : 0.4230769230769231\n",
      "Epoch 1590/10000, Loss: 1.6672405004501343, Train Acc : 0.41006049028971664 , Val Acc : 0.4230769230769231\n",
      "Epoch 1591/10000, Loss: 1.629008173942566, Train Acc : 0.41006049028971664 , Val Acc : 0.4230769230769231\n",
      "Epoch 1592/10000, Loss: 1.6624270677566528, Train Acc : 0.4103788602355938 , Val Acc : 0.4230769230769231\n",
      "Epoch 1593/10000, Loss: 1.5841847658157349, Train Acc : 0.4122890799108564 , Val Acc : 0.4230769230769231\n",
      "Epoch 1594/10000, Loss: 1.5934277772903442, Train Acc : 0.4113339700732251 , Val Acc : 0.4230769230769231\n",
      "Epoch 1595/10000, Loss: 1.6222589015960693, Train Acc : 0.411015600127348 , Val Acc : 0.4230769230769231\n",
      "Epoch 1596/10000, Loss: 1.616551399230957, Train Acc : 0.4103788602355938 , Val Acc : 0.4230769230769231\n",
      "Epoch 1597/10000, Loss: 1.6800216436386108, Train Acc : 0.41069723018147086 , Val Acc : 0.4230769230769231\n",
      "Epoch 1598/10000, Loss: 1.6756342649459839, Train Acc : 0.41069723018147086 , Val Acc : 0.4230769230769231\n",
      "Epoch 1599/10000, Loss: 1.632545828819275, Train Acc : 0.4113339700732251 , Val Acc : 0.4230769230769231\n",
      "Epoch 1600/10000, Loss: 1.657339334487915, Train Acc : 0.411015600127348 , Val Acc : 0.4230769230769231\n",
      "Epoch 1601/10000, Loss: 1.5938514471054077, Train Acc : 0.4113339700732251 , Val Acc : 0.4230769230769231\n",
      "Epoch 1602/10000, Loss: 1.6274417638778687, Train Acc : 0.411015600127348 , Val Acc : 0.4230769230769231\n",
      "Epoch 1603/10000, Loss: 1.6791541576385498, Train Acc : 0.41069723018147086 , Val Acc : 0.4230769230769231\n",
      "Epoch 1604/10000, Loss: 1.6869127750396729, Train Acc : 0.411015600127348 , Val Acc : 0.4230769230769231\n",
      "Epoch 1605/10000, Loss: 1.654395580291748, Train Acc : 0.411015600127348 , Val Acc : 0.4230769230769231\n",
      "Epoch 1606/10000, Loss: 1.6584309339523315, Train Acc : 0.4122890799108564 , Val Acc : 0.4230769230769231\n",
      "Epoch 1607/10000, Loss: 1.6302213668823242, Train Acc : 0.4119707099649793 , Val Acc : 0.4230769230769231\n",
      "Epoch 1608/10000, Loss: 1.665976643562317, Train Acc : 0.41165234001910217 , Val Acc : 0.4230769230769231\n",
      "Epoch 1609/10000, Loss: 1.6332952976226807, Train Acc : 0.4122890799108564 , Val Acc : 0.4230769230769231\n",
      "Epoch 1610/10000, Loss: 1.6184555292129517, Train Acc : 0.41165234001910217 , Val Acc : 0.4230769230769231\n",
      "Epoch 1611/10000, Loss: 1.684039831161499, Train Acc : 0.41165234001910217 , Val Acc : 0.4205128205128205\n",
      "Epoch 1612/10000, Loss: 1.6676695346832275, Train Acc : 0.4119707099649793 , Val Acc : 0.4230769230769231\n",
      "Epoch 1613/10000, Loss: 1.6349327564239502, Train Acc : 0.411015600127348 , Val Acc : 0.4230769230769231\n",
      "Epoch 1614/10000, Loss: 1.67579185962677, Train Acc : 0.4113339700732251 , Val Acc : 0.4230769230769231\n",
      "Epoch 1615/10000, Loss: 1.6751973628997803, Train Acc : 0.4119707099649793 , Val Acc : 0.4230769230769231\n",
      "Epoch 1616/10000, Loss: 1.5893135070800781, Train Acc : 0.4122890799108564 , Val Acc : 0.4230769230769231\n",
      "Epoch 1617/10000, Loss: 1.6082500219345093, Train Acc : 0.4113339700732251 , Val Acc : 0.4230769230769231\n",
      "Epoch 1618/10000, Loss: 1.6256139278411865, Train Acc : 0.4119707099649793 , Val Acc : 0.4230769230769231\n",
      "Epoch 1619/10000, Loss: 1.6330995559692383, Train Acc : 0.4129258198026106 , Val Acc : 0.4230769230769231\n",
      "Epoch 1620/10000, Loss: 1.5877782106399536, Train Acc : 0.41165234001910217 , Val Acc : 0.4230769230769231\n",
      "Epoch 1621/10000, Loss: 1.6674220561981201, Train Acc : 0.41165234001910217 , Val Acc : 0.4205128205128205\n",
      "Epoch 1622/10000, Loss: 1.628547191619873, Train Acc : 0.41260744985673353 , Val Acc : 0.4230769230769231\n",
      "Epoch 1623/10000, Loss: 1.6468614339828491, Train Acc : 0.41260744985673353 , Val Acc : 0.4230769230769231\n",
      "Epoch 1624/10000, Loss: 1.7025972604751587, Train Acc : 0.4122890799108564 , Val Acc : 0.4230769230769231\n",
      "Epoch 1625/10000, Loss: 1.6302711963653564, Train Acc : 0.4129258198026106 , Val Acc : 0.4230769230769231\n",
      "Epoch 1626/10000, Loss: 1.6608575582504272, Train Acc : 0.4119707099649793 , Val Acc : 0.4230769230769231\n",
      "Epoch 1627/10000, Loss: 1.639256477355957, Train Acc : 0.41260744985673353 , Val Acc : 0.4230769230769231\n",
      "Epoch 1628/10000, Loss: 1.711369514465332, Train Acc : 0.41260744985673353 , Val Acc : 0.4230769230769231\n",
      "Epoch 1629/10000, Loss: 1.5895733833312988, Train Acc : 0.41324418974848776 , Val Acc : 0.4230769230769231\n",
      "Epoch 1630/10000, Loss: 1.6876580715179443, Train Acc : 0.41324418974848776 , Val Acc : 0.4230769230769231\n",
      "Epoch 1631/10000, Loss: 1.6371803283691406, Train Acc : 0.41260744985673353 , Val Acc : 0.4230769230769231\n",
      "Epoch 1632/10000, Loss: 1.58668053150177, Train Acc : 0.4129258198026106 , Val Acc : 0.4230769230769231\n",
      "Epoch 1633/10000, Loss: 1.595598578453064, Train Acc : 0.41356255969436484 , Val Acc : 0.4230769230769231\n",
      "Epoch 1634/10000, Loss: 1.6281460523605347, Train Acc : 0.41324418974848776 , Val Acc : 0.4230769230769231\n",
      "Epoch 1635/10000, Loss: 1.6854114532470703, Train Acc : 0.41419929958611906 , Val Acc : 0.4230769230769231\n",
      "Epoch 1636/10000, Loss: 1.6239882707595825, Train Acc : 0.413880929640242 , Val Acc : 0.4230769230769231\n",
      "Epoch 1637/10000, Loss: 1.6778935194015503, Train Acc : 0.4129258198026106 , Val Acc : 0.4230769230769231\n",
      "Epoch 1638/10000, Loss: 1.5672757625579834, Train Acc : 0.413880929640242 , Val Acc : 0.4230769230769231\n",
      "Epoch 1639/10000, Loss: 1.6237316131591797, Train Acc : 0.41419929958611906 , Val Acc : 0.4230769230769231\n",
      "Epoch 1640/10000, Loss: 1.6112666130065918, Train Acc : 0.41356255969436484 , Val Acc : 0.4230769230769231\n",
      "Epoch 1641/10000, Loss: 1.6318248510360718, Train Acc : 0.41260744985673353 , Val Acc : 0.4205128205128205\n",
      "Epoch 1642/10000, Loss: 1.6026612520217896, Train Acc : 0.41356255969436484 , Val Acc : 0.4230769230769231\n",
      "Epoch 1643/10000, Loss: 1.6095294952392578, Train Acc : 0.4145176695319962 , Val Acc : 0.4230769230769231\n",
      "Epoch 1644/10000, Loss: 1.648201584815979, Train Acc : 0.41419929958611906 , Val Acc : 0.4205128205128205\n",
      "Epoch 1645/10000, Loss: 1.6558383703231812, Train Acc : 0.41324418974848776 , Val Acc : 0.4230769230769231\n",
      "Epoch 1646/10000, Loss: 1.5582349300384521, Train Acc : 0.41324418974848776 , Val Acc : 0.4205128205128205\n",
      "Epoch 1647/10000, Loss: 1.6322128772735596, Train Acc : 0.413880929640242 , Val Acc : 0.4205128205128205\n",
      "Epoch 1648/10000, Loss: 1.6246650218963623, Train Acc : 0.413880929640242 , Val Acc : 0.4230769230769231\n",
      "Epoch 1649/10000, Loss: 1.6026065349578857, Train Acc : 0.4148360394778733 , Val Acc : 0.4205128205128205\n",
      "Epoch 1650/10000, Loss: 1.6183345317840576, Train Acc : 0.413880929640242 , Val Acc : 0.4205128205128205\n",
      "Epoch 1651/10000, Loss: 1.6606132984161377, Train Acc : 0.41419929958611906 , Val Acc : 0.4205128205128205\n",
      "Epoch 1652/10000, Loss: 1.6442703008651733, Train Acc : 0.41419929958611906 , Val Acc : 0.4205128205128205\n",
      "Epoch 1653/10000, Loss: 1.6571245193481445, Train Acc : 0.4148360394778733 , Val Acc : 0.4205128205128205\n",
      "Epoch 1654/10000, Loss: 1.585618495941162, Train Acc : 0.413880929640242 , Val Acc : 0.4205128205128205\n",
      "Epoch 1655/10000, Loss: 1.6696628332138062, Train Acc : 0.4145176695319962 , Val Acc : 0.4205128205128205\n",
      "Epoch 1656/10000, Loss: 1.6854804754257202, Train Acc : 0.4145176695319962 , Val Acc : 0.4205128205128205\n",
      "Epoch 1657/10000, Loss: 1.5512300729751587, Train Acc : 0.41419929958611906 , Val Acc : 0.4205128205128205\n",
      "Epoch 1658/10000, Loss: 1.6727352142333984, Train Acc : 0.4148360394778733 , Val Acc : 0.4205128205128205\n",
      "Epoch 1659/10000, Loss: 1.617356538772583, Train Acc : 0.4145176695319962 , Val Acc : 0.4230769230769231\n",
      "Epoch 1660/10000, Loss: 1.6538963317871094, Train Acc : 0.4145176695319962 , Val Acc : 0.4205128205128205\n",
      "Epoch 1661/10000, Loss: 1.6157077550888062, Train Acc : 0.4145176695319962 , Val Acc : 0.4205128205128205\n",
      "Epoch 1662/10000, Loss: 1.6378785371780396, Train Acc : 0.4148360394778733 , Val Acc : 0.4230769230769231\n",
      "Epoch 1663/10000, Loss: 1.6039930582046509, Train Acc : 0.41356255969436484 , Val Acc : 0.4205128205128205\n",
      "Epoch 1664/10000, Loss: 1.6446046829223633, Train Acc : 0.4157911493155046 , Val Acc : 0.4230769230769231\n",
      "Epoch 1665/10000, Loss: 1.6592100858688354, Train Acc : 0.4148360394778733 , Val Acc : 0.4205128205128205\n",
      "Epoch 1666/10000, Loss: 1.705672264099121, Train Acc : 0.41419929958611906 , Val Acc : 0.4205128205128205\n",
      "Epoch 1667/10000, Loss: 1.6142160892486572, Train Acc : 0.4148360394778733 , Val Acc : 0.4230769230769231\n",
      "Epoch 1668/10000, Loss: 1.619221568107605, Train Acc : 0.4151544094237504 , Val Acc : 0.4205128205128205\n",
      "Epoch 1669/10000, Loss: 1.5940990447998047, Train Acc : 0.4151544094237504 , Val Acc : 0.4230769230769231\n",
      "Epoch 1670/10000, Loss: 1.6835010051727295, Train Acc : 0.4154727793696275 , Val Acc : 0.4205128205128205\n",
      "Epoch 1671/10000, Loss: 1.6701864004135132, Train Acc : 0.4154727793696275 , Val Acc : 0.4205128205128205\n",
      "Epoch 1672/10000, Loss: 1.6630736589431763, Train Acc : 0.4154727793696275 , Val Acc : 0.4205128205128205\n",
      "Epoch 1673/10000, Loss: 1.6299604177474976, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1674/10000, Loss: 1.7043644189834595, Train Acc : 0.4148360394778733 , Val Acc : 0.4205128205128205\n",
      "Epoch 1675/10000, Loss: 1.6283949613571167, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1676/10000, Loss: 1.6536448001861572, Train Acc : 0.4148360394778733 , Val Acc : 0.4205128205128205\n",
      "Epoch 1677/10000, Loss: 1.6347110271453857, Train Acc : 0.4154727793696275 , Val Acc : 0.4205128205128205\n",
      "Epoch 1678/10000, Loss: 1.6421546936035156, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1679/10000, Loss: 1.6167634725570679, Train Acc : 0.4154727793696275 , Val Acc : 0.4205128205128205\n",
      "Epoch 1680/10000, Loss: 1.6238023042678833, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1681/10000, Loss: 1.6947780847549438, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1682/10000, Loss: 1.6175202131271362, Train Acc : 0.4154727793696275 , Val Acc : 0.4205128205128205\n",
      "Epoch 1683/10000, Loss: 1.660697340965271, Train Acc : 0.4151544094237504 , Val Acc : 0.4205128205128205\n",
      "Epoch 1684/10000, Loss: 1.666306734085083, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1685/10000, Loss: 1.6303856372833252, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1686/10000, Loss: 1.6756446361541748, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1687/10000, Loss: 1.663699746131897, Train Acc : 0.4154727793696275 , Val Acc : 0.4205128205128205\n",
      "Epoch 1688/10000, Loss: 1.5341143608093262, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1689/10000, Loss: 1.6398804187774658, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1690/10000, Loss: 1.7084214687347412, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1691/10000, Loss: 1.585958480834961, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1692/10000, Loss: 1.6412609815597534, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1693/10000, Loss: 1.6586642265319824, Train Acc : 0.4154727793696275 , Val Acc : 0.4205128205128205\n",
      "Epoch 1694/10000, Loss: 1.7316094636917114, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1695/10000, Loss: 1.6819175481796265, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1696/10000, Loss: 1.645739197731018, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1697/10000, Loss: 1.6452478170394897, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1698/10000, Loss: 1.6321179866790771, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1699/10000, Loss: 1.6547621488571167, Train Acc : 0.41770136899076726 , Val Acc : 0.4205128205128205\n",
      "Epoch 1700/10000, Loss: 1.712066411972046, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1701/10000, Loss: 1.6289496421813965, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1702/10000, Loss: 1.6616218090057373, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1703/10000, Loss: 1.616227626800537, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1704/10000, Loss: 1.6804651021957397, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1705/10000, Loss: 1.6387200355529785, Train Acc : 0.41674625915313596 , Val Acc : 0.4205128205128205\n",
      "Epoch 1706/10000, Loss: 1.6237438917160034, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1707/10000, Loss: 1.697183609008789, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1708/10000, Loss: 1.605764389038086, Train Acc : 0.4151544094237504 , Val Acc : 0.4230769230769231\n",
      "Epoch 1709/10000, Loss: 1.635860800743103, Train Acc : 0.4157911493155046 , Val Acc : 0.4230769230769231\n",
      "Epoch 1710/10000, Loss: 1.6216659545898438, Train Acc : 0.4151544094237504 , Val Acc : 0.4230769230769231\n",
      "Epoch 1711/10000, Loss: 1.6321324110031128, Train Acc : 0.4151544094237504 , Val Acc : 0.4230769230769231\n",
      "Epoch 1712/10000, Loss: 1.6195228099822998, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1713/10000, Loss: 1.6745864152908325, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1714/10000, Loss: 1.667763590812683, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1715/10000, Loss: 1.627440333366394, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1716/10000, Loss: 1.6088204383850098, Train Acc : 0.4151544094237504 , Val Acc : 0.4230769230769231\n",
      "Epoch 1717/10000, Loss: 1.652623176574707, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1718/10000, Loss: 1.7105622291564941, Train Acc : 0.4157911493155046 , Val Acc : 0.4205128205128205\n",
      "Epoch 1719/10000, Loss: 1.6501526832580566, Train Acc : 0.4151544094237504 , Val Acc : 0.4205128205128205\n",
      "Epoch 1720/10000, Loss: 1.6630412340164185, Train Acc : 0.41610951926138173 , Val Acc : 0.4205128205128205\n",
      "Epoch 1721/10000, Loss: 1.6661969423294067, Train Acc : 0.4164278892072588 , Val Acc : 0.41794871794871796\n",
      "Epoch 1722/10000, Loss: 1.6428873538970947, Train Acc : 0.41610951926138173 , Val Acc : 0.41794871794871796\n",
      "Epoch 1723/10000, Loss: 1.6290949583053589, Train Acc : 0.4164278892072588 , Val Acc : 0.41794871794871796\n",
      "Epoch 1724/10000, Loss: 1.5793976783752441, Train Acc : 0.41610951926138173 , Val Acc : 0.41794871794871796\n",
      "Epoch 1725/10000, Loss: 1.650350570678711, Train Acc : 0.4157911493155046 , Val Acc : 0.41794871794871796\n",
      "Epoch 1726/10000, Loss: 1.6086616516113281, Train Acc : 0.41610951926138173 , Val Acc : 0.41794871794871796\n",
      "Epoch 1727/10000, Loss: 1.6222801208496094, Train Acc : 0.4164278892072588 , Val Acc : 0.41794871794871796\n",
      "Epoch 1728/10000, Loss: 1.5974355936050415, Train Acc : 0.4157911493155046 , Val Acc : 0.41794871794871796\n",
      "Epoch 1729/10000, Loss: 1.6976600885391235, Train Acc : 0.4164278892072588 , Val Acc : 0.41794871794871796\n",
      "Epoch 1730/10000, Loss: 1.6794120073318481, Train Acc : 0.4164278892072588 , Val Acc : 0.41794871794871796\n",
      "Epoch 1731/10000, Loss: 1.657029151916504, Train Acc : 0.4164278892072588 , Val Acc : 0.41794871794871796\n",
      "Epoch 1732/10000, Loss: 1.6734474897384644, Train Acc : 0.41674625915313596 , Val Acc : 0.41794871794871796\n",
      "Epoch 1733/10000, Loss: 1.6342759132385254, Train Acc : 0.4164278892072588 , Val Acc : 0.41794871794871796\n",
      "Epoch 1734/10000, Loss: 1.6661797761917114, Train Acc : 0.41706462909901304 , Val Acc : 0.41794871794871796\n",
      "Epoch 1735/10000, Loss: 1.6135437488555908, Train Acc : 0.41706462909901304 , Val Acc : 0.41794871794871796\n",
      "Epoch 1736/10000, Loss: 1.6511080265045166, Train Acc : 0.41674625915313596 , Val Acc : 0.41794871794871796\n",
      "Epoch 1737/10000, Loss: 1.654430866241455, Train Acc : 0.41706462909901304 , Val Acc : 0.41794871794871796\n",
      "Epoch 1738/10000, Loss: 1.642815351486206, Train Acc : 0.41706462909901304 , Val Acc : 0.41794871794871796\n",
      "Epoch 1739/10000, Loss: 1.6085999011993408, Train Acc : 0.4164278892072588 , Val Acc : 0.41794871794871796\n",
      "Epoch 1740/10000, Loss: 1.6161552667617798, Train Acc : 0.41674625915313596 , Val Acc : 0.41794871794871796\n",
      "Epoch 1741/10000, Loss: 1.6371487379074097, Train Acc : 0.4173829990448902 , Val Acc : 0.41794871794871796\n",
      "Epoch 1742/10000, Loss: 1.6159523725509644, Train Acc : 0.4164278892072588 , Val Acc : 0.41794871794871796\n",
      "Epoch 1743/10000, Loss: 1.6341325044631958, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1744/10000, Loss: 1.609778642654419, Train Acc : 0.4173829990448902 , Val Acc : 0.41794871794871796\n",
      "Epoch 1745/10000, Loss: 1.6243749856948853, Train Acc : 0.41674625915313596 , Val Acc : 0.41794871794871796\n",
      "Epoch 1746/10000, Loss: 1.643155574798584, Train Acc : 0.4173829990448902 , Val Acc : 0.4205128205128205\n",
      "Epoch 1747/10000, Loss: 1.5908859968185425, Train Acc : 0.41674625915313596 , Val Acc : 0.41794871794871796\n",
      "Epoch 1748/10000, Loss: 1.656256914138794, Train Acc : 0.41674625915313596 , Val Acc : 0.4205128205128205\n",
      "Epoch 1749/10000, Loss: 1.5962560176849365, Train Acc : 0.41674625915313596 , Val Acc : 0.41794871794871796\n",
      "Epoch 1750/10000, Loss: 1.5841448307037354, Train Acc : 0.41770136899076726 , Val Acc : 0.4205128205128205\n",
      "Epoch 1751/10000, Loss: 1.6364719867706299, Train Acc : 0.4164278892072588 , Val Acc : 0.4205128205128205\n",
      "Epoch 1752/10000, Loss: 1.6512739658355713, Train Acc : 0.41706462909901304 , Val Acc : 0.4205128205128205\n",
      "Epoch 1753/10000, Loss: 1.5633981227874756, Train Acc : 0.41770136899076726 , Val Acc : 0.4205128205128205\n",
      "Epoch 1754/10000, Loss: 1.6399437189102173, Train Acc : 0.41674625915313596 , Val Acc : 0.4205128205128205\n",
      "Epoch 1755/10000, Loss: 1.6310186386108398, Train Acc : 0.41706462909901304 , Val Acc : 0.4205128205128205\n",
      "Epoch 1756/10000, Loss: 1.669747233390808, Train Acc : 0.41674625915313596 , Val Acc : 0.4205128205128205\n",
      "Epoch 1757/10000, Loss: 1.6823680400848389, Train Acc : 0.41674625915313596 , Val Acc : 0.4230769230769231\n",
      "Epoch 1758/10000, Loss: 1.6088409423828125, Train Acc : 0.41610951926138173 , Val Acc : 0.4230769230769231\n",
      "Epoch 1759/10000, Loss: 1.654869794845581, Train Acc : 0.4173829990448902 , Val Acc : 0.4230769230769231\n",
      "Epoch 1760/10000, Loss: 1.6608233451843262, Train Acc : 0.41770136899076726 , Val Acc : 0.4205128205128205\n",
      "Epoch 1761/10000, Loss: 1.5609945058822632, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1762/10000, Loss: 1.6692843437194824, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1763/10000, Loss: 1.6211062669754028, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1764/10000, Loss: 1.6267517805099487, Train Acc : 0.4173829990448902 , Val Acc : 0.4230769230769231\n",
      "Epoch 1765/10000, Loss: 1.6877039670944214, Train Acc : 0.4164278892072588 , Val Acc : 0.4230769230769231\n",
      "Epoch 1766/10000, Loss: 1.6807279586791992, Train Acc : 0.41706462909901304 , Val Acc : 0.4230769230769231\n",
      "Epoch 1767/10000, Loss: 1.672290325164795, Train Acc : 0.41706462909901304 , Val Acc : 0.4230769230769231\n",
      "Epoch 1768/10000, Loss: 1.6065256595611572, Train Acc : 0.41706462909901304 , Val Acc : 0.4230769230769231\n",
      "Epoch 1769/10000, Loss: 1.6280131340026855, Train Acc : 0.4164278892072588 , Val Acc : 0.4230769230769231\n",
      "Epoch 1770/10000, Loss: 1.5787454843521118, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1771/10000, Loss: 1.5668548345565796, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1772/10000, Loss: 1.612317681312561, Train Acc : 0.4173829990448902 , Val Acc : 0.4230769230769231\n",
      "Epoch 1773/10000, Loss: 1.6917332410812378, Train Acc : 0.4173829990448902 , Val Acc : 0.4230769230769231\n",
      "Epoch 1774/10000, Loss: 1.746352195739746, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1775/10000, Loss: 1.5866197347640991, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1776/10000, Loss: 1.6170188188552856, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1777/10000, Loss: 1.6328001022338867, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1778/10000, Loss: 1.6384440660476685, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1779/10000, Loss: 1.66079843044281, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1780/10000, Loss: 1.6269582509994507, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1781/10000, Loss: 1.6721000671386719, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1782/10000, Loss: 1.6701605319976807, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1783/10000, Loss: 1.6863855123519897, Train Acc : 0.41961158866602993 , Val Acc : 0.4230769230769231\n",
      "Epoch 1784/10000, Loss: 1.6303766965866089, Train Acc : 0.4189748487742757 , Val Acc : 0.4230769230769231\n",
      "Epoch 1785/10000, Loss: 1.6129482984542847, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1786/10000, Loss: 1.6706459522247314, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1787/10000, Loss: 1.6089884042739868, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1788/10000, Loss: 1.674649953842163, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1789/10000, Loss: 1.646863579750061, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1790/10000, Loss: 1.6575971841812134, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1791/10000, Loss: 1.6489803791046143, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1792/10000, Loss: 1.6841092109680176, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1793/10000, Loss: 1.6349258422851562, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1794/10000, Loss: 1.650438666343689, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1795/10000, Loss: 1.6337019205093384, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1796/10000, Loss: 1.6245273351669312, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1797/10000, Loss: 1.652890682220459, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1798/10000, Loss: 1.6321320533752441, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1799/10000, Loss: 1.5755558013916016, Train Acc : 0.4192932187201528 , Val Acc : 0.4230769230769231\n",
      "Epoch 1800/10000, Loss: 1.6360664367675781, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1801/10000, Loss: 1.6685954332351685, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1802/10000, Loss: 1.6242825984954834, Train Acc : 0.4192932187201528 , Val Acc : 0.4230769230769231\n",
      "Epoch 1803/10000, Loss: 1.6077475547790527, Train Acc : 0.4189748487742757 , Val Acc : 0.4230769230769231\n",
      "Epoch 1804/10000, Loss: 1.6434251070022583, Train Acc : 0.4192932187201528 , Val Acc : 0.4230769230769231\n",
      "Epoch 1805/10000, Loss: 1.6690951585769653, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1806/10000, Loss: 1.6378769874572754, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1807/10000, Loss: 1.633188009262085, Train Acc : 0.4189748487742757 , Val Acc : 0.4230769230769231\n",
      "Epoch 1808/10000, Loss: 1.5905721187591553, Train Acc : 0.4192932187201528 , Val Acc : 0.4230769230769231\n",
      "Epoch 1809/10000, Loss: 1.7014687061309814, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1810/10000, Loss: 1.6782740354537964, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1811/10000, Loss: 1.665489912033081, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1812/10000, Loss: 1.6071840524673462, Train Acc : 0.4189748487742757 , Val Acc : 0.4230769230769231\n",
      "Epoch 1813/10000, Loss: 1.6871105432510376, Train Acc : 0.4189748487742757 , Val Acc : 0.4230769230769231\n",
      "Epoch 1814/10000, Loss: 1.6161773204803467, Train Acc : 0.419929958611907 , Val Acc : 0.4230769230769231\n",
      "Epoch 1815/10000, Loss: 1.6658368110656738, Train Acc : 0.4192932187201528 , Val Acc : 0.4230769230769231\n",
      "Epoch 1816/10000, Loss: 1.638990044593811, Train Acc : 0.41961158866602993 , Val Acc : 0.4230769230769231\n",
      "Epoch 1817/10000, Loss: 1.6654921770095825, Train Acc : 0.4189748487742757 , Val Acc : 0.4230769230769231\n",
      "Epoch 1818/10000, Loss: 1.6781617403030396, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1819/10000, Loss: 1.5529693365097046, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1820/10000, Loss: 1.601088047027588, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1821/10000, Loss: 1.6115697622299194, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1822/10000, Loss: 1.6478992700576782, Train Acc : 0.4189748487742757 , Val Acc : 0.4230769230769231\n",
      "Epoch 1823/10000, Loss: 1.6281406879425049, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1824/10000, Loss: 1.5993889570236206, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1825/10000, Loss: 1.676274061203003, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1826/10000, Loss: 1.6182868480682373, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1827/10000, Loss: 1.6260026693344116, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1828/10000, Loss: 1.6827293634414673, Train Acc : 0.41961158866602993 , Val Acc : 0.4230769230769231\n",
      "Epoch 1829/10000, Loss: 1.6400930881500244, Train Acc : 0.41961158866602993 , Val Acc : 0.4230769230769231\n",
      "Epoch 1830/10000, Loss: 1.5907156467437744, Train Acc : 0.4173829990448902 , Val Acc : 0.4230769230769231\n",
      "Epoch 1831/10000, Loss: 1.6419434547424316, Train Acc : 0.4173829990448902 , Val Acc : 0.4230769230769231\n",
      "Epoch 1832/10000, Loss: 1.6273788213729858, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1833/10000, Loss: 1.6269935369491577, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1834/10000, Loss: 1.5992366075515747, Train Acc : 0.4189748487742757 , Val Acc : 0.4230769230769231\n",
      "Epoch 1835/10000, Loss: 1.4847575426101685, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1836/10000, Loss: 1.5719517469406128, Train Acc : 0.41706462909901304 , Val Acc : 0.4256410256410256\n",
      "Epoch 1837/10000, Loss: 1.701127052307129, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1838/10000, Loss: 1.6044082641601562, Train Acc : 0.41770136899076726 , Val Acc : 0.4256410256410256\n",
      "Epoch 1839/10000, Loss: 1.5670945644378662, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1840/10000, Loss: 1.6030467748641968, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1841/10000, Loss: 1.6273826360702515, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1842/10000, Loss: 1.578925371170044, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1843/10000, Loss: 1.6785062551498413, Train Acc : 0.41770136899076726 , Val Acc : 0.4230769230769231\n",
      "Epoch 1844/10000, Loss: 1.5628869533538818, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1845/10000, Loss: 1.6215803623199463, Train Acc : 0.4186564788283986 , Val Acc : 0.4230769230769231\n",
      "Epoch 1846/10000, Loss: 1.6179653406143188, Train Acc : 0.4192932187201528 , Val Acc : 0.4230769230769231\n",
      "Epoch 1847/10000, Loss: 1.644243597984314, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1848/10000, Loss: 1.6599373817443848, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1849/10000, Loss: 1.7000396251678467, Train Acc : 0.4180197389366444 , Val Acc : 0.4230769230769231\n",
      "Epoch 1850/10000, Loss: 1.6658210754394531, Train Acc : 0.4183381088825215 , Val Acc : 0.4230769230769231\n",
      "Epoch 1851/10000, Loss: 1.6675950288772583, Train Acc : 0.4180197389366444 , Val Acc : 0.4256410256410256\n",
      "Epoch 1852/10000, Loss: 1.663757562637329, Train Acc : 0.4189748487742757 , Val Acc : 0.4256410256410256\n",
      "Epoch 1853/10000, Loss: 1.6217634677886963, Train Acc : 0.4192932187201528 , Val Acc : 0.4256410256410256\n",
      "Epoch 1854/10000, Loss: 1.6310511827468872, Train Acc : 0.4189748487742757 , Val Acc : 0.4256410256410256\n",
      "Epoch 1855/10000, Loss: 1.669862151145935, Train Acc : 0.41961158866602993 , Val Acc : 0.4256410256410256\n",
      "Epoch 1856/10000, Loss: 1.6081385612487793, Train Acc : 0.42024832855778416 , Val Acc : 0.4256410256410256\n",
      "Epoch 1857/10000, Loss: 1.5848482847213745, Train Acc : 0.4208850684495384 , Val Acc : 0.4256410256410256\n",
      "Epoch 1858/10000, Loss: 1.5913351774215698, Train Acc : 0.42056669850366124 , Val Acc : 0.4256410256410256\n",
      "Epoch 1859/10000, Loss: 1.6125025749206543, Train Acc : 0.42056669850366124 , Val Acc : 0.4256410256410256\n",
      "Epoch 1860/10000, Loss: 1.6496047973632812, Train Acc : 0.4192932187201528 , Val Acc : 0.4256410256410256\n",
      "Epoch 1861/10000, Loss: 1.6337624788284302, Train Acc : 0.4189748487742757 , Val Acc : 0.4282051282051282\n",
      "Epoch 1862/10000, Loss: 1.6152607202529907, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1863/10000, Loss: 1.6416963338851929, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1864/10000, Loss: 1.6856815814971924, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1865/10000, Loss: 1.64702308177948, Train Acc : 0.41961158866602993 , Val Acc : 0.4256410256410256\n",
      "Epoch 1866/10000, Loss: 1.6641850471496582, Train Acc : 0.41961158866602993 , Val Acc : 0.4256410256410256\n",
      "Epoch 1867/10000, Loss: 1.5855019092559814, Train Acc : 0.42056669850366124 , Val Acc : 0.4256410256410256\n",
      "Epoch 1868/10000, Loss: 1.6876907348632812, Train Acc : 0.42024832855778416 , Val Acc : 0.4256410256410256\n",
      "Epoch 1869/10000, Loss: 1.6149998903274536, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1870/10000, Loss: 1.6868749856948853, Train Acc : 0.41961158866602993 , Val Acc : 0.4256410256410256\n",
      "Epoch 1871/10000, Loss: 1.6617116928100586, Train Acc : 0.42024832855778416 , Val Acc : 0.4256410256410256\n",
      "Epoch 1872/10000, Loss: 1.6735670566558838, Train Acc : 0.41961158866602993 , Val Acc : 0.4256410256410256\n",
      "Epoch 1873/10000, Loss: 1.5900932550430298, Train Acc : 0.4189748487742757 , Val Acc : 0.4256410256410256\n",
      "Epoch 1874/10000, Loss: 1.6692655086517334, Train Acc : 0.42024832855778416 , Val Acc : 0.4256410256410256\n",
      "Epoch 1875/10000, Loss: 1.5687828063964844, Train Acc : 0.4192932187201528 , Val Acc : 0.4256410256410256\n",
      "Epoch 1876/10000, Loss: 1.6392090320587158, Train Acc : 0.42024832855778416 , Val Acc : 0.4256410256410256\n",
      "Epoch 1877/10000, Loss: 1.6607303619384766, Train Acc : 0.42024832855778416 , Val Acc : 0.4256410256410256\n",
      "Epoch 1878/10000, Loss: 1.6481213569641113, Train Acc : 0.42024832855778416 , Val Acc : 0.4256410256410256\n",
      "Epoch 1879/10000, Loss: 1.68889319896698, Train Acc : 0.42024832855778416 , Val Acc : 0.4256410256410256\n",
      "Epoch 1880/10000, Loss: 1.6015421152114868, Train Acc : 0.4192932187201528 , Val Acc : 0.4256410256410256\n",
      "Epoch 1881/10000, Loss: 1.5805233716964722, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1882/10000, Loss: 1.652273416519165, Train Acc : 0.41961158866602993 , Val Acc : 0.4256410256410256\n",
      "Epoch 1883/10000, Loss: 1.6530314683914185, Train Acc : 0.4192932187201528 , Val Acc : 0.4282051282051282\n",
      "Epoch 1884/10000, Loss: 1.6098179817199707, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1885/10000, Loss: 1.5557432174682617, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1886/10000, Loss: 1.6270605325698853, Train Acc : 0.4208850684495384 , Val Acc : 0.4256410256410256\n",
      "Epoch 1887/10000, Loss: 1.5732961893081665, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1888/10000, Loss: 1.5963904857635498, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1889/10000, Loss: 1.5775632858276367, Train Acc : 0.42024832855778416 , Val Acc : 0.4256410256410256\n",
      "Epoch 1890/10000, Loss: 1.5678631067276, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1891/10000, Loss: 1.6577818393707275, Train Acc : 0.419929958611907 , Val Acc : 0.4256410256410256\n",
      "Epoch 1892/10000, Loss: 1.6405725479125977, Train Acc : 0.419929958611907 , Val Acc : 0.4282051282051282\n",
      "Epoch 1893/10000, Loss: 1.6853866577148438, Train Acc : 0.419929958611907 , Val Acc : 0.4282051282051282\n",
      "Epoch 1894/10000, Loss: 1.665176510810852, Train Acc : 0.4183381088825215 , Val Acc : 0.4282051282051282\n",
      "Epoch 1895/10000, Loss: 1.6656256914138794, Train Acc : 0.41961158866602993 , Val Acc : 0.4282051282051282\n",
      "Epoch 1896/10000, Loss: 1.6120750904083252, Train Acc : 0.4192932187201528 , Val Acc : 0.4282051282051282\n",
      "Epoch 1897/10000, Loss: 1.704972743988037, Train Acc : 0.419929958611907 , Val Acc : 0.4282051282051282\n",
      "Epoch 1898/10000, Loss: 1.6387856006622314, Train Acc : 0.4186564788283986 , Val Acc : 0.4307692307692308\n",
      "Epoch 1899/10000, Loss: 1.6813092231750488, Train Acc : 0.4189748487742757 , Val Acc : 0.4282051282051282\n",
      "Epoch 1900/10000, Loss: 1.691921353340149, Train Acc : 0.419929958611907 , Val Acc : 0.4307692307692308\n",
      "Epoch 1901/10000, Loss: 1.6380689144134521, Train Acc : 0.42024832855778416 , Val Acc : 0.4282051282051282\n",
      "Epoch 1902/10000, Loss: 1.650266170501709, Train Acc : 0.42024832855778416 , Val Acc : 0.4307692307692308\n",
      "Epoch 1903/10000, Loss: 1.6805405616760254, Train Acc : 0.4192932187201528 , Val Acc : 0.4307692307692308\n",
      "Epoch 1904/10000, Loss: 1.6341619491577148, Train Acc : 0.4192932187201528 , Val Acc : 0.4307692307692308\n",
      "Epoch 1905/10000, Loss: 1.5522373914718628, Train Acc : 0.419929958611907 , Val Acc : 0.43333333333333335\n",
      "Epoch 1906/10000, Loss: 1.6421430110931396, Train Acc : 0.419929958611907 , Val Acc : 0.4307692307692308\n",
      "Epoch 1907/10000, Loss: 1.5502617359161377, Train Acc : 0.419929958611907 , Val Acc : 0.43333333333333335\n",
      "Epoch 1908/10000, Loss: 1.6226112842559814, Train Acc : 0.419929958611907 , Val Acc : 0.4307692307692308\n",
      "Epoch 1909/10000, Loss: 1.6691653728485107, Train Acc : 0.419929958611907 , Val Acc : 0.43333333333333335\n",
      "Epoch 1910/10000, Loss: 1.5766032934188843, Train Acc : 0.42024832855778416 , Val Acc : 0.43333333333333335\n",
      "Epoch 1911/10000, Loss: 1.6519004106521606, Train Acc : 0.419929958611907 , Val Acc : 0.43333333333333335\n",
      "Epoch 1912/10000, Loss: 1.6065925359725952, Train Acc : 0.419929958611907 , Val Acc : 0.43333333333333335\n",
      "Epoch 1913/10000, Loss: 1.6863991022109985, Train Acc : 0.419929958611907 , Val Acc : 0.43333333333333335\n",
      "Epoch 1914/10000, Loss: 1.6677749156951904, Train Acc : 0.419929958611907 , Val Acc : 0.4307692307692308\n",
      "Epoch 1915/10000, Loss: 1.6147559881210327, Train Acc : 0.42056669850366124 , Val Acc : 0.43333333333333335\n",
      "Epoch 1916/10000, Loss: 1.654963731765747, Train Acc : 0.4208850684495384 , Val Acc : 0.4307692307692308\n",
      "Epoch 1917/10000, Loss: 1.6252504587173462, Train Acc : 0.4208850684495384 , Val Acc : 0.4307692307692308\n",
      "Epoch 1918/10000, Loss: 1.6569777727127075, Train Acc : 0.4215218083412926 , Val Acc : 0.4307692307692308\n",
      "Epoch 1919/10000, Loss: 1.665010929107666, Train Acc : 0.4215218083412926 , Val Acc : 0.4307692307692308\n",
      "Epoch 1920/10000, Loss: 1.5931849479675293, Train Acc : 0.42056669850366124 , Val Acc : 0.4358974358974359\n",
      "Epoch 1921/10000, Loss: 1.6203522682189941, Train Acc : 0.42024832855778416 , Val Acc : 0.43333333333333335\n",
      "Epoch 1922/10000, Loss: 1.6779801845550537, Train Acc : 0.4208850684495384 , Val Acc : 0.4358974358974359\n",
      "Epoch 1923/10000, Loss: 1.6013044118881226, Train Acc : 0.42024832855778416 , Val Acc : 0.4358974358974359\n",
      "Epoch 1924/10000, Loss: 1.5921863317489624, Train Acc : 0.42056669850366124 , Val Acc : 0.43333333333333335\n",
      "Epoch 1925/10000, Loss: 1.6550359725952148, Train Acc : 0.4215218083412926 , Val Acc : 0.43333333333333335\n",
      "Epoch 1926/10000, Loss: 1.5812690258026123, Train Acc : 0.4215218083412926 , Val Acc : 0.43333333333333335\n",
      "Epoch 1927/10000, Loss: 1.6135528087615967, Train Acc : 0.42056669850366124 , Val Acc : 0.43333333333333335\n",
      "Epoch 1928/10000, Loss: 1.700411319732666, Train Acc : 0.42024832855778416 , Val Acc : 0.43333333333333335\n",
      "Epoch 1929/10000, Loss: 1.6014925241470337, Train Acc : 0.42024832855778416 , Val Acc : 0.43333333333333335\n",
      "Epoch 1930/10000, Loss: 1.6324862241744995, Train Acc : 0.4208850684495384 , Val Acc : 0.43333333333333335\n",
      "Epoch 1931/10000, Loss: 1.7052483558654785, Train Acc : 0.42056669850366124 , Val Acc : 0.4358974358974359\n",
      "Epoch 1932/10000, Loss: 1.6826684474945068, Train Acc : 0.4208850684495384 , Val Acc : 0.43333333333333335\n",
      "Epoch 1933/10000, Loss: 1.665792465209961, Train Acc : 0.4218401782871697 , Val Acc : 0.43333333333333335\n",
      "Epoch 1934/10000, Loss: 1.6498061418533325, Train Acc : 0.4218401782871697 , Val Acc : 0.43333333333333335\n",
      "Epoch 1935/10000, Loss: 1.6523478031158447, Train Acc : 0.42056669850366124 , Val Acc : 0.43333333333333335\n",
      "Epoch 1936/10000, Loss: 1.618492841720581, Train Acc : 0.4208850684495384 , Val Acc : 0.4358974358974359\n",
      "Epoch 1937/10000, Loss: 1.5907649993896484, Train Acc : 0.42056669850366124 , Val Acc : 0.4358974358974359\n",
      "Epoch 1938/10000, Loss: 1.5241724252700806, Train Acc : 0.42056669850366124 , Val Acc : 0.43333333333333335\n",
      "Epoch 1939/10000, Loss: 1.6777807474136353, Train Acc : 0.4208850684495384 , Val Acc : 0.4358974358974359\n",
      "Epoch 1940/10000, Loss: 1.6229286193847656, Train Acc : 0.4208850684495384 , Val Acc : 0.43333333333333335\n",
      "Epoch 1941/10000, Loss: 1.6058318614959717, Train Acc : 0.42056669850366124 , Val Acc : 0.43333333333333335\n",
      "Epoch 1942/10000, Loss: 1.6422754526138306, Train Acc : 0.4208850684495384 , Val Acc : 0.43333333333333335\n",
      "Epoch 1943/10000, Loss: 1.6089720726013184, Train Acc : 0.4208850684495384 , Val Acc : 0.43333333333333335\n",
      "Epoch 1944/10000, Loss: 1.5761973857879639, Train Acc : 0.4215218083412926 , Val Acc : 0.43333333333333335\n",
      "Epoch 1945/10000, Loss: 1.629464030265808, Train Acc : 0.42056669850366124 , Val Acc : 0.4358974358974359\n",
      "Epoch 1946/10000, Loss: 1.6540412902832031, Train Acc : 0.42120343839541546 , Val Acc : 0.43333333333333335\n",
      "Epoch 1947/10000, Loss: 1.7021030187606812, Train Acc : 0.42120343839541546 , Val Acc : 0.4358974358974359\n",
      "Epoch 1948/10000, Loss: 1.6103715896606445, Train Acc : 0.42120343839541546 , Val Acc : 0.43333333333333335\n",
      "Epoch 1949/10000, Loss: 1.6317094564437866, Train Acc : 0.4208850684495384 , Val Acc : 0.43333333333333335\n",
      "Epoch 1950/10000, Loss: 1.701438307762146, Train Acc : 0.42120343839541546 , Val Acc : 0.4358974358974359\n",
      "Epoch 1951/10000, Loss: 1.5666449069976807, Train Acc : 0.42120343839541546 , Val Acc : 0.4358974358974359\n",
      "Epoch 1952/10000, Loss: 1.5774873495101929, Train Acc : 0.4208850684495384 , Val Acc : 0.43333333333333335\n",
      "Epoch 1953/10000, Loss: 1.6216754913330078, Train Acc : 0.42120343839541546 , Val Acc : 0.43333333333333335\n",
      "Epoch 1954/10000, Loss: 1.5719237327575684, Train Acc : 0.4218401782871697 , Val Acc : 0.4358974358974359\n",
      "Epoch 1955/10000, Loss: 1.6859445571899414, Train Acc : 0.4208850684495384 , Val Acc : 0.4358974358974359\n",
      "Epoch 1956/10000, Loss: 1.6370341777801514, Train Acc : 0.4215218083412926 , Val Acc : 0.43333333333333335\n",
      "Epoch 1957/10000, Loss: 1.5514976978302002, Train Acc : 0.4218401782871697 , Val Acc : 0.43333333333333335\n",
      "Epoch 1958/10000, Loss: 1.6480435132980347, Train Acc : 0.42120343839541546 , Val Acc : 0.4358974358974359\n",
      "Epoch 1959/10000, Loss: 1.6315839290618896, Train Acc : 0.4218401782871697 , Val Acc : 0.43333333333333335\n",
      "Epoch 1960/10000, Loss: 1.6085090637207031, Train Acc : 0.4215218083412926 , Val Acc : 0.43333333333333335\n",
      "Epoch 1961/10000, Loss: 1.6337333917617798, Train Acc : 0.4215218083412926 , Val Acc : 0.4358974358974359\n",
      "Epoch 1962/10000, Loss: 1.6376086473464966, Train Acc : 0.42120343839541546 , Val Acc : 0.4358974358974359\n",
      "Epoch 1963/10000, Loss: 1.6957603693008423, Train Acc : 0.4215218083412926 , Val Acc : 0.43333333333333335\n",
      "Epoch 1964/10000, Loss: 1.5712031126022339, Train Acc : 0.4218401782871697 , Val Acc : 0.43333333333333335\n",
      "Epoch 1965/10000, Loss: 1.6443257331848145, Train Acc : 0.42120343839541546 , Val Acc : 0.4358974358974359\n",
      "Epoch 1966/10000, Loss: 1.6207795143127441, Train Acc : 0.42120343839541546 , Val Acc : 0.4358974358974359\n",
      "Epoch 1967/10000, Loss: 1.5907970666885376, Train Acc : 0.4215218083412926 , Val Acc : 0.43333333333333335\n",
      "Epoch 1968/10000, Loss: 1.6560393571853638, Train Acc : 0.4221585482330468 , Val Acc : 0.4358974358974359\n",
      "Epoch 1969/10000, Loss: 1.5875434875488281, Train Acc : 0.4224769181789239 , Val Acc : 0.43333333333333335\n",
      "Epoch 1970/10000, Loss: 1.5653421878814697, Train Acc : 0.4224769181789239 , Val Acc : 0.43333333333333335\n",
      "Epoch 1971/10000, Loss: 1.643682599067688, Train Acc : 0.4221585482330468 , Val Acc : 0.43333333333333335\n",
      "Epoch 1972/10000, Loss: 1.6048096418380737, Train Acc : 0.4215218083412926 , Val Acc : 0.4358974358974359\n",
      "Epoch 1973/10000, Loss: 1.6801999807357788, Train Acc : 0.4221585482330468 , Val Acc : 0.43333333333333335\n",
      "Epoch 1974/10000, Loss: 1.5712676048278809, Train Acc : 0.4224769181789239 , Val Acc : 0.4358974358974359\n",
      "Epoch 1975/10000, Loss: 1.5668070316314697, Train Acc : 0.4221585482330468 , Val Acc : 0.4358974358974359\n",
      "Epoch 1976/10000, Loss: 1.6720720529556274, Train Acc : 0.4215218083412926 , Val Acc : 0.43333333333333335\n",
      "Epoch 1977/10000, Loss: 1.6422706842422485, Train Acc : 0.42056669850366124 , Val Acc : 0.4358974358974359\n",
      "Epoch 1978/10000, Loss: 1.5876258611679077, Train Acc : 0.4218401782871697 , Val Acc : 0.4358974358974359\n",
      "Epoch 1979/10000, Loss: 1.6169475317001343, Train Acc : 0.4215218083412926 , Val Acc : 0.4358974358974359\n",
      "Epoch 1980/10000, Loss: 1.6087757349014282, Train Acc : 0.42311365807067813 , Val Acc : 0.4358974358974359\n",
      "Epoch 1981/10000, Loss: 1.596286654472351, Train Acc : 0.4224769181789239 , Val Acc : 0.4358974358974359\n",
      "Epoch 1982/10000, Loss: 1.638514518737793, Train Acc : 0.4221585482330468 , Val Acc : 0.4358974358974359\n",
      "Epoch 1983/10000, Loss: 1.7382854223251343, Train Acc : 0.4221585482330468 , Val Acc : 0.4358974358974359\n",
      "Epoch 1984/10000, Loss: 1.6039682626724243, Train Acc : 0.4224769181789239 , Val Acc : 0.4358974358974359\n",
      "Epoch 1985/10000, Loss: 1.6364084482192993, Train Acc : 0.4218401782871697 , Val Acc : 0.4358974358974359\n",
      "Epoch 1986/10000, Loss: 1.5375114679336548, Train Acc : 0.4224769181789239 , Val Acc : 0.4358974358974359\n",
      "Epoch 1987/10000, Loss: 1.6420129537582397, Train Acc : 0.4224769181789239 , Val Acc : 0.4358974358974359\n",
      "Epoch 1988/10000, Loss: 1.5813730955123901, Train Acc : 0.4234320280165552 , Val Acc : 0.43333333333333335\n",
      "Epoch 1989/10000, Loss: 1.6429423093795776, Train Acc : 0.4224769181789239 , Val Acc : 0.4358974358974359\n",
      "Epoch 1990/10000, Loss: 1.7196184396743774, Train Acc : 0.4224769181789239 , Val Acc : 0.4358974358974359\n",
      "Epoch 1991/10000, Loss: 1.5814906358718872, Train Acc : 0.4224769181789239 , Val Acc : 0.43333333333333335\n",
      "Epoch 1992/10000, Loss: 1.6704930067062378, Train Acc : 0.422795288124801 , Val Acc : 0.4358974358974359\n",
      "Epoch 1993/10000, Loss: 1.583662986755371, Train Acc : 0.42311365807067813 , Val Acc : 0.4358974358974359\n",
      "Epoch 1994/10000, Loss: 1.6123085021972656, Train Acc : 0.42375039796243236 , Val Acc : 0.4358974358974359\n",
      "Epoch 1995/10000, Loss: 1.6185166835784912, Train Acc : 0.422795288124801 , Val Acc : 0.4358974358974359\n",
      "Epoch 1996/10000, Loss: 1.635648488998413, Train Acc : 0.42311365807067813 , Val Acc : 0.43333333333333335\n",
      "Epoch 1997/10000, Loss: 1.5855375528335571, Train Acc : 0.4221585482330468 , Val Acc : 0.4358974358974359\n",
      "Epoch 1998/10000, Loss: 1.619983434677124, Train Acc : 0.4224769181789239 , Val Acc : 0.4358974358974359\n",
      "Epoch 1999/10000, Loss: 1.6067657470703125, Train Acc : 0.422795288124801 , Val Acc : 0.4358974358974359\n",
      "Epoch 2000/10000, Loss: 1.668561577796936, Train Acc : 0.42375039796243236 , Val Acc : 0.4358974358974359\n",
      "Epoch 2001/10000, Loss: 1.6014220714569092, Train Acc : 0.4224769181789239 , Val Acc : 0.43333333333333335\n",
      "Epoch 2002/10000, Loss: 1.6660383939743042, Train Acc : 0.42406876790830944 , Val Acc : 0.43333333333333335\n",
      "Epoch 2003/10000, Loss: 1.6103689670562744, Train Acc : 0.4243871378541866 , Val Acc : 0.4358974358974359\n",
      "Epoch 2004/10000, Loss: 1.684216022491455, Train Acc : 0.42375039796243236 , Val Acc : 0.43333333333333335\n",
      "Epoch 2005/10000, Loss: 1.6153755187988281, Train Acc : 0.4243871378541866 , Val Acc : 0.4358974358974359\n",
      "Epoch 2006/10000, Loss: 1.594178557395935, Train Acc : 0.42375039796243236 , Val Acc : 0.43333333333333335\n",
      "Epoch 2007/10000, Loss: 1.6507129669189453, Train Acc : 0.4234320280165552 , Val Acc : 0.4358974358974359\n",
      "Epoch 2008/10000, Loss: 1.6477408409118652, Train Acc : 0.4250238777459408 , Val Acc : 0.43333333333333335\n",
      "Epoch 2009/10000, Loss: 1.5945433378219604, Train Acc : 0.42406876790830944 , Val Acc : 0.4358974358974359\n",
      "Epoch 2010/10000, Loss: 1.6280739307403564, Train Acc : 0.42406876790830944 , Val Acc : 0.4358974358974359\n",
      "Epoch 2011/10000, Loss: 1.6732087135314941, Train Acc : 0.4250238777459408 , Val Acc : 0.4358974358974359\n",
      "Epoch 2012/10000, Loss: 1.620107650756836, Train Acc : 0.4250238777459408 , Val Acc : 0.43333333333333335\n",
      "Epoch 2013/10000, Loss: 1.6215232610702515, Train Acc : 0.42470550780006366 , Val Acc : 0.4358974358974359\n",
      "Epoch 2014/10000, Loss: 1.6425727605819702, Train Acc : 0.42406876790830944 , Val Acc : 0.4358974358974359\n",
      "Epoch 2015/10000, Loss: 1.567433476448059, Train Acc : 0.4243871378541866 , Val Acc : 0.4358974358974359\n",
      "Epoch 2016/10000, Loss: 1.5720466375350952, Train Acc : 0.4250238777459408 , Val Acc : 0.43333333333333335\n",
      "Epoch 2017/10000, Loss: 1.5983940362930298, Train Acc : 0.4250238777459408 , Val Acc : 0.4358974358974359\n",
      "Epoch 2018/10000, Loss: 1.638495683670044, Train Acc : 0.4250238777459408 , Val Acc : 0.4358974358974359\n",
      "Epoch 2019/10000, Loss: 1.592974066734314, Train Acc : 0.425660617637695 , Val Acc : 0.43333333333333335\n",
      "Epoch 2020/10000, Loss: 1.5986385345458984, Train Acc : 0.4250238777459408 , Val Acc : 0.43333333333333335\n",
      "Epoch 2021/10000, Loss: 1.620825171470642, Train Acc : 0.4250238777459408 , Val Acc : 0.43333333333333335\n",
      "Epoch 2022/10000, Loss: 1.5644752979278564, Train Acc : 0.4250238777459408 , Val Acc : 0.4358974358974359\n",
      "Epoch 2023/10000, Loss: 1.6829243898391724, Train Acc : 0.4243871378541866 , Val Acc : 0.43333333333333335\n",
      "Epoch 2024/10000, Loss: 1.6563637256622314, Train Acc : 0.4250238777459408 , Val Acc : 0.4358974358974359\n",
      "Epoch 2025/10000, Loss: 1.6360236406326294, Train Acc : 0.42406876790830944 , Val Acc : 0.4358974358974359\n",
      "Epoch 2026/10000, Loss: 1.712180495262146, Train Acc : 0.4253422476918179 , Val Acc : 0.43333333333333335\n",
      "Epoch 2027/10000, Loss: 1.579809308052063, Train Acc : 0.4250238777459408 , Val Acc : 0.43333333333333335\n",
      "Epoch 2028/10000, Loss: 1.5955736637115479, Train Acc : 0.4243871378541866 , Val Acc : 0.4358974358974359\n",
      "Epoch 2029/10000, Loss: 1.6299880743026733, Train Acc : 0.425660617637695 , Val Acc : 0.4358974358974359\n",
      "Epoch 2030/10000, Loss: 1.6587963104248047, Train Acc : 0.425660617637695 , Val Acc : 0.43333333333333335\n",
      "Epoch 2031/10000, Loss: 1.65457284450531, Train Acc : 0.4250238777459408 , Val Acc : 0.4358974358974359\n",
      "Epoch 2032/10000, Loss: 1.616493821144104, Train Acc : 0.4262973575294492 , Val Acc : 0.43333333333333335\n",
      "Epoch 2033/10000, Loss: 1.5570107698440552, Train Acc : 0.425660617637695 , Val Acc : 0.4358974358974359\n",
      "Epoch 2034/10000, Loss: 1.5747003555297852, Train Acc : 0.425660617637695 , Val Acc : 0.43333333333333335\n",
      "Epoch 2035/10000, Loss: 1.6142629384994507, Train Acc : 0.42470550780006366 , Val Acc : 0.43333333333333335\n",
      "Epoch 2036/10000, Loss: 1.5926295518875122, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2037/10000, Loss: 1.6309622526168823, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2038/10000, Loss: 1.632119059562683, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2039/10000, Loss: 1.6089167594909668, Train Acc : 0.4253422476918179 , Val Acc : 0.43333333333333335\n",
      "Epoch 2040/10000, Loss: 1.6196050643920898, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2041/10000, Loss: 1.5786014795303345, Train Acc : 0.425660617637695 , Val Acc : 0.43333333333333335\n",
      "Epoch 2042/10000, Loss: 1.600693941116333, Train Acc : 0.4253422476918179 , Val Acc : 0.43333333333333335\n",
      "Epoch 2043/10000, Loss: 1.6217002868652344, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2044/10000, Loss: 1.6066800355911255, Train Acc : 0.4250238777459408 , Val Acc : 0.4358974358974359\n",
      "Epoch 2045/10000, Loss: 1.5906308889389038, Train Acc : 0.42661572747532633 , Val Acc : 0.43333333333333335\n",
      "Epoch 2046/10000, Loss: 1.634704828262329, Train Acc : 0.4253422476918179 , Val Acc : 0.43333333333333335\n",
      "Epoch 2047/10000, Loss: 1.7254058122634888, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2048/10000, Loss: 1.6485778093338013, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2049/10000, Loss: 1.5874366760253906, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2050/10000, Loss: 1.6059399843215942, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2051/10000, Loss: 1.6463953256607056, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2052/10000, Loss: 1.6161413192749023, Train Acc : 0.4253422476918179 , Val Acc : 0.4358974358974359\n",
      "Epoch 2053/10000, Loss: 1.6788769960403442, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2054/10000, Loss: 1.5638484954833984, Train Acc : 0.4253422476918179 , Val Acc : 0.4358974358974359\n",
      "Epoch 2055/10000, Loss: 1.6304365396499634, Train Acc : 0.42661572747532633 , Val Acc : 0.43333333333333335\n",
      "Epoch 2056/10000, Loss: 1.5592879056930542, Train Acc : 0.425660617637695 , Val Acc : 0.4358974358974359\n",
      "Epoch 2057/10000, Loss: 1.5900237560272217, Train Acc : 0.4253422476918179 , Val Acc : 0.4358974358974359\n",
      "Epoch 2058/10000, Loss: 1.583646297454834, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2059/10000, Loss: 1.6059576272964478, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2060/10000, Loss: 1.5568459033966064, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2061/10000, Loss: 1.6799718141555786, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2062/10000, Loss: 1.547814130783081, Train Acc : 0.4253422476918179 , Val Acc : 0.43333333333333335\n",
      "Epoch 2063/10000, Loss: 1.6776914596557617, Train Acc : 0.42661572747532633 , Val Acc : 0.43333333333333335\n",
      "Epoch 2064/10000, Loss: 1.620484709739685, Train Acc : 0.42661572747532633 , Val Acc : 0.43333333333333335\n",
      "Epoch 2065/10000, Loss: 1.675449252128601, Train Acc : 0.4262973575294492 , Val Acc : 0.43333333333333335\n",
      "Epoch 2066/10000, Loss: 1.58860182762146, Train Acc : 0.425660617637695 , Val Acc : 0.43333333333333335\n",
      "Epoch 2067/10000, Loss: 1.5965379476547241, Train Acc : 0.425660617637695 , Val Acc : 0.43333333333333335\n",
      "Epoch 2068/10000, Loss: 1.6221396923065186, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2069/10000, Loss: 1.6106606721878052, Train Acc : 0.4262973575294492 , Val Acc : 0.43333333333333335\n",
      "Epoch 2070/10000, Loss: 1.644804835319519, Train Acc : 0.4253422476918179 , Val Acc : 0.4358974358974359\n",
      "Epoch 2071/10000, Loss: 1.602604627609253, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2072/10000, Loss: 1.6702189445495605, Train Acc : 0.4253422476918179 , Val Acc : 0.43333333333333335\n",
      "Epoch 2073/10000, Loss: 1.612202525138855, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2074/10000, Loss: 1.630737066268921, Train Acc : 0.425660617637695 , Val Acc : 0.43333333333333335\n",
      "Epoch 2075/10000, Loss: 1.6286405324935913, Train Acc : 0.4262973575294492 , Val Acc : 0.43333333333333335\n",
      "Epoch 2076/10000, Loss: 1.6526662111282349, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2077/10000, Loss: 1.6559070348739624, Train Acc : 0.4259789875835721 , Val Acc : 0.43846153846153846\n",
      "Epoch 2078/10000, Loss: 1.5957200527191162, Train Acc : 0.4262973575294492 , Val Acc : 0.43333333333333335\n",
      "Epoch 2079/10000, Loss: 1.6661465167999268, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2080/10000, Loss: 1.64761483669281, Train Acc : 0.425660617637695 , Val Acc : 0.4358974358974359\n",
      "Epoch 2081/10000, Loss: 1.6986368894577026, Train Acc : 0.425660617637695 , Val Acc : 0.4358974358974359\n",
      "Epoch 2082/10000, Loss: 1.560797095298767, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2083/10000, Loss: 1.6609431505203247, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2084/10000, Loss: 1.6387425661087036, Train Acc : 0.4259789875835721 , Val Acc : 0.43333333333333335\n",
      "Epoch 2085/10000, Loss: 1.6147657632827759, Train Acc : 0.4259789875835721 , Val Acc : 0.43846153846153846\n",
      "Epoch 2086/10000, Loss: 1.5713088512420654, Train Acc : 0.4269340974212034 , Val Acc : 0.43846153846153846\n",
      "Epoch 2087/10000, Loss: 1.67753005027771, Train Acc : 0.4262973575294492 , Val Acc : 0.43846153846153846\n",
      "Epoch 2088/10000, Loss: 1.5744109153747559, Train Acc : 0.4262973575294492 , Val Acc : 0.43846153846153846\n",
      "Epoch 2089/10000, Loss: 1.6465145349502563, Train Acc : 0.42661572747532633 , Val Acc : 0.43846153846153846\n",
      "Epoch 2090/10000, Loss: 1.5745105743408203, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2091/10000, Loss: 1.607897162437439, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2092/10000, Loss: 1.6668936014175415, Train Acc : 0.425660617637695 , Val Acc : 0.4358974358974359\n",
      "Epoch 2093/10000, Loss: 1.624937653541565, Train Acc : 0.4269340974212034 , Val Acc : 0.43846153846153846\n",
      "Epoch 2094/10000, Loss: 1.583815336227417, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2095/10000, Loss: 1.7307029962539673, Train Acc : 0.4269340974212034 , Val Acc : 0.43846153846153846\n",
      "Epoch 2096/10000, Loss: 1.618923306465149, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2097/10000, Loss: 1.5901179313659668, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2098/10000, Loss: 1.5903778076171875, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2099/10000, Loss: 1.6448382139205933, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2100/10000, Loss: 1.6479769945144653, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2101/10000, Loss: 1.6378074884414673, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2102/10000, Loss: 1.6580926179885864, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2103/10000, Loss: 1.6349889039993286, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2104/10000, Loss: 1.6147205829620361, Train Acc : 0.4253422476918179 , Val Acc : 0.4358974358974359\n",
      "Epoch 2105/10000, Loss: 1.666750192642212, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2106/10000, Loss: 1.630037546157837, Train Acc : 0.42661572747532633 , Val Acc : 0.43846153846153846\n",
      "Epoch 2107/10000, Loss: 1.6282932758331299, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2108/10000, Loss: 1.6950571537017822, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2109/10000, Loss: 1.7275824546813965, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2110/10000, Loss: 1.6316317319869995, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2111/10000, Loss: 1.5464520454406738, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2112/10000, Loss: 1.5932332277297974, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2113/10000, Loss: 1.5816081762313843, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2114/10000, Loss: 1.5533517599105835, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2115/10000, Loss: 1.6330474615097046, Train Acc : 0.4253422476918179 , Val Acc : 0.4358974358974359\n",
      "Epoch 2116/10000, Loss: 1.5686047077178955, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2117/10000, Loss: 1.6389997005462646, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2118/10000, Loss: 1.682813286781311, Train Acc : 0.4253422476918179 , Val Acc : 0.43846153846153846\n",
      "Epoch 2119/10000, Loss: 1.6031209230422974, Train Acc : 0.4259789875835721 , Val Acc : 0.43846153846153846\n",
      "Epoch 2120/10000, Loss: 1.581349492073059, Train Acc : 0.4259789875835721 , Val Acc : 0.43846153846153846\n",
      "Epoch 2121/10000, Loss: 1.660741925239563, Train Acc : 0.425660617637695 , Val Acc : 0.4358974358974359\n",
      "Epoch 2122/10000, Loss: 1.615228533744812, Train Acc : 0.4259789875835721 , Val Acc : 0.43846153846153846\n",
      "Epoch 2123/10000, Loss: 1.6536977291107178, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2124/10000, Loss: 1.671561598777771, Train Acc : 0.425660617637695 , Val Acc : 0.43846153846153846\n",
      "Epoch 2125/10000, Loss: 1.665079116821289, Train Acc : 0.425660617637695 , Val Acc : 0.4358974358974359\n",
      "Epoch 2126/10000, Loss: 1.587697982788086, Train Acc : 0.42661572747532633 , Val Acc : 0.43846153846153846\n",
      "Epoch 2127/10000, Loss: 1.6415621042251587, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2128/10000, Loss: 1.6388674974441528, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2129/10000, Loss: 1.670541763305664, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2130/10000, Loss: 1.6049678325653076, Train Acc : 0.4262973575294492 , Val Acc : 0.43846153846153846\n",
      "Epoch 2131/10000, Loss: 1.6666829586029053, Train Acc : 0.4259789875835721 , Val Acc : 0.4358974358974359\n",
      "Epoch 2132/10000, Loss: 1.568421721458435, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2133/10000, Loss: 1.618151068687439, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2134/10000, Loss: 1.6192327737808228, Train Acc : 0.42661572747532633 , Val Acc : 0.43846153846153846\n",
      "Epoch 2135/10000, Loss: 1.6789244413375854, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2136/10000, Loss: 1.6159604787826538, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2137/10000, Loss: 1.6636885404586792, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2138/10000, Loss: 1.6866958141326904, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2139/10000, Loss: 1.6170462369918823, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2140/10000, Loss: 1.5880365371704102, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2141/10000, Loss: 1.5808974504470825, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2142/10000, Loss: 1.515629768371582, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2143/10000, Loss: 1.6452711820602417, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2144/10000, Loss: 1.6092808246612549, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2145/10000, Loss: 1.5688332319259644, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2146/10000, Loss: 1.593830943107605, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2147/10000, Loss: 1.6848435401916504, Train Acc : 0.4262973575294492 , Val Acc : 0.4358974358974359\n",
      "Epoch 2148/10000, Loss: 1.576229453086853, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2149/10000, Loss: 1.6583809852600098, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2150/10000, Loss: 1.6978167295455933, Train Acc : 0.42757083731295764 , Val Acc : 0.43333333333333335\n",
      "Epoch 2151/10000, Loss: 1.5917387008666992, Train Acc : 0.42725246736708056 , Val Acc : 0.43333333333333335\n",
      "Epoch 2152/10000, Loss: 1.6138595342636108, Train Acc : 0.42725246736708056 , Val Acc : 0.43333333333333335\n",
      "Epoch 2153/10000, Loss: 1.6605333089828491, Train Acc : 0.4269340974212034 , Val Acc : 0.43333333333333335\n",
      "Epoch 2154/10000, Loss: 1.6199901103973389, Train Acc : 0.42661572747532633 , Val Acc : 0.43333333333333335\n",
      "Epoch 2155/10000, Loss: 1.59114408493042, Train Acc : 0.42725246736708056 , Val Acc : 0.43333333333333335\n",
      "Epoch 2156/10000, Loss: 1.5747921466827393, Train Acc : 0.42725246736708056 , Val Acc : 0.43333333333333335\n",
      "Epoch 2157/10000, Loss: 1.643517017364502, Train Acc : 0.42661572747532633 , Val Acc : 0.43333333333333335\n",
      "Epoch 2158/10000, Loss: 1.5774885416030884, Train Acc : 0.42661572747532633 , Val Acc : 0.43333333333333335\n",
      "Epoch 2159/10000, Loss: 1.6513252258300781, Train Acc : 0.4269340974212034 , Val Acc : 0.43333333333333335\n",
      "Epoch 2160/10000, Loss: 1.690425992012024, Train Acc : 0.42661572747532633 , Val Acc : 0.43333333333333335\n",
      "Epoch 2161/10000, Loss: 1.5884681940078735, Train Acc : 0.4269340974212034 , Val Acc : 0.43333333333333335\n",
      "Epoch 2162/10000, Loss: 1.614745855331421, Train Acc : 0.42725246736708056 , Val Acc : 0.43333333333333335\n",
      "Epoch 2163/10000, Loss: 1.6070599555969238, Train Acc : 0.42661572747532633 , Val Acc : 0.4358974358974359\n",
      "Epoch 2164/10000, Loss: 1.6448252201080322, Train Acc : 0.42725246736708056 , Val Acc : 0.43333333333333335\n",
      "Epoch 2165/10000, Loss: 1.5692070722579956, Train Acc : 0.42725246736708056 , Val Acc : 0.43333333333333335\n",
      "Epoch 2166/10000, Loss: 1.6440496444702148, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2167/10000, Loss: 1.6141488552093506, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2168/10000, Loss: 1.5944249629974365, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2169/10000, Loss: 1.5766775608062744, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2170/10000, Loss: 1.6132209300994873, Train Acc : 0.4269340974212034 , Val Acc : 0.43333333333333335\n",
      "Epoch 2171/10000, Loss: 1.6698238849639893, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2172/10000, Loss: 1.6298353672027588, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2173/10000, Loss: 1.5860190391540527, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2174/10000, Loss: 1.685124397277832, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2175/10000, Loss: 1.6664986610412598, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2176/10000, Loss: 1.6455912590026855, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2177/10000, Loss: 1.5765440464019775, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2178/10000, Loss: 1.6407458782196045, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2179/10000, Loss: 1.619994878768921, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2180/10000, Loss: 1.685608983039856, Train Acc : 0.42725246736708056 , Val Acc : 0.43846153846153846\n",
      "Epoch 2181/10000, Loss: 1.563162088394165, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2182/10000, Loss: 1.6465349197387695, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2183/10000, Loss: 1.5870471000671387, Train Acc : 0.42820757720471186 , Val Acc : 0.4358974358974359\n",
      "Epoch 2184/10000, Loss: 1.5659568309783936, Train Acc : 0.428525947150589 , Val Acc : 0.4358974358974359\n",
      "Epoch 2185/10000, Loss: 1.6392648220062256, Train Acc : 0.42725246736708056 , Val Acc : 0.4358974358974359\n",
      "Epoch 2186/10000, Loss: 1.6766438484191895, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2187/10000, Loss: 1.6297473907470703, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2188/10000, Loss: 1.6198769807815552, Train Acc : 0.42820757720471186 , Val Acc : 0.4358974358974359\n",
      "Epoch 2189/10000, Loss: 1.535096287727356, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2190/10000, Loss: 1.6473417282104492, Train Acc : 0.42820757720471186 , Val Acc : 0.4358974358974359\n",
      "Epoch 2191/10000, Loss: 1.639260172843933, Train Acc : 0.42820757720471186 , Val Acc : 0.4358974358974359\n",
      "Epoch 2192/10000, Loss: 1.6253883838653564, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2193/10000, Loss: 1.5696377754211426, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2194/10000, Loss: 1.6437253952026367, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2195/10000, Loss: 1.6252429485321045, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2196/10000, Loss: 1.590896725654602, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2197/10000, Loss: 1.66172194480896, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2198/10000, Loss: 1.5860249996185303, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2199/10000, Loss: 1.5907325744628906, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2200/10000, Loss: 1.5536150932312012, Train Acc : 0.42820757720471186 , Val Acc : 0.4358974358974359\n",
      "Epoch 2201/10000, Loss: 1.6319106817245483, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2202/10000, Loss: 1.61912202835083, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2203/10000, Loss: 1.639036774635315, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2204/10000, Loss: 1.6677693128585815, Train Acc : 0.4269340974212034 , Val Acc : 0.4358974358974359\n",
      "Epoch 2205/10000, Loss: 1.6593518257141113, Train Acc : 0.428525947150589 , Val Acc : 0.4358974358974359\n",
      "Epoch 2206/10000, Loss: 1.6531018018722534, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2207/10000, Loss: 1.5409804582595825, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2208/10000, Loss: 1.6665258407592773, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2209/10000, Loss: 1.5668052434921265, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2210/10000, Loss: 1.636562705039978, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2211/10000, Loss: 1.6098958253860474, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2212/10000, Loss: 1.6749224662780762, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2213/10000, Loss: 1.5827194452285767, Train Acc : 0.42820757720471186 , Val Acc : 0.4358974358974359\n",
      "Epoch 2214/10000, Loss: 1.66402268409729, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2215/10000, Loss: 1.5905091762542725, Train Acc : 0.428525947150589 , Val Acc : 0.4358974358974359\n",
      "Epoch 2216/10000, Loss: 1.6447516679763794, Train Acc : 0.42820757720471186 , Val Acc : 0.4358974358974359\n",
      "Epoch 2217/10000, Loss: 1.5701115131378174, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2218/10000, Loss: 1.5940521955490112, Train Acc : 0.428525947150589 , Val Acc : 0.4358974358974359\n",
      "Epoch 2219/10000, Loss: 1.6450351476669312, Train Acc : 0.42820757720471186 , Val Acc : 0.4358974358974359\n",
      "Epoch 2220/10000, Loss: 1.6143746376037598, Train Acc : 0.4278892072588348 , Val Acc : 0.4358974358974359\n",
      "Epoch 2221/10000, Loss: 1.6170376539230347, Train Acc : 0.42757083731295764 , Val Acc : 0.4358974358974359\n",
      "Epoch 2222/10000, Loss: 1.617613673210144, Train Acc : 0.4294810569882203 , Val Acc : 0.4358974358974359\n",
      "Epoch 2223/10000, Loss: 1.547084927558899, Train Acc : 0.4288443170964661 , Val Acc : 0.4358974358974359\n",
      "Epoch 2224/10000, Loss: 1.5924780368804932, Train Acc : 0.428525947150589 , Val Acc : 0.4358974358974359\n",
      "Epoch 2225/10000, Loss: 1.6977429389953613, Train Acc : 0.4288443170964661 , Val Acc : 0.4358974358974359\n",
      "Epoch 2226/10000, Loss: 1.605665922164917, Train Acc : 0.4291626870423432 , Val Acc : 0.4358974358974359\n",
      "Epoch 2227/10000, Loss: 1.5450650453567505, Train Acc : 0.4288443170964661 , Val Acc : 0.4358974358974359\n",
      "Epoch 2228/10000, Loss: 1.5792436599731445, Train Acc : 0.428525947150589 , Val Acc : 0.4358974358974359\n",
      "Epoch 2229/10000, Loss: 1.604763150215149, Train Acc : 0.428525947150589 , Val Acc : 0.43846153846153846\n",
      "Epoch 2230/10000, Loss: 1.6194640398025513, Train Acc : 0.428525947150589 , Val Acc : 0.4358974358974359\n",
      "Epoch 2231/10000, Loss: 1.5728532075881958, Train Acc : 0.428525947150589 , Val Acc : 0.4358974358974359\n",
      "Epoch 2232/10000, Loss: 1.6278259754180908, Train Acc : 0.4291626870423432 , Val Acc : 0.4358974358974359\n",
      "Epoch 2233/10000, Loss: 1.647425889968872, Train Acc : 0.428525947150589 , Val Acc : 0.4358974358974359\n",
      "Epoch 2234/10000, Loss: 1.6424058675765991, Train Acc : 0.4294810569882203 , Val Acc : 0.4358974358974359\n",
      "Epoch 2235/10000, Loss: 1.6450999975204468, Train Acc : 0.4297994269340974 , Val Acc : 0.4358974358974359\n",
      "Epoch 2236/10000, Loss: 1.659804105758667, Train Acc : 0.4288443170964661 , Val Acc : 0.4358974358974359\n",
      "Epoch 2237/10000, Loss: 1.5503501892089844, Train Acc : 0.4291626870423432 , Val Acc : 0.4358974358974359\n",
      "Epoch 2238/10000, Loss: 1.5854434967041016, Train Acc : 0.4288443170964661 , Val Acc : 0.4358974358974359\n",
      "Epoch 2239/10000, Loss: 1.6356738805770874, Train Acc : 0.4294810569882203 , Val Acc : 0.4358974358974359\n",
      "Epoch 2240/10000, Loss: 1.6360373497009277, Train Acc : 0.4288443170964661 , Val Acc : 0.4358974358974359\n",
      "Epoch 2241/10000, Loss: 1.6475781202316284, Train Acc : 0.4291626870423432 , Val Acc : 0.4358974358974359\n",
      "Epoch 2242/10000, Loss: 1.6557656526565552, Train Acc : 0.4291626870423432 , Val Acc : 0.4358974358974359\n",
      "Epoch 2243/10000, Loss: 1.6786775588989258, Train Acc : 0.4288443170964661 , Val Acc : 0.4358974358974359\n",
      "Epoch 2244/10000, Loss: 1.6100304126739502, Train Acc : 0.4294810569882203 , Val Acc : 0.4358974358974359\n",
      "Epoch 2245/10000, Loss: 1.6230043172836304, Train Acc : 0.4297994269340974 , Val Acc : 0.43846153846153846\n",
      "Epoch 2246/10000, Loss: 1.64517080783844, Train Acc : 0.4297994269340974 , Val Acc : 0.4358974358974359\n",
      "Epoch 2247/10000, Loss: 1.5808662176132202, Train Acc : 0.4297994269340974 , Val Acc : 0.43846153846153846\n",
      "Epoch 2248/10000, Loss: 1.6046932935714722, Train Acc : 0.4291626870423432 , Val Acc : 0.4358974358974359\n",
      "Epoch 2249/10000, Loss: 1.5948829650878906, Train Acc : 0.4297994269340974 , Val Acc : 0.4358974358974359\n",
      "Epoch 2250/10000, Loss: 1.6130471229553223, Train Acc : 0.4297994269340974 , Val Acc : 0.43333333333333335\n",
      "Epoch 2251/10000, Loss: 1.6639423370361328, Train Acc : 0.4297994269340974 , Val Acc : 0.4358974358974359\n",
      "Epoch 2252/10000, Loss: 1.5842571258544922, Train Acc : 0.43011779687997453 , Val Acc : 0.43846153846153846\n",
      "Epoch 2253/10000, Loss: 1.5943288803100586, Train Acc : 0.4297994269340974 , Val Acc : 0.4358974358974359\n",
      "Epoch 2254/10000, Loss: 1.5986112356185913, Train Acc : 0.43011779687997453 , Val Acc : 0.4358974358974359\n",
      "Epoch 2255/10000, Loss: 1.545541763305664, Train Acc : 0.43011779687997453 , Val Acc : 0.43333333333333335\n",
      "Epoch 2256/10000, Loss: 1.5890586376190186, Train Acc : 0.43011779687997453 , Val Acc : 0.4358974358974359\n",
      "Epoch 2257/10000, Loss: 1.6196205615997314, Train Acc : 0.4304361668258516 , Val Acc : 0.4358974358974359\n",
      "Epoch 2258/10000, Loss: 1.6151199340820312, Train Acc : 0.4291626870423432 , Val Acc : 0.4358974358974359\n",
      "Epoch 2259/10000, Loss: 1.6308071613311768, Train Acc : 0.43011779687997453 , Val Acc : 0.43846153846153846\n",
      "Epoch 2260/10000, Loss: 1.5615286827087402, Train Acc : 0.4294810569882203 , Val Acc : 0.43846153846153846\n",
      "Epoch 2261/10000, Loss: 1.5855157375335693, Train Acc : 0.4297994269340974 , Val Acc : 0.43846153846153846\n",
      "Epoch 2262/10000, Loss: 1.5526981353759766, Train Acc : 0.43011779687997453 , Val Acc : 0.4358974358974359\n",
      "Epoch 2263/10000, Loss: 1.6100537776947021, Train Acc : 0.4304361668258516 , Val Acc : 0.43846153846153846\n",
      "Epoch 2264/10000, Loss: 1.584524393081665, Train Acc : 0.43011779687997453 , Val Acc : 0.4358974358974359\n",
      "Epoch 2265/10000, Loss: 1.591648817062378, Train Acc : 0.43011779687997453 , Val Acc : 0.43846153846153846\n",
      "Epoch 2266/10000, Loss: 1.5665100812911987, Train Acc : 0.43011779687997453 , Val Acc : 0.4358974358974359\n",
      "Epoch 2267/10000, Loss: 1.5814200639724731, Train Acc : 0.43011779687997453 , Val Acc : 0.4358974358974359\n",
      "Epoch 2268/10000, Loss: 1.5648725032806396, Train Acc : 0.4304361668258516 , Val Acc : 0.4358974358974359\n",
      "Epoch 2269/10000, Loss: 1.6551343202590942, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2270/10000, Loss: 1.641550898551941, Train Acc : 0.43011779687997453 , Val Acc : 0.4358974358974359\n",
      "Epoch 2271/10000, Loss: 1.5449600219726562, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2272/10000, Loss: 1.610991358757019, Train Acc : 0.4297994269340974 , Val Acc : 0.4358974358974359\n",
      "Epoch 2273/10000, Loss: 1.6263562440872192, Train Acc : 0.43075453677172876 , Val Acc : 0.43333333333333335\n",
      "Epoch 2274/10000, Loss: 1.6452654600143433, Train Acc : 0.43011779687997453 , Val Acc : 0.4358974358974359\n",
      "Epoch 2275/10000, Loss: 1.6637389659881592, Train Acc : 0.4304361668258516 , Val Acc : 0.4358974358974359\n",
      "Epoch 2276/10000, Loss: 1.6638338565826416, Train Acc : 0.4297994269340974 , Val Acc : 0.4358974358974359\n",
      "Epoch 2277/10000, Loss: 1.5917251110076904, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2278/10000, Loss: 1.6140862703323364, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2279/10000, Loss: 1.5995898246765137, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2280/10000, Loss: 1.6645251512527466, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2281/10000, Loss: 1.606998085975647, Train Acc : 0.4304361668258516 , Val Acc : 0.4358974358974359\n",
      "Epoch 2282/10000, Loss: 1.592495322227478, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2283/10000, Loss: 1.6281533241271973, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2284/10000, Loss: 1.6732699871063232, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2285/10000, Loss: 1.618059515953064, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2286/10000, Loss: 1.633028268814087, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2287/10000, Loss: 1.6043026447296143, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2288/10000, Loss: 1.5780078172683716, Train Acc : 0.4304361668258516 , Val Acc : 0.4358974358974359\n",
      "Epoch 2289/10000, Loss: 1.620073676109314, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2290/10000, Loss: 1.5919663906097412, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2291/10000, Loss: 1.6519172191619873, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2292/10000, Loss: 1.6227056980133057, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2293/10000, Loss: 1.5783051252365112, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2294/10000, Loss: 1.6144323348999023, Train Acc : 0.43170964660936006 , Val Acc : 0.43846153846153846\n",
      "Epoch 2295/10000, Loss: 1.6120755672454834, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2296/10000, Loss: 1.6295045614242554, Train Acc : 0.4304361668258516 , Val Acc : 0.4358974358974359\n",
      "Epoch 2297/10000, Loss: 1.605322003364563, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2298/10000, Loss: 1.643377423286438, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2299/10000, Loss: 1.6872719526290894, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2300/10000, Loss: 1.6198753118515015, Train Acc : 0.43075453677172876 , Val Acc : 0.4358974358974359\n",
      "Epoch 2301/10000, Loss: 1.6845989227294922, Train Acc : 0.43011779687997453 , Val Acc : 0.43846153846153846\n",
      "Epoch 2302/10000, Loss: 1.616274356842041, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2303/10000, Loss: 1.6126995086669922, Train Acc : 0.4304361668258516 , Val Acc : 0.4358974358974359\n",
      "Epoch 2304/10000, Loss: 1.6439388990402222, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2305/10000, Loss: 1.6542669534683228, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2306/10000, Loss: 1.6428428888320923, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2307/10000, Loss: 1.652092456817627, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2308/10000, Loss: 1.614682912826538, Train Acc : 0.431391276663483 , Val Acc : 0.43846153846153846\n",
      "Epoch 2309/10000, Loss: 1.6237889528274536, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2310/10000, Loss: 1.6508326530456543, Train Acc : 0.4323463865011143 , Val Acc : 0.43846153846153846\n",
      "Epoch 2311/10000, Loss: 1.6995645761489868, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2312/10000, Loss: 1.5524952411651611, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2313/10000, Loss: 1.623419165611267, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2314/10000, Loss: 1.5852115154266357, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2315/10000, Loss: 1.6251884698867798, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2316/10000, Loss: 1.5612983703613281, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2317/10000, Loss: 1.6351076364517212, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2318/10000, Loss: 1.6625347137451172, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2319/10000, Loss: 1.6226258277893066, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2320/10000, Loss: 1.5509252548217773, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2321/10000, Loss: 1.6658686399459839, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2322/10000, Loss: 1.6314643621444702, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2323/10000, Loss: 1.6455376148223877, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2324/10000, Loss: 1.624953269958496, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2325/10000, Loss: 1.561888575553894, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2326/10000, Loss: 1.6141295433044434, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2327/10000, Loss: 1.509966254234314, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2328/10000, Loss: 1.611269474029541, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2329/10000, Loss: 1.5908764600753784, Train Acc : 0.43170964660936006 , Val Acc : 0.43846153846153846\n",
      "Epoch 2330/10000, Loss: 1.5391769409179688, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2331/10000, Loss: 1.6238428354263306, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2332/10000, Loss: 1.5947121381759644, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2333/10000, Loss: 1.576819658279419, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2334/10000, Loss: 1.5901069641113281, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2335/10000, Loss: 1.6202903985977173, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2336/10000, Loss: 1.6205633878707886, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2337/10000, Loss: 1.668225884437561, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2338/10000, Loss: 1.6172223091125488, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2339/10000, Loss: 1.5953584909439087, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2340/10000, Loss: 1.6355286836624146, Train Acc : 0.43107290671760584 , Val Acc : 0.4358974358974359\n",
      "Epoch 2341/10000, Loss: 1.6131718158721924, Train Acc : 0.4320280165552372 , Val Acc : 0.43846153846153846\n",
      "Epoch 2342/10000, Loss: 1.5713530778884888, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2343/10000, Loss: 1.6557210683822632, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2344/10000, Loss: 1.6497489213943481, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2345/10000, Loss: 1.5795860290527344, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2346/10000, Loss: 1.6818668842315674, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2347/10000, Loss: 1.6295225620269775, Train Acc : 0.4323463865011143 , Val Acc : 0.43846153846153846\n",
      "Epoch 2348/10000, Loss: 1.6178333759307861, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2349/10000, Loss: 1.6258010864257812, Train Acc : 0.43170964660936006 , Val Acc : 0.43846153846153846\n",
      "Epoch 2350/10000, Loss: 1.621597170829773, Train Acc : 0.4323463865011143 , Val Acc : 0.43846153846153846\n",
      "Epoch 2351/10000, Loss: 1.6282870769500732, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2352/10000, Loss: 1.5425256490707397, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2353/10000, Loss: 1.592179536819458, Train Acc : 0.4320280165552372 , Val Acc : 0.43846153846153846\n",
      "Epoch 2354/10000, Loss: 1.6402403116226196, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2355/10000, Loss: 1.6648017168045044, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2356/10000, Loss: 1.6245687007904053, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2357/10000, Loss: 1.6463383436203003, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2358/10000, Loss: 1.6175391674041748, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2359/10000, Loss: 1.6085411310195923, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2360/10000, Loss: 1.6375786066055298, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2361/10000, Loss: 1.5312812328338623, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2362/10000, Loss: 1.5922893285751343, Train Acc : 0.4323463865011143 , Val Acc : 0.43846153846153846\n",
      "Epoch 2363/10000, Loss: 1.6568636894226074, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2364/10000, Loss: 1.5768988132476807, Train Acc : 0.4323463865011143 , Val Acc : 0.43846153846153846\n",
      "Epoch 2365/10000, Loss: 1.5638725757598877, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2366/10000, Loss: 1.7015804052352905, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2367/10000, Loss: 1.6062486171722412, Train Acc : 0.43170964660936006 , Val Acc : 0.43846153846153846\n",
      "Epoch 2368/10000, Loss: 1.6424790620803833, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2369/10000, Loss: 1.6349761486053467, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2370/10000, Loss: 1.6031322479248047, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2371/10000, Loss: 1.6595509052276611, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2372/10000, Loss: 1.6136863231658936, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2373/10000, Loss: 1.7007250785827637, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2374/10000, Loss: 1.6509910821914673, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2375/10000, Loss: 1.6084834337234497, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2376/10000, Loss: 1.6445109844207764, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2377/10000, Loss: 1.6513237953186035, Train Acc : 0.4323463865011143 , Val Acc : 0.43846153846153846\n",
      "Epoch 2378/10000, Loss: 1.6068711280822754, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2379/10000, Loss: 1.5832208395004272, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2380/10000, Loss: 1.6610972881317139, Train Acc : 0.431391276663483 , Val Acc : 0.4358974358974359\n",
      "Epoch 2381/10000, Loss: 1.6089915037155151, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2382/10000, Loss: 1.6163322925567627, Train Acc : 0.4326647564469914 , Val Acc : 0.4358974358974359\n",
      "Epoch 2383/10000, Loss: 1.6378830671310425, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2384/10000, Loss: 1.6024081707000732, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2385/10000, Loss: 1.625037431716919, Train Acc : 0.4323463865011143 , Val Acc : 0.43846153846153846\n",
      "Epoch 2386/10000, Loss: 1.625810980796814, Train Acc : 0.43170964660936006 , Val Acc : 0.4358974358974359\n",
      "Epoch 2387/10000, Loss: 1.6057460308074951, Train Acc : 0.4320280165552372 , Val Acc : 0.43846153846153846\n",
      "Epoch 2388/10000, Loss: 1.5917671918869019, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2389/10000, Loss: 1.6176451444625854, Train Acc : 0.43425660617637696 , Val Acc : 0.43846153846153846\n",
      "Epoch 2390/10000, Loss: 1.646470308303833, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2391/10000, Loss: 1.587965726852417, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2392/10000, Loss: 1.6038776636123657, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2393/10000, Loss: 1.5870873928070068, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2394/10000, Loss: 1.5769238471984863, Train Acc : 0.4320280165552372 , Val Acc : 0.4358974358974359\n",
      "Epoch 2395/10000, Loss: 1.6829626560211182, Train Acc : 0.4326647564469914 , Val Acc : 0.4358974358974359\n",
      "Epoch 2396/10000, Loss: 1.5883495807647705, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2397/10000, Loss: 1.6183128356933594, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2398/10000, Loss: 1.610622763633728, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2399/10000, Loss: 1.5496304035186768, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2400/10000, Loss: 1.511777639389038, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2401/10000, Loss: 1.5913087129592896, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2402/10000, Loss: 1.6837283372879028, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2403/10000, Loss: 1.6040550470352173, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2404/10000, Loss: 1.6117976903915405, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2405/10000, Loss: 1.6807634830474854, Train Acc : 0.4333014963387456 , Val Acc : 0.4358974358974359\n",
      "Epoch 2406/10000, Loss: 1.6677789688110352, Train Acc : 0.4323463865011143 , Val Acc : 0.43846153846153846\n",
      "Epoch 2407/10000, Loss: 1.6412640810012817, Train Acc : 0.4326647564469914 , Val Acc : 0.4358974358974359\n",
      "Epoch 2408/10000, Loss: 1.6461906433105469, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2409/10000, Loss: 1.6112933158874512, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2410/10000, Loss: 1.6126970052719116, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2411/10000, Loss: 1.6449466943740845, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2412/10000, Loss: 1.4930678606033325, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2413/10000, Loss: 1.602518081665039, Train Acc : 0.4326647564469914 , Val Acc : 0.4358974358974359\n",
      "Epoch 2414/10000, Loss: 1.5861706733703613, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2415/10000, Loss: 1.5965849161148071, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2416/10000, Loss: 1.6645418405532837, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2417/10000, Loss: 1.557163953781128, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2418/10000, Loss: 1.619770884513855, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2419/10000, Loss: 1.5887190103530884, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2420/10000, Loss: 1.5830899477005005, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2421/10000, Loss: 1.6430654525756836, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2422/10000, Loss: 1.6460429430007935, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2423/10000, Loss: 1.571798324584961, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2424/10000, Loss: 1.640692949295044, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2425/10000, Loss: 1.6561017036437988, Train Acc : 0.4323463865011143 , Val Acc : 0.4358974358974359\n",
      "Epoch 2426/10000, Loss: 1.6274802684783936, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2427/10000, Loss: 1.6604024171829224, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2428/10000, Loss: 1.6573506593704224, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2429/10000, Loss: 1.6273643970489502, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2430/10000, Loss: 1.6084331274032593, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2431/10000, Loss: 1.6178737878799438, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2432/10000, Loss: 1.5918121337890625, Train Acc : 0.4329831263928685 , Val Acc : 0.4358974358974359\n",
      "Epoch 2433/10000, Loss: 1.516431212425232, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2434/10000, Loss: 1.6476562023162842, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2435/10000, Loss: 1.6485180854797363, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2436/10000, Loss: 1.6884387731552124, Train Acc : 0.4329831263928685 , Val Acc : 0.43846153846153846\n",
      "Epoch 2437/10000, Loss: 1.5946534872055054, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2438/10000, Loss: 1.5742992162704468, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2439/10000, Loss: 1.6022382974624634, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2440/10000, Loss: 1.6048513650894165, Train Acc : 0.43425660617637696 , Val Acc : 0.43846153846153846\n",
      "Epoch 2441/10000, Loss: 1.5898385047912598, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2442/10000, Loss: 1.6096891164779663, Train Acc : 0.43361986628462273 , Val Acc : 0.4358974358974359\n",
      "Epoch 2443/10000, Loss: 1.4792265892028809, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2444/10000, Loss: 1.6032718420028687, Train Acc : 0.43425660617637696 , Val Acc : 0.4358974358974359\n",
      "Epoch 2445/10000, Loss: 1.5764967203140259, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2446/10000, Loss: 1.6671254634857178, Train Acc : 0.4326647564469914 , Val Acc : 0.43846153846153846\n",
      "Epoch 2447/10000, Loss: 1.6407872438430786, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2448/10000, Loss: 1.6333396434783936, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2449/10000, Loss: 1.6351261138916016, Train Acc : 0.43425660617637696 , Val Acc : 0.43846153846153846\n",
      "Epoch 2450/10000, Loss: 1.6273847818374634, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2451/10000, Loss: 1.6617848873138428, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2452/10000, Loss: 1.6096320152282715, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2453/10000, Loss: 1.661385178565979, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2454/10000, Loss: 1.6486237049102783, Train Acc : 0.43361986628462273 , Val Acc : 0.43846153846153846\n",
      "Epoch 2455/10000, Loss: 1.5561851263046265, Train Acc : 0.4333014963387456 , Val Acc : 0.43846153846153846\n",
      "Epoch 2456/10000, Loss: 1.6018993854522705, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2457/10000, Loss: 1.6082292795181274, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2458/10000, Loss: 1.6233091354370117, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2459/10000, Loss: 1.5690938234329224, Train Acc : 0.43425660617637696 , Val Acc : 0.43846153846153846\n",
      "Epoch 2460/10000, Loss: 1.7047823667526245, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2461/10000, Loss: 1.5710357427597046, Train Acc : 0.43425660617637696 , Val Acc : 0.43846153846153846\n",
      "Epoch 2462/10000, Loss: 1.6112561225891113, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2463/10000, Loss: 1.5903774499893188, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2464/10000, Loss: 1.6794990301132202, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2465/10000, Loss: 1.6124753952026367, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2466/10000, Loss: 1.5329945087432861, Train Acc : 0.43425660617637696 , Val Acc : 0.43846153846153846\n",
      "Epoch 2467/10000, Loss: 1.6112205982208252, Train Acc : 0.43425660617637696 , Val Acc : 0.43846153846153846\n",
      "Epoch 2468/10000, Loss: 1.5940582752227783, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2469/10000, Loss: 1.5717881917953491, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2470/10000, Loss: 1.6374990940093994, Train Acc : 0.4339382362304998 , Val Acc : 0.43846153846153846\n",
      "Epoch 2471/10000, Loss: 1.563069224357605, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2472/10000, Loss: 1.6895302534103394, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2473/10000, Loss: 1.5664615631103516, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2474/10000, Loss: 1.6388710737228394, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2475/10000, Loss: 1.642237901687622, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2476/10000, Loss: 1.6028836965560913, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2477/10000, Loss: 1.6299657821655273, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2478/10000, Loss: 1.7239552736282349, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2479/10000, Loss: 1.5888476371765137, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2480/10000, Loss: 1.6454840898513794, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2481/10000, Loss: 1.6157164573669434, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2482/10000, Loss: 1.6696699857711792, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2483/10000, Loss: 1.6168980598449707, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2484/10000, Loss: 1.6248259544372559, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2485/10000, Loss: 1.6134915351867676, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2486/10000, Loss: 1.6712113618850708, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2487/10000, Loss: 1.5661280155181885, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2488/10000, Loss: 1.6485004425048828, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2489/10000, Loss: 1.5972952842712402, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2490/10000, Loss: 1.5125515460968018, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2491/10000, Loss: 1.6325603723526, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2492/10000, Loss: 1.6485283374786377, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2493/10000, Loss: 1.5779582262039185, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2494/10000, Loss: 1.5799936056137085, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2495/10000, Loss: 1.5824456214904785, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2496/10000, Loss: 1.5633368492126465, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2497/10000, Loss: 1.515730619430542, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2498/10000, Loss: 1.5537073612213135, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2499/10000, Loss: 1.5853992700576782, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2500/10000, Loss: 1.603371024131775, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2501/10000, Loss: 1.6562988758087158, Train Acc : 0.43457497612225404 , Val Acc : 0.43846153846153846\n",
      "Epoch 2502/10000, Loss: 1.6274303197860718, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2503/10000, Loss: 1.6081321239471436, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2504/10000, Loss: 1.6092976331710815, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2505/10000, Loss: 1.5863683223724365, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2506/10000, Loss: 1.5812122821807861, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2507/10000, Loss: 1.5721209049224854, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2508/10000, Loss: 1.6537368297576904, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2509/10000, Loss: 1.5884135961532593, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2510/10000, Loss: 1.5724958181381226, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2511/10000, Loss: 1.6264019012451172, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2512/10000, Loss: 1.5824483633041382, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2513/10000, Loss: 1.5608991384506226, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2514/10000, Loss: 1.6031333208084106, Train Acc : 0.43712193568927094 , Val Acc : 0.43846153846153846\n",
      "Epoch 2515/10000, Loss: 1.6159735918045044, Train Acc : 0.4364851957975167 , Val Acc : 0.43846153846153846\n",
      "Epoch 2516/10000, Loss: 1.5836387872695923, Train Acc : 0.43616682585163963 , Val Acc : 0.43846153846153846\n",
      "Epoch 2517/10000, Loss: 1.6523311138153076, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2518/10000, Loss: 1.6397022008895874, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2519/10000, Loss: 1.6238727569580078, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2520/10000, Loss: 1.5632154941558838, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2521/10000, Loss: 1.6139440536499023, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2522/10000, Loss: 1.6491429805755615, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2523/10000, Loss: 1.6072548627853394, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2524/10000, Loss: 1.6076781749725342, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2525/10000, Loss: 1.609242558479309, Train Acc : 0.43616682585163963 , Val Acc : 0.43846153846153846\n",
      "Epoch 2526/10000, Loss: 1.630021333694458, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2527/10000, Loss: 1.6239038705825806, Train Acc : 0.4364851957975167 , Val Acc : 0.43846153846153846\n",
      "Epoch 2528/10000, Loss: 1.6530303955078125, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2529/10000, Loss: 1.6170470714569092, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2530/10000, Loss: 1.6620930433273315, Train Acc : 0.437440305635148 , Val Acc : 0.43846153846153846\n",
      "Epoch 2531/10000, Loss: 1.5798523426055908, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2532/10000, Loss: 1.631724238395691, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2533/10000, Loss: 1.6204841136932373, Train Acc : 0.43616682585163963 , Val Acc : 0.43846153846153846\n",
      "Epoch 2534/10000, Loss: 1.5938445329666138, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2535/10000, Loss: 1.6636085510253906, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2536/10000, Loss: 1.5590827465057373, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2537/10000, Loss: 1.531031608581543, Train Acc : 0.4348933460681312 , Val Acc : 0.43846153846153846\n",
      "Epoch 2538/10000, Loss: 1.617207646369934, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2539/10000, Loss: 1.5967533588409424, Train Acc : 0.4364851957975167 , Val Acc : 0.43846153846153846\n",
      "Epoch 2540/10000, Loss: 1.6869192123413086, Train Acc : 0.4364851957975167 , Val Acc : 0.43846153846153846\n",
      "Epoch 2541/10000, Loss: 1.6718695163726807, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2542/10000, Loss: 1.6536626815795898, Train Acc : 0.43712193568927094 , Val Acc : 0.43846153846153846\n",
      "Epoch 2543/10000, Loss: 1.5725147724151611, Train Acc : 0.4364851957975167 , Val Acc : 0.43846153846153846\n",
      "Epoch 2544/10000, Loss: 1.5388528108596802, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2545/10000, Loss: 1.6313401460647583, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2546/10000, Loss: 1.6760822534561157, Train Acc : 0.43616682585163963 , Val Acc : 0.43846153846153846\n",
      "Epoch 2547/10000, Loss: 1.6077167987823486, Train Acc : 0.4364851957975167 , Val Acc : 0.43846153846153846\n",
      "Epoch 2548/10000, Loss: 1.5799028873443604, Train Acc : 0.43616682585163963 , Val Acc : 0.43846153846153846\n",
      "Epoch 2549/10000, Loss: 1.546190619468689, Train Acc : 0.4364851957975167 , Val Acc : 0.43846153846153846\n",
      "Epoch 2550/10000, Loss: 1.6301636695861816, Train Acc : 0.43680356574339385 , Val Acc : 0.43846153846153846\n",
      "Epoch 2551/10000, Loss: 1.5998843908309937, Train Acc : 0.4364851957975167 , Val Acc : 0.44358974358974357\n",
      "Epoch 2552/10000, Loss: 1.6455472707748413, Train Acc : 0.4364851957975167 , Val Acc : 0.441025641025641\n",
      "Epoch 2553/10000, Loss: 1.663045048713684, Train Acc : 0.43680356574339385 , Val Acc : 0.441025641025641\n",
      "Epoch 2554/10000, Loss: 1.5461363792419434, Train Acc : 0.4358484559057625 , Val Acc : 0.441025641025641\n",
      "Epoch 2555/10000, Loss: 1.636078953742981, Train Acc : 0.43616682585163963 , Val Acc : 0.441025641025641\n",
      "Epoch 2556/10000, Loss: 1.6758368015289307, Train Acc : 0.43616682585163963 , Val Acc : 0.441025641025641\n",
      "Epoch 2557/10000, Loss: 1.5687328577041626, Train Acc : 0.4355300859598854 , Val Acc : 0.441025641025641\n",
      "Epoch 2558/10000, Loss: 1.5419549942016602, Train Acc : 0.43616682585163963 , Val Acc : 0.441025641025641\n",
      "Epoch 2559/10000, Loss: 1.6604331731796265, Train Acc : 0.43616682585163963 , Val Acc : 0.441025641025641\n",
      "Epoch 2560/10000, Loss: 1.5492274761199951, Train Acc : 0.437440305635148 , Val Acc : 0.441025641025641\n",
      "Epoch 2561/10000, Loss: 1.651771903038025, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2562/10000, Loss: 1.6234172582626343, Train Acc : 0.4364851957975167 , Val Acc : 0.43846153846153846\n",
      "Epoch 2563/10000, Loss: 1.6108814477920532, Train Acc : 0.4364851957975167 , Val Acc : 0.441025641025641\n",
      "Epoch 2564/10000, Loss: 1.6585458517074585, Train Acc : 0.4364851957975167 , Val Acc : 0.441025641025641\n",
      "Epoch 2565/10000, Loss: 1.6560189723968506, Train Acc : 0.4355300859598854 , Val Acc : 0.43846153846153846\n",
      "Epoch 2566/10000, Loss: 1.5926917791366577, Train Acc : 0.43521171601400827 , Val Acc : 0.43846153846153846\n",
      "Epoch 2567/10000, Loss: 1.6295677423477173, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2568/10000, Loss: 1.6175464391708374, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2569/10000, Loss: 1.5449378490447998, Train Acc : 0.4358484559057625 , Val Acc : 0.43846153846153846\n",
      "Epoch 2570/10000, Loss: 1.6251252889633179, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2571/10000, Loss: 1.6486732959747314, Train Acc : 0.4355300859598854 , Val Acc : 0.441025641025641\n",
      "Epoch 2572/10000, Loss: 1.5775038003921509, Train Acc : 0.43616682585163963 , Val Acc : 0.441025641025641\n",
      "Epoch 2573/10000, Loss: 1.5897773504257202, Train Acc : 0.4364851957975167 , Val Acc : 0.441025641025641\n",
      "Epoch 2574/10000, Loss: 1.554517388343811, Train Acc : 0.4358484559057625 , Val Acc : 0.441025641025641\n",
      "Epoch 2575/10000, Loss: 1.6099061965942383, Train Acc : 0.4358484559057625 , Val Acc : 0.441025641025641\n",
      "Epoch 2576/10000, Loss: 1.5790094137191772, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2577/10000, Loss: 1.6895545721054077, Train Acc : 0.43616682585163963 , Val Acc : 0.441025641025641\n",
      "Epoch 2578/10000, Loss: 1.6604734659194946, Train Acc : 0.43616682585163963 , Val Acc : 0.441025641025641\n",
      "Epoch 2579/10000, Loss: 1.6249467134475708, Train Acc : 0.4358484559057625 , Val Acc : 0.441025641025641\n",
      "Epoch 2580/10000, Loss: 1.592018961906433, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2581/10000, Loss: 1.681099534034729, Train Acc : 0.43775867558102516 , Val Acc : 0.44358974358974357\n",
      "Epoch 2582/10000, Loss: 1.6539790630340576, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2583/10000, Loss: 1.6068252325057983, Train Acc : 0.4364851957975167 , Val Acc : 0.441025641025641\n",
      "Epoch 2584/10000, Loss: 1.6272720098495483, Train Acc : 0.43680356574339385 , Val Acc : 0.441025641025641\n",
      "Epoch 2585/10000, Loss: 1.5966765880584717, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2586/10000, Loss: 1.5932601690292358, Train Acc : 0.43775867558102516 , Val Acc : 0.44358974358974357\n",
      "Epoch 2587/10000, Loss: 1.6241339445114136, Train Acc : 0.437440305635148 , Val Acc : 0.44358974358974357\n",
      "Epoch 2588/10000, Loss: 1.576850175857544, Train Acc : 0.43775867558102516 , Val Acc : 0.441025641025641\n",
      "Epoch 2589/10000, Loss: 1.6102606058120728, Train Acc : 0.43616682585163963 , Val Acc : 0.441025641025641\n",
      "Epoch 2590/10000, Loss: 1.5750205516815186, Train Acc : 0.4364851957975167 , Val Acc : 0.441025641025641\n",
      "Epoch 2591/10000, Loss: 1.5841985940933228, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2592/10000, Loss: 1.6147425174713135, Train Acc : 0.43680356574339385 , Val Acc : 0.441025641025641\n",
      "Epoch 2593/10000, Loss: 1.6333240270614624, Train Acc : 0.43680356574339385 , Val Acc : 0.441025641025641\n",
      "Epoch 2594/10000, Loss: 1.6177372932434082, Train Acc : 0.437440305635148 , Val Acc : 0.44358974358974357\n",
      "Epoch 2595/10000, Loss: 1.6433576345443726, Train Acc : 0.4383954154727794 , Val Acc : 0.44358974358974357\n",
      "Epoch 2596/10000, Loss: 1.6393544673919678, Train Acc : 0.43807704552690224 , Val Acc : 0.441025641025641\n",
      "Epoch 2597/10000, Loss: 1.540401577949524, Train Acc : 0.4364851957975167 , Val Acc : 0.441025641025641\n",
      "Epoch 2598/10000, Loss: 1.6497795581817627, Train Acc : 0.4364851957975167 , Val Acc : 0.441025641025641\n",
      "Epoch 2599/10000, Loss: 1.6173235177993774, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2600/10000, Loss: 1.5737937688827515, Train Acc : 0.43680356574339385 , Val Acc : 0.441025641025641\n",
      "Epoch 2601/10000, Loss: 1.5800813436508179, Train Acc : 0.43775867558102516 , Val Acc : 0.44358974358974357\n",
      "Epoch 2602/10000, Loss: 1.655491828918457, Train Acc : 0.43807704552690224 , Val Acc : 0.44358974358974357\n",
      "Epoch 2603/10000, Loss: 1.6322171688079834, Train Acc : 0.437440305635148 , Val Acc : 0.441025641025641\n",
      "Epoch 2604/10000, Loss: 1.6111886501312256, Train Acc : 0.43680356574339385 , Val Acc : 0.441025641025641\n",
      "Epoch 2605/10000, Loss: 1.6325011253356934, Train Acc : 0.437440305635148 , Val Acc : 0.441025641025641\n",
      "Epoch 2606/10000, Loss: 1.6070455312728882, Train Acc : 0.437440305635148 , Val Acc : 0.441025641025641\n",
      "Epoch 2607/10000, Loss: 1.580708384513855, Train Acc : 0.43775867558102516 , Val Acc : 0.44358974358974357\n",
      "Epoch 2608/10000, Loss: 1.624433994293213, Train Acc : 0.437440305635148 , Val Acc : 0.441025641025641\n",
      "Epoch 2609/10000, Loss: 1.5630382299423218, Train Acc : 0.43680356574339385 , Val Acc : 0.441025641025641\n",
      "Epoch 2610/10000, Loss: 1.5887776613235474, Train Acc : 0.43807704552690224 , Val Acc : 0.44358974358974357\n",
      "Epoch 2611/10000, Loss: 1.5448790788650513, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2612/10000, Loss: 1.6111701726913452, Train Acc : 0.437440305635148 , Val Acc : 0.441025641025641\n",
      "Epoch 2613/10000, Loss: 1.6874943971633911, Train Acc : 0.437440305635148 , Val Acc : 0.441025641025641\n",
      "Epoch 2614/10000, Loss: 1.6456871032714844, Train Acc : 0.4383954154727794 , Val Acc : 0.44358974358974357\n",
      "Epoch 2615/10000, Loss: 1.569223403930664, Train Acc : 0.43807704552690224 , Val Acc : 0.44358974358974357\n",
      "Epoch 2616/10000, Loss: 1.689365029335022, Train Acc : 0.43775867558102516 , Val Acc : 0.44358974358974357\n",
      "Epoch 2617/10000, Loss: 1.6849651336669922, Train Acc : 0.437440305635148 , Val Acc : 0.441025641025641\n",
      "Epoch 2618/10000, Loss: 1.6499511003494263, Train Acc : 0.43712193568927094 , Val Acc : 0.44358974358974357\n",
      "Epoch 2619/10000, Loss: 1.5945309400558472, Train Acc : 0.43775867558102516 , Val Acc : 0.441025641025641\n",
      "Epoch 2620/10000, Loss: 1.5408387184143066, Train Acc : 0.43775867558102516 , Val Acc : 0.441025641025641\n",
      "Epoch 2621/10000, Loss: 1.621107578277588, Train Acc : 0.437440305635148 , Val Acc : 0.44358974358974357\n",
      "Epoch 2622/10000, Loss: 1.6096580028533936, Train Acc : 0.4393505253104107 , Val Acc : 0.44358974358974357\n",
      "Epoch 2623/10000, Loss: 1.6376374959945679, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2624/10000, Loss: 1.5852257013320923, Train Acc : 0.437440305635148 , Val Acc : 0.44358974358974357\n",
      "Epoch 2625/10000, Loss: 1.5147782564163208, Train Acc : 0.43807704552690224 , Val Acc : 0.441025641025641\n",
      "Epoch 2626/10000, Loss: 1.6038646697998047, Train Acc : 0.43775867558102516 , Val Acc : 0.441025641025641\n",
      "Epoch 2627/10000, Loss: 1.6451319456100464, Train Acc : 0.4383954154727794 , Val Acc : 0.44358974358974357\n",
      "Epoch 2628/10000, Loss: 1.6503676176071167, Train Acc : 0.43712193568927094 , Val Acc : 0.441025641025641\n",
      "Epoch 2629/10000, Loss: 1.58033287525177, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2630/10000, Loss: 1.6253823041915894, Train Acc : 0.4393505253104107 , Val Acc : 0.441025641025641\n",
      "Epoch 2631/10000, Loss: 1.6700823307037354, Train Acc : 0.43775867558102516 , Val Acc : 0.441025641025641\n",
      "Epoch 2632/10000, Loss: 1.6670441627502441, Train Acc : 0.43807704552690224 , Val Acc : 0.44358974358974357\n",
      "Epoch 2633/10000, Loss: 1.5816634893417358, Train Acc : 0.4393505253104107 , Val Acc : 0.441025641025641\n",
      "Epoch 2634/10000, Loss: 1.6482048034667969, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2635/10000, Loss: 1.621376872062683, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2636/10000, Loss: 1.6005825996398926, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2637/10000, Loss: 1.6533818244934082, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2638/10000, Loss: 1.627604603767395, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2639/10000, Loss: 1.6620872020721436, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2640/10000, Loss: 1.6230262517929077, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2641/10000, Loss: 1.6146963834762573, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2642/10000, Loss: 1.6249878406524658, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2643/10000, Loss: 1.602420687675476, Train Acc : 0.4383954154727794 , Val Acc : 0.44358974358974357\n",
      "Epoch 2644/10000, Loss: 1.605147361755371, Train Acc : 0.4393505253104107 , Val Acc : 0.44358974358974357\n",
      "Epoch 2645/10000, Loss: 1.571673035621643, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2646/10000, Loss: 1.651822566986084, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2647/10000, Loss: 1.5530004501342773, Train Acc : 0.4393505253104107 , Val Acc : 0.44358974358974357\n",
      "Epoch 2648/10000, Loss: 1.49411940574646, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2649/10000, Loss: 1.5930405855178833, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2650/10000, Loss: 1.6094359159469604, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2651/10000, Loss: 1.6429386138916016, Train Acc : 0.4393505253104107 , Val Acc : 0.44358974358974357\n",
      "Epoch 2652/10000, Loss: 1.64760160446167, Train Acc : 0.4393505253104107 , Val Acc : 0.441025641025641\n",
      "Epoch 2653/10000, Loss: 1.5875740051269531, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2654/10000, Loss: 1.6476659774780273, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2655/10000, Loss: 1.6618189811706543, Train Acc : 0.4383954154727794 , Val Acc : 0.44358974358974357\n",
      "Epoch 2656/10000, Loss: 1.562391757965088, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2657/10000, Loss: 1.658982753753662, Train Acc : 0.43966889525628783 , Val Acc : 0.44358974358974357\n",
      "Epoch 2658/10000, Loss: 1.5545601844787598, Train Acc : 0.44030563514804205 , Val Acc : 0.44358974358974357\n",
      "Epoch 2659/10000, Loss: 1.61113703250885, Train Acc : 0.43966889525628783 , Val Acc : 0.44358974358974357\n",
      "Epoch 2660/10000, Loss: 1.6500035524368286, Train Acc : 0.43966889525628783 , Val Acc : 0.44358974358974357\n",
      "Epoch 2661/10000, Loss: 1.6171413660049438, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2662/10000, Loss: 1.6355531215667725, Train Acc : 0.4399872652021649 , Val Acc : 0.4461538461538462\n",
      "Epoch 2663/10000, Loss: 1.62250816822052, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2664/10000, Loss: 1.6451383829116821, Train Acc : 0.43966889525628783 , Val Acc : 0.44358974358974357\n",
      "Epoch 2665/10000, Loss: 1.6046154499053955, Train Acc : 0.4399872652021649 , Val Acc : 0.441025641025641\n",
      "Epoch 2666/10000, Loss: 1.714019536972046, Train Acc : 0.4399872652021649 , Val Acc : 0.4461538461538462\n",
      "Epoch 2667/10000, Loss: 1.6138759851455688, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2668/10000, Loss: 1.6794092655181885, Train Acc : 0.4393505253104107 , Val Acc : 0.44358974358974357\n",
      "Epoch 2669/10000, Loss: 1.6420084238052368, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2670/10000, Loss: 1.652938723564148, Train Acc : 0.4399872652021649 , Val Acc : 0.4461538461538462\n",
      "Epoch 2671/10000, Loss: 1.5901864767074585, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2672/10000, Loss: 1.599855661392212, Train Acc : 0.44030563514804205 , Val Acc : 0.44358974358974357\n",
      "Epoch 2673/10000, Loss: 1.6352838277816772, Train Acc : 0.4393505253104107 , Val Acc : 0.44358974358974357\n",
      "Epoch 2674/10000, Loss: 1.6683505773544312, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2675/10000, Loss: 1.6019470691680908, Train Acc : 0.43966889525628783 , Val Acc : 0.441025641025641\n",
      "Epoch 2676/10000, Loss: 1.5519901514053345, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2677/10000, Loss: 1.6498879194259644, Train Acc : 0.4390321553645336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2678/10000, Loss: 1.6300352811813354, Train Acc : 0.44030563514804205 , Val Acc : 0.44358974358974357\n",
      "Epoch 2679/10000, Loss: 1.6008460521697998, Train Acc : 0.43966889525628783 , Val Acc : 0.44358974358974357\n",
      "Epoch 2680/10000, Loss: 1.6309220790863037, Train Acc : 0.43966889525628783 , Val Acc : 0.44358974358974357\n",
      "Epoch 2681/10000, Loss: 1.6732689142227173, Train Acc : 0.43966889525628783 , Val Acc : 0.44358974358974357\n",
      "Epoch 2682/10000, Loss: 1.6206358671188354, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2683/10000, Loss: 1.545211911201477, Train Acc : 0.43871378541865647 , Val Acc : 0.44358974358974357\n",
      "Epoch 2684/10000, Loss: 1.5523381233215332, Train Acc : 0.43966889525628783 , Val Acc : 0.4461538461538462\n",
      "Epoch 2685/10000, Loss: 1.5077720880508423, Train Acc : 0.44030563514804205 , Val Acc : 0.44358974358974357\n",
      "Epoch 2686/10000, Loss: 1.582734227180481, Train Acc : 0.44030563514804205 , Val Acc : 0.4461538461538462\n",
      "Epoch 2687/10000, Loss: 1.6069878339767456, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2688/10000, Loss: 1.6420260667800903, Train Acc : 0.4393505253104107 , Val Acc : 0.44358974358974357\n",
      "Epoch 2689/10000, Loss: 1.6052544116973877, Train Acc : 0.4393505253104107 , Val Acc : 0.44358974358974357\n",
      "Epoch 2690/10000, Loss: 1.666230320930481, Train Acc : 0.43966889525628783 , Val Acc : 0.4461538461538462\n",
      "Epoch 2691/10000, Loss: 1.6322129964828491, Train Acc : 0.4409423750397962 , Val Acc : 0.44358974358974357\n",
      "Epoch 2692/10000, Loss: 1.5502697229385376, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2693/10000, Loss: 1.535941243171692, Train Acc : 0.44062400509391914 , Val Acc : 0.44358974358974357\n",
      "Epoch 2694/10000, Loss: 1.591516137123108, Train Acc : 0.44062400509391914 , Val Acc : 0.44358974358974357\n",
      "Epoch 2695/10000, Loss: 1.5427335500717163, Train Acc : 0.4409423750397962 , Val Acc : 0.4461538461538462\n",
      "Epoch 2696/10000, Loss: 1.6315362453460693, Train Acc : 0.44030563514804205 , Val Acc : 0.44358974358974357\n",
      "Epoch 2697/10000, Loss: 1.643031358718872, Train Acc : 0.4409423750397962 , Val Acc : 0.4461538461538462\n",
      "Epoch 2698/10000, Loss: 1.587608814239502, Train Acc : 0.4399872652021649 , Val Acc : 0.44358974358974357\n",
      "Epoch 2699/10000, Loss: 1.5509330034255981, Train Acc : 0.4399872652021649 , Val Acc : 0.441025641025641\n",
      "Epoch 2700/10000, Loss: 1.732359766960144, Train Acc : 0.44126074498567336 , Val Acc : 0.4461538461538462\n",
      "Epoch 2701/10000, Loss: 1.6690504550933838, Train Acc : 0.44030563514804205 , Val Acc : 0.4461538461538462\n",
      "Epoch 2702/10000, Loss: 1.6447173357009888, Train Acc : 0.4409423750397962 , Val Acc : 0.4461538461538462\n",
      "Epoch 2703/10000, Loss: 1.5723772048950195, Train Acc : 0.44062400509391914 , Val Acc : 0.4461538461538462\n",
      "Epoch 2704/10000, Loss: 1.5167698860168457, Train Acc : 0.44030563514804205 , Val Acc : 0.44358974358974357\n",
      "Epoch 2705/10000, Loss: 1.6360752582550049, Train Acc : 0.4409423750397962 , Val Acc : 0.44358974358974357\n",
      "Epoch 2706/10000, Loss: 1.6074520349502563, Train Acc : 0.44030563514804205 , Val Acc : 0.44358974358974357\n",
      "Epoch 2707/10000, Loss: 1.6080925464630127, Train Acc : 0.44126074498567336 , Val Acc : 0.4461538461538462\n",
      "Epoch 2708/10000, Loss: 1.5933791399002075, Train Acc : 0.44157911493155044 , Val Acc : 0.44358974358974357\n",
      "Epoch 2709/10000, Loss: 1.5436699390411377, Train Acc : 0.44062400509391914 , Val Acc : 0.44358974358974357\n",
      "Epoch 2710/10000, Loss: 1.6075083017349243, Train Acc : 0.4399872652021649 , Val Acc : 0.4461538461538462\n",
      "Epoch 2711/10000, Loss: 1.61765718460083, Train Acc : 0.44157911493155044 , Val Acc : 0.44358974358974357\n",
      "Epoch 2712/10000, Loss: 1.5362709760665894, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2713/10000, Loss: 1.6126588582992554, Train Acc : 0.4418974848774276 , Val Acc : 0.44358974358974357\n",
      "Epoch 2714/10000, Loss: 1.6278752088546753, Train Acc : 0.44126074498567336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2715/10000, Loss: 1.5025081634521484, Train Acc : 0.4418974848774276 , Val Acc : 0.44358974358974357\n",
      "Epoch 2716/10000, Loss: 1.6225546598434448, Train Acc : 0.44157911493155044 , Val Acc : 0.44358974358974357\n",
      "Epoch 2717/10000, Loss: 1.5950003862380981, Train Acc : 0.4409423750397962 , Val Acc : 0.44358974358974357\n",
      "Epoch 2718/10000, Loss: 1.5663669109344482, Train Acc : 0.44062400509391914 , Val Acc : 0.44358974358974357\n",
      "Epoch 2719/10000, Loss: 1.6003682613372803, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2720/10000, Loss: 1.5897408723831177, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2721/10000, Loss: 1.6422094106674194, Train Acc : 0.44157911493155044 , Val Acc : 0.44358974358974357\n",
      "Epoch 2722/10000, Loss: 1.654147744178772, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2723/10000, Loss: 1.5592106580734253, Train Acc : 0.44221585482330467 , Val Acc : 0.44358974358974357\n",
      "Epoch 2724/10000, Loss: 1.5958526134490967, Train Acc : 0.44157911493155044 , Val Acc : 0.44358974358974357\n",
      "Epoch 2725/10000, Loss: 1.6511820554733276, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2726/10000, Loss: 1.5820318460464478, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2727/10000, Loss: 1.5264227390289307, Train Acc : 0.44157911493155044 , Val Acc : 0.44358974358974357\n",
      "Epoch 2728/10000, Loss: 1.5924443006515503, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2729/10000, Loss: 1.563459873199463, Train Acc : 0.44157911493155044 , Val Acc : 0.44358974358974357\n",
      "Epoch 2730/10000, Loss: 1.6909453868865967, Train Acc : 0.4418974848774276 , Val Acc : 0.44358974358974357\n",
      "Epoch 2731/10000, Loss: 1.6577054262161255, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2732/10000, Loss: 1.5933587551116943, Train Acc : 0.44221585482330467 , Val Acc : 0.4461538461538462\n",
      "Epoch 2733/10000, Loss: 1.6277440786361694, Train Acc : 0.44126074498567336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2734/10000, Loss: 1.6153124570846558, Train Acc : 0.4409423750397962 , Val Acc : 0.44358974358974357\n",
      "Epoch 2735/10000, Loss: 1.6647889614105225, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2736/10000, Loss: 1.6250015497207642, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2737/10000, Loss: 1.6470623016357422, Train Acc : 0.4418974848774276 , Val Acc : 0.44358974358974357\n",
      "Epoch 2738/10000, Loss: 1.6114894151687622, Train Acc : 0.4409423750397962 , Val Acc : 0.44358974358974357\n",
      "Epoch 2739/10000, Loss: 1.557698130607605, Train Acc : 0.44221585482330467 , Val Acc : 0.4461538461538462\n",
      "Epoch 2740/10000, Loss: 1.6408408880233765, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2741/10000, Loss: 1.6290911436080933, Train Acc : 0.4418974848774276 , Val Acc : 0.44358974358974357\n",
      "Epoch 2742/10000, Loss: 1.6251472234725952, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2743/10000, Loss: 1.6353150606155396, Train Acc : 0.44221585482330467 , Val Acc : 0.4461538461538462\n",
      "Epoch 2744/10000, Loss: 1.673424482345581, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2745/10000, Loss: 1.6169345378875732, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2746/10000, Loss: 1.6136161088943481, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2747/10000, Loss: 1.6224157810211182, Train Acc : 0.44221585482330467 , Val Acc : 0.44358974358974357\n",
      "Epoch 2748/10000, Loss: 1.630226731300354, Train Acc : 0.44221585482330467 , Val Acc : 0.44358974358974357\n",
      "Epoch 2749/10000, Loss: 1.5756782293319702, Train Acc : 0.4425342247691818 , Val Acc : 0.44358974358974357\n",
      "Epoch 2750/10000, Loss: 1.6951241493225098, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2751/10000, Loss: 1.6242761611938477, Train Acc : 0.4418974848774276 , Val Acc : 0.44358974358974357\n",
      "Epoch 2752/10000, Loss: 1.5907491445541382, Train Acc : 0.4418974848774276 , Val Acc : 0.44358974358974357\n",
      "Epoch 2753/10000, Loss: 1.6417336463928223, Train Acc : 0.44126074498567336 , Val Acc : 0.44358974358974357\n",
      "Epoch 2754/10000, Loss: 1.619170069694519, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2755/10000, Loss: 1.6519235372543335, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2756/10000, Loss: 1.6512963771820068, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2757/10000, Loss: 1.56770920753479, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2758/10000, Loss: 1.6536349058151245, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2759/10000, Loss: 1.6159557104110718, Train Acc : 0.44221585482330467 , Val Acc : 0.4461538461538462\n",
      "Epoch 2760/10000, Loss: 1.5962979793548584, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2761/10000, Loss: 1.5626765489578247, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2762/10000, Loss: 1.6058343648910522, Train Acc : 0.44157911493155044 , Val Acc : 0.4461538461538462\n",
      "Epoch 2763/10000, Loss: 1.6880629062652588, Train Acc : 0.44221585482330467 , Val Acc : 0.44871794871794873\n",
      "Epoch 2764/10000, Loss: 1.6713976860046387, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2765/10000, Loss: 1.594688057899475, Train Acc : 0.4428525947150589 , Val Acc : 0.4461538461538462\n",
      "Epoch 2766/10000, Loss: 1.566728949546814, Train Acc : 0.44126074498567336 , Val Acc : 0.4461538461538462\n",
      "Epoch 2767/10000, Loss: 1.5599373579025269, Train Acc : 0.44157911493155044 , Val Acc : 0.44358974358974357\n",
      "Epoch 2768/10000, Loss: 1.652669072151184, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2769/10000, Loss: 1.5996543169021606, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2770/10000, Loss: 1.6578924655914307, Train Acc : 0.44221585482330467 , Val Acc : 0.44358974358974357\n",
      "Epoch 2771/10000, Loss: 1.6665674448013306, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2772/10000, Loss: 1.6430745124816895, Train Acc : 0.4428525947150589 , Val Acc : 0.4461538461538462\n",
      "Epoch 2773/10000, Loss: 1.6105443239212036, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2774/10000, Loss: 1.607496976852417, Train Acc : 0.44221585482330467 , Val Acc : 0.441025641025641\n",
      "Epoch 2775/10000, Loss: 1.6918764114379883, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2776/10000, Loss: 1.6637102365493774, Train Acc : 0.4425342247691818 , Val Acc : 0.4461538461538462\n",
      "Epoch 2777/10000, Loss: 1.6738861799240112, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2778/10000, Loss: 1.6142398118972778, Train Acc : 0.4425342247691818 , Val Acc : 0.44871794871794873\n",
      "Epoch 2779/10000, Loss: 1.5752698183059692, Train Acc : 0.4425342247691818 , Val Acc : 0.44358974358974357\n",
      "Epoch 2780/10000, Loss: 1.5242515802383423, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2781/10000, Loss: 1.6180001497268677, Train Acc : 0.44380770455269025 , Val Acc : 0.4461538461538462\n",
      "Epoch 2782/10000, Loss: 1.5857014656066895, Train Acc : 0.44317096466093603 , Val Acc : 0.4461538461538462\n",
      "Epoch 2783/10000, Loss: 1.6842148303985596, Train Acc : 0.4418974848774276 , Val Acc : 0.4461538461538462\n",
      "Epoch 2784/10000, Loss: 1.6497905254364014, Train Acc : 0.4428525947150589 , Val Acc : 0.44358974358974357\n",
      "Epoch 2785/10000, Loss: 1.6673734188079834, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2786/10000, Loss: 1.444323182106018, Train Acc : 0.4428525947150589 , Val Acc : 0.44358974358974357\n",
      "Epoch 2787/10000, Loss: 1.5897102355957031, Train Acc : 0.4428525947150589 , Val Acc : 0.44358974358974357\n",
      "Epoch 2788/10000, Loss: 1.6130965948104858, Train Acc : 0.4425342247691818 , Val Acc : 0.44358974358974357\n",
      "Epoch 2789/10000, Loss: 1.6479514837265015, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2790/10000, Loss: 1.634880781173706, Train Acc : 0.4428525947150589 , Val Acc : 0.441025641025641\n",
      "Epoch 2791/10000, Loss: 1.5822227001190186, Train Acc : 0.4425342247691818 , Val Acc : 0.44358974358974357\n",
      "Epoch 2792/10000, Loss: 1.6495972871780396, Train Acc : 0.4428525947150589 , Val Acc : 0.441025641025641\n",
      "Epoch 2793/10000, Loss: 1.5870780944824219, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2794/10000, Loss: 1.5804909467697144, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2795/10000, Loss: 1.5840404033660889, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2796/10000, Loss: 1.6336815357208252, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2797/10000, Loss: 1.6010595560073853, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2798/10000, Loss: 1.6121904850006104, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2799/10000, Loss: 1.5857034921646118, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2800/10000, Loss: 1.6366870403289795, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2801/10000, Loss: 1.6461832523345947, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2802/10000, Loss: 1.6005653142929077, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2803/10000, Loss: 1.5765944719314575, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2804/10000, Loss: 1.5878874063491821, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2805/10000, Loss: 1.5400716066360474, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2806/10000, Loss: 1.6710017919540405, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2807/10000, Loss: 1.5349992513656616, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2808/10000, Loss: 1.6073119640350342, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2809/10000, Loss: 1.625726580619812, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2810/10000, Loss: 1.6070332527160645, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2811/10000, Loss: 1.481603980064392, Train Acc : 0.44412607449856734 , Val Acc : 0.44358974358974357\n",
      "Epoch 2812/10000, Loss: 1.6402826309204102, Train Acc : 0.4428525947150589 , Val Acc : 0.44358974358974357\n",
      "Epoch 2813/10000, Loss: 1.631990671157837, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2814/10000, Loss: 1.565837025642395, Train Acc : 0.4428525947150589 , Val Acc : 0.44358974358974357\n",
      "Epoch 2815/10000, Loss: 1.605326533317566, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2816/10000, Loss: 1.6147966384887695, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2817/10000, Loss: 1.632983684539795, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2818/10000, Loss: 1.6017470359802246, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2819/10000, Loss: 1.6040143966674805, Train Acc : 0.44380770455269025 , Val Acc : 0.44358974358974357\n",
      "Epoch 2820/10000, Loss: 1.6180775165557861, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2821/10000, Loss: 1.6272391080856323, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2822/10000, Loss: 1.6646398305892944, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2823/10000, Loss: 1.631629228591919, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2824/10000, Loss: 1.58119535446167, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2825/10000, Loss: 1.6185944080352783, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2826/10000, Loss: 1.569071650505066, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2827/10000, Loss: 1.6923213005065918, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2828/10000, Loss: 1.6019387245178223, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2829/10000, Loss: 1.578399896621704, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2830/10000, Loss: 1.5721278190612793, Train Acc : 0.44317096466093603 , Val Acc : 0.44358974358974357\n",
      "Epoch 2831/10000, Loss: 1.6211013793945312, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2832/10000, Loss: 1.566881775856018, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2833/10000, Loss: 1.60564124584198, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2834/10000, Loss: 1.618449091911316, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2835/10000, Loss: 1.5999797582626343, Train Acc : 0.44221585482330467 , Val Acc : 0.44358974358974357\n",
      "Epoch 2836/10000, Loss: 1.651458501815796, Train Acc : 0.4428525947150589 , Val Acc : 0.441025641025641\n",
      "Epoch 2837/10000, Loss: 1.661520004272461, Train Acc : 0.4428525947150589 , Val Acc : 0.441025641025641\n",
      "Epoch 2838/10000, Loss: 1.6369478702545166, Train Acc : 0.4428525947150589 , Val Acc : 0.44358974358974357\n",
      "Epoch 2839/10000, Loss: 1.601519227027893, Train Acc : 0.4425342247691818 , Val Acc : 0.44358974358974357\n",
      "Epoch 2840/10000, Loss: 1.7013815641403198, Train Acc : 0.4425342247691818 , Val Acc : 0.44358974358974357\n",
      "Epoch 2841/10000, Loss: 1.628636360168457, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2842/10000, Loss: 1.5471736192703247, Train Acc : 0.4428525947150589 , Val Acc : 0.44358974358974357\n",
      "Epoch 2843/10000, Loss: 1.627252221107483, Train Acc : 0.4425342247691818 , Val Acc : 0.44358974358974357\n",
      "Epoch 2844/10000, Loss: 1.615628719329834, Train Acc : 0.4428525947150589 , Val Acc : 0.441025641025641\n",
      "Epoch 2845/10000, Loss: 1.579792857170105, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2846/10000, Loss: 1.6071935892105103, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2847/10000, Loss: 1.6608428955078125, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2848/10000, Loss: 1.5752811431884766, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2849/10000, Loss: 1.5825282335281372, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2850/10000, Loss: 1.5789752006530762, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2851/10000, Loss: 1.5802336931228638, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2852/10000, Loss: 1.5816441774368286, Train Acc : 0.44317096466093603 , Val Acc : 0.441025641025641\n",
      "Epoch 2853/10000, Loss: 1.6068638563156128, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2854/10000, Loss: 1.6494503021240234, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2855/10000, Loss: 1.5821328163146973, Train Acc : 0.44380770455269025 , Val Acc : 0.44358974358974357\n",
      "Epoch 2856/10000, Loss: 1.5923868417739868, Train Acc : 0.44380770455269025 , Val Acc : 0.44358974358974357\n",
      "Epoch 2857/10000, Loss: 1.614547848701477, Train Acc : 0.44412607449856734 , Val Acc : 0.441025641025641\n",
      "Epoch 2858/10000, Loss: 1.6029610633850098, Train Acc : 0.44412607449856734 , Val Acc : 0.44358974358974357\n",
      "Epoch 2859/10000, Loss: 1.6206690073013306, Train Acc : 0.44412607449856734 , Val Acc : 0.441025641025641\n",
      "Epoch 2860/10000, Loss: 1.5625879764556885, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2861/10000, Loss: 1.558464765548706, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2862/10000, Loss: 1.6285232305526733, Train Acc : 0.44412607449856734 , Val Acc : 0.441025641025641\n",
      "Epoch 2863/10000, Loss: 1.6753236055374146, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2864/10000, Loss: 1.6469264030456543, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2865/10000, Loss: 1.5733954906463623, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2866/10000, Loss: 1.6925650835037231, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2867/10000, Loss: 1.5927588939666748, Train Acc : 0.44412607449856734 , Val Acc : 0.441025641025641\n",
      "Epoch 2868/10000, Loss: 1.5819863080978394, Train Acc : 0.44380770455269025 , Val Acc : 0.44358974358974357\n",
      "Epoch 2869/10000, Loss: 1.6237308979034424, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2870/10000, Loss: 1.684228777885437, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2871/10000, Loss: 1.5457541942596436, Train Acc : 0.44412607449856734 , Val Acc : 0.44358974358974357\n",
      "Epoch 2872/10000, Loss: 1.593515396118164, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2873/10000, Loss: 1.6479825973510742, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2874/10000, Loss: 1.6520063877105713, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2875/10000, Loss: 1.6831899881362915, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2876/10000, Loss: 1.4865676164627075, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2877/10000, Loss: 1.6509010791778564, Train Acc : 0.44412607449856734 , Val Acc : 0.441025641025641\n",
      "Epoch 2878/10000, Loss: 1.5890907049179077, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2879/10000, Loss: 1.5753778219223022, Train Acc : 0.44412607449856734 , Val Acc : 0.441025641025641\n",
      "Epoch 2880/10000, Loss: 1.5782519578933716, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2881/10000, Loss: 1.5369391441345215, Train Acc : 0.44412607449856734 , Val Acc : 0.441025641025641\n",
      "Epoch 2882/10000, Loss: 1.610155463218689, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2883/10000, Loss: 1.6535285711288452, Train Acc : 0.44476281439032156 , Val Acc : 0.441025641025641\n",
      "Epoch 2884/10000, Loss: 1.6091254949569702, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2885/10000, Loss: 1.6709444522857666, Train Acc : 0.44412607449856734 , Val Acc : 0.44358974358974357\n",
      "Epoch 2886/10000, Loss: 1.625084638595581, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2887/10000, Loss: 1.590941071510315, Train Acc : 0.4453995542820758 , Val Acc : 0.44358974358974357\n",
      "Epoch 2888/10000, Loss: 1.5748258829116821, Train Acc : 0.44412607449856734 , Val Acc : 0.44358974358974357\n",
      "Epoch 2889/10000, Loss: 1.5825080871582031, Train Acc : 0.44412607449856734 , Val Acc : 0.44358974358974357\n",
      "Epoch 2890/10000, Loss: 1.6509709358215332, Train Acc : 0.44380770455269025 , Val Acc : 0.44358974358974357\n",
      "Epoch 2891/10000, Loss: 1.6722923517227173, Train Acc : 0.44412607449856734 , Val Acc : 0.44358974358974357\n",
      "Epoch 2892/10000, Loss: 1.575003743171692, Train Acc : 0.44412607449856734 , Val Acc : 0.44358974358974357\n",
      "Epoch 2893/10000, Loss: 1.6251533031463623, Train Acc : 0.4434893346068131 , Val Acc : 0.44358974358974357\n",
      "Epoch 2894/10000, Loss: 1.6374430656433105, Train Acc : 0.4434893346068131 , Val Acc : 0.441025641025641\n",
      "Epoch 2895/10000, Loss: 1.5993763208389282, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2896/10000, Loss: 1.565477728843689, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2897/10000, Loss: 1.5617555379867554, Train Acc : 0.44476281439032156 , Val Acc : 0.441025641025641\n",
      "Epoch 2898/10000, Loss: 1.5361485481262207, Train Acc : 0.44476281439032156 , Val Acc : 0.441025641025641\n",
      "Epoch 2899/10000, Loss: 1.6383297443389893, Train Acc : 0.44412607449856734 , Val Acc : 0.44358974358974357\n",
      "Epoch 2900/10000, Loss: 1.5908348560333252, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2901/10000, Loss: 1.594944715499878, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2902/10000, Loss: 1.5740703344345093, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2903/10000, Loss: 1.5647526979446411, Train Acc : 0.44508118433619864 , Val Acc : 0.441025641025641\n",
      "Epoch 2904/10000, Loss: 1.6318258047103882, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2905/10000, Loss: 1.5606765747070312, Train Acc : 0.44412607449856734 , Val Acc : 0.441025641025641\n",
      "Epoch 2906/10000, Loss: 1.6538079977035522, Train Acc : 0.44380770455269025 , Val Acc : 0.441025641025641\n",
      "Epoch 2907/10000, Loss: 1.636975884437561, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2908/10000, Loss: 1.5584291219711304, Train Acc : 0.44476281439032156 , Val Acc : 0.441025641025641\n",
      "Epoch 2909/10000, Loss: 1.5629770755767822, Train Acc : 0.44508118433619864 , Val Acc : 0.441025641025641\n",
      "Epoch 2910/10000, Loss: 1.6320425271987915, Train Acc : 0.44476281439032156 , Val Acc : 0.441025641025641\n",
      "Epoch 2911/10000, Loss: 1.5995677709579468, Train Acc : 0.44476281439032156 , Val Acc : 0.441025641025641\n",
      "Epoch 2912/10000, Loss: 1.643518328666687, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2913/10000, Loss: 1.6532078981399536, Train Acc : 0.4453995542820758 , Val Acc : 0.441025641025641\n",
      "Epoch 2914/10000, Loss: 1.5001329183578491, Train Acc : 0.44476281439032156 , Val Acc : 0.441025641025641\n",
      "Epoch 2915/10000, Loss: 1.6074137687683105, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2916/10000, Loss: 1.5917346477508545, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2917/10000, Loss: 1.617754578590393, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2918/10000, Loss: 1.6353200674057007, Train Acc : 0.44476281439032156 , Val Acc : 0.441025641025641\n",
      "Epoch 2919/10000, Loss: 1.7040624618530273, Train Acc : 0.44476281439032156 , Val Acc : 0.441025641025641\n",
      "Epoch 2920/10000, Loss: 1.5640020370483398, Train Acc : 0.44508118433619864 , Val Acc : 0.441025641025641\n",
      "Epoch 2921/10000, Loss: 1.5802613496780396, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2922/10000, Loss: 1.5698902606964111, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2923/10000, Loss: 1.6436437368392944, Train Acc : 0.4444444444444444 , Val Acc : 0.441025641025641\n",
      "Epoch 2924/10000, Loss: 1.6079723834991455, Train Acc : 0.4453995542820758 , Val Acc : 0.441025641025641\n",
      "Epoch 2925/10000, Loss: 1.615319013595581, Train Acc : 0.44508118433619864 , Val Acc : 0.4461538461538462\n",
      "Epoch 2926/10000, Loss: 1.5936607122421265, Train Acc : 0.44476281439032156 , Val Acc : 0.4461538461538462\n",
      "Epoch 2927/10000, Loss: 1.6548244953155518, Train Acc : 0.4444444444444444 , Val Acc : 0.4461538461538462\n",
      "Epoch 2928/10000, Loss: 1.6406452655792236, Train Acc : 0.44508118433619864 , Val Acc : 0.44358974358974357\n",
      "Epoch 2929/10000, Loss: 1.5981884002685547, Train Acc : 0.4444444444444444 , Val Acc : 0.4461538461538462\n",
      "Epoch 2930/10000, Loss: 1.657301902770996, Train Acc : 0.44508118433619864 , Val Acc : 0.4461538461538462\n",
      "Epoch 2931/10000, Loss: 1.6052042245864868, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2932/10000, Loss: 1.6884042024612427, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2933/10000, Loss: 1.5464128255844116, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2934/10000, Loss: 1.6146409511566162, Train Acc : 0.44508118433619864 , Val Acc : 0.44358974358974357\n",
      "Epoch 2935/10000, Loss: 1.571509599685669, Train Acc : 0.4453995542820758 , Val Acc : 0.4461538461538462\n",
      "Epoch 2936/10000, Loss: 1.6158134937286377, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2937/10000, Loss: 1.5928504467010498, Train Acc : 0.4453995542820758 , Val Acc : 0.44358974358974357\n",
      "Epoch 2938/10000, Loss: 1.6259633302688599, Train Acc : 0.4453995542820758 , Val Acc : 0.44358974358974357\n",
      "Epoch 2939/10000, Loss: 1.6108837127685547, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2940/10000, Loss: 1.5342360734939575, Train Acc : 0.4444444444444444 , Val Acc : 0.4461538461538462\n",
      "Epoch 2941/10000, Loss: 1.630079984664917, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2942/10000, Loss: 1.6405138969421387, Train Acc : 0.4453995542820758 , Val Acc : 0.44358974358974357\n",
      "Epoch 2943/10000, Loss: 1.632602572441101, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2944/10000, Loss: 1.6732922792434692, Train Acc : 0.4444444444444444 , Val Acc : 0.4461538461538462\n",
      "Epoch 2945/10000, Loss: 1.613031029701233, Train Acc : 0.44508118433619864 , Val Acc : 0.44358974358974357\n",
      "Epoch 2946/10000, Loss: 1.6171506643295288, Train Acc : 0.4453995542820758 , Val Acc : 0.44358974358974357\n",
      "Epoch 2947/10000, Loss: 1.588683843612671, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2948/10000, Loss: 1.6294212341308594, Train Acc : 0.44508118433619864 , Val Acc : 0.44358974358974357\n",
      "Epoch 2949/10000, Loss: 1.6076706647872925, Train Acc : 0.4453995542820758 , Val Acc : 0.4461538461538462\n",
      "Epoch 2950/10000, Loss: 1.673904538154602, Train Acc : 0.44476281439032156 , Val Acc : 0.4461538461538462\n",
      "Epoch 2951/10000, Loss: 1.5515252351760864, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2952/10000, Loss: 1.5737403631210327, Train Acc : 0.44508118433619864 , Val Acc : 0.44358974358974357\n",
      "Epoch 2953/10000, Loss: 1.6420458555221558, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2954/10000, Loss: 1.5865018367767334, Train Acc : 0.44380770455269025 , Val Acc : 0.4461538461538462\n",
      "Epoch 2955/10000, Loss: 1.615387201309204, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2956/10000, Loss: 1.5529502630233765, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2957/10000, Loss: 1.6413884162902832, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2958/10000, Loss: 1.658430576324463, Train Acc : 0.44508118433619864 , Val Acc : 0.44358974358974357\n",
      "Epoch 2959/10000, Loss: 1.5848547220230103, Train Acc : 0.44508118433619864 , Val Acc : 0.44358974358974357\n",
      "Epoch 2960/10000, Loss: 1.619269847869873, Train Acc : 0.4453995542820758 , Val Acc : 0.44358974358974357\n",
      "Epoch 2961/10000, Loss: 1.665000557899475, Train Acc : 0.44571792422795287 , Val Acc : 0.44358974358974357\n",
      "Epoch 2962/10000, Loss: 1.5770219564437866, Train Acc : 0.4453995542820758 , Val Acc : 0.44358974358974357\n",
      "Epoch 2963/10000, Loss: 1.6191362142562866, Train Acc : 0.44571792422795287 , Val Acc : 0.4461538461538462\n",
      "Epoch 2964/10000, Loss: 1.513323187828064, Train Acc : 0.4453995542820758 , Val Acc : 0.4461538461538462\n",
      "Epoch 2965/10000, Loss: 1.6106582880020142, Train Acc : 0.4453995542820758 , Val Acc : 0.4461538461538462\n",
      "Epoch 2966/10000, Loss: 1.6128733158111572, Train Acc : 0.44571792422795287 , Val Acc : 0.44358974358974357\n",
      "Epoch 2967/10000, Loss: 1.5791131258010864, Train Acc : 0.4444444444444444 , Val Acc : 0.44358974358974357\n",
      "Epoch 2968/10000, Loss: 1.6048862934112549, Train Acc : 0.44476281439032156 , Val Acc : 0.4461538461538462\n",
      "Epoch 2969/10000, Loss: 1.5699694156646729, Train Acc : 0.4453995542820758 , Val Acc : 0.44358974358974357\n",
      "Epoch 2970/10000, Loss: 1.5199387073516846, Train Acc : 0.44476281439032156 , Val Acc : 0.44871794871794873\n",
      "Epoch 2971/10000, Loss: 1.6022789478302002, Train Acc : 0.44476281439032156 , Val Acc : 0.44358974358974357\n",
      "Epoch 2972/10000, Loss: 1.5424437522888184, Train Acc : 0.44571792422795287 , Val Acc : 0.44358974358974357\n",
      "Epoch 2973/10000, Loss: 1.5761638879776, Train Acc : 0.44571792422795287 , Val Acc : 0.4461538461538462\n",
      "Epoch 2974/10000, Loss: 1.5366055965423584, Train Acc : 0.44508118433619864 , Val Acc : 0.44358974358974357\n",
      "Epoch 2975/10000, Loss: 1.655576229095459, Train Acc : 0.44476281439032156 , Val Acc : 0.4461538461538462\n",
      "Epoch 2976/10000, Loss: 1.5718168020248413, Train Acc : 0.44508118433619864 , Val Acc : 0.4461538461538462\n",
      "Epoch 2977/10000, Loss: 1.599709153175354, Train Acc : 0.44508118433619864 , Val Acc : 0.44871794871794873\n",
      "Epoch 2978/10000, Loss: 1.6213784217834473, Train Acc : 0.4444444444444444 , Val Acc : 0.44871794871794873\n",
      "Epoch 2979/10000, Loss: 1.599165439605713, Train Acc : 0.4444444444444444 , Val Acc : 0.44871794871794873\n",
      "Epoch 2980/10000, Loss: 1.5463683605194092, Train Acc : 0.4453995542820758 , Val Acc : 0.4461538461538462\n",
      "Epoch 2981/10000, Loss: 1.5984433889389038, Train Acc : 0.4463546641197071 , Val Acc : 0.4461538461538462\n",
      "Epoch 2982/10000, Loss: 1.676324486732483, Train Acc : 0.4463546641197071 , Val Acc : 0.4461538461538462\n",
      "Epoch 2983/10000, Loss: 1.5642369985580444, Train Acc : 0.44603629417383 , Val Acc : 0.44871794871794873\n",
      "Epoch 2984/10000, Loss: 1.6608023643493652, Train Acc : 0.44571792422795287 , Val Acc : 0.4461538461538462\n",
      "Epoch 2985/10000, Loss: 1.6266257762908936, Train Acc : 0.44508118433619864 , Val Acc : 0.4461538461538462\n",
      "Epoch 2986/10000, Loss: 1.6248759031295776, Train Acc : 0.4463546641197071 , Val Acc : 0.4461538461538462\n",
      "Epoch 2987/10000, Loss: 1.6039905548095703, Train Acc : 0.4463546641197071 , Val Acc : 0.4461538461538462\n",
      "Epoch 2988/10000, Loss: 1.6048290729522705, Train Acc : 0.44603629417383 , Val Acc : 0.4461538461538462\n",
      "Epoch 2989/10000, Loss: 1.5825738906860352, Train Acc : 0.44667303406558423 , Val Acc : 0.4461538461538462\n",
      "Epoch 2990/10000, Loss: 1.6809200048446655, Train Acc : 0.44508118433619864 , Val Acc : 0.4461538461538462\n",
      "Epoch 2991/10000, Loss: 1.641073226928711, Train Acc : 0.44603629417383 , Val Acc : 0.4461538461538462\n",
      "Epoch 2992/10000, Loss: 1.6416255235671997, Train Acc : 0.44667303406558423 , Val Acc : 0.4461538461538462\n",
      "Epoch 2993/10000, Loss: 1.6091786623001099, Train Acc : 0.4453995542820758 , Val Acc : 0.44871794871794873\n",
      "Epoch 2994/10000, Loss: 1.6079723834991455, Train Acc : 0.44667303406558423 , Val Acc : 0.4461538461538462\n",
      "Epoch 2995/10000, Loss: 1.5645445585250854, Train Acc : 0.4463546641197071 , Val Acc : 0.4461538461538462\n",
      "Epoch 2996/10000, Loss: 1.5832277536392212, Train Acc : 0.4469914040114613 , Val Acc : 0.4461538461538462\n",
      "Epoch 2997/10000, Loss: 1.6086448431015015, Train Acc : 0.4463546641197071 , Val Acc : 0.44871794871794873\n",
      "Epoch 2998/10000, Loss: 1.6375491619110107, Train Acc : 0.44476281439032156 , Val Acc : 0.44871794871794873\n",
      "Epoch 2999/10000, Loss: 1.5894073247909546, Train Acc : 0.4463546641197071 , Val Acc : 0.4461538461538462\n",
      "Epoch 3000/10000, Loss: 1.6464954614639282, Train Acc : 0.4453995542820758 , Val Acc : 0.4461538461538462\n",
      "Epoch 3001/10000, Loss: 1.548017144203186, Train Acc : 0.44667303406558423 , Val Acc : 0.4461538461538462\n",
      "Epoch 3002/10000, Loss: 1.6066917181015015, Train Acc : 0.44571792422795287 , Val Acc : 0.44871794871794873\n",
      "Epoch 3003/10000, Loss: 1.6192445755004883, Train Acc : 0.44603629417383 , Val Acc : 0.4461538461538462\n",
      "Epoch 3004/10000, Loss: 1.524021863937378, Train Acc : 0.44571792422795287 , Val Acc : 0.44871794871794873\n",
      "Epoch 3005/10000, Loss: 1.5554732084274292, Train Acc : 0.44476281439032156 , Val Acc : 0.44871794871794873\n",
      "Epoch 3006/10000, Loss: 1.5845537185668945, Train Acc : 0.44667303406558423 , Val Acc : 0.44871794871794873\n",
      "Epoch 3007/10000, Loss: 1.602015733718872, Train Acc : 0.4469914040114613 , Val Acc : 0.4461538461538462\n",
      "Epoch 3008/10000, Loss: 1.6189649105072021, Train Acc : 0.4469914040114613 , Val Acc : 0.4461538461538462\n",
      "Epoch 3009/10000, Loss: 1.6215938329696655, Train Acc : 0.44667303406558423 , Val Acc : 0.4461538461538462\n",
      "Epoch 3010/10000, Loss: 1.6265279054641724, Train Acc : 0.44571792422795287 , Val Acc : 0.44871794871794873\n",
      "Epoch 3011/10000, Loss: 1.5434648990631104, Train Acc : 0.44603629417383 , Val Acc : 0.44871794871794873\n",
      "Epoch 3012/10000, Loss: 1.6499773263931274, Train Acc : 0.4463546641197071 , Val Acc : 0.4461538461538462\n",
      "Epoch 3013/10000, Loss: 1.6919572353363037, Train Acc : 0.44667303406558423 , Val Acc : 0.4461538461538462\n",
      "Epoch 3014/10000, Loss: 1.600318193435669, Train Acc : 0.4463546641197071 , Val Acc : 0.44871794871794873\n",
      "Epoch 3015/10000, Loss: 1.6128485202789307, Train Acc : 0.4463546641197071 , Val Acc : 0.4461538461538462\n",
      "Epoch 3016/10000, Loss: 1.6050472259521484, Train Acc : 0.44667303406558423 , Val Acc : 0.4461538461538462\n",
      "Epoch 3017/10000, Loss: 1.6055445671081543, Train Acc : 0.44667303406558423 , Val Acc : 0.4461538461538462\n",
      "Epoch 3018/10000, Loss: 1.577917218208313, Train Acc : 0.44667303406558423 , Val Acc : 0.44871794871794873\n",
      "Epoch 3019/10000, Loss: 1.6631780862808228, Train Acc : 0.44730977395733845 , Val Acc : 0.4461538461538462\n",
      "Epoch 3020/10000, Loss: 1.6688134670257568, Train Acc : 0.44667303406558423 , Val Acc : 0.4512820512820513\n",
      "Epoch 3021/10000, Loss: 1.581345796585083, Train Acc : 0.44667303406558423 , Val Acc : 0.4512820512820513\n",
      "Epoch 3022/10000, Loss: 1.581310749053955, Train Acc : 0.44667303406558423 , Val Acc : 0.44871794871794873\n",
      "Epoch 3023/10000, Loss: 1.6666158437728882, Train Acc : 0.44667303406558423 , Val Acc : 0.4461538461538462\n",
      "Epoch 3024/10000, Loss: 1.5370221138000488, Train Acc : 0.44667303406558423 , Val Acc : 0.4512820512820513\n",
      "Epoch 3025/10000, Loss: 1.5752958059310913, Train Acc : 0.4469914040114613 , Val Acc : 0.4512820512820513\n",
      "Epoch 3026/10000, Loss: 1.605334758758545, Train Acc : 0.44667303406558423 , Val Acc : 0.44871794871794873\n",
      "Epoch 3027/10000, Loss: 1.6573081016540527, Train Acc : 0.4479465138490926 , Val Acc : 0.4512820512820513\n",
      "Epoch 3028/10000, Loss: 1.5812071561813354, Train Acc : 0.4469914040114613 , Val Acc : 0.4461538461538462\n",
      "Epoch 3029/10000, Loss: 1.5744801759719849, Train Acc : 0.4453995542820758 , Val Acc : 0.4461538461538462\n",
      "Epoch 3030/10000, Loss: 1.6903550624847412, Train Acc : 0.4469914040114613 , Val Acc : 0.4461538461538462\n",
      "Epoch 3031/10000, Loss: 1.5906076431274414, Train Acc : 0.44762814390321554 , Val Acc : 0.4461538461538462\n",
      "Epoch 3032/10000, Loss: 1.5470176935195923, Train Acc : 0.44762814390321554 , Val Acc : 0.4461538461538462\n",
      "Epoch 3033/10000, Loss: 1.5502238273620605, Train Acc : 0.44730977395733845 , Val Acc : 0.44871794871794873\n",
      "Epoch 3034/10000, Loss: 1.5610038042068481, Train Acc : 0.4469914040114613 , Val Acc : 0.44871794871794873\n",
      "Epoch 3035/10000, Loss: 1.4899559020996094, Train Acc : 0.44730977395733845 , Val Acc : 0.4461538461538462\n",
      "Epoch 3036/10000, Loss: 1.6970018148422241, Train Acc : 0.4453995542820758 , Val Acc : 0.4461538461538462\n",
      "Epoch 3037/10000, Loss: 1.6247183084487915, Train Acc : 0.4469914040114613 , Val Acc : 0.44871794871794873\n",
      "Epoch 3038/10000, Loss: 1.6451306343078613, Train Acc : 0.44730977395733845 , Val Acc : 0.44871794871794873\n",
      "Epoch 3039/10000, Loss: 1.592122197151184, Train Acc : 0.44826488379496976 , Val Acc : 0.44871794871794873\n",
      "Epoch 3040/10000, Loss: 1.5078924894332886, Train Acc : 0.44762814390321554 , Val Acc : 0.44871794871794873\n",
      "Epoch 3041/10000, Loss: 1.5416545867919922, Train Acc : 0.44730977395733845 , Val Acc : 0.4461538461538462\n",
      "Epoch 3042/10000, Loss: 1.5649025440216064, Train Acc : 0.44762814390321554 , Val Acc : 0.4461538461538462\n",
      "Epoch 3043/10000, Loss: 1.584100604057312, Train Acc : 0.44730977395733845 , Val Acc : 0.44871794871794873\n",
      "Epoch 3044/10000, Loss: 1.5966078042984009, Train Acc : 0.44730977395733845 , Val Acc : 0.44871794871794873\n",
      "Epoch 3045/10000, Loss: 1.575319766998291, Train Acc : 0.4479465138490926 , Val Acc : 0.44871794871794873\n",
      "Epoch 3046/10000, Loss: 1.5869022607803345, Train Acc : 0.44826488379496976 , Val Acc : 0.44871794871794873\n",
      "Epoch 3047/10000, Loss: 1.5902111530303955, Train Acc : 0.44730977395733845 , Val Acc : 0.4461538461538462\n",
      "Epoch 3048/10000, Loss: 1.636884331703186, Train Acc : 0.44858325374084684 , Val Acc : 0.4512820512820513\n",
      "Epoch 3049/10000, Loss: 1.558521032333374, Train Acc : 0.4479465138490926 , Val Acc : 0.44871794871794873\n",
      "Epoch 3050/10000, Loss: 1.5919288396835327, Train Acc : 0.44826488379496976 , Val Acc : 0.4461538461538462\n",
      "Epoch 3051/10000, Loss: 1.584985375404358, Train Acc : 0.4479465138490926 , Val Acc : 0.44871794871794873\n",
      "Epoch 3052/10000, Loss: 1.5727511644363403, Train Acc : 0.44762814390321554 , Val Acc : 0.44871794871794873\n",
      "Epoch 3053/10000, Loss: 1.6439855098724365, Train Acc : 0.4479465138490926 , Val Acc : 0.4461538461538462\n",
      "Epoch 3054/10000, Loss: 1.6310689449310303, Train Acc : 0.44826488379496976 , Val Acc : 0.44871794871794873\n",
      "Epoch 3055/10000, Loss: 1.6083070039749146, Train Acc : 0.44858325374084684 , Val Acc : 0.4461538461538462\n",
      "Epoch 3056/10000, Loss: 1.6617149114608765, Train Acc : 0.44858325374084684 , Val Acc : 0.4461538461538462\n",
      "Epoch 3057/10000, Loss: 1.5973674058914185, Train Acc : 0.4479465138490926 , Val Acc : 0.4461538461538462\n",
      "Epoch 3058/10000, Loss: 1.6519416570663452, Train Acc : 0.44826488379496976 , Val Acc : 0.44871794871794873\n",
      "Epoch 3059/10000, Loss: 1.6367820501327515, Train Acc : 0.44921999363260107 , Val Acc : 0.4461538461538462\n",
      "Epoch 3060/10000, Loss: 1.6222690343856812, Train Acc : 0.448901623686724 , Val Acc : 0.44871794871794873\n",
      "Epoch 3061/10000, Loss: 1.5511373281478882, Train Acc : 0.44826488379496976 , Val Acc : 0.44871794871794873\n",
      "Epoch 3062/10000, Loss: 1.5509514808654785, Train Acc : 0.448901623686724 , Val Acc : 0.4461538461538462\n",
      "Epoch 3063/10000, Loss: 1.6754151582717896, Train Acc : 0.44858325374084684 , Val Acc : 0.44871794871794873\n",
      "Epoch 3064/10000, Loss: 1.57020103931427, Train Acc : 0.448901623686724 , Val Acc : 0.44871794871794873\n",
      "Epoch 3065/10000, Loss: 1.5685664415359497, Train Acc : 0.44921999363260107 , Val Acc : 0.4461538461538462\n",
      "Epoch 3066/10000, Loss: 1.6657018661499023, Train Acc : 0.44858325374084684 , Val Acc : 0.44871794871794873\n",
      "Epoch 3067/10000, Loss: 1.5650413036346436, Train Acc : 0.44921999363260107 , Val Acc : 0.4461538461538462\n",
      "Epoch 3068/10000, Loss: 1.6463018655776978, Train Acc : 0.448901623686724 , Val Acc : 0.44871794871794873\n",
      "Epoch 3069/10000, Loss: 1.6257152557373047, Train Acc : 0.44858325374084684 , Val Acc : 0.44871794871794873\n",
      "Epoch 3070/10000, Loss: 1.5352323055267334, Train Acc : 0.4495383635784782 , Val Acc : 0.4461538461538462\n",
      "Epoch 3071/10000, Loss: 1.5381816625595093, Train Acc : 0.44858325374084684 , Val Acc : 0.4461538461538462\n",
      "Epoch 3072/10000, Loss: 1.5177499055862427, Train Acc : 0.448901623686724 , Val Acc : 0.4461538461538462\n",
      "Epoch 3073/10000, Loss: 1.6377683877944946, Train Acc : 0.44921999363260107 , Val Acc : 0.44871794871794873\n",
      "Epoch 3074/10000, Loss: 1.6075741052627563, Train Acc : 0.44921999363260107 , Val Acc : 0.44871794871794873\n",
      "Epoch 3075/10000, Loss: 1.5116183757781982, Train Acc : 0.44858325374084684 , Val Acc : 0.44871794871794873\n",
      "Epoch 3076/10000, Loss: 1.6524484157562256, Train Acc : 0.44921999363260107 , Val Acc : 0.4461538461538462\n",
      "Epoch 3077/10000, Loss: 1.6461138725280762, Train Acc : 0.448901623686724 , Val Acc : 0.44871794871794873\n",
      "Epoch 3078/10000, Loss: 1.5762577056884766, Train Acc : 0.44921999363260107 , Val Acc : 0.44871794871794873\n",
      "Epoch 3079/10000, Loss: 1.6347973346710205, Train Acc : 0.44858325374084684 , Val Acc : 0.44871794871794873\n",
      "Epoch 3080/10000, Loss: 1.5797497034072876, Train Acc : 0.44921999363260107 , Val Acc : 0.4461538461538462\n",
      "Epoch 3081/10000, Loss: 1.5550501346588135, Train Acc : 0.4495383635784782 , Val Acc : 0.44871794871794873\n",
      "Epoch 3082/10000, Loss: 1.64845609664917, Train Acc : 0.448901623686724 , Val Acc : 0.44871794871794873\n",
      "Epoch 3083/10000, Loss: 1.5382888317108154, Train Acc : 0.4495383635784782 , Val Acc : 0.44871794871794873\n",
      "Epoch 3084/10000, Loss: 1.6351782083511353, Train Acc : 0.448901623686724 , Val Acc : 0.44871794871794873\n",
      "Epoch 3085/10000, Loss: 1.551063895225525, Train Acc : 0.448901623686724 , Val Acc : 0.4461538461538462\n",
      "Epoch 3086/10000, Loss: 1.7180702686309814, Train Acc : 0.448901623686724 , Val Acc : 0.4461538461538462\n",
      "Epoch 3087/10000, Loss: 1.6787548065185547, Train Acc : 0.44858325374084684 , Val Acc : 0.4461538461538462\n",
      "Epoch 3088/10000, Loss: 1.6594727039337158, Train Acc : 0.4495383635784782 , Val Acc : 0.4461538461538462\n",
      "Epoch 3089/10000, Loss: 1.5748777389526367, Train Acc : 0.44921999363260107 , Val Acc : 0.4461538461538462\n",
      "Epoch 3090/10000, Loss: 1.6288132667541504, Train Acc : 0.44921999363260107 , Val Acc : 0.44871794871794873\n",
      "Epoch 3091/10000, Loss: 1.6118311882019043, Train Acc : 0.44921999363260107 , Val Acc : 0.4461538461538462\n",
      "Epoch 3092/10000, Loss: 1.6014922857284546, Train Acc : 0.44921999363260107 , Val Acc : 0.44871794871794873\n",
      "Epoch 3093/10000, Loss: 1.6018760204315186, Train Acc : 0.44921999363260107 , Val Acc : 0.44871794871794873\n",
      "Epoch 3094/10000, Loss: 1.5514955520629883, Train Acc : 0.44921999363260107 , Val Acc : 0.4461538461538462\n",
      "Epoch 3095/10000, Loss: 1.5734916925430298, Train Acc : 0.448901623686724 , Val Acc : 0.44871794871794873\n",
      "Epoch 3096/10000, Loss: 1.6379214525222778, Train Acc : 0.448901623686724 , Val Acc : 0.44871794871794873\n",
      "Epoch 3097/10000, Loss: 1.6118481159210205, Train Acc : 0.448901623686724 , Val Acc : 0.4461538461538462\n",
      "Epoch 3098/10000, Loss: 1.6362693309783936, Train Acc : 0.448901623686724 , Val Acc : 0.4512820512820513\n",
      "Epoch 3099/10000, Loss: 1.5542035102844238, Train Acc : 0.44921999363260107 , Val Acc : 0.44871794871794873\n",
      "Epoch 3100/10000, Loss: 1.5515435934066772, Train Acc : 0.448901623686724 , Val Acc : 0.44871794871794873\n",
      "Epoch 3101/10000, Loss: 1.6573387384414673, Train Acc : 0.44921999363260107 , Val Acc : 0.44871794871794873\n",
      "Epoch 3102/10000, Loss: 1.610494613647461, Train Acc : 0.4498567335243553 , Val Acc : 0.44871794871794873\n",
      "Epoch 3103/10000, Loss: 1.621279239654541, Train Acc : 0.4495383635784782 , Val Acc : 0.4512820512820513\n",
      "Epoch 3104/10000, Loss: 1.6137226819992065, Train Acc : 0.4495383635784782 , Val Acc : 0.44871794871794873\n",
      "Epoch 3105/10000, Loss: 1.6207906007766724, Train Acc : 0.4495383635784782 , Val Acc : 0.44871794871794873\n",
      "Epoch 3106/10000, Loss: 1.6208560466766357, Train Acc : 0.4498567335243553 , Val Acc : 0.4512820512820513\n",
      "Epoch 3107/10000, Loss: 1.5569764375686646, Train Acc : 0.44921999363260107 , Val Acc : 0.45384615384615384\n",
      "Epoch 3108/10000, Loss: 1.5695502758026123, Train Acc : 0.4498567335243553 , Val Acc : 0.4512820512820513\n",
      "Epoch 3109/10000, Loss: 1.5829886198043823, Train Acc : 0.4495383635784782 , Val Acc : 0.44871794871794873\n",
      "Epoch 3110/10000, Loss: 1.6087262630462646, Train Acc : 0.4495383635784782 , Val Acc : 0.4564102564102564\n",
      "Epoch 3111/10000, Loss: 1.6374894380569458, Train Acc : 0.4498567335243553 , Val Acc : 0.4512820512820513\n",
      "Epoch 3112/10000, Loss: 1.514026403427124, Train Acc : 0.45017510347023243 , Val Acc : 0.4564102564102564\n",
      "Epoch 3113/10000, Loss: 1.5525059700012207, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3114/10000, Loss: 1.5838664770126343, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3115/10000, Loss: 1.576018214225769, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3116/10000, Loss: 1.6637961864471436, Train Acc : 0.4495383635784782 , Val Acc : 0.4512820512820513\n",
      "Epoch 3117/10000, Loss: 1.5485320091247559, Train Acc : 0.4495383635784782 , Val Acc : 0.4512820512820513\n",
      "Epoch 3118/10000, Loss: 1.6732912063598633, Train Acc : 0.4495383635784782 , Val Acc : 0.4512820512820513\n",
      "Epoch 3119/10000, Loss: 1.587428092956543, Train Acc : 0.44921999363260107 , Val Acc : 0.4512820512820513\n",
      "Epoch 3120/10000, Loss: 1.627785563468933, Train Acc : 0.4495383635784782 , Val Acc : 0.4512820512820513\n",
      "Epoch 3121/10000, Loss: 1.6292892694473267, Train Acc : 0.4498567335243553 , Val Acc : 0.4512820512820513\n",
      "Epoch 3122/10000, Loss: 1.6463942527770996, Train Acc : 0.4495383635784782 , Val Acc : 0.44871794871794873\n",
      "Epoch 3123/10000, Loss: 1.584230899810791, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3124/10000, Loss: 1.595672369003296, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3125/10000, Loss: 1.644181728363037, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3126/10000, Loss: 1.5435785055160522, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3127/10000, Loss: 1.66671621799469, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3128/10000, Loss: 1.620857834815979, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3129/10000, Loss: 1.5850334167480469, Train Acc : 0.45017510347023243 , Val Acc : 0.4564102564102564\n",
      "Epoch 3130/10000, Loss: 1.5887709856033325, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3131/10000, Loss: 1.625190019607544, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3132/10000, Loss: 1.5765334367752075, Train Acc : 0.4495383635784782 , Val Acc : 0.45384615384615384\n",
      "Epoch 3133/10000, Loss: 1.6250362396240234, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3134/10000, Loss: 1.6866576671600342, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3135/10000, Loss: 1.6002378463745117, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3136/10000, Loss: 1.5375654697418213, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3137/10000, Loss: 1.5733094215393066, Train Acc : 0.4498567335243553 , Val Acc : 0.4564102564102564\n",
      "Epoch 3138/10000, Loss: 1.584418535232544, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3139/10000, Loss: 1.583534836769104, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3140/10000, Loss: 1.5836963653564453, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3141/10000, Loss: 1.586742639541626, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3142/10000, Loss: 1.6919015645980835, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3143/10000, Loss: 1.5522526502609253, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3144/10000, Loss: 1.5800820589065552, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3145/10000, Loss: 1.5847554206848145, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3146/10000, Loss: 1.5935308933258057, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3147/10000, Loss: 1.6191551685333252, Train Acc : 0.45113021330786374 , Val Acc : 0.4564102564102564\n",
      "Epoch 3148/10000, Loss: 1.6100918054580688, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3149/10000, Loss: 1.5965814590454102, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3150/10000, Loss: 1.5713553428649902, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3151/10000, Loss: 1.526674747467041, Train Acc : 0.4495383635784782 , Val Acc : 0.45384615384615384\n",
      "Epoch 3152/10000, Loss: 1.6576780080795288, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3153/10000, Loss: 1.6034235954284668, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3154/10000, Loss: 1.5957529544830322, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3155/10000, Loss: 1.6442954540252686, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3156/10000, Loss: 1.6791895627975464, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3157/10000, Loss: 1.5956792831420898, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3158/10000, Loss: 1.5999422073364258, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3159/10000, Loss: 1.5822409391403198, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3160/10000, Loss: 1.5987639427185059, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3161/10000, Loss: 1.590926170349121, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3162/10000, Loss: 1.6196842193603516, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3163/10000, Loss: 1.591058611869812, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3164/10000, Loss: 1.64471435546875, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3165/10000, Loss: 1.604910135269165, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3166/10000, Loss: 1.646360993385315, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3167/10000, Loss: 1.5883874893188477, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3168/10000, Loss: 1.617414951324463, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3169/10000, Loss: 1.5269429683685303, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3170/10000, Loss: 1.5486574172973633, Train Acc : 0.45017510347023243 , Val Acc : 0.45384615384615384\n",
      "Epoch 3171/10000, Loss: 1.6388545036315918, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3172/10000, Loss: 1.632854700088501, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3173/10000, Loss: 1.6308610439300537, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3174/10000, Loss: 1.6603140830993652, Train Acc : 0.4498567335243553 , Val Acc : 0.45384615384615384\n",
      "Epoch 3175/10000, Loss: 1.6665656566619873, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3176/10000, Loss: 1.6245980262756348, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3177/10000, Loss: 1.6392672061920166, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3178/10000, Loss: 1.5039674043655396, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3179/10000, Loss: 1.6099083423614502, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3180/10000, Loss: 1.5919253826141357, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3181/10000, Loss: 1.5652536153793335, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3182/10000, Loss: 1.5610098838806152, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3183/10000, Loss: 1.5604122877120972, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3184/10000, Loss: 1.608418583869934, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3185/10000, Loss: 1.5482726097106934, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3186/10000, Loss: 1.5728081464767456, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3187/10000, Loss: 1.5316407680511475, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3188/10000, Loss: 1.6446688175201416, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3189/10000, Loss: 1.7018357515335083, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3190/10000, Loss: 1.4932838678359985, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3191/10000, Loss: 1.540366768836975, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3192/10000, Loss: 1.6949480772018433, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3193/10000, Loss: 1.6430296897888184, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3194/10000, Loss: 1.6238744258880615, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3195/10000, Loss: 1.5730781555175781, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3196/10000, Loss: 1.531247854232788, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3197/10000, Loss: 1.5177124738693237, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3198/10000, Loss: 1.6076023578643799, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3199/10000, Loss: 1.5861151218414307, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3200/10000, Loss: 1.5903222560882568, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3201/10000, Loss: 1.5972806215286255, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3202/10000, Loss: 1.5042603015899658, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3203/10000, Loss: 1.5990840196609497, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3204/10000, Loss: 1.5816583633422852, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3205/10000, Loss: 1.5792003870010376, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3206/10000, Loss: 1.5903253555297852, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3207/10000, Loss: 1.5474203824996948, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3208/10000, Loss: 1.5755274295806885, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3209/10000, Loss: 1.5715550184249878, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3210/10000, Loss: 1.6019355058670044, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3211/10000, Loss: 1.5839297771453857, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3212/10000, Loss: 1.623101830482483, Train Acc : 0.4504934734161095 , Val Acc : 0.45384615384615384\n",
      "Epoch 3213/10000, Loss: 1.6147593259811401, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3214/10000, Loss: 1.6141012907028198, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3215/10000, Loss: 1.6242705583572388, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3216/10000, Loss: 1.5251810550689697, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3217/10000, Loss: 1.6066198348999023, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3218/10000, Loss: 1.6023030281066895, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3219/10000, Loss: 1.5359361171722412, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3220/10000, Loss: 1.605829119682312, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3221/10000, Loss: 1.634719967842102, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3222/10000, Loss: 1.6230090856552124, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3223/10000, Loss: 1.6118775606155396, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3224/10000, Loss: 1.6357547044754028, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3225/10000, Loss: 1.5822054147720337, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3226/10000, Loss: 1.6059038639068604, Train Acc : 0.45081184336198665 , Val Acc : 0.45384615384615384\n",
      "Epoch 3227/10000, Loss: 1.6687116622924805, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3228/10000, Loss: 1.5135550498962402, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3229/10000, Loss: 1.5979636907577515, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3230/10000, Loss: 1.5948817729949951, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3231/10000, Loss: 1.655759334564209, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3232/10000, Loss: 1.5340639352798462, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3233/10000, Loss: 1.566615343093872, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3234/10000, Loss: 1.6221444606781006, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3235/10000, Loss: 1.6331158876419067, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3236/10000, Loss: 1.6546739339828491, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3237/10000, Loss: 1.614700436592102, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3238/10000, Loss: 1.5871597528457642, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3239/10000, Loss: 1.5991545915603638, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3240/10000, Loss: 1.6057389974594116, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3241/10000, Loss: 1.5636318922042847, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3242/10000, Loss: 1.559847354888916, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3243/10000, Loss: 1.5984176397323608, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3244/10000, Loss: 1.648334264755249, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3245/10000, Loss: 1.60930335521698, Train Acc : 0.45113021330786374 , Val Acc : 0.45384615384615384\n",
      "Epoch 3246/10000, Loss: 1.5830827951431274, Train Acc : 0.4514485832537408 , Val Acc : 0.45384615384615384\n",
      "Epoch 3247/10000, Loss: 1.5906509160995483, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3248/10000, Loss: 1.6090370416641235, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3249/10000, Loss: 1.6150184869766235, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3250/10000, Loss: 1.563239574432373, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3251/10000, Loss: 1.6250495910644531, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3252/10000, Loss: 1.5293693542480469, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3253/10000, Loss: 1.5394397974014282, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3254/10000, Loss: 1.5516996383666992, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3255/10000, Loss: 1.666078805923462, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3256/10000, Loss: 1.5650476217269897, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3257/10000, Loss: 1.6252796649932861, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3258/10000, Loss: 1.4950190782546997, Train Acc : 0.45176695319961796 , Val Acc : 0.45384615384615384\n",
      "Epoch 3259/10000, Loss: 1.587275743484497, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3260/10000, Loss: 1.66374671459198, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3261/10000, Loss: 1.665027379989624, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3262/10000, Loss: 1.5915042161941528, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3263/10000, Loss: 1.5659499168395996, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3264/10000, Loss: 1.580399990081787, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3265/10000, Loss: 1.6469529867172241, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3266/10000, Loss: 1.605764627456665, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3267/10000, Loss: 1.5631415843963623, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3268/10000, Loss: 1.6680854558944702, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3269/10000, Loss: 1.6139569282531738, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3270/10000, Loss: 1.594438076019287, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3271/10000, Loss: 1.5919169187545776, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3272/10000, Loss: 1.651071310043335, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3273/10000, Loss: 1.6095099449157715, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3274/10000, Loss: 1.6684584617614746, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3275/10000, Loss: 1.5835278034210205, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3276/10000, Loss: 1.6375068426132202, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3277/10000, Loss: 1.5878556966781616, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3278/10000, Loss: 1.6494238376617432, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3279/10000, Loss: 1.6704113483428955, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3280/10000, Loss: 1.5757051706314087, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3281/10000, Loss: 1.6251312494277954, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3282/10000, Loss: 1.5708543062210083, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3283/10000, Loss: 1.623002529144287, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3284/10000, Loss: 1.6360172033309937, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3285/10000, Loss: 1.557271957397461, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3286/10000, Loss: 1.6082463264465332, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3287/10000, Loss: 1.4942047595977783, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3288/10000, Loss: 1.6946576833724976, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3289/10000, Loss: 1.5777043104171753, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3290/10000, Loss: 1.598783254623413, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3291/10000, Loss: 1.5765222311019897, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3292/10000, Loss: 1.613828420639038, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3293/10000, Loss: 1.6826494932174683, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3294/10000, Loss: 1.5966774225234985, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3295/10000, Loss: 1.6106122732162476, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3296/10000, Loss: 1.5762946605682373, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3297/10000, Loss: 1.5531107187271118, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3298/10000, Loss: 1.6131768226623535, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3299/10000, Loss: 1.5990116596221924, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3300/10000, Loss: 1.488873839378357, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3301/10000, Loss: 1.5965025424957275, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3302/10000, Loss: 1.6614151000976562, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3303/10000, Loss: 1.621076226234436, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3304/10000, Loss: 1.635291576385498, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3305/10000, Loss: 1.654309868812561, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3306/10000, Loss: 1.6746326684951782, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3307/10000, Loss: 1.6330448389053345, Train Acc : 0.45208532314549504 , Val Acc : 0.45384615384615384\n",
      "Epoch 3308/10000, Loss: 1.599276065826416, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3309/10000, Loss: 1.6316331624984741, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3310/10000, Loss: 1.6146811246871948, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3311/10000, Loss: 1.6073554754257202, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3312/10000, Loss: 1.5382189750671387, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3313/10000, Loss: 1.5511912107467651, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3314/10000, Loss: 1.5853992700576782, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3315/10000, Loss: 1.5195289850234985, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3316/10000, Loss: 1.5914512872695923, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3317/10000, Loss: 1.5854101181030273, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3318/10000, Loss: 1.6066420078277588, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3319/10000, Loss: 1.6199883222579956, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3320/10000, Loss: 1.5790470838546753, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3321/10000, Loss: 1.5551893711090088, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3322/10000, Loss: 1.606537938117981, Train Acc : 0.4524036930913722 , Val Acc : 0.45384615384615384\n",
      "Epoch 3323/10000, Loss: 1.607344150543213, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3324/10000, Loss: 1.6022647619247437, Train Acc : 0.45272206303724927 , Val Acc : 0.45384615384615384\n",
      "Epoch 3325/10000, Loss: 1.6776152849197388, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3326/10000, Loss: 1.601277232170105, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3327/10000, Loss: 1.5837129354476929, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3328/10000, Loss: 1.6137057542800903, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3329/10000, Loss: 1.615681529045105, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3330/10000, Loss: 1.7028772830963135, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3331/10000, Loss: 1.592731237411499, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3332/10000, Loss: 1.5685712099075317, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3333/10000, Loss: 1.557740569114685, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3334/10000, Loss: 1.6030076742172241, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3335/10000, Loss: 1.597690224647522, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3336/10000, Loss: 1.6474732160568237, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3337/10000, Loss: 1.5924845933914185, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3338/10000, Loss: 1.5380475521087646, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3339/10000, Loss: 1.585599660873413, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3340/10000, Loss: 1.6251904964447021, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3341/10000, Loss: 1.5991151332855225, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3342/10000, Loss: 1.6110939979553223, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3343/10000, Loss: 1.63966703414917, Train Acc : 0.4530404329831264 , Val Acc : 0.45384615384615384\n",
      "Epoch 3344/10000, Loss: 1.6509010791778564, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3345/10000, Loss: 1.6193290948867798, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3346/10000, Loss: 1.5926464796066284, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3347/10000, Loss: 1.6593093872070312, Train Acc : 0.4533588029290035 , Val Acc : 0.45384615384615384\n",
      "Epoch 3348/10000, Loss: 1.6040664911270142, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3349/10000, Loss: 1.5555492639541626, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3350/10000, Loss: 1.5903040170669556, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3351/10000, Loss: 1.659097671508789, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3352/10000, Loss: 1.5986584424972534, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3353/10000, Loss: 1.6281744241714478, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3354/10000, Loss: 1.586103081703186, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3355/10000, Loss: 1.6024914979934692, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3356/10000, Loss: 1.638739824295044, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3357/10000, Loss: 1.5677876472473145, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3358/10000, Loss: 1.5669002532958984, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3359/10000, Loss: 1.6080646514892578, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3360/10000, Loss: 1.5804579257965088, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3361/10000, Loss: 1.5551605224609375, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3362/10000, Loss: 1.6161760091781616, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3363/10000, Loss: 1.5890458822250366, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3364/10000, Loss: 1.6398429870605469, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3365/10000, Loss: 1.5556262731552124, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3366/10000, Loss: 1.5813324451446533, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3367/10000, Loss: 1.5730273723602295, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3368/10000, Loss: 1.6240392923355103, Train Acc : 0.45367717287488063 , Val Acc : 0.4512820512820513\n",
      "Epoch 3369/10000, Loss: 1.6052908897399902, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3370/10000, Loss: 1.6290032863616943, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3371/10000, Loss: 1.5793066024780273, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3372/10000, Loss: 1.6032798290252686, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3373/10000, Loss: 1.6363862752914429, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3374/10000, Loss: 1.632707953453064, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3375/10000, Loss: 1.5359171628952026, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3376/10000, Loss: 1.5781790018081665, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3377/10000, Loss: 1.5515860319137573, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3378/10000, Loss: 1.540498971939087, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3379/10000, Loss: 1.5646148920059204, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3380/10000, Loss: 1.5480988025665283, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3381/10000, Loss: 1.6738026142120361, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3382/10000, Loss: 1.5703561305999756, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3383/10000, Loss: 1.5628114938735962, Train Acc : 0.45367717287488063 , Val Acc : 0.45384615384615384\n",
      "Epoch 3384/10000, Loss: 1.5920990705490112, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3385/10000, Loss: 1.5467513799667358, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3386/10000, Loss: 1.4834651947021484, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3387/10000, Loss: 1.630674123764038, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3388/10000, Loss: 1.6657997369766235, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3389/10000, Loss: 1.5811233520507812, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3390/10000, Loss: 1.5783042907714844, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3391/10000, Loss: 1.6066663265228271, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3392/10000, Loss: 1.6167598962783813, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3393/10000, Loss: 1.5687793493270874, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3394/10000, Loss: 1.6613894701004028, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3395/10000, Loss: 1.5966507196426392, Train Acc : 0.454950652658389 , Val Acc : 0.4512820512820513\n",
      "Epoch 3396/10000, Loss: 1.6375257968902588, Train Acc : 0.45463228271251194 , Val Acc : 0.4512820512820513\n",
      "Epoch 3397/10000, Loss: 1.5933390855789185, Train Acc : 0.45526902260426616 , Val Acc : 0.45384615384615384\n",
      "Epoch 3398/10000, Loss: 1.6232420206069946, Train Acc : 0.45526902260426616 , Val Acc : 0.4512820512820513\n",
      "Epoch 3399/10000, Loss: 1.6088111400604248, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3400/10000, Loss: 1.6561917066574097, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3401/10000, Loss: 1.6503040790557861, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3402/10000, Loss: 1.5523416996002197, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3403/10000, Loss: 1.5924890041351318, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3404/10000, Loss: 1.6143625974655151, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3405/10000, Loss: 1.494136929512024, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3406/10000, Loss: 1.6384230852127075, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3407/10000, Loss: 1.6294124126434326, Train Acc : 0.45431391276663485 , Val Acc : 0.4512820512820513\n",
      "Epoch 3408/10000, Loss: 1.61735999584198, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3409/10000, Loss: 1.529465913772583, Train Acc : 0.45463228271251194 , Val Acc : 0.4512820512820513\n",
      "Epoch 3410/10000, Loss: 1.5010040998458862, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3411/10000, Loss: 1.5960978269577026, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3412/10000, Loss: 1.5474915504455566, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3413/10000, Loss: 1.5522388219833374, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3414/10000, Loss: 1.5755304098129272, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3415/10000, Loss: 1.5652798414230347, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3416/10000, Loss: 1.6598888635635376, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3417/10000, Loss: 1.6404296159744263, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3418/10000, Loss: 1.647325038909912, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3419/10000, Loss: 1.5259408950805664, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3420/10000, Loss: 1.4900187253952026, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3421/10000, Loss: 1.6146034002304077, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3422/10000, Loss: 1.5710093975067139, Train Acc : 0.45526902260426616 , Val Acc : 0.45384615384615384\n",
      "Epoch 3423/10000, Loss: 1.5886597633361816, Train Acc : 0.45463228271251194 , Val Acc : 0.4512820512820513\n",
      "Epoch 3424/10000, Loss: 1.621755838394165, Train Acc : 0.45526902260426616 , Val Acc : 0.4512820512820513\n",
      "Epoch 3425/10000, Loss: 1.6328116655349731, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3426/10000, Loss: 1.6363996267318726, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3427/10000, Loss: 1.591909408569336, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3428/10000, Loss: 1.5746628046035767, Train Acc : 0.45463228271251194 , Val Acc : 0.45384615384615384\n",
      "Epoch 3429/10000, Loss: 1.6480056047439575, Train Acc : 0.454950652658389 , Val Acc : 0.45384615384615384\n",
      "Epoch 3430/10000, Loss: 1.49842369556427, Train Acc : 0.454950652658389 , Val Acc : 0.4564102564102564\n",
      "Epoch 3431/10000, Loss: 1.62093985080719, Train Acc : 0.454950652658389 , Val Acc : 0.4564102564102564\n",
      "Epoch 3432/10000, Loss: 1.6349126100540161, Train Acc : 0.45431391276663485 , Val Acc : 0.45384615384615384\n",
      "Epoch 3433/10000, Loss: 1.6096217632293701, Train Acc : 0.4539955428207577 , Val Acc : 0.45384615384615384\n",
      "Epoch 3434/10000, Loss: 1.6685227155685425, Train Acc : 0.45431391276663485 , Val Acc : 0.4564102564102564\n",
      "Epoch 3435/10000, Loss: 1.553392767906189, Train Acc : 0.45431391276663485 , Val Acc : 0.4564102564102564\n",
      "Epoch 3436/10000, Loss: 1.6556293964385986, Train Acc : 0.4539955428207577 , Val Acc : 0.4564102564102564\n",
      "Epoch 3437/10000, Loss: 1.6089907884597778, Train Acc : 0.45463228271251194 , Val Acc : 0.4564102564102564\n",
      "Epoch 3438/10000, Loss: 1.5440788269042969, Train Acc : 0.454950652658389 , Val Acc : 0.4564102564102564\n",
      "Epoch 3439/10000, Loss: 1.5826724767684937, Train Acc : 0.45463228271251194 , Val Acc : 0.4564102564102564\n",
      "Epoch 3440/10000, Loss: 1.5522361993789673, Train Acc : 0.45463228271251194 , Val Acc : 0.4564102564102564\n",
      "Epoch 3441/10000, Loss: 1.610919713973999, Train Acc : 0.45463228271251194 , Val Acc : 0.4564102564102564\n",
      "Epoch 3442/10000, Loss: 1.6021019220352173, Train Acc : 0.454950652658389 , Val Acc : 0.4564102564102564\n",
      "Epoch 3443/10000, Loss: 1.5614814758300781, Train Acc : 0.45463228271251194 , Val Acc : 0.4564102564102564\n",
      "Epoch 3444/10000, Loss: 1.5986186265945435, Train Acc : 0.454950652658389 , Val Acc : 0.4564102564102564\n",
      "Epoch 3445/10000, Loss: 1.6309014558792114, Train Acc : 0.45558739255014324 , Val Acc : 0.4564102564102564\n",
      "Epoch 3446/10000, Loss: 1.6838274002075195, Train Acc : 0.45463228271251194 , Val Acc : 0.4564102564102564\n",
      "Epoch 3447/10000, Loss: 1.5623526573181152, Train Acc : 0.454950652658389 , Val Acc : 0.4564102564102564\n",
      "Epoch 3448/10000, Loss: 1.636847734451294, Train Acc : 0.454950652658389 , Val Acc : 0.4564102564102564\n",
      "Epoch 3449/10000, Loss: 1.5938518047332764, Train Acc : 0.454950652658389 , Val Acc : 0.4564102564102564\n",
      "Epoch 3450/10000, Loss: 1.6500821113586426, Train Acc : 0.45558739255014324 , Val Acc : 0.4564102564102564\n",
      "Epoch 3451/10000, Loss: 1.6406036615371704, Train Acc : 0.45558739255014324 , Val Acc : 0.4564102564102564\n",
      "Epoch 3452/10000, Loss: 1.6563905477523804, Train Acc : 0.45526902260426616 , Val Acc : 0.4564102564102564\n",
      "Epoch 3453/10000, Loss: 1.5226463079452515, Train Acc : 0.45463228271251194 , Val Acc : 0.4564102564102564\n",
      "Epoch 3454/10000, Loss: 1.569356918334961, Train Acc : 0.45526902260426616 , Val Acc : 0.4564102564102564\n",
      "Epoch 3455/10000, Loss: 1.582068681716919, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3456/10000, Loss: 1.5689228773117065, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3457/10000, Loss: 1.6409956216812134, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3458/10000, Loss: 1.5607960224151611, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3459/10000, Loss: 1.613141417503357, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3460/10000, Loss: 1.6172116994857788, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3461/10000, Loss: 1.5941087007522583, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3462/10000, Loss: 1.5672438144683838, Train Acc : 0.45431391276663485 , Val Acc : 0.4564102564102564\n",
      "Epoch 3463/10000, Loss: 1.5797133445739746, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3464/10000, Loss: 1.6095987558364868, Train Acc : 0.4539955428207577 , Val Acc : 0.4564102564102564\n",
      "Epoch 3465/10000, Loss: 1.5338571071624756, Train Acc : 0.45463228271251194 , Val Acc : 0.45897435897435895\n",
      "Epoch 3466/10000, Loss: 1.532193899154663, Train Acc : 0.45463228271251194 , Val Acc : 0.4564102564102564\n",
      "Epoch 3467/10000, Loss: 1.6885253190994263, Train Acc : 0.45463228271251194 , Val Acc : 0.45897435897435895\n",
      "Epoch 3468/10000, Loss: 1.6098101139068604, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3469/10000, Loss: 1.6393506526947021, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3470/10000, Loss: 1.644077181816101, Train Acc : 0.45558739255014324 , Val Acc : 0.45897435897435895\n",
      "Epoch 3471/10000, Loss: 1.5840625762939453, Train Acc : 0.45463228271251194 , Val Acc : 0.4564102564102564\n",
      "Epoch 3472/10000, Loss: 1.5602245330810547, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3473/10000, Loss: 1.6199616193771362, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3474/10000, Loss: 1.5752290487289429, Train Acc : 0.4559057624960204 , Val Acc : 0.45897435897435895\n",
      "Epoch 3475/10000, Loss: 1.582241177558899, Train Acc : 0.45558739255014324 , Val Acc : 0.4564102564102564\n",
      "Epoch 3476/10000, Loss: 1.595166563987732, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3477/10000, Loss: 1.6435024738311768, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3478/10000, Loss: 1.5708714723587036, Train Acc : 0.45558739255014324 , Val Acc : 0.4564102564102564\n",
      "Epoch 3479/10000, Loss: 1.6169774532318115, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3480/10000, Loss: 1.632891058921814, Train Acc : 0.45558739255014324 , Val Acc : 0.4564102564102564\n",
      "Epoch 3481/10000, Loss: 1.5356667041778564, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3482/10000, Loss: 1.5836659669876099, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3483/10000, Loss: 1.5632600784301758, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3484/10000, Loss: 1.5769033432006836, Train Acc : 0.45558739255014324 , Val Acc : 0.45897435897435895\n",
      "Epoch 3485/10000, Loss: 1.5874098539352417, Train Acc : 0.4559057624960204 , Val Acc : 0.45897435897435895\n",
      "Epoch 3486/10000, Loss: 1.5626481771469116, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3487/10000, Loss: 1.6200495958328247, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3488/10000, Loss: 1.5654667615890503, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3489/10000, Loss: 1.5663855075836182, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3490/10000, Loss: 1.5109126567840576, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3491/10000, Loss: 1.6646019220352173, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3492/10000, Loss: 1.5377469062805176, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3493/10000, Loss: 1.5185490846633911, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3494/10000, Loss: 1.5779609680175781, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3495/10000, Loss: 1.5269008874893188, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3496/10000, Loss: 1.5872862339019775, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3497/10000, Loss: 1.5073493719100952, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3498/10000, Loss: 1.6157193183898926, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3499/10000, Loss: 1.6246393918991089, Train Acc : 0.454950652658389 , Val Acc : 0.45897435897435895\n",
      "Epoch 3500/10000, Loss: 1.578821063041687, Train Acc : 0.45526902260426616 , Val Acc : 0.45897435897435895\n",
      "Epoch 3501/10000, Loss: 1.5389460325241089, Train Acc : 0.45558739255014324 , Val Acc : 0.45897435897435895\n",
      "Epoch 3502/10000, Loss: 1.6046851873397827, Train Acc : 0.45558739255014324 , Val Acc : 0.45897435897435895\n",
      "Epoch 3503/10000, Loss: 1.5968228578567505, Train Acc : 0.45558739255014324 , Val Acc : 0.45897435897435895\n",
      "Epoch 3504/10000, Loss: 1.6083117723464966, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3505/10000, Loss: 1.5731356143951416, Train Acc : 0.45622413244189747 , Val Acc : 0.4564102564102564\n",
      "Epoch 3506/10000, Loss: 1.6048262119293213, Train Acc : 0.45558739255014324 , Val Acc : 0.45897435897435895\n",
      "Epoch 3507/10000, Loss: 1.6123988628387451, Train Acc : 0.4559057624960204 , Val Acc : 0.4564102564102564\n",
      "Epoch 3508/10000, Loss: 1.5658327341079712, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3509/10000, Loss: 1.5922565460205078, Train Acc : 0.4559057624960204 , Val Acc : 0.45897435897435895\n",
      "Epoch 3510/10000, Loss: 1.5843193531036377, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3511/10000, Loss: 1.6081585884094238, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3512/10000, Loss: 1.594672441482544, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3513/10000, Loss: 1.6546648740768433, Train Acc : 0.45558739255014324 , Val Acc : 0.4564102564102564\n",
      "Epoch 3514/10000, Loss: 1.593100905418396, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3515/10000, Loss: 1.631230354309082, Train Acc : 0.4565425023877746 , Val Acc : 0.4564102564102564\n",
      "Epoch 3516/10000, Loss: 1.5565564632415771, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3517/10000, Loss: 1.5889194011688232, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3518/10000, Loss: 1.5819237232208252, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3519/10000, Loss: 1.616979718208313, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3520/10000, Loss: 1.6127922534942627, Train Acc : 0.4559057624960204 , Val Acc : 0.45897435897435895\n",
      "Epoch 3521/10000, Loss: 1.6087487936019897, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3522/10000, Loss: 1.6505743265151978, Train Acc : 0.4559057624960204 , Val Acc : 0.45897435897435895\n",
      "Epoch 3523/10000, Loss: 1.5601823329925537, Train Acc : 0.4559057624960204 , Val Acc : 0.45897435897435895\n",
      "Epoch 3524/10000, Loss: 1.6622908115386963, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3525/10000, Loss: 1.6177164316177368, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3526/10000, Loss: 1.5501335859298706, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3527/10000, Loss: 1.5785126686096191, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3528/10000, Loss: 1.5536444187164307, Train Acc : 0.45558739255014324 , Val Acc : 0.46153846153846156\n",
      "Epoch 3529/10000, Loss: 1.6012855768203735, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3530/10000, Loss: 1.6627049446105957, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3531/10000, Loss: 1.5949312448501587, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3532/10000, Loss: 1.6009219884872437, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3533/10000, Loss: 1.6030387878417969, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3534/10000, Loss: 1.6244853734970093, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3535/10000, Loss: 1.5838087797164917, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3536/10000, Loss: 1.6098072528839111, Train Acc : 0.4559057624960204 , Val Acc : 0.45897435897435895\n",
      "Epoch 3537/10000, Loss: 1.6226898431777954, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3538/10000, Loss: 1.607403039932251, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3539/10000, Loss: 1.6010749340057373, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3540/10000, Loss: 1.5695757865905762, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3541/10000, Loss: 1.621052622795105, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3542/10000, Loss: 1.5954769849777222, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3543/10000, Loss: 1.5579191446304321, Train Acc : 0.45622413244189747 , Val Acc : 0.4564102564102564\n",
      "Epoch 3544/10000, Loss: 1.6466267108917236, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3545/10000, Loss: 1.6693494319915771, Train Acc : 0.45526902260426616 , Val Acc : 0.46153846153846156\n",
      "Epoch 3546/10000, Loss: 1.5355544090270996, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3547/10000, Loss: 1.573531150817871, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3548/10000, Loss: 1.5388875007629395, Train Acc : 0.4559057624960204 , Val Acc : 0.45897435897435895\n",
      "Epoch 3549/10000, Loss: 1.590533971786499, Train Acc : 0.4565425023877746 , Val Acc : 0.46153846153846156\n",
      "Epoch 3550/10000, Loss: 1.5127227306365967, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3551/10000, Loss: 1.5994223356246948, Train Acc : 0.45781598217128305 , Val Acc : 0.45897435897435895\n",
      "Epoch 3552/10000, Loss: 1.5402203798294067, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3553/10000, Loss: 1.5745246410369873, Train Acc : 0.4559057624960204 , Val Acc : 0.46153846153846156\n",
      "Epoch 3554/10000, Loss: 1.5710517168045044, Train Acc : 0.45622413244189747 , Val Acc : 0.46153846153846156\n",
      "Epoch 3555/10000, Loss: 1.6873732805252075, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3556/10000, Loss: 1.6529520750045776, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3557/10000, Loss: 1.6487696170806885, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3558/10000, Loss: 1.6523857116699219, Train Acc : 0.4565425023877746 , Val Acc : 0.46153846153846156\n",
      "Epoch 3559/10000, Loss: 1.6071162223815918, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3560/10000, Loss: 1.641211748123169, Train Acc : 0.45622413244189747 , Val Acc : 0.45897435897435895\n",
      "Epoch 3561/10000, Loss: 1.5084542036056519, Train Acc : 0.4565425023877746 , Val Acc : 0.46153846153846156\n",
      "Epoch 3562/10000, Loss: 1.601699709892273, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3563/10000, Loss: 1.6192450523376465, Train Acc : 0.4565425023877746 , Val Acc : 0.46153846153846156\n",
      "Epoch 3564/10000, Loss: 1.6222988367080688, Train Acc : 0.4565425023877746 , Val Acc : 0.46153846153846156\n",
      "Epoch 3565/10000, Loss: 1.6536107063293457, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3566/10000, Loss: 1.6555709838867188, Train Acc : 0.45781598217128305 , Val Acc : 0.45897435897435895\n",
      "Epoch 3567/10000, Loss: 1.6155211925506592, Train Acc : 0.45781598217128305 , Val Acc : 0.45897435897435895\n",
      "Epoch 3568/10000, Loss: 1.603498101234436, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3569/10000, Loss: 1.6260876655578613, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3570/10000, Loss: 1.6466701030731201, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3571/10000, Loss: 1.5960440635681152, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3572/10000, Loss: 1.7099876403808594, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3573/10000, Loss: 1.6003986597061157, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3574/10000, Loss: 1.5680303573608398, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3575/10000, Loss: 1.582308053970337, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3576/10000, Loss: 1.4725481271743774, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3577/10000, Loss: 1.5652389526367188, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3578/10000, Loss: 1.5613493919372559, Train Acc : 0.4568608723336517 , Val Acc : 0.46153846153846156\n",
      "Epoch 3579/10000, Loss: 1.5841195583343506, Train Acc : 0.4568608723336517 , Val Acc : 0.46153846153846156\n",
      "Epoch 3580/10000, Loss: 1.6714248657226562, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3581/10000, Loss: 1.6209585666656494, Train Acc : 0.4568608723336517 , Val Acc : 0.4564102564102564\n",
      "Epoch 3582/10000, Loss: 1.6028538942337036, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3583/10000, Loss: 1.5981138944625854, Train Acc : 0.45717924227952883 , Val Acc : 0.4564102564102564\n",
      "Epoch 3584/10000, Loss: 1.5629535913467407, Train Acc : 0.45781598217128305 , Val Acc : 0.45897435897435895\n",
      "Epoch 3585/10000, Loss: 1.5413880348205566, Train Acc : 0.4565425023877746 , Val Acc : 0.46153846153846156\n",
      "Epoch 3586/10000, Loss: 1.575363278388977, Train Acc : 0.45813435211716014 , Val Acc : 0.45897435897435895\n",
      "Epoch 3587/10000, Loss: 1.5808933973312378, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3588/10000, Loss: 1.6166383028030396, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3589/10000, Loss: 1.5420541763305664, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3590/10000, Loss: 1.535735845565796, Train Acc : 0.4574976122254059 , Val Acc : 0.46153846153846156\n",
      "Epoch 3591/10000, Loss: 1.6347798109054565, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3592/10000, Loss: 1.6191015243530273, Train Acc : 0.4568608723336517 , Val Acc : 0.45897435897435895\n",
      "Epoch 3593/10000, Loss: 1.5873280763626099, Train Acc : 0.4568608723336517 , Val Acc : 0.4564102564102564\n",
      "Epoch 3594/10000, Loss: 1.5911283493041992, Train Acc : 0.4568608723336517 , Val Acc : 0.4564102564102564\n",
      "Epoch 3595/10000, Loss: 1.609764814376831, Train Acc : 0.45717924227952883 , Val Acc : 0.4564102564102564\n",
      "Epoch 3596/10000, Loss: 1.5679312944412231, Train Acc : 0.45717924227952883 , Val Acc : 0.4564102564102564\n",
      "Epoch 3597/10000, Loss: 1.605713129043579, Train Acc : 0.4574976122254059 , Val Acc : 0.46153846153846156\n",
      "Epoch 3598/10000, Loss: 1.5961520671844482, Train Acc : 0.45813435211716014 , Val Acc : 0.45897435897435895\n",
      "Epoch 3599/10000, Loss: 1.6215559244155884, Train Acc : 0.45717924227952883 , Val Acc : 0.46153846153846156\n",
      "Epoch 3600/10000, Loss: 1.5950464010238647, Train Acc : 0.4568608723336517 , Val Acc : 0.46153846153846156\n",
      "Epoch 3601/10000, Loss: 1.6017310619354248, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3602/10000, Loss: 1.6103754043579102, Train Acc : 0.4568608723336517 , Val Acc : 0.46153846153846156\n",
      "Epoch 3603/10000, Loss: 1.5431667566299438, Train Acc : 0.45717924227952883 , Val Acc : 0.46153846153846156\n",
      "Epoch 3604/10000, Loss: 1.5836679935455322, Train Acc : 0.4574976122254059 , Val Acc : 0.46153846153846156\n",
      "Epoch 3605/10000, Loss: 1.5838654041290283, Train Acc : 0.45717924227952883 , Val Acc : 0.46153846153846156\n",
      "Epoch 3606/10000, Loss: 1.5433201789855957, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3607/10000, Loss: 1.6188303232192993, Train Acc : 0.4565425023877746 , Val Acc : 0.4564102564102564\n",
      "Epoch 3608/10000, Loss: 1.6013984680175781, Train Acc : 0.45717924227952883 , Val Acc : 0.46153846153846156\n",
      "Epoch 3609/10000, Loss: 1.5712171792984009, Train Acc : 0.45781598217128305 , Val Acc : 0.45897435897435895\n",
      "Epoch 3610/10000, Loss: 1.643742322921753, Train Acc : 0.45781598217128305 , Val Acc : 0.45897435897435895\n",
      "Epoch 3611/10000, Loss: 1.6216576099395752, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3612/10000, Loss: 1.61806321144104, Train Acc : 0.4568608723336517 , Val Acc : 0.46153846153846156\n",
      "Epoch 3613/10000, Loss: 1.5527317523956299, Train Acc : 0.45781598217128305 , Val Acc : 0.45897435897435895\n",
      "Epoch 3614/10000, Loss: 1.595436692237854, Train Acc : 0.4574976122254059 , Val Acc : 0.46153846153846156\n",
      "Epoch 3615/10000, Loss: 1.63970148563385, Train Acc : 0.45813435211716014 , Val Acc : 0.46153846153846156\n",
      "Epoch 3616/10000, Loss: 1.555992841720581, Train Acc : 0.45813435211716014 , Val Acc : 0.45897435897435895\n",
      "Epoch 3617/10000, Loss: 1.597686767578125, Train Acc : 0.45813435211716014 , Val Acc : 0.46153846153846156\n",
      "Epoch 3618/10000, Loss: 1.5406166315078735, Train Acc : 0.4574976122254059 , Val Acc : 0.46153846153846156\n",
      "Epoch 3619/10000, Loss: 1.6491427421569824, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3620/10000, Loss: 1.579087495803833, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3621/10000, Loss: 1.5667673349380493, Train Acc : 0.45717924227952883 , Val Acc : 0.46153846153846156\n",
      "Epoch 3622/10000, Loss: 1.6013092994689941, Train Acc : 0.4565425023877746 , Val Acc : 0.45897435897435895\n",
      "Epoch 3623/10000, Loss: 1.5731849670410156, Train Acc : 0.45781598217128305 , Val Acc : 0.45897435897435895\n",
      "Epoch 3624/10000, Loss: 1.6167510747909546, Train Acc : 0.45813435211716014 , Val Acc : 0.46153846153846156\n",
      "Epoch 3625/10000, Loss: 1.5576552152633667, Train Acc : 0.45781598217128305 , Val Acc : 0.46153846153846156\n",
      "Epoch 3626/10000, Loss: 1.5511378049850464, Train Acc : 0.4584527220630373 , Val Acc : 0.46153846153846156\n",
      "Epoch 3627/10000, Loss: 1.656266689300537, Train Acc : 0.45781598217128305 , Val Acc : 0.4564102564102564\n",
      "Epoch 3628/10000, Loss: 1.5882538557052612, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3629/10000, Loss: 1.62812077999115, Train Acc : 0.4574976122254059 , Val Acc : 0.45897435897435895\n",
      "Epoch 3630/10000, Loss: 1.5686172246932983, Train Acc : 0.45717924227952883 , Val Acc : 0.45897435897435895\n",
      "Epoch 3631/10000, Loss: 1.621778964996338, Train Acc : 0.4574976122254059 , Val Acc : 0.4641025641025641\n",
      "Epoch 3632/10000, Loss: 1.5420619249343872, Train Acc : 0.4574976122254059 , Val Acc : 0.4564102564102564\n",
      "Epoch 3633/10000, Loss: 1.5936779975891113, Train Acc : 0.45781598217128305 , Val Acc : 0.4564102564102564\n",
      "Epoch 3634/10000, Loss: 1.5154529809951782, Train Acc : 0.45813435211716014 , Val Acc : 0.4564102564102564\n",
      "Epoch 3635/10000, Loss: 1.5185878276824951, Train Acc : 0.45813435211716014 , Val Acc : 0.46153846153846156\n",
      "Epoch 3636/10000, Loss: 1.6046009063720703, Train Acc : 0.45717924227952883 , Val Acc : 0.46153846153846156\n",
      "Epoch 3637/10000, Loss: 1.590213418006897, Train Acc : 0.4574976122254059 , Val Acc : 0.4564102564102564\n",
      "Epoch 3638/10000, Loss: 1.6280906200408936, Train Acc : 0.4584527220630373 , Val Acc : 0.4641025641025641\n",
      "Epoch 3639/10000, Loss: 1.5727741718292236, Train Acc : 0.4574976122254059 , Val Acc : 0.4641025641025641\n",
      "Epoch 3640/10000, Loss: 1.6957813501358032, Train Acc : 0.4574976122254059 , Val Acc : 0.4564102564102564\n",
      "Epoch 3641/10000, Loss: 1.638972520828247, Train Acc : 0.4584527220630373 , Val Acc : 0.4641025641025641\n",
      "Epoch 3642/10000, Loss: 1.5456262826919556, Train Acc : 0.4574976122254059 , Val Acc : 0.4641025641025641\n",
      "Epoch 3643/10000, Loss: 1.5548465251922607, Train Acc : 0.45813435211716014 , Val Acc : 0.4641025641025641\n",
      "Epoch 3644/10000, Loss: 1.6358000040054321, Train Acc : 0.45781598217128305 , Val Acc : 0.4641025641025641\n",
      "Epoch 3645/10000, Loss: 1.571226716041565, Train Acc : 0.45781598217128305 , Val Acc : 0.46153846153846156\n",
      "Epoch 3646/10000, Loss: 1.6084339618682861, Train Acc : 0.45877109200891436 , Val Acc : 0.46153846153846156\n",
      "Epoch 3647/10000, Loss: 1.570898413658142, Train Acc : 0.45877109200891436 , Val Acc : 0.46153846153846156\n",
      "Epoch 3648/10000, Loss: 1.56769859790802, Train Acc : 0.45877109200891436 , Val Acc : 0.4641025641025641\n",
      "Epoch 3649/10000, Loss: 1.593828558921814, Train Acc : 0.45813435211716014 , Val Acc : 0.4641025641025641\n",
      "Epoch 3650/10000, Loss: 1.5522873401641846, Train Acc : 0.45781598217128305 , Val Acc : 0.4641025641025641\n",
      "Epoch 3651/10000, Loss: 1.583403468132019, Train Acc : 0.45813435211716014 , Val Acc : 0.46153846153846156\n",
      "Epoch 3652/10000, Loss: 1.6617927551269531, Train Acc : 0.4584527220630373 , Val Acc : 0.4641025641025641\n",
      "Epoch 3653/10000, Loss: 1.5515094995498657, Train Acc : 0.4574976122254059 , Val Acc : 0.4641025641025641\n",
      "Epoch 3654/10000, Loss: 1.658425211906433, Train Acc : 0.4574976122254059 , Val Acc : 0.4641025641025641\n",
      "Epoch 3655/10000, Loss: 1.5943820476531982, Train Acc : 0.45781598217128305 , Val Acc : 0.4641025641025641\n",
      "Epoch 3656/10000, Loss: 1.6127400398254395, Train Acc : 0.45813435211716014 , Val Acc : 0.46153846153846156\n",
      "Epoch 3657/10000, Loss: 1.6317592859268188, Train Acc : 0.45813435211716014 , Val Acc : 0.4641025641025641\n",
      "Epoch 3658/10000, Loss: 1.571784257888794, Train Acc : 0.45781598217128305 , Val Acc : 0.4641025641025641\n",
      "Epoch 3659/10000, Loss: 1.5746327638626099, Train Acc : 0.45781598217128305 , Val Acc : 0.45897435897435895\n",
      "Epoch 3660/10000, Loss: 1.5726051330566406, Train Acc : 0.45717924227952883 , Val Acc : 0.4641025641025641\n",
      "Epoch 3661/10000, Loss: 1.5554578304290771, Train Acc : 0.45781598217128305 , Val Acc : 0.4641025641025641\n",
      "Epoch 3662/10000, Loss: 1.5561248064041138, Train Acc : 0.4584527220630373 , Val Acc : 0.4641025641025641\n",
      "Epoch 3663/10000, Loss: 1.4720171689987183, Train Acc : 0.45781598217128305 , Val Acc : 0.4641025641025641\n",
      "Epoch 3664/10000, Loss: 1.5988351106643677, Train Acc : 0.4584527220630373 , Val Acc : 0.46153846153846156\n",
      "Epoch 3665/10000, Loss: 1.6463079452514648, Train Acc : 0.45781598217128305 , Val Acc : 0.4641025641025641\n",
      "Epoch 3666/10000, Loss: 1.6641231775283813, Train Acc : 0.45813435211716014 , Val Acc : 0.4641025641025641\n",
      "Epoch 3667/10000, Loss: 1.5813952684402466, Train Acc : 0.4574976122254059 , Val Acc : 0.4641025641025641\n",
      "Epoch 3668/10000, Loss: 1.5424472093582153, Train Acc : 0.45781598217128305 , Val Acc : 0.46153846153846156\n",
      "Epoch 3669/10000, Loss: 1.6394387483596802, Train Acc : 0.45877109200891436 , Val Acc : 0.46153846153846156\n",
      "Epoch 3670/10000, Loss: 1.6130257844924927, Train Acc : 0.4584527220630373 , Val Acc : 0.46153846153846156\n",
      "Epoch 3671/10000, Loss: 1.565032720565796, Train Acc : 0.4574976122254059 , Val Acc : 0.4641025641025641\n",
      "Epoch 3672/10000, Loss: 1.56490159034729, Train Acc : 0.45813435211716014 , Val Acc : 0.4641025641025641\n",
      "Epoch 3673/10000, Loss: 1.634278655052185, Train Acc : 0.45781598217128305 , Val Acc : 0.4641025641025641\n",
      "Epoch 3674/10000, Loss: 1.6807345151901245, Train Acc : 0.45813435211716014 , Val Acc : 0.4641025641025641\n",
      "Epoch 3675/10000, Loss: 1.5322846174240112, Train Acc : 0.4584527220630373 , Val Acc : 0.4641025641025641\n",
      "Epoch 3676/10000, Loss: 1.4918525218963623, Train Acc : 0.4584527220630373 , Val Acc : 0.46153846153846156\n",
      "Epoch 3677/10000, Loss: 1.547278642654419, Train Acc : 0.4584527220630373 , Val Acc : 0.4641025641025641\n",
      "Epoch 3678/10000, Loss: 1.5190860033035278, Train Acc : 0.45877109200891436 , Val Acc : 0.46153846153846156\n",
      "Epoch 3679/10000, Loss: 1.5662273168563843, Train Acc : 0.45877109200891436 , Val Acc : 0.4641025641025641\n",
      "Epoch 3680/10000, Loss: 1.5459731817245483, Train Acc : 0.45813435211716014 , Val Acc : 0.46153846153846156\n",
      "Epoch 3681/10000, Loss: 1.6256989240646362, Train Acc : 0.45908946195479144 , Val Acc : 0.46153846153846156\n",
      "Epoch 3682/10000, Loss: 1.5833094120025635, Train Acc : 0.45877109200891436 , Val Acc : 0.4641025641025641\n",
      "Epoch 3683/10000, Loss: 1.6086549758911133, Train Acc : 0.45877109200891436 , Val Acc : 0.4641025641025641\n",
      "Epoch 3684/10000, Loss: 1.5541105270385742, Train Acc : 0.45877109200891436 , Val Acc : 0.4641025641025641\n",
      "Epoch 3685/10000, Loss: 1.5408672094345093, Train Acc : 0.4584527220630373 , Val Acc : 0.46153846153846156\n",
      "Epoch 3686/10000, Loss: 1.6060553789138794, Train Acc : 0.45908946195479144 , Val Acc : 0.46153846153846156\n",
      "Epoch 3687/10000, Loss: 1.6312311887741089, Train Acc : 0.45908946195479144 , Val Acc : 0.46153846153846156\n",
      "Epoch 3688/10000, Loss: 1.5685243606567383, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3689/10000, Loss: 1.6148529052734375, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3690/10000, Loss: 1.538230538368225, Train Acc : 0.45877109200891436 , Val Acc : 0.4641025641025641\n",
      "Epoch 3691/10000, Loss: 1.5779920816421509, Train Acc : 0.45877109200891436 , Val Acc : 0.46153846153846156\n",
      "Epoch 3692/10000, Loss: 1.6048214435577393, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3693/10000, Loss: 1.6423566341400146, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3694/10000, Loss: 1.6333290338516235, Train Acc : 0.45908946195479144 , Val Acc : 0.4641025641025641\n",
      "Epoch 3695/10000, Loss: 1.5847324132919312, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3696/10000, Loss: 1.5357643365859985, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3697/10000, Loss: 1.583021879196167, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3698/10000, Loss: 1.50806725025177, Train Acc : 0.45908946195479144 , Val Acc : 0.4641025641025641\n",
      "Epoch 3699/10000, Loss: 1.6216249465942383, Train Acc : 0.4584527220630373 , Val Acc : 0.4641025641025641\n",
      "Epoch 3700/10000, Loss: 1.5338596105575562, Train Acc : 0.45813435211716014 , Val Acc : 0.4666666666666667\n",
      "Epoch 3701/10000, Loss: 1.5469762086868286, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3702/10000, Loss: 1.6156151294708252, Train Acc : 0.4594078319006686 , Val Acc : 0.46153846153846156\n",
      "Epoch 3703/10000, Loss: 1.5527265071868896, Train Acc : 0.4594078319006686 , Val Acc : 0.46153846153846156\n",
      "Epoch 3704/10000, Loss: 1.5872763395309448, Train Acc : 0.45813435211716014 , Val Acc : 0.4666666666666667\n",
      "Epoch 3705/10000, Loss: 1.5728363990783691, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3706/10000, Loss: 1.5726096630096436, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3707/10000, Loss: 1.6099952459335327, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3708/10000, Loss: 1.5795629024505615, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3709/10000, Loss: 1.5297460556030273, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3710/10000, Loss: 1.557708501815796, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3711/10000, Loss: 1.670189380645752, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3712/10000, Loss: 1.6196967363357544, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3713/10000, Loss: 1.536685585975647, Train Acc : 0.45877109200891436 , Val Acc : 0.4641025641025641\n",
      "Epoch 3714/10000, Loss: 1.6238610744476318, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3715/10000, Loss: 1.5233986377716064, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3716/10000, Loss: 1.5225622653961182, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3717/10000, Loss: 1.5106024742126465, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3718/10000, Loss: 1.61064612865448, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3719/10000, Loss: 1.5861258506774902, Train Acc : 0.4584527220630373 , Val Acc : 0.4641025641025641\n",
      "Epoch 3720/10000, Loss: 1.5656059980392456, Train Acc : 0.4584527220630373 , Val Acc : 0.4666666666666667\n",
      "Epoch 3721/10000, Loss: 1.6624737977981567, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3722/10000, Loss: 1.5745517015457153, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3723/10000, Loss: 1.6375466585159302, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3724/10000, Loss: 1.51549232006073, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3725/10000, Loss: 1.6182522773742676, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3726/10000, Loss: 1.5807172060012817, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3727/10000, Loss: 1.5586072206497192, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3728/10000, Loss: 1.5920419692993164, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3729/10000, Loss: 1.5763331651687622, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3730/10000, Loss: 1.5469944477081299, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3731/10000, Loss: 1.532147765159607, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3732/10000, Loss: 1.6482033729553223, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3733/10000, Loss: 1.5961467027664185, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3734/10000, Loss: 1.5883150100708008, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3735/10000, Loss: 1.548504114151001, Train Acc : 0.45908946195479144 , Val Acc : 0.4641025641025641\n",
      "Epoch 3736/10000, Loss: 1.6416865587234497, Train Acc : 0.4584527220630373 , Val Acc : 0.4666666666666667\n",
      "Epoch 3737/10000, Loss: 1.6138421297073364, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3738/10000, Loss: 1.6403038501739502, Train Acc : 0.4584527220630373 , Val Acc : 0.4666666666666667\n",
      "Epoch 3739/10000, Loss: 1.5738697052001953, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3740/10000, Loss: 1.5254859924316406, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3741/10000, Loss: 1.5651607513427734, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3742/10000, Loss: 1.602184772491455, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3743/10000, Loss: 1.5950523614883423, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3744/10000, Loss: 1.648635983467102, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3745/10000, Loss: 1.6186167001724243, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3746/10000, Loss: 1.5665205717086792, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3747/10000, Loss: 1.6141375303268433, Train Acc : 0.4584527220630373 , Val Acc : 0.4666666666666667\n",
      "Epoch 3748/10000, Loss: 1.6242173910140991, Train Acc : 0.4584527220630373 , Val Acc : 0.4666666666666667\n",
      "Epoch 3749/10000, Loss: 1.6596381664276123, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3750/10000, Loss: 1.5186407566070557, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3751/10000, Loss: 1.606170654296875, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3752/10000, Loss: 1.6270424127578735, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3753/10000, Loss: 1.600648045539856, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3754/10000, Loss: 1.4972596168518066, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3755/10000, Loss: 1.5292441844940186, Train Acc : 0.4584527220630373 , Val Acc : 0.4666666666666667\n",
      "Epoch 3756/10000, Loss: 1.5798734426498413, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3757/10000, Loss: 1.5849169492721558, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3758/10000, Loss: 1.4929859638214111, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3759/10000, Loss: 1.5508191585540771, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3760/10000, Loss: 1.5995457172393799, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3761/10000, Loss: 1.5666909217834473, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3762/10000, Loss: 1.6074637174606323, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3763/10000, Loss: 1.5804144144058228, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3764/10000, Loss: 1.6235462427139282, Train Acc : 0.4584527220630373 , Val Acc : 0.4666666666666667\n",
      "Epoch 3765/10000, Loss: 1.6062219142913818, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3766/10000, Loss: 1.5899157524108887, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3767/10000, Loss: 1.597489595413208, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3768/10000, Loss: 1.6679338216781616, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3769/10000, Loss: 1.610792636871338, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3770/10000, Loss: 1.618153691291809, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3771/10000, Loss: 1.606991171836853, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3772/10000, Loss: 1.6096526384353638, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3773/10000, Loss: 1.4970612525939941, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3774/10000, Loss: 1.6203206777572632, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3775/10000, Loss: 1.5025628805160522, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3776/10000, Loss: 1.6206161975860596, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3777/10000, Loss: 1.6464529037475586, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3778/10000, Loss: 1.6039924621582031, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3779/10000, Loss: 1.6127007007598877, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3780/10000, Loss: 1.6303879022598267, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3781/10000, Loss: 1.5529686212539673, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3782/10000, Loss: 1.6638480424880981, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3783/10000, Loss: 1.5613895654678345, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3784/10000, Loss: 1.5623019933700562, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3785/10000, Loss: 1.577561855316162, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3786/10000, Loss: 1.592589020729065, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3787/10000, Loss: 1.5929756164550781, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3788/10000, Loss: 1.5764524936676025, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3789/10000, Loss: 1.5597108602523804, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3790/10000, Loss: 1.5366930961608887, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3791/10000, Loss: 1.5624606609344482, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3792/10000, Loss: 1.520675778388977, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3793/10000, Loss: 1.6007038354873657, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3794/10000, Loss: 1.5921086072921753, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3795/10000, Loss: 1.550736665725708, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3796/10000, Loss: 1.6352208852767944, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3797/10000, Loss: 1.6226706504821777, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3798/10000, Loss: 1.6029164791107178, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3799/10000, Loss: 1.5963685512542725, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3800/10000, Loss: 1.6002861261367798, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3801/10000, Loss: 1.6161853075027466, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3802/10000, Loss: 1.6224921941757202, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3803/10000, Loss: 1.6229225397109985, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3804/10000, Loss: 1.5889060497283936, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3805/10000, Loss: 1.6108064651489258, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3806/10000, Loss: 1.4975191354751587, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3807/10000, Loss: 1.573415756225586, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3808/10000, Loss: 1.5508712530136108, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3809/10000, Loss: 1.5488802194595337, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3810/10000, Loss: 1.5684878826141357, Train Acc : 0.45877109200891436 , Val Acc : 0.4666666666666667\n",
      "Epoch 3811/10000, Loss: 1.4852099418640137, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3812/10000, Loss: 1.5770400762557983, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3813/10000, Loss: 1.5967575311660767, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3814/10000, Loss: 1.5812666416168213, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3815/10000, Loss: 1.6162029504776, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3816/10000, Loss: 1.5710173845291138, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3817/10000, Loss: 1.5123862028121948, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3818/10000, Loss: 1.6711227893829346, Train Acc : 0.45908946195479144 , Val Acc : 0.4641025641025641\n",
      "Epoch 3819/10000, Loss: 1.5709179639816284, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3820/10000, Loss: 1.6163241863250732, Train Acc : 0.45908946195479144 , Val Acc : 0.4641025641025641\n",
      "Epoch 3821/10000, Loss: 1.6032088994979858, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3822/10000, Loss: 1.6318063735961914, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3823/10000, Loss: 1.5768885612487793, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3824/10000, Loss: 1.6224113702774048, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3825/10000, Loss: 1.601557731628418, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3826/10000, Loss: 1.5311068296432495, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3827/10000, Loss: 1.545921802520752, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3828/10000, Loss: 1.5126205682754517, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3829/10000, Loss: 1.5590990781784058, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3830/10000, Loss: 1.6120069026947021, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3831/10000, Loss: 1.5329684019088745, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3832/10000, Loss: 1.5311181545257568, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3833/10000, Loss: 1.6101397275924683, Train Acc : 0.45908946195479144 , Val Acc : 0.4641025641025641\n",
      "Epoch 3834/10000, Loss: 1.5520975589752197, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3835/10000, Loss: 1.6175718307495117, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3836/10000, Loss: 1.5975773334503174, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3837/10000, Loss: 1.5500552654266357, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3838/10000, Loss: 1.640385627746582, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3839/10000, Loss: 1.608157753944397, Train Acc : 0.46068131168417703 , Val Acc : 0.4666666666666667\n",
      "Epoch 3840/10000, Loss: 1.6193296909332275, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3841/10000, Loss: 1.6456670761108398, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3842/10000, Loss: 1.6103756427764893, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3843/10000, Loss: 1.5633258819580078, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3844/10000, Loss: 1.620067834854126, Train Acc : 0.4603629417382999 , Val Acc : 0.4666666666666667\n",
      "Epoch 3845/10000, Loss: 1.6044341325759888, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3846/10000, Loss: 1.5650125741958618, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3847/10000, Loss: 1.6113182306289673, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3848/10000, Loss: 1.5751615762710571, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3849/10000, Loss: 1.6585538387298584, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3850/10000, Loss: 1.5724905729293823, Train Acc : 0.4603629417382999 , Val Acc : 0.4666666666666667\n",
      "Epoch 3851/10000, Loss: 1.672448992729187, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3852/10000, Loss: 1.4871585369110107, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3853/10000, Loss: 1.5696979761123657, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3854/10000, Loss: 1.6199954748153687, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3855/10000, Loss: 1.5848166942596436, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3856/10000, Loss: 1.6016182899475098, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3857/10000, Loss: 1.646411657333374, Train Acc : 0.45972620184654567 , Val Acc : 0.4666666666666667\n",
      "Epoch 3858/10000, Loss: 1.497956395149231, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3859/10000, Loss: 1.507402777671814, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3860/10000, Loss: 1.5622915029525757, Train Acc : 0.4603629417382999 , Val Acc : 0.4666666666666667\n",
      "Epoch 3861/10000, Loss: 1.5793901681900024, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3862/10000, Loss: 1.5378974676132202, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3863/10000, Loss: 1.621050238609314, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3864/10000, Loss: 1.555641531944275, Train Acc : 0.4603629417382999 , Val Acc : 0.4666666666666667\n",
      "Epoch 3865/10000, Loss: 1.6015797853469849, Train Acc : 0.4600445717924228 , Val Acc : 0.4666666666666667\n",
      "Epoch 3866/10000, Loss: 1.5139257907867432, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3867/10000, Loss: 1.5879673957824707, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3868/10000, Loss: 1.5763702392578125, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3869/10000, Loss: 1.6320370435714722, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3870/10000, Loss: 1.5702061653137207, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3871/10000, Loss: 1.5506209135055542, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3872/10000, Loss: 1.4952552318572998, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3873/10000, Loss: 1.557767629623413, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3874/10000, Loss: 1.5972874164581299, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3875/10000, Loss: 1.5792746543884277, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3876/10000, Loss: 1.5704048871994019, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3877/10000, Loss: 1.5476646423339844, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3878/10000, Loss: 1.5606714487075806, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3879/10000, Loss: 1.549789547920227, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3880/10000, Loss: 1.6694304943084717, Train Acc : 0.4594078319006686 , Val Acc : 0.4666666666666667\n",
      "Epoch 3881/10000, Loss: 1.50210440158844, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3882/10000, Loss: 1.6185240745544434, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3883/10000, Loss: 1.6861073970794678, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3884/10000, Loss: 1.5562083721160889, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3885/10000, Loss: 1.617842674255371, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3886/10000, Loss: 1.5745465755462646, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3887/10000, Loss: 1.529749870300293, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3888/10000, Loss: 1.6048812866210938, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3889/10000, Loss: 1.6263494491577148, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3890/10000, Loss: 1.6487280130386353, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3891/10000, Loss: 1.6408898830413818, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3892/10000, Loss: 1.602889895439148, Train Acc : 0.45972620184654567 , Val Acc : 0.4641025641025641\n",
      "Epoch 3893/10000, Loss: 1.6520129442214966, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3894/10000, Loss: 1.5405304431915283, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3895/10000, Loss: 1.5121333599090576, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3896/10000, Loss: 1.541491150856018, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3897/10000, Loss: 1.6755688190460205, Train Acc : 0.4600445717924228 , Val Acc : 0.4641025641025641\n",
      "Epoch 3898/10000, Loss: 1.6084665060043335, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3899/10000, Loss: 1.495461344718933, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3900/10000, Loss: 1.5384325981140137, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3901/10000, Loss: 1.6640568971633911, Train Acc : 0.4609996816300541 , Val Acc : 0.4641025641025641\n",
      "Epoch 3902/10000, Loss: 1.6096932888031006, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3903/10000, Loss: 1.6417677402496338, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3904/10000, Loss: 1.5848335027694702, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3905/10000, Loss: 1.6136242151260376, Train Acc : 0.45908946195479144 , Val Acc : 0.4666666666666667\n",
      "Epoch 3906/10000, Loss: 1.6277905702590942, Train Acc : 0.4594078319006686 , Val Acc : 0.4641025641025641\n",
      "Epoch 3907/10000, Loss: 1.619417667388916, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3908/10000, Loss: 1.6565907001495361, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3909/10000, Loss: 1.6448185443878174, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3910/10000, Loss: 1.528417944908142, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3911/10000, Loss: 1.5793688297271729, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3912/10000, Loss: 1.5355597734451294, Train Acc : 0.46131805157593125 , Val Acc : 0.4641025641025641\n",
      "Epoch 3913/10000, Loss: 1.6314774751663208, Train Acc : 0.4609996816300541 , Val Acc : 0.4641025641025641\n",
      "Epoch 3914/10000, Loss: 1.564704179763794, Train Acc : 0.4609996816300541 , Val Acc : 0.4641025641025641\n",
      "Epoch 3915/10000, Loss: 1.612905740737915, Train Acc : 0.46163642152180834 , Val Acc : 0.4641025641025641\n",
      "Epoch 3916/10000, Loss: 1.6256985664367676, Train Acc : 0.46163642152180834 , Val Acc : 0.4641025641025641\n",
      "Epoch 3917/10000, Loss: 1.6440482139587402, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3918/10000, Loss: 1.6014455556869507, Train Acc : 0.46068131168417703 , Val Acc : 0.4641025641025641\n",
      "Epoch 3919/10000, Loss: 1.59224534034729, Train Acc : 0.4609996816300541 , Val Acc : 0.4641025641025641\n",
      "Epoch 3920/10000, Loss: 1.5933113098144531, Train Acc : 0.46131805157593125 , Val Acc : 0.4641025641025641\n",
      "Epoch 3921/10000, Loss: 1.497750163078308, Train Acc : 0.4609996816300541 , Val Acc : 0.4641025641025641\n",
      "Epoch 3922/10000, Loss: 1.6135507822036743, Train Acc : 0.4609996816300541 , Val Acc : 0.4641025641025641\n",
      "Epoch 3923/10000, Loss: 1.6038734912872314, Train Acc : 0.4603629417382999 , Val Acc : 0.4641025641025641\n",
      "Epoch 3924/10000, Loss: 1.6226972341537476, Train Acc : 0.46131805157593125 , Val Acc : 0.4641025641025641\n",
      "Epoch 3925/10000, Loss: 1.571158766746521, Train Acc : 0.4609996816300541 , Val Acc : 0.4641025641025641\n",
      "Epoch 3926/10000, Loss: 1.5553251504898071, Train Acc : 0.46131805157593125 , Val Acc : 0.4641025641025641\n",
      "Epoch 3927/10000, Loss: 1.5730634927749634, Train Acc : 0.46131805157593125 , Val Acc : 0.4641025641025641\n",
      "Epoch 3928/10000, Loss: 1.5204004049301147, Train Acc : 0.46131805157593125 , Val Acc : 0.4641025641025641\n",
      "Epoch 3929/10000, Loss: 1.5975229740142822, Train Acc : 0.4609996816300541 , Val Acc : 0.4641025641025641\n",
      "Epoch 3930/10000, Loss: 1.571884036064148, Train Acc : 0.46068131168417703 , Val Acc : 0.4666666666666667\n",
      "Epoch 3931/10000, Loss: 1.5807334184646606, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3932/10000, Loss: 1.6041955947875977, Train Acc : 0.46131805157593125 , Val Acc : 0.4641025641025641\n",
      "Epoch 3933/10000, Loss: 1.6072224378585815, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3934/10000, Loss: 1.5289846658706665, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3935/10000, Loss: 1.5915782451629639, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3936/10000, Loss: 1.5878373384475708, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3937/10000, Loss: 1.6126922369003296, Train Acc : 0.4609996816300541 , Val Acc : 0.4641025641025641\n",
      "Epoch 3938/10000, Loss: 1.6498113870620728, Train Acc : 0.4609996816300541 , Val Acc : 0.4666666666666667\n",
      "Epoch 3939/10000, Loss: 1.5896615982055664, Train Acc : 0.4609996816300541 , Val Acc : 0.4666666666666667\n",
      "Epoch 3940/10000, Loss: 1.586925745010376, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3941/10000, Loss: 1.5749708414077759, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3942/10000, Loss: 1.588854193687439, Train Acc : 0.4609996816300541 , Val Acc : 0.4666666666666667\n",
      "Epoch 3943/10000, Loss: 1.6325013637542725, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3944/10000, Loss: 1.4889767169952393, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3945/10000, Loss: 1.5703983306884766, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3946/10000, Loss: 1.5730067491531372, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 3947/10000, Loss: 1.4978996515274048, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3948/10000, Loss: 1.6366230249404907, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3949/10000, Loss: 1.5340427160263062, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3950/10000, Loss: 1.5886225700378418, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3951/10000, Loss: 1.6400343179702759, Train Acc : 0.4609996816300541 , Val Acc : 0.4666666666666667\n",
      "Epoch 3952/10000, Loss: 1.5657392740249634, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3953/10000, Loss: 1.562556266784668, Train Acc : 0.4609996816300541 , Val Acc : 0.4666666666666667\n",
      "Epoch 3954/10000, Loss: 1.6115514039993286, Train Acc : 0.4609996816300541 , Val Acc : 0.4666666666666667\n",
      "Epoch 3955/10000, Loss: 1.616890549659729, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3956/10000, Loss: 1.5824867486953735, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3957/10000, Loss: 1.4867258071899414, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3958/10000, Loss: 1.6825065612792969, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3959/10000, Loss: 1.6342358589172363, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3960/10000, Loss: 1.5346351861953735, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3961/10000, Loss: 1.6246116161346436, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3962/10000, Loss: 1.5108429193496704, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 3963/10000, Loss: 1.6216380596160889, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3964/10000, Loss: 1.6335471868515015, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3965/10000, Loss: 1.6466377973556519, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3966/10000, Loss: 1.585854172706604, Train Acc : 0.4609996816300541 , Val Acc : 0.4666666666666667\n",
      "Epoch 3967/10000, Loss: 1.5216110944747925, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 3968/10000, Loss: 1.5836261510849, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3969/10000, Loss: 1.5800082683563232, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3970/10000, Loss: 1.6601325273513794, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 3971/10000, Loss: 1.5940604209899902, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3972/10000, Loss: 1.6648719310760498, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3973/10000, Loss: 1.6054282188415527, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3974/10000, Loss: 1.6619268655776978, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3975/10000, Loss: 1.6553958654403687, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3976/10000, Loss: 1.597713828086853, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3977/10000, Loss: 1.6277343034744263, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3978/10000, Loss: 1.5325443744659424, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3979/10000, Loss: 1.6100273132324219, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3980/10000, Loss: 1.684119462966919, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3981/10000, Loss: 1.5229485034942627, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3982/10000, Loss: 1.546676754951477, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3983/10000, Loss: 1.6087660789489746, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3984/10000, Loss: 1.5748921632766724, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3985/10000, Loss: 1.6426236629486084, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3986/10000, Loss: 1.629921317100525, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3987/10000, Loss: 1.5489168167114258, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3988/10000, Loss: 1.6038490533828735, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3989/10000, Loss: 1.629809021949768, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 3990/10000, Loss: 1.568016767501831, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3991/10000, Loss: 1.6572110652923584, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 3992/10000, Loss: 1.6005210876464844, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3993/10000, Loss: 1.5757325887680054, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 3994/10000, Loss: 1.6583456993103027, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 3995/10000, Loss: 1.600645661354065, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3996/10000, Loss: 1.5538718700408936, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 3997/10000, Loss: 1.5280842781066895, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 3998/10000, Loss: 1.5570749044418335, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 3999/10000, Loss: 1.5352582931518555, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4000/10000, Loss: 1.486029863357544, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 4001/10000, Loss: 1.5875502824783325, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4002/10000, Loss: 1.5778952836990356, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4003/10000, Loss: 1.6018924713134766, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4004/10000, Loss: 1.5657358169555664, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4005/10000, Loss: 1.540968418121338, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4006/10000, Loss: 1.5446134805679321, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4007/10000, Loss: 1.6063512563705444, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4008/10000, Loss: 1.5489234924316406, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4009/10000, Loss: 1.598920464515686, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4010/10000, Loss: 1.538297176361084, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4011/10000, Loss: 1.5752373933792114, Train Acc : 0.46131805157593125 , Val Acc : 0.4666666666666667\n",
      "Epoch 4012/10000, Loss: 1.602912425994873, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4013/10000, Loss: 1.6278425455093384, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4014/10000, Loss: 1.5064140558242798, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 4015/10000, Loss: 1.6086297035217285, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 4016/10000, Loss: 1.60028076171875, Train Acc : 0.46163642152180834 , Val Acc : 0.4666666666666667\n",
      "Epoch 4017/10000, Loss: 1.6400563716888428, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4018/10000, Loss: 1.5622442960739136, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4019/10000, Loss: 1.4530161619186401, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4020/10000, Loss: 1.6113618612289429, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4021/10000, Loss: 1.6509974002838135, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4022/10000, Loss: 1.58592689037323, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4023/10000, Loss: 1.5690157413482666, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4024/10000, Loss: 1.6050633192062378, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4025/10000, Loss: 1.5650434494018555, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4026/10000, Loss: 1.6442909240722656, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4027/10000, Loss: 1.5939592123031616, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4028/10000, Loss: 1.50589120388031, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4029/10000, Loss: 1.6693942546844482, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4030/10000, Loss: 1.565589189529419, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4031/10000, Loss: 1.5681737661361694, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4032/10000, Loss: 1.586225986480713, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4033/10000, Loss: 1.666375756263733, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4034/10000, Loss: 1.608618974685669, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4035/10000, Loss: 1.5234795808792114, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4036/10000, Loss: 1.5547382831573486, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4037/10000, Loss: 1.5696113109588623, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4038/10000, Loss: 1.565165400505066, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4039/10000, Loss: 1.4989769458770752, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4040/10000, Loss: 1.640876054763794, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4041/10000, Loss: 1.597224473953247, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4042/10000, Loss: 1.5684505701065063, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4043/10000, Loss: 1.5699193477630615, Train Acc : 0.4619547914676855 , Val Acc : 0.4666666666666667\n",
      "Epoch 4044/10000, Loss: 1.6812437772750854, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4045/10000, Loss: 1.5810617208480835, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4046/10000, Loss: 1.581719160079956, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4047/10000, Loss: 1.6442110538482666, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4048/10000, Loss: 1.5875970125198364, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4049/10000, Loss: 1.6504746675491333, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4050/10000, Loss: 1.5714095830917358, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4051/10000, Loss: 1.6001877784729004, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4052/10000, Loss: 1.650197982788086, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4053/10000, Loss: 1.575058102607727, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4054/10000, Loss: 1.6116136312484741, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4055/10000, Loss: 1.5736360549926758, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4056/10000, Loss: 1.553804874420166, Train Acc : 0.463546641197071 , Val Acc : 0.4666666666666667\n",
      "Epoch 4057/10000, Loss: 1.5850478410720825, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4058/10000, Loss: 1.569239616394043, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4059/10000, Loss: 1.600754737854004, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4060/10000, Loss: 1.6175222396850586, Train Acc : 0.463546641197071 , Val Acc : 0.4666666666666667\n",
      "Epoch 4061/10000, Loss: 1.587310791015625, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4062/10000, Loss: 1.6316584348678589, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4063/10000, Loss: 1.6146624088287354, Train Acc : 0.46227316141356256 , Val Acc : 0.4666666666666667\n",
      "Epoch 4064/10000, Loss: 1.6059036254882812, Train Acc : 0.4638650111429481 , Val Acc : 0.4666666666666667\n",
      "Epoch 4065/10000, Loss: 1.651672124862671, Train Acc : 0.463546641197071 , Val Acc : 0.4666666666666667\n",
      "Epoch 4066/10000, Loss: 1.5252412557601929, Train Acc : 0.463546641197071 , Val Acc : 0.4666666666666667\n",
      "Epoch 4067/10000, Loss: 1.6344144344329834, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4068/10000, Loss: 1.4896520376205444, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4069/10000, Loss: 1.504003643989563, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4070/10000, Loss: 1.513397455215454, Train Acc : 0.4638650111429481 , Val Acc : 0.4666666666666667\n",
      "Epoch 4071/10000, Loss: 1.5815770626068115, Train Acc : 0.4638650111429481 , Val Acc : 0.4666666666666667\n",
      "Epoch 4072/10000, Loss: 1.6002373695373535, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4073/10000, Loss: 1.565981149673462, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4074/10000, Loss: 1.6205048561096191, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4075/10000, Loss: 1.5470314025878906, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4076/10000, Loss: 1.5248174667358398, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4077/10000, Loss: 1.5235668420791626, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4078/10000, Loss: 1.6153862476348877, Train Acc : 0.46259153135943964 , Val Acc : 0.4666666666666667\n",
      "Epoch 4079/10000, Loss: 1.5712019205093384, Train Acc : 0.463546641197071 , Val Acc : 0.4666666666666667\n",
      "Epoch 4080/10000, Loss: 1.6420605182647705, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4081/10000, Loss: 1.622100830078125, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4082/10000, Loss: 1.6120773553848267, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4083/10000, Loss: 1.5827991962432861, Train Acc : 0.46227316141356256 , Val Acc : 0.46923076923076923\n",
      "Epoch 4084/10000, Loss: 1.6147068738937378, Train Acc : 0.4629099013053168 , Val Acc : 0.4666666666666667\n",
      "Epoch 4085/10000, Loss: 1.547589898109436, Train Acc : 0.46322827125119387 , Val Acc : 0.4717948717948718\n",
      "Epoch 4086/10000, Loss: 1.586977243423462, Train Acc : 0.46322827125119387 , Val Acc : 0.4717948717948718\n",
      "Epoch 4087/10000, Loss: 1.6329511404037476, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4088/10000, Loss: 1.6673802137374878, Train Acc : 0.46259153135943964 , Val Acc : 0.46923076923076923\n",
      "Epoch 4089/10000, Loss: 1.5866504907608032, Train Acc : 0.4629099013053168 , Val Acc : 0.46923076923076923\n",
      "Epoch 4090/10000, Loss: 1.5758464336395264, Train Acc : 0.4629099013053168 , Val Acc : 0.4717948717948718\n",
      "Epoch 4091/10000, Loss: 1.6414419412612915, Train Acc : 0.4629099013053168 , Val Acc : 0.46923076923076923\n",
      "Epoch 4092/10000, Loss: 1.6007661819458008, Train Acc : 0.463546641197071 , Val Acc : 0.46923076923076923\n",
      "Epoch 4093/10000, Loss: 1.549855351448059, Train Acc : 0.4638650111429481 , Val Acc : 0.46923076923076923\n",
      "Epoch 4094/10000, Loss: 1.571881651878357, Train Acc : 0.463546641197071 , Val Acc : 0.46923076923076923\n",
      "Epoch 4095/10000, Loss: 1.559374451637268, Train Acc : 0.46418338108882523 , Val Acc : 0.46923076923076923\n",
      "Epoch 4096/10000, Loss: 1.6422077417373657, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4097/10000, Loss: 1.541384220123291, Train Acc : 0.463546641197071 , Val Acc : 0.4717948717948718\n",
      "Epoch 4098/10000, Loss: 1.6119964122772217, Train Acc : 0.46322827125119387 , Val Acc : 0.46923076923076923\n",
      "Epoch 4099/10000, Loss: 1.6036064624786377, Train Acc : 0.46227316141356256 , Val Acc : 0.4717948717948718\n",
      "Epoch 4100/10000, Loss: 1.6178576946258545, Train Acc : 0.46322827125119387 , Val Acc : 0.4666666666666667\n",
      "Epoch 4101/10000, Loss: 1.6603368520736694, Train Acc : 0.463546641197071 , Val Acc : 0.46923076923076923\n",
      "Epoch 4102/10000, Loss: 1.5560600757598877, Train Acc : 0.46418338108882523 , Val Acc : 0.4666666666666667\n",
      "Epoch 4103/10000, Loss: 1.5352298021316528, Train Acc : 0.4638650111429481 , Val Acc : 0.46923076923076923\n",
      "Epoch 4104/10000, Loss: 1.4727011919021606, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4105/10000, Loss: 1.6219291687011719, Train Acc : 0.4645017510347023 , Val Acc : 0.46923076923076923\n",
      "Epoch 4106/10000, Loss: 1.6666182279586792, Train Acc : 0.46418338108882523 , Val Acc : 0.4717948717948718\n",
      "Epoch 4107/10000, Loss: 1.6018038988113403, Train Acc : 0.46322827125119387 , Val Acc : 0.4717948717948718\n",
      "Epoch 4108/10000, Loss: 1.5758271217346191, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4109/10000, Loss: 1.6317098140716553, Train Acc : 0.46418338108882523 , Val Acc : 0.46923076923076923\n",
      "Epoch 4110/10000, Loss: 1.570311188697815, Train Acc : 0.46322827125119387 , Val Acc : 0.4717948717948718\n",
      "Epoch 4111/10000, Loss: 1.535641074180603, Train Acc : 0.46418338108882523 , Val Acc : 0.4717948717948718\n",
      "Epoch 4112/10000, Loss: 1.6214667558670044, Train Acc : 0.4638650111429481 , Val Acc : 0.46923076923076923\n",
      "Epoch 4113/10000, Loss: 1.6287254095077515, Train Acc : 0.46322827125119387 , Val Acc : 0.4717948717948718\n",
      "Epoch 4114/10000, Loss: 1.575518012046814, Train Acc : 0.4645017510347023 , Val Acc : 0.4717948717948718\n",
      "Epoch 4115/10000, Loss: 1.5993221998214722, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4116/10000, Loss: 1.5788054466247559, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4117/10000, Loss: 1.5372389554977417, Train Acc : 0.46418338108882523 , Val Acc : 0.4717948717948718\n",
      "Epoch 4118/10000, Loss: 1.6279525756835938, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4119/10000, Loss: 1.5556318759918213, Train Acc : 0.46418338108882523 , Val Acc : 0.4717948717948718\n",
      "Epoch 4120/10000, Loss: 1.5897687673568726, Train Acc : 0.4645017510347023 , Val Acc : 0.4717948717948718\n",
      "Epoch 4121/10000, Loss: 1.5262678861618042, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4122/10000, Loss: 1.5286577939987183, Train Acc : 0.4645017510347023 , Val Acc : 0.4717948717948718\n",
      "Epoch 4123/10000, Loss: 1.5983495712280273, Train Acc : 0.46418338108882523 , Val Acc : 0.4717948717948718\n",
      "Epoch 4124/10000, Loss: 1.600464105606079, Train Acc : 0.46418338108882523 , Val Acc : 0.4717948717948718\n",
      "Epoch 4125/10000, Loss: 1.597912073135376, Train Acc : 0.46418338108882523 , Val Acc : 0.4717948717948718\n",
      "Epoch 4126/10000, Loss: 1.5490752458572388, Train Acc : 0.46322827125119387 , Val Acc : 0.4717948717948718\n",
      "Epoch 4127/10000, Loss: 1.6199917793273926, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4128/10000, Loss: 1.485211968421936, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4129/10000, Loss: 1.6147634983062744, Train Acc : 0.46322827125119387 , Val Acc : 0.4717948717948718\n",
      "Epoch 4130/10000, Loss: 1.5758137702941895, Train Acc : 0.4645017510347023 , Val Acc : 0.4717948717948718\n",
      "Epoch 4131/10000, Loss: 1.582661509513855, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4132/10000, Loss: 1.6766984462738037, Train Acc : 0.463546641197071 , Val Acc : 0.4717948717948718\n",
      "Epoch 4133/10000, Loss: 1.6505197286605835, Train Acc : 0.46322827125119387 , Val Acc : 0.47435897435897434\n",
      "Epoch 4134/10000, Loss: 1.593070149421692, Train Acc : 0.46322827125119387 , Val Acc : 0.47435897435897434\n",
      "Epoch 4135/10000, Loss: 1.6034355163574219, Train Acc : 0.46322827125119387 , Val Acc : 0.47435897435897434\n",
      "Epoch 4136/10000, Loss: 1.5385379791259766, Train Acc : 0.46322827125119387 , Val Acc : 0.47435897435897434\n",
      "Epoch 4137/10000, Loss: 1.6423406600952148, Train Acc : 0.4629099013053168 , Val Acc : 0.47435897435897434\n",
      "Epoch 4138/10000, Loss: 1.62632155418396, Train Acc : 0.4638650111429481 , Val Acc : 0.47435897435897434\n",
      "Epoch 4139/10000, Loss: 1.5703538656234741, Train Acc : 0.46322827125119387 , Val Acc : 0.4717948717948718\n",
      "Epoch 4140/10000, Loss: 1.6514678001403809, Train Acc : 0.4638650111429481 , Val Acc : 0.47435897435897434\n",
      "Epoch 4141/10000, Loss: 1.6072245836257935, Train Acc : 0.463546641197071 , Val Acc : 0.47435897435897434\n",
      "Epoch 4142/10000, Loss: 1.5679521560668945, Train Acc : 0.4638650111429481 , Val Acc : 0.47435897435897434\n",
      "Epoch 4143/10000, Loss: 1.56048583984375, Train Acc : 0.4638650111429481 , Val Acc : 0.47435897435897434\n",
      "Epoch 4144/10000, Loss: 1.550803542137146, Train Acc : 0.4638650111429481 , Val Acc : 0.47435897435897434\n",
      "Epoch 4145/10000, Loss: 1.6166187524795532, Train Acc : 0.4638650111429481 , Val Acc : 0.4717948717948718\n",
      "Epoch 4146/10000, Loss: 1.512552261352539, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4147/10000, Loss: 1.5948166847229004, Train Acc : 0.46482012098057945 , Val Acc : 0.4717948717948718\n",
      "Epoch 4148/10000, Loss: 1.5244133472442627, Train Acc : 0.46418338108882523 , Val Acc : 0.47435897435897434\n",
      "Epoch 4149/10000, Loss: 1.6453826427459717, Train Acc : 0.46418338108882523 , Val Acc : 0.47435897435897434\n",
      "Epoch 4150/10000, Loss: 1.5507159233093262, Train Acc : 0.4638650111429481 , Val Acc : 0.47435897435897434\n",
      "Epoch 4151/10000, Loss: 1.517215609550476, Train Acc : 0.4638650111429481 , Val Acc : 0.47435897435897434\n",
      "Epoch 4152/10000, Loss: 1.659183144569397, Train Acc : 0.46418338108882523 , Val Acc : 0.4717948717948718\n",
      "Epoch 4153/10000, Loss: 1.6217292547225952, Train Acc : 0.46513849092645654 , Val Acc : 0.4717948717948718\n",
      "Epoch 4154/10000, Loss: 1.572295069694519, Train Acc : 0.46513849092645654 , Val Acc : 0.47435897435897434\n",
      "Epoch 4155/10000, Loss: 1.5937767028808594, Train Acc : 0.46418338108882523 , Val Acc : 0.47435897435897434\n",
      "Epoch 4156/10000, Loss: 1.6814448833465576, Train Acc : 0.4654568608723337 , Val Acc : 0.47435897435897434\n",
      "Epoch 4157/10000, Loss: 1.6253360509872437, Train Acc : 0.46482012098057945 , Val Acc : 0.4717948717948718\n",
      "Epoch 4158/10000, Loss: 1.5900062322616577, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4159/10000, Loss: 1.548045039176941, Train Acc : 0.46418338108882523 , Val Acc : 0.47435897435897434\n",
      "Epoch 4160/10000, Loss: 1.5850900411605835, Train Acc : 0.46418338108882523 , Val Acc : 0.47435897435897434\n",
      "Epoch 4161/10000, Loss: 1.5510940551757812, Train Acc : 0.4645017510347023 , Val Acc : 0.47435897435897434\n",
      "Epoch 4162/10000, Loss: 1.5208909511566162, Train Acc : 0.46418338108882523 , Val Acc : 0.47435897435897434\n",
      "Epoch 4163/10000, Loss: 1.5450392961502075, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4164/10000, Loss: 1.6341519355773926, Train Acc : 0.46513849092645654 , Val Acc : 0.4717948717948718\n",
      "Epoch 4165/10000, Loss: 1.5555652379989624, Train Acc : 0.46513849092645654 , Val Acc : 0.4717948717948718\n",
      "Epoch 4166/10000, Loss: 1.6127490997314453, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4167/10000, Loss: 1.6228928565979004, Train Acc : 0.46482012098057945 , Val Acc : 0.4717948717948718\n",
      "Epoch 4168/10000, Loss: 1.6132590770721436, Train Acc : 0.46418338108882523 , Val Acc : 0.47435897435897434\n",
      "Epoch 4169/10000, Loss: 1.5511339902877808, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4170/10000, Loss: 1.6011555194854736, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4171/10000, Loss: 1.587985634803772, Train Acc : 0.4645017510347023 , Val Acc : 0.47435897435897434\n",
      "Epoch 4172/10000, Loss: 1.547306776046753, Train Acc : 0.46418338108882523 , Val Acc : 0.47435897435897434\n",
      "Epoch 4173/10000, Loss: 1.6191644668579102, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4174/10000, Loss: 1.603171944618225, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4175/10000, Loss: 1.546148419380188, Train Acc : 0.46513849092645654 , Val Acc : 0.47435897435897434\n",
      "Epoch 4176/10000, Loss: 1.5832394361495972, Train Acc : 0.4645017510347023 , Val Acc : 0.47435897435897434\n",
      "Epoch 4177/10000, Loss: 1.654218077659607, Train Acc : 0.4645017510347023 , Val Acc : 0.47435897435897434\n",
      "Epoch 4178/10000, Loss: 1.5969810485839844, Train Acc : 0.46418338108882523 , Val Acc : 0.47435897435897434\n",
      "Epoch 4179/10000, Loss: 1.5777597427368164, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4180/10000, Loss: 1.6474759578704834, Train Acc : 0.46513849092645654 , Val Acc : 0.47435897435897434\n",
      "Epoch 4181/10000, Loss: 1.602312445640564, Train Acc : 0.46577523081821076 , Val Acc : 0.47435897435897434\n",
      "Epoch 4182/10000, Loss: 1.7146334648132324, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4183/10000, Loss: 1.6021195650100708, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4184/10000, Loss: 1.6331372261047363, Train Acc : 0.4645017510347023 , Val Acc : 0.47435897435897434\n",
      "Epoch 4185/10000, Loss: 1.5543932914733887, Train Acc : 0.46513849092645654 , Val Acc : 0.47435897435897434\n",
      "Epoch 4186/10000, Loss: 1.5278971195220947, Train Acc : 0.46577523081821076 , Val Acc : 0.47435897435897434\n",
      "Epoch 4187/10000, Loss: 1.5813761949539185, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4188/10000, Loss: 1.6254887580871582, Train Acc : 0.46577523081821076 , Val Acc : 0.47435897435897434\n",
      "Epoch 4189/10000, Loss: 1.5299352407455444, Train Acc : 0.4654568608723337 , Val Acc : 0.47435897435897434\n",
      "Epoch 4190/10000, Loss: 1.515465497970581, Train Acc : 0.46513849092645654 , Val Acc : 0.47435897435897434\n",
      "Epoch 4191/10000, Loss: 1.553589940071106, Train Acc : 0.4654568608723337 , Val Acc : 0.47435897435897434\n",
      "Epoch 4192/10000, Loss: 1.516844630241394, Train Acc : 0.46609360076408785 , Val Acc : 0.47435897435897434\n",
      "Epoch 4193/10000, Loss: 1.5760529041290283, Train Acc : 0.46577523081821076 , Val Acc : 0.47435897435897434\n",
      "Epoch 4194/10000, Loss: 1.6197363138198853, Train Acc : 0.46609360076408785 , Val Acc : 0.47435897435897434\n",
      "Epoch 4195/10000, Loss: 1.6278972625732422, Train Acc : 0.46673034065584207 , Val Acc : 0.47435897435897434\n",
      "Epoch 4196/10000, Loss: 1.5854209661483765, Train Acc : 0.4654568608723337 , Val Acc : 0.47435897435897434\n",
      "Epoch 4197/10000, Loss: 1.5501877069473267, Train Acc : 0.46513849092645654 , Val Acc : 0.47435897435897434\n",
      "Epoch 4198/10000, Loss: 1.5915637016296387, Train Acc : 0.46513849092645654 , Val Acc : 0.47435897435897434\n",
      "Epoch 4199/10000, Loss: 1.67351233959198, Train Acc : 0.4645017510347023 , Val Acc : 0.47435897435897434\n",
      "Epoch 4200/10000, Loss: 1.522964358329773, Train Acc : 0.4645017510347023 , Val Acc : 0.47435897435897434\n",
      "Epoch 4201/10000, Loss: 1.6245452165603638, Train Acc : 0.4645017510347023 , Val Acc : 0.47435897435897434\n",
      "Epoch 4202/10000, Loss: 1.5480635166168213, Train Acc : 0.46482012098057945 , Val Acc : 0.47435897435897434\n",
      "Epoch 4203/10000, Loss: 1.5788733959197998, Train Acc : 0.4645017510347023 , Val Acc : 0.47435897435897434\n",
      "Epoch 4204/10000, Loss: 1.565118670463562, Train Acc : 0.46577523081821076 , Val Acc : 0.47435897435897434\n",
      "Epoch 4205/10000, Loss: 1.5836306810379028, Train Acc : 0.46609360076408785 , Val Acc : 0.47435897435897434\n",
      "Epoch 4206/10000, Loss: 1.5409928560256958, Train Acc : 0.466411970709965 , Val Acc : 0.47435897435897434\n",
      "Epoch 4207/10000, Loss: 1.680246114730835, Train Acc : 0.46609360076408785 , Val Acc : 0.47435897435897434\n",
      "Epoch 4208/10000, Loss: 1.631614089012146, Train Acc : 0.4654568608723337 , Val Acc : 0.47435897435897434\n",
      "Epoch 4209/10000, Loss: 1.537838339805603, Train Acc : 0.46609360076408785 , Val Acc : 0.47435897435897434\n",
      "Epoch 4210/10000, Loss: 1.5199487209320068, Train Acc : 0.46513849092645654 , Val Acc : 0.47435897435897434\n",
      "Epoch 4211/10000, Loss: 1.5703755617141724, Train Acc : 0.46609360076408785 , Val Acc : 0.47435897435897434\n",
      "Epoch 4212/10000, Loss: 1.5568946599960327, Train Acc : 0.46673034065584207 , Val Acc : 0.47435897435897434\n",
      "Epoch 4213/10000, Loss: 1.5886117219924927, Train Acc : 0.4670487106017192 , Val Acc : 0.47435897435897434\n",
      "Epoch 4214/10000, Loss: 1.5392639636993408, Train Acc : 0.466411970709965 , Val Acc : 0.47435897435897434\n",
      "Epoch 4215/10000, Loss: 1.533271074295044, Train Acc : 0.46577523081821076 , Val Acc : 0.47435897435897434\n",
      "Epoch 4216/10000, Loss: 1.6041206121444702, Train Acc : 0.46577523081821076 , Val Acc : 0.47435897435897434\n",
      "Epoch 4217/10000, Loss: 1.5913190841674805, Train Acc : 0.466411970709965 , Val Acc : 0.47435897435897434\n",
      "Epoch 4218/10000, Loss: 1.503401517868042, Train Acc : 0.46673034065584207 , Val Acc : 0.47435897435897434\n",
      "Epoch 4219/10000, Loss: 1.587408185005188, Train Acc : 0.466411970709965 , Val Acc : 0.47435897435897434\n",
      "Epoch 4220/10000, Loss: 1.5591078996658325, Train Acc : 0.46673034065584207 , Val Acc : 0.47435897435897434\n",
      "Epoch 4221/10000, Loss: 1.5491396188735962, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4222/10000, Loss: 1.5643116235733032, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4223/10000, Loss: 1.6059529781341553, Train Acc : 0.46673034065584207 , Val Acc : 0.47435897435897434\n",
      "Epoch 4224/10000, Loss: 1.5644029378890991, Train Acc : 0.4670487106017192 , Val Acc : 0.47435897435897434\n",
      "Epoch 4225/10000, Loss: 1.537083625793457, Train Acc : 0.466411970709965 , Val Acc : 0.47435897435897434\n",
      "Epoch 4226/10000, Loss: 1.5583959817886353, Train Acc : 0.466411970709965 , Val Acc : 0.47435897435897434\n",
      "Epoch 4227/10000, Loss: 1.5850696563720703, Train Acc : 0.46673034065584207 , Val Acc : 0.47435897435897434\n",
      "Epoch 4228/10000, Loss: 1.5289555788040161, Train Acc : 0.4670487106017192 , Val Acc : 0.47435897435897434\n",
      "Epoch 4229/10000, Loss: 1.6125627756118774, Train Acc : 0.4670487106017192 , Val Acc : 0.47435897435897434\n",
      "Epoch 4230/10000, Loss: 1.5328902006149292, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4231/10000, Loss: 1.5914688110351562, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4232/10000, Loss: 1.5620887279510498, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4233/10000, Loss: 1.6048818826675415, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4234/10000, Loss: 1.6267668008804321, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4235/10000, Loss: 1.5892269611358643, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4236/10000, Loss: 1.5692574977874756, Train Acc : 0.4670487106017192 , Val Acc : 0.47435897435897434\n",
      "Epoch 4237/10000, Loss: 1.5523868799209595, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4238/10000, Loss: 1.5516974925994873, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4239/10000, Loss: 1.5704938173294067, Train Acc : 0.4670487106017192 , Val Acc : 0.47435897435897434\n",
      "Epoch 4240/10000, Loss: 1.4954707622528076, Train Acc : 0.46673034065584207 , Val Acc : 0.47435897435897434\n",
      "Epoch 4241/10000, Loss: 1.553039312362671, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4242/10000, Loss: 1.5750123262405396, Train Acc : 0.46673034065584207 , Val Acc : 0.47435897435897434\n",
      "Epoch 4243/10000, Loss: 1.6321276426315308, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4244/10000, Loss: 1.630852460861206, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4245/10000, Loss: 1.5586916208267212, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4246/10000, Loss: 1.5727415084838867, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4247/10000, Loss: 1.5917564630508423, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4248/10000, Loss: 1.556627869606018, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4249/10000, Loss: 1.6788090467453003, Train Acc : 0.4670487106017192 , Val Acc : 0.47435897435897434\n",
      "Epoch 4250/10000, Loss: 1.6254017353057861, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4251/10000, Loss: 1.5535423755645752, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4252/10000, Loss: 1.5902864933013916, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4253/10000, Loss: 1.545520544052124, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4254/10000, Loss: 1.5735772848129272, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4255/10000, Loss: 1.6023014783859253, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4256/10000, Loss: 1.5842759609222412, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4257/10000, Loss: 1.5702219009399414, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4258/10000, Loss: 1.4667870998382568, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4259/10000, Loss: 1.5577030181884766, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4260/10000, Loss: 1.5325820446014404, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4261/10000, Loss: 1.6316790580749512, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4262/10000, Loss: 1.6041744947433472, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4263/10000, Loss: 1.6393638849258423, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4264/10000, Loss: 1.6752959489822388, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4265/10000, Loss: 1.6199324131011963, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4266/10000, Loss: 1.6016532182693481, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4267/10000, Loss: 1.5884852409362793, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4268/10000, Loss: 1.631395697593689, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4269/10000, Loss: 1.5447887182235718, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4270/10000, Loss: 1.6718132495880127, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4271/10000, Loss: 1.5892442464828491, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4272/10000, Loss: 1.6056779623031616, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4273/10000, Loss: 1.6073827743530273, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4274/10000, Loss: 1.6285858154296875, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4275/10000, Loss: 1.555119276046753, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4276/10000, Loss: 1.6187477111816406, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4277/10000, Loss: 1.5992411375045776, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4278/10000, Loss: 1.4215214252471924, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4279/10000, Loss: 1.528662085533142, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4280/10000, Loss: 1.632120132446289, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4281/10000, Loss: 1.6142489910125732, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4282/10000, Loss: 1.5955688953399658, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4283/10000, Loss: 1.6007250547409058, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4284/10000, Loss: 1.566754937171936, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4285/10000, Loss: 1.5373458862304688, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4286/10000, Loss: 1.6295053958892822, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4287/10000, Loss: 1.5631616115570068, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4288/10000, Loss: 1.6505929231643677, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4289/10000, Loss: 1.5894349813461304, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4290/10000, Loss: 1.5608253479003906, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4291/10000, Loss: 1.5944234132766724, Train Acc : 0.4689589302769819 , Val Acc : 0.47435897435897434\n",
      "Epoch 4292/10000, Loss: 1.5992003679275513, Train Acc : 0.4673670805475963 , Val Acc : 0.47435897435897434\n",
      "Epoch 4293/10000, Loss: 1.5289229154586792, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4294/10000, Loss: 1.5784721374511719, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4295/10000, Loss: 1.5933696031570435, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4296/10000, Loss: 1.5627931356430054, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4297/10000, Loss: 1.699682354927063, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4298/10000, Loss: 1.6789021492004395, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4299/10000, Loss: 1.5496634244918823, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4300/10000, Loss: 1.614052653312683, Train Acc : 0.46832219038522765 , Val Acc : 0.4717948717948718\n",
      "Epoch 4301/10000, Loss: 1.475052833557129, Train Acc : 0.46864056033110474 , Val Acc : 0.4717948717948718\n",
      "Epoch 4302/10000, Loss: 1.539014458656311, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4303/10000, Loss: 1.5731302499771118, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4304/10000, Loss: 1.5984140634536743, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4305/10000, Loss: 1.5058541297912598, Train Acc : 0.4689589302769819 , Val Acc : 0.47435897435897434\n",
      "Epoch 4306/10000, Loss: 1.5321072340011597, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4307/10000, Loss: 1.5887806415557861, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4308/10000, Loss: 1.518545389175415, Train Acc : 0.4680038204393505 , Val Acc : 0.47435897435897434\n",
      "Epoch 4309/10000, Loss: 1.5881019830703735, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4310/10000, Loss: 1.6048557758331299, Train Acc : 0.46927730022285896 , Val Acc : 0.47435897435897434\n",
      "Epoch 4311/10000, Loss: 1.683239459991455, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4312/10000, Loss: 1.5359611511230469, Train Acc : 0.4670487106017192 , Val Acc : 0.47435897435897434\n",
      "Epoch 4313/10000, Loss: 1.5704175233840942, Train Acc : 0.4689589302769819 , Val Acc : 0.47435897435897434\n",
      "Epoch 4314/10000, Loss: 1.5879878997802734, Train Acc : 0.4689589302769819 , Val Acc : 0.47435897435897434\n",
      "Epoch 4315/10000, Loss: 1.6549681425094604, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4316/10000, Loss: 1.5903977155685425, Train Acc : 0.4689589302769819 , Val Acc : 0.47435897435897434\n",
      "Epoch 4317/10000, Loss: 1.5606054067611694, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4318/10000, Loss: 1.6116812229156494, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4319/10000, Loss: 1.5621007680892944, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4320/10000, Loss: 1.558562159538269, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4321/10000, Loss: 1.496018648147583, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4322/10000, Loss: 1.564992904663086, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4323/10000, Loss: 1.5923348665237427, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4324/10000, Loss: 1.5506213903427124, Train Acc : 0.46768545049347343 , Val Acc : 0.47435897435897434\n",
      "Epoch 4325/10000, Loss: 1.5144305229187012, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4326/10000, Loss: 1.584901213645935, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4327/10000, Loss: 1.5528148412704468, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4328/10000, Loss: 1.6633058786392212, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4329/10000, Loss: 1.5693261623382568, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4330/10000, Loss: 1.5534307956695557, Train Acc : 0.4689589302769819 , Val Acc : 0.47435897435897434\n",
      "Epoch 4331/10000, Loss: 1.5798161029815674, Train Acc : 0.46832219038522765 , Val Acc : 0.47435897435897434\n",
      "Epoch 4332/10000, Loss: 1.6290620565414429, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4333/10000, Loss: 1.5916094779968262, Train Acc : 0.46864056033110474 , Val Acc : 0.47435897435897434\n",
      "Epoch 4334/10000, Loss: 1.5565763711929321, Train Acc : 0.4689589302769819 , Val Acc : 0.47435897435897434\n",
      "Epoch 4335/10000, Loss: 1.6342887878417969, Train Acc : 0.46832219038522765 , Val Acc : 0.4717948717948718\n",
      "Epoch 4336/10000, Loss: 1.561996340751648, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4337/10000, Loss: 1.6061557531356812, Train Acc : 0.46832219038522765 , Val Acc : 0.4717948717948718\n",
      "Epoch 4338/10000, Loss: 1.6273199319839478, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4339/10000, Loss: 1.6220581531524658, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4340/10000, Loss: 1.6100404262542725, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4341/10000, Loss: 1.6352847814559937, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4342/10000, Loss: 1.5904083251953125, Train Acc : 0.46768545049347343 , Val Acc : 0.4717948717948718\n",
      "Epoch 4343/10000, Loss: 1.5807163715362549, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4344/10000, Loss: 1.5291250944137573, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4345/10000, Loss: 1.6009047031402588, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4346/10000, Loss: 1.6073776483535767, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4347/10000, Loss: 1.5504884719848633, Train Acc : 0.46832219038522765 , Val Acc : 0.4717948717948718\n",
      "Epoch 4348/10000, Loss: 1.5106966495513916, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4349/10000, Loss: 1.5769367218017578, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4350/10000, Loss: 1.5919361114501953, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4351/10000, Loss: 1.5768591165542603, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4352/10000, Loss: 1.5497448444366455, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4353/10000, Loss: 1.4763405323028564, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4354/10000, Loss: 1.5908559560775757, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4355/10000, Loss: 1.6402621269226074, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4356/10000, Loss: 1.6575204133987427, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4357/10000, Loss: 1.60881507396698, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4358/10000, Loss: 1.5548007488250732, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4359/10000, Loss: 1.6802525520324707, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4360/10000, Loss: 1.6088981628417969, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4361/10000, Loss: 1.5642768144607544, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4362/10000, Loss: 1.5791488885879517, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4363/10000, Loss: 1.5847628116607666, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4364/10000, Loss: 1.5685887336730957, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4365/10000, Loss: 1.4429198503494263, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4366/10000, Loss: 1.5581108331680298, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4367/10000, Loss: 1.6335901021957397, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4368/10000, Loss: 1.5994030237197876, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4369/10000, Loss: 1.5101101398468018, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4370/10000, Loss: 1.5761817693710327, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4371/10000, Loss: 1.5304635763168335, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4372/10000, Loss: 1.6318714618682861, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4373/10000, Loss: 1.49604332447052, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4374/10000, Loss: 1.5640316009521484, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4375/10000, Loss: 1.6035634279251099, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4376/10000, Loss: 1.6455495357513428, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4377/10000, Loss: 1.5378121137619019, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4378/10000, Loss: 1.5958166122436523, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4379/10000, Loss: 1.6161012649536133, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4380/10000, Loss: 1.561597466468811, Train Acc : 0.46864056033110474 , Val Acc : 0.4717948717948718\n",
      "Epoch 4381/10000, Loss: 1.5818305015563965, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4382/10000, Loss: 1.6004780530929565, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4383/10000, Loss: 1.5657192468643188, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4384/10000, Loss: 1.6199324131011963, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4385/10000, Loss: 1.5825377702713013, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4386/10000, Loss: 1.6270722150802612, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4387/10000, Loss: 1.6238279342651367, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4388/10000, Loss: 1.5827219486236572, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4389/10000, Loss: 1.5549341440200806, Train Acc : 0.4699140401146132 , Val Acc : 0.4717948717948718\n",
      "Epoch 4390/10000, Loss: 1.5408705472946167, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4391/10000, Loss: 1.6228042840957642, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4392/10000, Loss: 1.5691362619400024, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4393/10000, Loss: 1.606932282447815, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4394/10000, Loss: 1.619649887084961, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4395/10000, Loss: 1.5799720287322998, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4396/10000, Loss: 1.660320520401001, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4397/10000, Loss: 1.5745184421539307, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4398/10000, Loss: 1.5336668491363525, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4399/10000, Loss: 1.5819774866104126, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4400/10000, Loss: 1.5782550573349, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4401/10000, Loss: 1.6887294054031372, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4402/10000, Loss: 1.6445181369781494, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4403/10000, Loss: 1.5912193059921265, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4404/10000, Loss: 1.5878053903579712, Train Acc : 0.4699140401146132 , Val Acc : 0.4717948717948718\n",
      "Epoch 4405/10000, Loss: 1.5112922191619873, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4406/10000, Loss: 1.6100105047225952, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4407/10000, Loss: 1.617647647857666, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4408/10000, Loss: 1.5960898399353027, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4409/10000, Loss: 1.5709973573684692, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4410/10000, Loss: 1.5735582113265991, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4411/10000, Loss: 1.5413117408752441, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4412/10000, Loss: 1.686866044998169, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4413/10000, Loss: 1.557059645652771, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4414/10000, Loss: 1.5383644104003906, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4415/10000, Loss: 1.626029133796692, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4416/10000, Loss: 1.6581131219863892, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4417/10000, Loss: 1.5741569995880127, Train Acc : 0.4689589302769819 , Val Acc : 0.4717948717948718\n",
      "Epoch 4418/10000, Loss: 1.5344200134277344, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4419/10000, Loss: 1.5586532354354858, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4420/10000, Loss: 1.6369694471359253, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4421/10000, Loss: 1.5244923830032349, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4422/10000, Loss: 1.5528916120529175, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4423/10000, Loss: 1.5778826475143433, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4424/10000, Loss: 1.5883135795593262, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4425/10000, Loss: 1.5376616716384888, Train Acc : 0.4699140401146132 , Val Acc : 0.4717948717948718\n",
      "Epoch 4426/10000, Loss: 1.537221074104309, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4427/10000, Loss: 1.6085898876190186, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4428/10000, Loss: 1.5805519819259644, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4429/10000, Loss: 1.542742371559143, Train Acc : 0.46864056033110474 , Val Acc : 0.4717948717948718\n",
      "Epoch 4430/10000, Loss: 1.5840381383895874, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4431/10000, Loss: 1.5922836065292358, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4432/10000, Loss: 1.6175132989883423, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4433/10000, Loss: 1.5981873273849487, Train Acc : 0.4699140401146132 , Val Acc : 0.4717948717948718\n",
      "Epoch 4434/10000, Loss: 1.602022647857666, Train Acc : 0.47023241006049027 , Val Acc : 0.4717948717948718\n",
      "Epoch 4435/10000, Loss: 1.657364010810852, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4436/10000, Loss: 1.714470386505127, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4437/10000, Loss: 1.6412492990493774, Train Acc : 0.46959567016873605 , Val Acc : 0.47435897435897434\n",
      "Epoch 4438/10000, Loss: 1.548559308052063, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4439/10000, Loss: 1.6258596181869507, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4440/10000, Loss: 1.5931730270385742, Train Acc : 0.46927730022285896 , Val Acc : 0.47435897435897434\n",
      "Epoch 4441/10000, Loss: 1.6086829900741577, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4442/10000, Loss: 1.5781179666519165, Train Acc : 0.4699140401146132 , Val Acc : 0.4717948717948718\n",
      "Epoch 4443/10000, Loss: 1.6470328569412231, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4444/10000, Loss: 1.5435997247695923, Train Acc : 0.46959567016873605 , Val Acc : 0.4717948717948718\n",
      "Epoch 4445/10000, Loss: 1.644179105758667, Train Acc : 0.46959567016873605 , Val Acc : 0.47435897435897434\n",
      "Epoch 4446/10000, Loss: 1.5701667070388794, Train Acc : 0.4699140401146132 , Val Acc : 0.47435897435897434\n",
      "Epoch 4447/10000, Loss: 1.619687795639038, Train Acc : 0.4699140401146132 , Val Acc : 0.4717948717948718\n",
      "Epoch 4448/10000, Loss: 1.6017788648605347, Train Acc : 0.46959567016873605 , Val Acc : 0.47435897435897434\n",
      "Epoch 4449/10000, Loss: 1.6124846935272217, Train Acc : 0.46959567016873605 , Val Acc : 0.47435897435897434\n",
      "Epoch 4450/10000, Loss: 1.6307125091552734, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4451/10000, Loss: 1.6545647382736206, Train Acc : 0.46927730022285896 , Val Acc : 0.4717948717948718\n",
      "Epoch 4452/10000, Loss: 1.5771502256393433, Train Acc : 0.46959567016873605 , Val Acc : 0.47435897435897434\n",
      "Epoch 4453/10000, Loss: 1.5579485893249512, Train Acc : 0.4689589302769819 , Val Acc : 0.47435897435897434\n",
      "Epoch 4454/10000, Loss: 1.538574457168579, Train Acc : 0.46959567016873605 , Val Acc : 0.47435897435897434\n",
      "Epoch 4455/10000, Loss: 1.5304745435714722, Train Acc : 0.46927730022285896 , Val Acc : 0.47435897435897434\n",
      "Epoch 4456/10000, Loss: 1.6363219022750854, Train Acc : 0.4699140401146132 , Val Acc : 0.4717948717948718\n",
      "Epoch 4457/10000, Loss: 1.6537507772445679, Train Acc : 0.46959567016873605 , Val Acc : 0.47435897435897434\n",
      "Epoch 4458/10000, Loss: 1.6673521995544434, Train Acc : 0.4689589302769819 , Val Acc : 0.47435897435897434\n",
      "Epoch 4459/10000, Loss: 1.5923528671264648, Train Acc : 0.4699140401146132 , Val Acc : 0.47435897435897434\n",
      "Epoch 4460/10000, Loss: 1.52512526512146, Train Acc : 0.46927730022285896 , Val Acc : 0.47435897435897434\n",
      "Epoch 4461/10000, Loss: 1.6057591438293457, Train Acc : 0.46927730022285896 , Val Acc : 0.47435897435897434\n",
      "Epoch 4462/10000, Loss: 1.5580345392227173, Train Acc : 0.46927730022285896 , Val Acc : 0.47435897435897434\n",
      "Epoch 4463/10000, Loss: 1.5870949029922485, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4464/10000, Loss: 1.491334080696106, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4465/10000, Loss: 1.5830024480819702, Train Acc : 0.46959567016873605 , Val Acc : 0.47435897435897434\n",
      "Epoch 4466/10000, Loss: 1.6021062135696411, Train Acc : 0.46927730022285896 , Val Acc : 0.47692307692307695\n",
      "Epoch 4467/10000, Loss: 1.5958378314971924, Train Acc : 0.4689589302769819 , Val Acc : 0.47692307692307695\n",
      "Epoch 4468/10000, Loss: 1.4982341527938843, Train Acc : 0.46927730022285896 , Val Acc : 0.47692307692307695\n",
      "Epoch 4469/10000, Loss: 1.5550117492675781, Train Acc : 0.46927730022285896 , Val Acc : 0.47692307692307695\n",
      "Epoch 4470/10000, Loss: 1.60550856590271, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4471/10000, Loss: 1.6292822360992432, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4472/10000, Loss: 1.6082961559295654, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4473/10000, Loss: 1.5632078647613525, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4474/10000, Loss: 1.5426007509231567, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4475/10000, Loss: 1.5442112684249878, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4476/10000, Loss: 1.5902456045150757, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4477/10000, Loss: 1.6092387437820435, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4478/10000, Loss: 1.6245596408843994, Train Acc : 0.46927730022285896 , Val Acc : 0.47692307692307695\n",
      "Epoch 4479/10000, Loss: 1.6629019975662231, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4480/10000, Loss: 1.6002352237701416, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4481/10000, Loss: 1.5847772359848022, Train Acc : 0.46927730022285896 , Val Acc : 0.47692307692307695\n",
      "Epoch 4482/10000, Loss: 1.6753861904144287, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4483/10000, Loss: 1.5274800062179565, Train Acc : 0.46927730022285896 , Val Acc : 0.47692307692307695\n",
      "Epoch 4484/10000, Loss: 1.5950827598571777, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4485/10000, Loss: 1.5209290981292725, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4486/10000, Loss: 1.6054673194885254, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4487/10000, Loss: 1.6061608791351318, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4488/10000, Loss: 1.538669228553772, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4489/10000, Loss: 1.6969470977783203, Train Acc : 0.4689589302769819 , Val Acc : 0.47692307692307695\n",
      "Epoch 4490/10000, Loss: 1.607117772102356, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4491/10000, Loss: 1.6211239099502563, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4492/10000, Loss: 1.5404729843139648, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4493/10000, Loss: 1.6551698446273804, Train Acc : 0.46927730022285896 , Val Acc : 0.47692307692307695\n",
      "Epoch 4494/10000, Loss: 1.5406944751739502, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4495/10000, Loss: 1.5246559381484985, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4496/10000, Loss: 1.5598149299621582, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4497/10000, Loss: 1.6226789951324463, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4498/10000, Loss: 1.598802924156189, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4499/10000, Loss: 1.5785748958587646, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4500/10000, Loss: 1.5535061359405518, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4501/10000, Loss: 1.53543221950531, Train Acc : 0.4708691499522445 , Val Acc : 0.47692307692307695\n",
      "Epoch 4502/10000, Loss: 1.6024268865585327, Train Acc : 0.4708691499522445 , Val Acc : 0.47692307692307695\n",
      "Epoch 4503/10000, Loss: 1.5735043287277222, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4504/10000, Loss: 1.5404512882232666, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4505/10000, Loss: 1.5692875385284424, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4506/10000, Loss: 1.5279978513717651, Train Acc : 0.4708691499522445 , Val Acc : 0.47692307692307695\n",
      "Epoch 4507/10000, Loss: 1.5507210493087769, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4508/10000, Loss: 1.5973294973373413, Train Acc : 0.47118751989812163 , Val Acc : 0.47692307692307695\n",
      "Epoch 4509/10000, Loss: 1.623828411102295, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4510/10000, Loss: 1.4735585451126099, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4511/10000, Loss: 1.4967881441116333, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4512/10000, Loss: 1.5267497301101685, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4513/10000, Loss: 1.6090573072433472, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4514/10000, Loss: 1.6040149927139282, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4515/10000, Loss: 1.6312841176986694, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4516/10000, Loss: 1.55658757686615, Train Acc : 0.46959567016873605 , Val Acc : 0.47692307692307695\n",
      "Epoch 4517/10000, Loss: 1.6378511190414429, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4518/10000, Loss: 1.5755891799926758, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4519/10000, Loss: 1.6059808731079102, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4520/10000, Loss: 1.586472511291504, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4521/10000, Loss: 1.6597685813903809, Train Acc : 0.4708691499522445 , Val Acc : 0.47692307692307695\n",
      "Epoch 4522/10000, Loss: 1.5697871446609497, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4523/10000, Loss: 1.5700265169143677, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4524/10000, Loss: 1.572395920753479, Train Acc : 0.4705507800063674 , Val Acc : 0.47692307692307695\n",
      "Epoch 4525/10000, Loss: 1.491394281387329, Train Acc : 0.4715058898439987 , Val Acc : 0.47692307692307695\n",
      "Epoch 4526/10000, Loss: 1.5411295890808105, Train Acc : 0.47118751989812163 , Val Acc : 0.47692307692307695\n",
      "Epoch 4527/10000, Loss: 1.5978952646255493, Train Acc : 0.47118751989812163 , Val Acc : 0.47692307692307695\n",
      "Epoch 4528/10000, Loss: 1.5986424684524536, Train Acc : 0.47118751989812163 , Val Acc : 0.47692307692307695\n",
      "Epoch 4529/10000, Loss: 1.5654100179672241, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4530/10000, Loss: 1.5937330722808838, Train Acc : 0.47118751989812163 , Val Acc : 0.47692307692307695\n",
      "Epoch 4531/10000, Loss: 1.5849428176879883, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4532/10000, Loss: 1.5931682586669922, Train Acc : 0.47118751989812163 , Val Acc : 0.47692307692307695\n",
      "Epoch 4533/10000, Loss: 1.6022663116455078, Train Acc : 0.47118751989812163 , Val Acc : 0.47692307692307695\n",
      "Epoch 4534/10000, Loss: 1.56406569480896, Train Acc : 0.4708691499522445 , Val Acc : 0.47692307692307695\n",
      "Epoch 4535/10000, Loss: 1.6363327503204346, Train Acc : 0.47023241006049027 , Val Acc : 0.47692307692307695\n",
      "Epoch 4536/10000, Loss: 1.5203359127044678, Train Acc : 0.4708691499522445 , Val Acc : 0.4794871794871795\n",
      "Epoch 4537/10000, Loss: 1.537148118019104, Train Acc : 0.47182425978987586 , Val Acc : 0.47692307692307695\n",
      "Epoch 4538/10000, Loss: 1.521927833557129, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4539/10000, Loss: 1.5824778079986572, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4540/10000, Loss: 1.558261752128601, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4541/10000, Loss: 1.583318829536438, Train Acc : 0.47118751989812163 , Val Acc : 0.47692307692307695\n",
      "Epoch 4542/10000, Loss: 1.5668888092041016, Train Acc : 0.4699140401146132 , Val Acc : 0.47692307692307695\n",
      "Epoch 4543/10000, Loss: 1.6223759651184082, Train Acc : 0.4715058898439987 , Val Acc : 0.47692307692307695\n",
      "Epoch 4544/10000, Loss: 1.5806723833084106, Train Acc : 0.4715058898439987 , Val Acc : 0.47692307692307695\n",
      "Epoch 4545/10000, Loss: 1.486628770828247, Train Acc : 0.4715058898439987 , Val Acc : 0.47692307692307695\n",
      "Epoch 4546/10000, Loss: 1.5707935094833374, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4547/10000, Loss: 1.5438357591629028, Train Acc : 0.47118751989812163 , Val Acc : 0.47692307692307695\n",
      "Epoch 4548/10000, Loss: 1.5848053693771362, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4549/10000, Loss: 1.5521633625030518, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4550/10000, Loss: 1.5624268054962158, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4551/10000, Loss: 1.5880988836288452, Train Acc : 0.4708691499522445 , Val Acc : 0.47692307692307695\n",
      "Epoch 4552/10000, Loss: 1.6048496961593628, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4553/10000, Loss: 1.6186044216156006, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4554/10000, Loss: 1.579754114151001, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4555/10000, Loss: 1.616552710533142, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4556/10000, Loss: 1.5771466493606567, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4557/10000, Loss: 1.5724517107009888, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4558/10000, Loss: 1.5327879190444946, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4559/10000, Loss: 1.6485644578933716, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4560/10000, Loss: 1.5941232442855835, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4561/10000, Loss: 1.6022553443908691, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4562/10000, Loss: 1.529781460762024, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4563/10000, Loss: 1.5311133861541748, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4564/10000, Loss: 1.64955735206604, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4565/10000, Loss: 1.5433087348937988, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4566/10000, Loss: 1.5988715887069702, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4567/10000, Loss: 1.612025260925293, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4568/10000, Loss: 1.5887147188186646, Train Acc : 0.4708691499522445 , Val Acc : 0.4794871794871795\n",
      "Epoch 4569/10000, Loss: 1.5596675872802734, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4570/10000, Loss: 1.5520530939102173, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4571/10000, Loss: 1.6789828538894653, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4572/10000, Loss: 1.4992562532424927, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4573/10000, Loss: 1.616168737411499, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4574/10000, Loss: 1.5866332054138184, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4575/10000, Loss: 1.623499870300293, Train Acc : 0.4708691499522445 , Val Acc : 0.4794871794871795\n",
      "Epoch 4576/10000, Loss: 1.523533821105957, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4577/10000, Loss: 1.569214105606079, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4578/10000, Loss: 1.4840553998947144, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4579/10000, Loss: 1.668769359588623, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4580/10000, Loss: 1.5869286060333252, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4581/10000, Loss: 1.6030547618865967, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4582/10000, Loss: 1.601619839668274, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4583/10000, Loss: 1.5039243698120117, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4584/10000, Loss: 1.5968866348266602, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4585/10000, Loss: 1.5566966533660889, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4586/10000, Loss: 1.6135797500610352, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4587/10000, Loss: 1.5116335153579712, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4588/10000, Loss: 1.6098957061767578, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4589/10000, Loss: 1.5023748874664307, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4590/10000, Loss: 1.568682074546814, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4591/10000, Loss: 1.5712450742721558, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4592/10000, Loss: 1.5578721761703491, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4593/10000, Loss: 1.6303913593292236, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4594/10000, Loss: 1.6346482038497925, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4595/10000, Loss: 1.6022940874099731, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4596/10000, Loss: 1.4651178121566772, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4597/10000, Loss: 1.5040276050567627, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4598/10000, Loss: 1.646500825881958, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4599/10000, Loss: 1.6235055923461914, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4600/10000, Loss: 1.6317973136901855, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4601/10000, Loss: 1.5654786825180054, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4602/10000, Loss: 1.5317573547363281, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4603/10000, Loss: 1.549489140510559, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4604/10000, Loss: 1.6188607215881348, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4605/10000, Loss: 1.5419820547103882, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4606/10000, Loss: 1.5726838111877441, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4607/10000, Loss: 1.5665671825408936, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4608/10000, Loss: 1.5301767587661743, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4609/10000, Loss: 1.5876694917678833, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4610/10000, Loss: 1.601650595664978, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4611/10000, Loss: 1.5353742837905884, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4612/10000, Loss: 1.5583763122558594, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4613/10000, Loss: 1.5546218156814575, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4614/10000, Loss: 1.6051386594772339, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4615/10000, Loss: 1.651128888130188, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4616/10000, Loss: 1.5477972030639648, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4617/10000, Loss: 1.5319576263427734, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4618/10000, Loss: 1.5275144577026367, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4619/10000, Loss: 1.655295968055725, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4620/10000, Loss: 1.5555408000946045, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4621/10000, Loss: 1.5983314514160156, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4622/10000, Loss: 1.530882477760315, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4623/10000, Loss: 1.581207036972046, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4624/10000, Loss: 1.5556640625, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4625/10000, Loss: 1.5154263973236084, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4626/10000, Loss: 1.613524317741394, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4627/10000, Loss: 1.6187511682510376, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4628/10000, Loss: 1.561889886856079, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4629/10000, Loss: 1.5381358861923218, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4630/10000, Loss: 1.5138829946517944, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4631/10000, Loss: 1.5667213201522827, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4632/10000, Loss: 1.542653203010559, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4633/10000, Loss: 1.648400068283081, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4634/10000, Loss: 1.5408252477645874, Train Acc : 0.47118751989812163 , Val Acc : 0.4794871794871795\n",
      "Epoch 4635/10000, Loss: 1.5851174592971802, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4636/10000, Loss: 1.539612054824829, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4637/10000, Loss: 1.5782597064971924, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4638/10000, Loss: 1.621790885925293, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4639/10000, Loss: 1.5630247592926025, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4640/10000, Loss: 1.5506645441055298, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4641/10000, Loss: 1.5947166681289673, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4642/10000, Loss: 1.680816650390625, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4643/10000, Loss: 1.5557801723480225, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4644/10000, Loss: 1.5598440170288086, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4645/10000, Loss: 1.5205293893814087, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4646/10000, Loss: 1.541632890701294, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4647/10000, Loss: 1.5348788499832153, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4648/10000, Loss: 1.6146678924560547, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4649/10000, Loss: 1.6173232793807983, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4650/10000, Loss: 1.5846878290176392, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4651/10000, Loss: 1.674156665802002, Train Acc : 0.4715058898439987 , Val Acc : 0.4794871794871795\n",
      "Epoch 4652/10000, Loss: 1.5858598947525024, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4653/10000, Loss: 1.5447638034820557, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4654/10000, Loss: 1.5253491401672363, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4655/10000, Loss: 1.6098060607910156, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4656/10000, Loss: 1.6644152402877808, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4657/10000, Loss: 1.5569428205490112, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4658/10000, Loss: 1.617889642715454, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4659/10000, Loss: 1.6024521589279175, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4660/10000, Loss: 1.5812681913375854, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4661/10000, Loss: 1.4713436365127563, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4662/10000, Loss: 1.55905020236969, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4663/10000, Loss: 1.5916203260421753, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4664/10000, Loss: 1.6302167177200317, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4665/10000, Loss: 1.5995123386383057, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4666/10000, Loss: 1.5513139963150024, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4667/10000, Loss: 1.5597889423370361, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4668/10000, Loss: 1.5871061086654663, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4669/10000, Loss: 1.5396639108657837, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4670/10000, Loss: 1.581631064414978, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4671/10000, Loss: 1.621733546257019, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4672/10000, Loss: 1.6611006259918213, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4673/10000, Loss: 1.6085689067840576, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4674/10000, Loss: 1.496464729309082, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4675/10000, Loss: 1.5506023168563843, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4676/10000, Loss: 1.5535334348678589, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4677/10000, Loss: 1.5535191297531128, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4678/10000, Loss: 1.6228656768798828, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4679/10000, Loss: 1.528001308441162, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4680/10000, Loss: 1.5325090885162354, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4681/10000, Loss: 1.5349278450012207, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4682/10000, Loss: 1.5394973754882812, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4683/10000, Loss: 1.4990004301071167, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4684/10000, Loss: 1.6175360679626465, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4685/10000, Loss: 1.4623017311096191, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4686/10000, Loss: 1.7213335037231445, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4687/10000, Loss: 1.6639668941497803, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4688/10000, Loss: 1.5751386880874634, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4689/10000, Loss: 1.6113426685333252, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4690/10000, Loss: 1.5190684795379639, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4691/10000, Loss: 1.5484472513198853, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4692/10000, Loss: 1.5222960710525513, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4693/10000, Loss: 1.6176599264144897, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4694/10000, Loss: 1.609762191772461, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4695/10000, Loss: 1.580471158027649, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4696/10000, Loss: 1.533436894416809, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4697/10000, Loss: 1.622087836265564, Train Acc : 0.47214262973575294 , Val Acc : 0.4794871794871795\n",
      "Epoch 4698/10000, Loss: 1.585680603981018, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4699/10000, Loss: 1.578940987586975, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4700/10000, Loss: 1.6327495574951172, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4701/10000, Loss: 1.5631515979766846, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4702/10000, Loss: 1.5199894905090332, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4703/10000, Loss: 1.6485670804977417, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4704/10000, Loss: 1.561213731765747, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4705/10000, Loss: 1.5364980697631836, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4706/10000, Loss: 1.4650145769119263, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4707/10000, Loss: 1.5484243631362915, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4708/10000, Loss: 1.5797145366668701, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4709/10000, Loss: 1.598815679550171, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4710/10000, Loss: 1.6192182302474976, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4711/10000, Loss: 1.5634794235229492, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4712/10000, Loss: 1.635353922843933, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4713/10000, Loss: 1.5609759092330933, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4714/10000, Loss: 1.51469087600708, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4715/10000, Loss: 1.5717060565948486, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4716/10000, Loss: 1.5327613353729248, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4717/10000, Loss: 1.5993146896362305, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4718/10000, Loss: 1.6386488676071167, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4719/10000, Loss: 1.527413249015808, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4720/10000, Loss: 1.5922375917434692, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4721/10000, Loss: 1.5379548072814941, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4722/10000, Loss: 1.5399696826934814, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4723/10000, Loss: 1.671054720878601, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4724/10000, Loss: 1.5364757776260376, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4725/10000, Loss: 1.598398208618164, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4726/10000, Loss: 1.5413720607757568, Train Acc : 0.47182425978987586 , Val Acc : 0.4794871794871795\n",
      "Epoch 4727/10000, Loss: 1.6307648420333862, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4728/10000, Loss: 1.5561749935150146, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4729/10000, Loss: 1.5210261344909668, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4730/10000, Loss: 1.5944615602493286, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4731/10000, Loss: 1.555233120918274, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4732/10000, Loss: 1.7041538953781128, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4733/10000, Loss: 1.4880658388137817, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4734/10000, Loss: 1.574925184249878, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4735/10000, Loss: 1.5402220487594604, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4736/10000, Loss: 1.6035032272338867, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4737/10000, Loss: 1.5823214054107666, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4738/10000, Loss: 1.5028427839279175, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4739/10000, Loss: 1.5518907308578491, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4740/10000, Loss: 1.5281437635421753, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4741/10000, Loss: 1.5543996095657349, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4742/10000, Loss: 1.5982836484909058, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4743/10000, Loss: 1.6316628456115723, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4744/10000, Loss: 1.5483070611953735, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4745/10000, Loss: 1.5743943452835083, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4746/10000, Loss: 1.5642790794372559, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4747/10000, Loss: 1.6508426666259766, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4748/10000, Loss: 1.5985321998596191, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4749/10000, Loss: 1.614662528038025, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4750/10000, Loss: 1.566165804862976, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4751/10000, Loss: 1.672520637512207, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4752/10000, Loss: 1.5433541536331177, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4753/10000, Loss: 1.5881810188293457, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4754/10000, Loss: 1.6365187168121338, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4755/10000, Loss: 1.6659069061279297, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4756/10000, Loss: 1.625448226928711, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4757/10000, Loss: 1.6011165380477905, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4758/10000, Loss: 1.5231053829193115, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4759/10000, Loss: 1.5337852239608765, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4760/10000, Loss: 1.622299313545227, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4761/10000, Loss: 1.5508743524551392, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4762/10000, Loss: 1.5467722415924072, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4763/10000, Loss: 1.605612874031067, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4764/10000, Loss: 1.6076771020889282, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4765/10000, Loss: 1.501768946647644, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4766/10000, Loss: 1.4919575452804565, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4767/10000, Loss: 1.559539556503296, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4768/10000, Loss: 1.5411062240600586, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4769/10000, Loss: 1.5586494207382202, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4770/10000, Loss: 1.5806103944778442, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4771/10000, Loss: 1.6799614429473877, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4772/10000, Loss: 1.5812736749649048, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4773/10000, Loss: 1.4958394765853882, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4774/10000, Loss: 1.6034200191497803, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4775/10000, Loss: 1.5130773782730103, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4776/10000, Loss: 1.5950318574905396, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4777/10000, Loss: 1.56832754611969, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4778/10000, Loss: 1.6344921588897705, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4779/10000, Loss: 1.4972918033599854, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4780/10000, Loss: 1.6063488721847534, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4781/10000, Loss: 1.5646491050720215, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4782/10000, Loss: 1.5839179754257202, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4783/10000, Loss: 1.5558626651763916, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4784/10000, Loss: 1.5754550695419312, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4785/10000, Loss: 1.480560541152954, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4786/10000, Loss: 1.5339696407318115, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4787/10000, Loss: 1.5244646072387695, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4788/10000, Loss: 1.5485904216766357, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4789/10000, Loss: 1.5537418127059937, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4790/10000, Loss: 1.6760406494140625, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4791/10000, Loss: 1.5572545528411865, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4792/10000, Loss: 1.647687554359436, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4793/10000, Loss: 1.604912519454956, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4794/10000, Loss: 1.5178062915802002, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4795/10000, Loss: 1.5372686386108398, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4796/10000, Loss: 1.6090600490570068, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4797/10000, Loss: 1.6049023866653442, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4798/10000, Loss: 1.6080728769302368, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4799/10000, Loss: 1.56972336769104, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4800/10000, Loss: 1.6513115167617798, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4801/10000, Loss: 1.5629138946533203, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4802/10000, Loss: 1.5993598699569702, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4803/10000, Loss: 1.5163240432739258, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4804/10000, Loss: 1.5191725492477417, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4805/10000, Loss: 1.5171558856964111, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4806/10000, Loss: 1.5626671314239502, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4807/10000, Loss: 1.6715295314788818, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4808/10000, Loss: 1.566798448562622, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4809/10000, Loss: 1.5665411949157715, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4810/10000, Loss: 1.5260608196258545, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4811/10000, Loss: 1.529185175895691, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4812/10000, Loss: 1.5877670049667358, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4813/10000, Loss: 1.5492007732391357, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4814/10000, Loss: 1.5637474060058594, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4815/10000, Loss: 1.6116015911102295, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4816/10000, Loss: 1.6018798351287842, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4817/10000, Loss: 1.5515159368515015, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4818/10000, Loss: 1.5390902757644653, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4819/10000, Loss: 1.6136741638183594, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4820/10000, Loss: 1.6114718914031982, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4821/10000, Loss: 1.5819040536880493, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4822/10000, Loss: 1.629683017730713, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4823/10000, Loss: 1.529656171798706, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4824/10000, Loss: 1.6086193323135376, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4825/10000, Loss: 1.6068427562713623, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4826/10000, Loss: 1.5420359373092651, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4827/10000, Loss: 1.5534316301345825, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4828/10000, Loss: 1.5674687623977661, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4829/10000, Loss: 1.6342743635177612, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4830/10000, Loss: 1.6660741567611694, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4831/10000, Loss: 1.611629605293274, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4832/10000, Loss: 1.5721408128738403, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4833/10000, Loss: 1.607243299484253, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4834/10000, Loss: 1.5999512672424316, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4835/10000, Loss: 1.5738390684127808, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4836/10000, Loss: 1.5901015996932983, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4837/10000, Loss: 1.545689344406128, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4838/10000, Loss: 1.5927420854568481, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4839/10000, Loss: 1.5367754697799683, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4840/10000, Loss: 1.6388872861862183, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4841/10000, Loss: 1.58291494846344, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4842/10000, Loss: 1.5614066123962402, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4843/10000, Loss: 1.6249432563781738, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4844/10000, Loss: 1.6374950408935547, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4845/10000, Loss: 1.5220493078231812, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4846/10000, Loss: 1.592171311378479, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4847/10000, Loss: 1.5819599628448486, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4848/10000, Loss: 1.6078211069107056, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4849/10000, Loss: 1.541710376739502, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4850/10000, Loss: 1.5673091411590576, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4851/10000, Loss: 1.5766721963882446, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4852/10000, Loss: 1.4997812509536743, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4853/10000, Loss: 1.6130293607711792, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4854/10000, Loss: 1.5855568647384644, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4855/10000, Loss: 1.5986781120300293, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4856/10000, Loss: 1.4668785333633423, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4857/10000, Loss: 1.5858566761016846, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4858/10000, Loss: 1.5870659351348877, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4859/10000, Loss: 1.589648723602295, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4860/10000, Loss: 1.570407748222351, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4861/10000, Loss: 1.5267516374588013, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4862/10000, Loss: 1.6019306182861328, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4863/10000, Loss: 1.515504002571106, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4864/10000, Loss: 1.5639472007751465, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4865/10000, Loss: 1.4817676544189453, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4866/10000, Loss: 1.6569286584854126, Train Acc : 0.4724609996816301 , Val Acc : 0.4794871794871795\n",
      "Epoch 4867/10000, Loss: 1.5598167181015015, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4868/10000, Loss: 1.5605583190917969, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4869/10000, Loss: 1.4999560117721558, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4870/10000, Loss: 1.5685771703720093, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4871/10000, Loss: 1.5177671909332275, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4872/10000, Loss: 1.6305936574935913, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4873/10000, Loss: 1.5538618564605713, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4874/10000, Loss: 1.5958179235458374, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4875/10000, Loss: 1.5692137479782104, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 4876/10000, Loss: 1.5821534395217896, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4877/10000, Loss: 1.6278495788574219, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4878/10000, Loss: 1.463788628578186, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4879/10000, Loss: 1.649773359298706, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4880/10000, Loss: 1.5100624561309814, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4881/10000, Loss: 1.5487773418426514, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4882/10000, Loss: 1.5717498064041138, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4883/10000, Loss: 1.6339304447174072, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4884/10000, Loss: 1.639432430267334, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4885/10000, Loss: 1.6119261980056763, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4886/10000, Loss: 1.506731390953064, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4887/10000, Loss: 1.5996911525726318, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4888/10000, Loss: 1.6335976123809814, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4889/10000, Loss: 1.5828490257263184, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4890/10000, Loss: 1.534301519393921, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4891/10000, Loss: 1.529427409172058, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4892/10000, Loss: 1.5671743154525757, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4893/10000, Loss: 1.5879254341125488, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4894/10000, Loss: 1.5763134956359863, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4895/10000, Loss: 1.5882580280303955, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4896/10000, Loss: 1.5780029296875, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4897/10000, Loss: 1.5221220254898071, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4898/10000, Loss: 1.5341250896453857, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4899/10000, Loss: 1.600492000579834, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4900/10000, Loss: 1.6483303308486938, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4901/10000, Loss: 1.645397663116455, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4902/10000, Loss: 1.6129926443099976, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 4903/10000, Loss: 1.5662986040115356, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4904/10000, Loss: 1.5974011421203613, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4905/10000, Loss: 1.6008247137069702, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4906/10000, Loss: 1.5772446393966675, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4907/10000, Loss: 1.5887762308120728, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4908/10000, Loss: 1.5725769996643066, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4909/10000, Loss: 1.6046394109725952, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4910/10000, Loss: 1.4525936841964722, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4911/10000, Loss: 1.6020128726959229, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4912/10000, Loss: 1.5795010328292847, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4913/10000, Loss: 1.542426347732544, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4914/10000, Loss: 1.5820589065551758, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4915/10000, Loss: 1.6548572778701782, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4916/10000, Loss: 1.5424357652664185, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4917/10000, Loss: 1.6571093797683716, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 4918/10000, Loss: 1.5546284914016724, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4919/10000, Loss: 1.6026991605758667, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4920/10000, Loss: 1.5616228580474854, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4921/10000, Loss: 1.6289342641830444, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4922/10000, Loss: 1.5674254894256592, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4923/10000, Loss: 1.5895949602127075, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4924/10000, Loss: 1.6109769344329834, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4925/10000, Loss: 1.5657373666763306, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4926/10000, Loss: 1.5808507204055786, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4927/10000, Loss: 1.5878691673278809, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4928/10000, Loss: 1.5376479625701904, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4929/10000, Loss: 1.5780764818191528, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4930/10000, Loss: 1.6481558084487915, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4931/10000, Loss: 1.6155810356140137, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4932/10000, Loss: 1.4855573177337646, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4933/10000, Loss: 1.6114009618759155, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4934/10000, Loss: 1.5873795747756958, Train Acc : 0.47277936962750716 , Val Acc : 0.4794871794871795\n",
      "Epoch 4935/10000, Loss: 1.4635324478149414, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 4936/10000, Loss: 1.5666009187698364, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4937/10000, Loss: 1.4827229976654053, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4938/10000, Loss: 1.5745998620986938, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4939/10000, Loss: 1.6066206693649292, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4940/10000, Loss: 1.53315007686615, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4941/10000, Loss: 1.5338294506072998, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4942/10000, Loss: 1.5626617670059204, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4943/10000, Loss: 1.5572515726089478, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4944/10000, Loss: 1.5752960443496704, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4945/10000, Loss: 1.5718419551849365, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 4946/10000, Loss: 1.618826150894165, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4947/10000, Loss: 1.5990632772445679, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4948/10000, Loss: 1.5739634037017822, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4949/10000, Loss: 1.5574322938919067, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4950/10000, Loss: 1.5739384889602661, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 4951/10000, Loss: 1.5526759624481201, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4952/10000, Loss: 1.5813409090042114, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4953/10000, Loss: 1.5703428983688354, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4954/10000, Loss: 1.6972365379333496, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4955/10000, Loss: 1.5581554174423218, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4956/10000, Loss: 1.562268853187561, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4957/10000, Loss: 1.6072126626968384, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 4958/10000, Loss: 1.4762592315673828, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4959/10000, Loss: 1.6086134910583496, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4960/10000, Loss: 1.5602076053619385, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4961/10000, Loss: 1.6067641973495483, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 4962/10000, Loss: 1.5560448169708252, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4963/10000, Loss: 1.5555120706558228, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4964/10000, Loss: 1.5287007093429565, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4965/10000, Loss: 1.5405832529067993, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4966/10000, Loss: 1.5782603025436401, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4967/10000, Loss: 1.6798160076141357, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4968/10000, Loss: 1.5426102876663208, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4969/10000, Loss: 1.6198924779891968, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 4970/10000, Loss: 1.5851081609725952, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4971/10000, Loss: 1.6108226776123047, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4972/10000, Loss: 1.4798463582992554, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 4973/10000, Loss: 1.5800341367721558, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4974/10000, Loss: 1.5321756601333618, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4975/10000, Loss: 1.6371742486953735, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 4976/10000, Loss: 1.5614023208618164, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 4977/10000, Loss: 1.5587393045425415, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 4978/10000, Loss: 1.5271022319793701, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4979/10000, Loss: 1.5490764379501343, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4980/10000, Loss: 1.5752067565917969, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4981/10000, Loss: 1.529186487197876, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4982/10000, Loss: 1.553868055343628, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4983/10000, Loss: 1.5347352027893066, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4984/10000, Loss: 1.5428674221038818, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 4985/10000, Loss: 1.552129864692688, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4986/10000, Loss: 1.5847777128219604, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 4987/10000, Loss: 1.5446792840957642, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4988/10000, Loss: 1.5053597688674927, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4989/10000, Loss: 1.5838253498077393, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 4990/10000, Loss: 1.5891927480697632, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4991/10000, Loss: 1.6761364936828613, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4992/10000, Loss: 1.6129939556121826, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4993/10000, Loss: 1.6512101888656616, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4994/10000, Loss: 1.5307751893997192, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4995/10000, Loss: 1.6140074729919434, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4996/10000, Loss: 1.59449303150177, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4997/10000, Loss: 1.5851378440856934, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 4998/10000, Loss: 1.5472640991210938, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 4999/10000, Loss: 1.6549996137619019, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5000/10000, Loss: 1.4975471496582031, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5001/10000, Loss: 1.6128311157226562, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5002/10000, Loss: 1.58696711063385, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5003/10000, Loss: 1.552286148071289, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5004/10000, Loss: 1.6182825565338135, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5005/10000, Loss: 1.5291086435317993, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5006/10000, Loss: 1.535711407661438, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5007/10000, Loss: 1.5965245962142944, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5008/10000, Loss: 1.5558747053146362, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5009/10000, Loss: 1.5595136880874634, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5010/10000, Loss: 1.4905792474746704, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5011/10000, Loss: 1.6071372032165527, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5012/10000, Loss: 1.5479100942611694, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5013/10000, Loss: 1.5323666334152222, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5014/10000, Loss: 1.5753984451293945, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5015/10000, Loss: 1.6218169927597046, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5016/10000, Loss: 1.6468112468719482, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5017/10000, Loss: 1.5810903310775757, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5018/10000, Loss: 1.6345666646957397, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5019/10000, Loss: 1.5186119079589844, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5020/10000, Loss: 1.600649118423462, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5021/10000, Loss: 1.6184494495391846, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5022/10000, Loss: 1.5907129049301147, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5023/10000, Loss: 1.5330244302749634, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5024/10000, Loss: 1.582959771156311, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5025/10000, Loss: 1.6397334337234497, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5026/10000, Loss: 1.5908403396606445, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5027/10000, Loss: 1.6238325834274292, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5028/10000, Loss: 1.6127692461013794, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5029/10000, Loss: 1.657606840133667, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5030/10000, Loss: 1.6578032970428467, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5031/10000, Loss: 1.5758018493652344, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5032/10000, Loss: 1.5152697563171387, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5033/10000, Loss: 1.510983943939209, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5034/10000, Loss: 1.6038185358047485, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5035/10000, Loss: 1.5205585956573486, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5036/10000, Loss: 1.591179609298706, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5037/10000, Loss: 1.5809496641159058, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5038/10000, Loss: 1.6005885601043701, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5039/10000, Loss: 1.626604437828064, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5040/10000, Loss: 1.630170226097107, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5041/10000, Loss: 1.5083929300308228, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5042/10000, Loss: 1.514093041419983, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5043/10000, Loss: 1.577655553817749, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5044/10000, Loss: 1.6478592157363892, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5045/10000, Loss: 1.5950560569763184, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5046/10000, Loss: 1.5684586763381958, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5047/10000, Loss: 1.5493285655975342, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5048/10000, Loss: 1.5377838611602783, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5049/10000, Loss: 1.5825655460357666, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5050/10000, Loss: 1.5809324979782104, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5051/10000, Loss: 1.5765306949615479, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5052/10000, Loss: 1.4327614307403564, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5053/10000, Loss: 1.6808656454086304, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5054/10000, Loss: 1.5769166946411133, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5055/10000, Loss: 1.587249994277954, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5056/10000, Loss: 1.43477463722229, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5057/10000, Loss: 1.5217032432556152, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5058/10000, Loss: 1.5601359605789185, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5059/10000, Loss: 1.536716103553772, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5060/10000, Loss: 1.5875144004821777, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5061/10000, Loss: 1.5652377605438232, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5062/10000, Loss: 1.6040056943893433, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5063/10000, Loss: 1.588073492050171, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5064/10000, Loss: 1.6203467845916748, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5065/10000, Loss: 1.5042171478271484, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5066/10000, Loss: 1.5327860116958618, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5067/10000, Loss: 1.578700304031372, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5068/10000, Loss: 1.561918020248413, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5069/10000, Loss: 1.5983909368515015, Train Acc : 0.47277936962750716 , Val Acc : 0.48205128205128206\n",
      "Epoch 5070/10000, Loss: 1.563065767288208, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5071/10000, Loss: 1.5452722311019897, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5072/10000, Loss: 1.605265736579895, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5073/10000, Loss: 1.608432412147522, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5074/10000, Loss: 1.6037721633911133, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5075/10000, Loss: 1.6110605001449585, Train Acc : 0.47277936962750716 , Val Acc : 0.48205128205128206\n",
      "Epoch 5076/10000, Loss: 1.5786504745483398, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5077/10000, Loss: 1.581731915473938, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5078/10000, Loss: 1.6250544786453247, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5079/10000, Loss: 1.5194417238235474, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5080/10000, Loss: 1.5132337808609009, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5081/10000, Loss: 1.5907838344573975, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5082/10000, Loss: 1.5787053108215332, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5083/10000, Loss: 1.6165448427200317, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5084/10000, Loss: 1.5288654565811157, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5085/10000, Loss: 1.5476670265197754, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5086/10000, Loss: 1.5162159204483032, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5087/10000, Loss: 1.5972973108291626, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5088/10000, Loss: 1.6147743463516235, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5089/10000, Loss: 1.5846226215362549, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5090/10000, Loss: 1.5406471490859985, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5091/10000, Loss: 1.6318823099136353, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5092/10000, Loss: 1.5439447164535522, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5093/10000, Loss: 1.6022605895996094, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5094/10000, Loss: 1.5642372369766235, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5095/10000, Loss: 1.5462331771850586, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5096/10000, Loss: 1.5642738342285156, Train Acc : 0.47277936962750716 , Val Acc : 0.48205128205128206\n",
      "Epoch 5097/10000, Loss: 1.6047477722167969, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5098/10000, Loss: 1.601772427558899, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5099/10000, Loss: 1.5417299270629883, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5100/10000, Loss: 1.5501911640167236, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5101/10000, Loss: 1.6139180660247803, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5102/10000, Loss: 1.603031039237976, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5103/10000, Loss: 1.5949907302856445, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5104/10000, Loss: 1.554790735244751, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5105/10000, Loss: 1.5843420028686523, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5106/10000, Loss: 1.5858745574951172, Train Acc : 0.47277936962750716 , Val Acc : 0.48205128205128206\n",
      "Epoch 5107/10000, Loss: 1.58148193359375, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5108/10000, Loss: 1.5973436832427979, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5109/10000, Loss: 1.6215980052947998, Train Acc : 0.47277936962750716 , Val Acc : 0.48205128205128206\n",
      "Epoch 5110/10000, Loss: 1.5847601890563965, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5111/10000, Loss: 1.644116997718811, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5112/10000, Loss: 1.628438949584961, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5113/10000, Loss: 1.5457581281661987, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5114/10000, Loss: 1.603210210800171, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5115/10000, Loss: 1.5443652868270874, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5116/10000, Loss: 1.5975369215011597, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5117/10000, Loss: 1.5991688966751099, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5118/10000, Loss: 1.559220552444458, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5119/10000, Loss: 1.6553999185562134, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5120/10000, Loss: 1.5482282638549805, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5121/10000, Loss: 1.5892771482467651, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5122/10000, Loss: 1.525667667388916, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5123/10000, Loss: 1.5517301559448242, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5124/10000, Loss: 1.5469502210617065, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5125/10000, Loss: 1.560309886932373, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5126/10000, Loss: 1.5410484075546265, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5127/10000, Loss: 1.5730332136154175, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5128/10000, Loss: 1.5128977298736572, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5129/10000, Loss: 1.5163531303405762, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5130/10000, Loss: 1.55875825881958, Train Acc : 0.47277936962750716 , Val Acc : 0.48205128205128206\n",
      "Epoch 5131/10000, Loss: 1.5179635286331177, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5132/10000, Loss: 1.5975494384765625, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5133/10000, Loss: 1.5781440734863281, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5134/10000, Loss: 1.5549867153167725, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5135/10000, Loss: 1.5368512868881226, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5136/10000, Loss: 1.5638405084609985, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5137/10000, Loss: 1.6047133207321167, Train Acc : 0.47277936962750716 , Val Acc : 0.48205128205128206\n",
      "Epoch 5138/10000, Loss: 1.5687934160232544, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5139/10000, Loss: 1.5904877185821533, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5140/10000, Loss: 1.6640938520431519, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5141/10000, Loss: 1.5492147207260132, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5142/10000, Loss: 1.498036503791809, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5143/10000, Loss: 1.6677451133728027, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5144/10000, Loss: 1.586570382118225, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5145/10000, Loss: 1.6048630475997925, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5146/10000, Loss: 1.524314045906067, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5147/10000, Loss: 1.619582176208496, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5148/10000, Loss: 1.5838762521743774, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5149/10000, Loss: 1.5190759897232056, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5150/10000, Loss: 1.469313144683838, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5151/10000, Loss: 1.5291416645050049, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5152/10000, Loss: 1.5829153060913086, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5153/10000, Loss: 1.5656189918518066, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5154/10000, Loss: 1.5183292627334595, Train Acc : 0.4724609996816301 , Val Acc : 0.48205128205128206\n",
      "Epoch 5155/10000, Loss: 1.5330346822738647, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5156/10000, Loss: 1.498253583908081, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5157/10000, Loss: 1.523909568786621, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5158/10000, Loss: 1.5889171361923218, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5159/10000, Loss: 1.5796583890914917, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5160/10000, Loss: 1.5875227451324463, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5161/10000, Loss: 1.566152811050415, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5162/10000, Loss: 1.581864833831787, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5163/10000, Loss: 1.570860505104065, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5164/10000, Loss: 1.5926029682159424, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5165/10000, Loss: 1.4970930814743042, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 5166/10000, Loss: 1.5528281927108765, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5167/10000, Loss: 1.5932363271713257, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5168/10000, Loss: 1.621936321258545, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5169/10000, Loss: 1.6026232242584229, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5170/10000, Loss: 1.554868221282959, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5171/10000, Loss: 1.5265018939971924, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5172/10000, Loss: 1.6131585836410522, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5173/10000, Loss: 1.585767149925232, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5174/10000, Loss: 1.5660364627838135, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5175/10000, Loss: 1.5820903778076172, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5176/10000, Loss: 1.6259816884994507, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5177/10000, Loss: 1.4928200244903564, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5178/10000, Loss: 1.6459676027297974, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5179/10000, Loss: 1.6501843929290771, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5180/10000, Loss: 1.517066240310669, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 5181/10000, Loss: 1.6037070751190186, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 5182/10000, Loss: 1.5292396545410156, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 5183/10000, Loss: 1.538786768913269, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5184/10000, Loss: 1.5355722904205322, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 5185/10000, Loss: 1.6010239124298096, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5186/10000, Loss: 1.5169802904129028, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5187/10000, Loss: 1.4828134775161743, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5188/10000, Loss: 1.5434978008270264, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5189/10000, Loss: 1.619034767150879, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5190/10000, Loss: 1.5163638591766357, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5191/10000, Loss: 1.5162997245788574, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5192/10000, Loss: 1.6627734899520874, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5193/10000, Loss: 1.6048195362091064, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5194/10000, Loss: 1.563193678855896, Train Acc : 0.47309773957338425 , Val Acc : 0.48205128205128206\n",
      "Epoch 5195/10000, Loss: 1.5986007452011108, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5196/10000, Loss: 1.5970380306243896, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5197/10000, Loss: 1.622829794883728, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5198/10000, Loss: 1.5506782531738281, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5199/10000, Loss: 1.5435574054718018, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 5200/10000, Loss: 1.530763030052185, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5201/10000, Loss: 1.5078785419464111, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5202/10000, Loss: 1.5284764766693115, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5203/10000, Loss: 1.5726773738861084, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5204/10000, Loss: 1.5927320718765259, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5205/10000, Loss: 1.5631439685821533, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5206/10000, Loss: 1.5853040218353271, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5207/10000, Loss: 1.5966264009475708, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5208/10000, Loss: 1.5933024883270264, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5209/10000, Loss: 1.591890573501587, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5210/10000, Loss: 1.5667027235031128, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5211/10000, Loss: 1.5378663539886475, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5212/10000, Loss: 1.524393081665039, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5213/10000, Loss: 1.5625253915786743, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5214/10000, Loss: 1.5294663906097412, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5215/10000, Loss: 1.4804095029830933, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5216/10000, Loss: 1.5878289937973022, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5217/10000, Loss: 1.5534460544586182, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5218/10000, Loss: 1.4844551086425781, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5219/10000, Loss: 1.6747068166732788, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5220/10000, Loss: 1.586809515953064, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5221/10000, Loss: 1.6013391017913818, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5222/10000, Loss: 1.544281244277954, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5223/10000, Loss: 1.4780808687210083, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5224/10000, Loss: 1.5450527667999268, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5225/10000, Loss: 1.5533604621887207, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5226/10000, Loss: 1.581074595451355, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5227/10000, Loss: 1.5403563976287842, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5228/10000, Loss: 1.5646798610687256, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5229/10000, Loss: 1.6435706615447998, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5230/10000, Loss: 1.572503685951233, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5231/10000, Loss: 1.530791163444519, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5232/10000, Loss: 1.5564781427383423, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5233/10000, Loss: 1.545861005783081, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5234/10000, Loss: 1.6779695749282837, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5235/10000, Loss: 1.5771900415420532, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5236/10000, Loss: 1.52750825881958, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5237/10000, Loss: 1.595896601676941, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5238/10000, Loss: 1.5491806268692017, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 5239/10000, Loss: 1.629611611366272, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5240/10000, Loss: 1.542157769203186, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5241/10000, Loss: 1.564910650253296, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 5242/10000, Loss: 1.566766619682312, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5243/10000, Loss: 1.5225608348846436, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5244/10000, Loss: 1.5478311777114868, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5245/10000, Loss: 1.6119729280471802, Train Acc : 0.47309773957338425 , Val Acc : 0.4794871794871795\n",
      "Epoch 5246/10000, Loss: 1.603686809539795, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 5247/10000, Loss: 1.5789783000946045, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 5248/10000, Loss: 1.5265711545944214, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5249/10000, Loss: 1.557646632194519, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5250/10000, Loss: 1.5511136054992676, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5251/10000, Loss: 1.5913176536560059, Train Acc : 0.4734161095192614 , Val Acc : 0.4794871794871795\n",
      "Epoch 5252/10000, Loss: 1.5381115674972534, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 5253/10000, Loss: 1.5677579641342163, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5254/10000, Loss: 1.5828604698181152, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 5255/10000, Loss: 1.556091070175171, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 5256/10000, Loss: 1.5705633163452148, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 5257/10000, Loss: 1.5386807918548584, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 5258/10000, Loss: 1.608733057975769, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5259/10000, Loss: 1.609076976776123, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5260/10000, Loss: 1.5527993440628052, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5261/10000, Loss: 1.5589914321899414, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5262/10000, Loss: 1.6056963205337524, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5263/10000, Loss: 1.6453410387039185, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 5264/10000, Loss: 1.5373328924179077, Train Acc : 0.4740528494110156 , Val Acc : 0.4794871794871795\n",
      "Epoch 5265/10000, Loss: 1.4598474502563477, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5266/10000, Loss: 1.5979615449905396, Train Acc : 0.4743712193568927 , Val Acc : 0.4794871794871795\n",
      "Epoch 5267/10000, Loss: 1.6598591804504395, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5268/10000, Loss: 1.6171629428863525, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5269/10000, Loss: 1.5920562744140625, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5270/10000, Loss: 1.5550636053085327, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5271/10000, Loss: 1.6229652166366577, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5272/10000, Loss: 1.6258842945098877, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5273/10000, Loss: 1.6282906532287598, Train Acc : 0.4750079592486469 , Val Acc : 0.48205128205128206\n",
      "Epoch 5274/10000, Loss: 1.5241854190826416, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5275/10000, Loss: 1.571021318435669, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5276/10000, Loss: 1.5821479558944702, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5277/10000, Loss: 1.6178003549575806, Train Acc : 0.47373447946513847 , Val Acc : 0.4794871794871795\n",
      "Epoch 5278/10000, Loss: 1.6176117658615112, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5279/10000, Loss: 1.5559911727905273, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5280/10000, Loss: 1.6405998468399048, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5281/10000, Loss: 1.6076639890670776, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5282/10000, Loss: 1.6611623764038086, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5283/10000, Loss: 1.559219479560852, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5284/10000, Loss: 1.5935508012771606, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5285/10000, Loss: 1.5652124881744385, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5286/10000, Loss: 1.5808519124984741, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5287/10000, Loss: 1.47477126121521, Train Acc : 0.47468958930276983 , Val Acc : 0.48205128205128206\n",
      "Epoch 5288/10000, Loss: 1.6839087009429932, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5289/10000, Loss: 1.4456762075424194, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5290/10000, Loss: 1.511948823928833, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5291/10000, Loss: 1.595797061920166, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5292/10000, Loss: 1.5366666316986084, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5293/10000, Loss: 1.5477373600006104, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5294/10000, Loss: 1.502223253250122, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5295/10000, Loss: 1.569577693939209, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5296/10000, Loss: 1.6082181930541992, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5297/10000, Loss: 1.5374330282211304, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5298/10000, Loss: 1.5096352100372314, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5299/10000, Loss: 1.5545963048934937, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5300/10000, Loss: 1.5777099132537842, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5301/10000, Loss: 1.5724140405654907, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5302/10000, Loss: 1.59331476688385, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5303/10000, Loss: 1.5850073099136353, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5304/10000, Loss: 1.5573737621307373, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5305/10000, Loss: 1.5177175998687744, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5306/10000, Loss: 1.6031368970870972, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5307/10000, Loss: 1.5915108919143677, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5308/10000, Loss: 1.5837976932525635, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5309/10000, Loss: 1.5970890522003174, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5310/10000, Loss: 1.564893364906311, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5311/10000, Loss: 1.656354546546936, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5312/10000, Loss: 1.6269937753677368, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5313/10000, Loss: 1.5836565494537354, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5314/10000, Loss: 1.5807058811187744, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5315/10000, Loss: 1.6229726076126099, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5316/10000, Loss: 1.5638378858566284, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5317/10000, Loss: 1.6270065307617188, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5318/10000, Loss: 1.5991935729980469, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5319/10000, Loss: 1.5454145669937134, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5320/10000, Loss: 1.461957573890686, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5321/10000, Loss: 1.6344702243804932, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5322/10000, Loss: 1.4919209480285645, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5323/10000, Loss: 1.643439531326294, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5324/10000, Loss: 1.6513110399246216, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5325/10000, Loss: 1.5586825609207153, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5326/10000, Loss: 1.6158250570297241, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5327/10000, Loss: 1.5262861251831055, Train Acc : 0.47468958930276983 , Val Acc : 0.48205128205128206\n",
      "Epoch 5328/10000, Loss: 1.5102256536483765, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5329/10000, Loss: 1.5633654594421387, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5330/10000, Loss: 1.519868016242981, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5331/10000, Loss: 1.5715163946151733, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5332/10000, Loss: 1.6047768592834473, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5333/10000, Loss: 1.5536788702011108, Train Acc : 0.4740528494110156 , Val Acc : 0.48205128205128206\n",
      "Epoch 5334/10000, Loss: 1.5798567533493042, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5335/10000, Loss: 1.6057446002960205, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5336/10000, Loss: 1.5527145862579346, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5337/10000, Loss: 1.576884150505066, Train Acc : 0.4734161095192614 , Val Acc : 0.48205128205128206\n",
      "Epoch 5338/10000, Loss: 1.5889554023742676, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5339/10000, Loss: 1.4483649730682373, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5340/10000, Loss: 1.6128110885620117, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5341/10000, Loss: 1.5453509092330933, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5342/10000, Loss: 1.5071563720703125, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5343/10000, Loss: 1.5559780597686768, Train Acc : 0.47468958930276983 , Val Acc : 0.48205128205128206\n",
      "Epoch 5344/10000, Loss: 1.5868183374404907, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5345/10000, Loss: 1.4573702812194824, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5346/10000, Loss: 1.6226252317428589, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5347/10000, Loss: 1.557762861251831, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5348/10000, Loss: 1.4904206991195679, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5349/10000, Loss: 1.5250585079193115, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5350/10000, Loss: 1.5913256406784058, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5351/10000, Loss: 1.6474815607070923, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5352/10000, Loss: 1.617762565612793, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5353/10000, Loss: 1.6733999252319336, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5354/10000, Loss: 1.507867455482483, Train Acc : 0.4734161095192614 , Val Acc : 0.4846153846153846\n",
      "Epoch 5355/10000, Loss: 1.6197704076766968, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5356/10000, Loss: 1.5254452228546143, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5357/10000, Loss: 1.5913200378417969, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5358/10000, Loss: 1.5947905778884888, Train Acc : 0.4734161095192614 , Val Acc : 0.4846153846153846\n",
      "Epoch 5359/10000, Loss: 1.5609588623046875, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5360/10000, Loss: 1.6409742832183838, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5361/10000, Loss: 1.5702561140060425, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5362/10000, Loss: 1.5677627325057983, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5363/10000, Loss: 1.576114296913147, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5364/10000, Loss: 1.5946074724197388, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5365/10000, Loss: 1.6176731586456299, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5366/10000, Loss: 1.6315786838531494, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5367/10000, Loss: 1.5245769023895264, Train Acc : 0.4734161095192614 , Val Acc : 0.4846153846153846\n",
      "Epoch 5368/10000, Loss: 1.5539206266403198, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5369/10000, Loss: 1.5744491815567017, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5370/10000, Loss: 1.5898782014846802, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5371/10000, Loss: 1.6217498779296875, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5372/10000, Loss: 1.5071271657943726, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5373/10000, Loss: 1.528361201286316, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5374/10000, Loss: 1.610077142715454, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5375/10000, Loss: 1.6662153005599976, Train Acc : 0.4734161095192614 , Val Acc : 0.4846153846153846\n",
      "Epoch 5376/10000, Loss: 1.4718436002731323, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5377/10000, Loss: 1.5942600965499878, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5378/10000, Loss: 1.563539743423462, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5379/10000, Loss: 1.5781720876693726, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5380/10000, Loss: 1.4823932647705078, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5381/10000, Loss: 1.521633267402649, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5382/10000, Loss: 1.5060615539550781, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5383/10000, Loss: 1.5900428295135498, Train Acc : 0.4734161095192614 , Val Acc : 0.4846153846153846\n",
      "Epoch 5384/10000, Loss: 1.536139965057373, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5385/10000, Loss: 1.5223220586776733, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5386/10000, Loss: 1.6146905422210693, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5387/10000, Loss: 1.5269856452941895, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5388/10000, Loss: 1.5287353992462158, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5389/10000, Loss: 1.54918372631073, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5390/10000, Loss: 1.615586519241333, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5391/10000, Loss: 1.577771544456482, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5392/10000, Loss: 1.5411025285720825, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5393/10000, Loss: 1.5894482135772705, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5394/10000, Loss: 1.6341562271118164, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5395/10000, Loss: 1.577368140220642, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5396/10000, Loss: 1.527397871017456, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5397/10000, Loss: 1.5759358406066895, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5398/10000, Loss: 1.5585333108901978, Train Acc : 0.4734161095192614 , Val Acc : 0.4846153846153846\n",
      "Epoch 5399/10000, Loss: 1.5927691459655762, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5400/10000, Loss: 1.5367720127105713, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5401/10000, Loss: 1.5654019117355347, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5402/10000, Loss: 1.6012910604476929, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5403/10000, Loss: 1.6484931707382202, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5404/10000, Loss: 1.5867960453033447, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5405/10000, Loss: 1.6011101007461548, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5406/10000, Loss: 1.6037415266036987, Train Acc : 0.47373447946513847 , Val Acc : 0.4846153846153846\n",
      "Epoch 5407/10000, Loss: 1.5717357397079468, Train Acc : 0.4740528494110156 , Val Acc : 0.4846153846153846\n",
      "Epoch 5408/10000, Loss: 1.644468069076538, Train Acc : 0.47373447946513847 , Val Acc : 0.48205128205128206\n",
      "Epoch 5409/10000, Loss: 1.601008415222168, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5410/10000, Loss: 1.4873347282409668, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5411/10000, Loss: 1.6053216457366943, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5412/10000, Loss: 1.4670602083206177, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5413/10000, Loss: 1.5338294506072998, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5414/10000, Loss: 1.5594288110733032, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5415/10000, Loss: 1.6033447980880737, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5416/10000, Loss: 1.5537346601486206, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5417/10000, Loss: 1.5131627321243286, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5418/10000, Loss: 1.5755836963653564, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5419/10000, Loss: 1.5013622045516968, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5420/10000, Loss: 1.5526504516601562, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5421/10000, Loss: 1.4752898216247559, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5422/10000, Loss: 1.6105705499649048, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5423/10000, Loss: 1.6103737354278564, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5424/10000, Loss: 1.532857894897461, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5425/10000, Loss: 1.6093733310699463, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5426/10000, Loss: 1.5963108539581299, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5427/10000, Loss: 1.523484468460083, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5428/10000, Loss: 1.5412827730178833, Train Acc : 0.4743712193568927 , Val Acc : 0.4846153846153846\n",
      "Epoch 5429/10000, Loss: 1.5975761413574219, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5430/10000, Loss: 1.5408515930175781, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5431/10000, Loss: 1.5014092922210693, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5432/10000, Loss: 1.547956943511963, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5433/10000, Loss: 1.6267083883285522, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5434/10000, Loss: 1.5743026733398438, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5435/10000, Loss: 1.5390281677246094, Train Acc : 0.4750079592486469 , Val Acc : 0.48205128205128206\n",
      "Epoch 5436/10000, Loss: 1.5965486764907837, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5437/10000, Loss: 1.5228550434112549, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5438/10000, Loss: 1.6074975728988647, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5439/10000, Loss: 1.5622230768203735, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5440/10000, Loss: 1.597505807876587, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5441/10000, Loss: 1.5642739534378052, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5442/10000, Loss: 1.5289171934127808, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5443/10000, Loss: 1.5615626573562622, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5444/10000, Loss: 1.5632076263427734, Train Acc : 0.47468958930276983 , Val Acc : 0.48205128205128206\n",
      "Epoch 5445/10000, Loss: 1.5113739967346191, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5446/10000, Loss: 1.5720034837722778, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5447/10000, Loss: 1.6126221418380737, Train Acc : 0.4743712193568927 , Val Acc : 0.48205128205128206\n",
      "Epoch 5448/10000, Loss: 1.5651168823242188, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5449/10000, Loss: 1.5230249166488647, Train Acc : 0.4750079592486469 , Val Acc : 0.48205128205128206\n",
      "Epoch 5450/10000, Loss: 1.6560051441192627, Train Acc : 0.47468958930276983 , Val Acc : 0.48205128205128206\n",
      "Epoch 5451/10000, Loss: 1.5727391242980957, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5452/10000, Loss: 1.5752942562103271, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5453/10000, Loss: 1.5914007425308228, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5454/10000, Loss: 1.698732852935791, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5455/10000, Loss: 1.5947340726852417, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5456/10000, Loss: 1.5257171392440796, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5457/10000, Loss: 1.550210952758789, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5458/10000, Loss: 1.5878441333770752, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5459/10000, Loss: 1.5154361724853516, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5460/10000, Loss: 1.5879006385803223, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5461/10000, Loss: 1.5306732654571533, Train Acc : 0.47468958930276983 , Val Acc : 0.48205128205128206\n",
      "Epoch 5462/10000, Loss: 1.5747040510177612, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5463/10000, Loss: 1.586053490638733, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5464/10000, Loss: 1.54843270778656, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5465/10000, Loss: 1.5657838582992554, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5466/10000, Loss: 1.5281075239181519, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5467/10000, Loss: 1.610985517501831, Train Acc : 0.47468958930276983 , Val Acc : 0.4846153846153846\n",
      "Epoch 5468/10000, Loss: 1.570661187171936, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5469/10000, Loss: 1.5950065851211548, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5470/10000, Loss: 1.4137130975723267, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5471/10000, Loss: 1.5474003553390503, Train Acc : 0.4750079592486469 , Val Acc : 0.4846153846153846\n",
      "Epoch 5472/10000, Loss: 1.6358039379119873, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5473/10000, Loss: 1.5725911855697632, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5474/10000, Loss: 1.6155478954315186, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5475/10000, Loss: 1.5296598672866821, Train Acc : 0.4750079592486469 , Val Acc : 0.48205128205128206\n",
      "Epoch 5476/10000, Loss: 1.546082615852356, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5477/10000, Loss: 1.5148570537567139, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5478/10000, Loss: 1.617103934288025, Train Acc : 0.47532632919452406 , Val Acc : 0.4846153846153846\n",
      "Epoch 5479/10000, Loss: 1.703722596168518, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5480/10000, Loss: 1.5864207744598389, Train Acc : 0.47628143903215536 , Val Acc : 0.4846153846153846\n",
      "Epoch 5481/10000, Loss: 1.5284463167190552, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5482/10000, Loss: 1.546507716178894, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5483/10000, Loss: 1.5085045099258423, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5484/10000, Loss: 1.6374956369400024, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5485/10000, Loss: 1.5478075742721558, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5486/10000, Loss: 1.4840636253356934, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5487/10000, Loss: 1.4825230836868286, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5488/10000, Loss: 1.5323363542556763, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5489/10000, Loss: 1.613295316696167, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5490/10000, Loss: 1.5358734130859375, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5491/10000, Loss: 1.5009461641311646, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5492/10000, Loss: 1.5456897020339966, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5493/10000, Loss: 1.574921727180481, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5494/10000, Loss: 1.5566790103912354, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5495/10000, Loss: 1.568424940109253, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5496/10000, Loss: 1.6318438053131104, Train Acc : 0.47659980897803245 , Val Acc : 0.4846153846153846\n",
      "Epoch 5497/10000, Loss: 1.5636941194534302, Train Acc : 0.47468958930276983 , Val Acc : 0.48205128205128206\n",
      "Epoch 5498/10000, Loss: 1.5574421882629395, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5499/10000, Loss: 1.651689887046814, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5500/10000, Loss: 1.5466059446334839, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5501/10000, Loss: 1.54454505443573, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5502/10000, Loss: 1.4764559268951416, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5503/10000, Loss: 1.5290342569351196, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5504/10000, Loss: 1.5038169622421265, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5505/10000, Loss: 1.5562338829040527, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5506/10000, Loss: 1.5397017002105713, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5507/10000, Loss: 1.579175591468811, Train Acc : 0.47628143903215536 , Val Acc : 0.4846153846153846\n",
      "Epoch 5508/10000, Loss: 1.5598580837249756, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5509/10000, Loss: 1.5064667463302612, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5510/10000, Loss: 1.556147813796997, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5511/10000, Loss: 1.5801581144332886, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5512/10000, Loss: 1.6944663524627686, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5513/10000, Loss: 1.5257771015167236, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5514/10000, Loss: 1.5740493535995483, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5515/10000, Loss: 1.6636773347854614, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5516/10000, Loss: 1.605426549911499, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5517/10000, Loss: 1.5197696685791016, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5518/10000, Loss: 1.5356967449188232, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5519/10000, Loss: 1.4935120344161987, Train Acc : 0.4759630690862783 , Val Acc : 0.4846153846153846\n",
      "Epoch 5520/10000, Loss: 1.5205944776535034, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5521/10000, Loss: 1.6088680028915405, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5522/10000, Loss: 1.5680629014968872, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5523/10000, Loss: 1.630770206451416, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5524/10000, Loss: 1.5613285303115845, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5525/10000, Loss: 1.595110297203064, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5526/10000, Loss: 1.5369893312454224, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5527/10000, Loss: 1.58424711227417, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5528/10000, Loss: 1.5928140878677368, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5529/10000, Loss: 1.6272438764572144, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5530/10000, Loss: 1.5951486825942993, Train Acc : 0.4750079592486469 , Val Acc : 0.48205128205128206\n",
      "Epoch 5531/10000, Loss: 1.5920249223709106, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5532/10000, Loss: 1.4778095483779907, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5533/10000, Loss: 1.5348924398422241, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5534/10000, Loss: 1.6398800611495972, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5535/10000, Loss: 1.5253835916519165, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5536/10000, Loss: 1.5509331226348877, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5537/10000, Loss: 1.5688705444335938, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5538/10000, Loss: 1.5383238792419434, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5539/10000, Loss: 1.6181844472885132, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5540/10000, Loss: 1.491265058517456, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5541/10000, Loss: 1.5314232110977173, Train Acc : 0.47564469914040114 , Val Acc : 0.4846153846153846\n",
      "Epoch 5542/10000, Loss: 1.4794894456863403, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5543/10000, Loss: 1.6472764015197754, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5544/10000, Loss: 1.6253561973571777, Train Acc : 0.47532632919452406 , Val Acc : 0.48205128205128206\n",
      "Epoch 5545/10000, Loss: 1.5587284564971924, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5546/10000, Loss: 1.5985386371612549, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5547/10000, Loss: 1.5733245611190796, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5548/10000, Loss: 1.5997058153152466, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5549/10000, Loss: 1.5258064270019531, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5550/10000, Loss: 1.5923079252243042, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5551/10000, Loss: 1.539501667022705, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5552/10000, Loss: 1.6138375997543335, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5553/10000, Loss: 1.6333959102630615, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5554/10000, Loss: 1.5735470056533813, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5555/10000, Loss: 1.6155574321746826, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5556/10000, Loss: 1.5564740896224976, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5557/10000, Loss: 1.5735441446304321, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5558/10000, Loss: 1.5444517135620117, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5559/10000, Loss: 1.5782872438430786, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5560/10000, Loss: 1.4383608102798462, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5561/10000, Loss: 1.5987240076065063, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5562/10000, Loss: 1.5873936414718628, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5563/10000, Loss: 1.6194037199020386, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5564/10000, Loss: 1.5707170963287354, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5565/10000, Loss: 1.5538194179534912, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5566/10000, Loss: 1.529077410697937, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5567/10000, Loss: 1.5298744440078735, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5568/10000, Loss: 1.5595946311950684, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5569/10000, Loss: 1.592331051826477, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5570/10000, Loss: 1.560500144958496, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5571/10000, Loss: 1.5170561075210571, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5572/10000, Loss: 1.589311122894287, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5573/10000, Loss: 1.6344738006591797, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5574/10000, Loss: 1.5810967683792114, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5575/10000, Loss: 1.614426851272583, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5576/10000, Loss: 1.5524171590805054, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5577/10000, Loss: 1.6040229797363281, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5578/10000, Loss: 1.5588784217834473, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5579/10000, Loss: 1.5719070434570312, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5580/10000, Loss: 1.5398597717285156, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5581/10000, Loss: 1.6507041454315186, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5582/10000, Loss: 1.580971598625183, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5583/10000, Loss: 1.5915007591247559, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5584/10000, Loss: 1.5515273809432983, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5585/10000, Loss: 1.5656216144561768, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5586/10000, Loss: 1.5246022939682007, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5587/10000, Loss: 1.5774579048156738, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5588/10000, Loss: 1.5610467195510864, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5589/10000, Loss: 1.5890464782714844, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5590/10000, Loss: 1.6423131227493286, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5591/10000, Loss: 1.578972578048706, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5592/10000, Loss: 1.6115944385528564, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5593/10000, Loss: 1.5617510080337524, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5594/10000, Loss: 1.5809653997421265, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5595/10000, Loss: 1.573610782623291, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5596/10000, Loss: 1.674735426902771, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5597/10000, Loss: 1.6501959562301636, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5598/10000, Loss: 1.5224441289901733, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5599/10000, Loss: 1.630366325378418, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5600/10000, Loss: 1.5950244665145874, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5601/10000, Loss: 1.6173542737960815, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5602/10000, Loss: 1.6197936534881592, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5603/10000, Loss: 1.5386998653411865, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5604/10000, Loss: 1.5885131359100342, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5605/10000, Loss: 1.5898582935333252, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5606/10000, Loss: 1.5879554748535156, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5607/10000, Loss: 1.6349378824234009, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5608/10000, Loss: 1.6422048807144165, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5609/10000, Loss: 1.5377002954483032, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5610/10000, Loss: 1.6887712478637695, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5611/10000, Loss: 1.5607017278671265, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5612/10000, Loss: 1.5679819583892822, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5613/10000, Loss: 1.5810253620147705, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5614/10000, Loss: 1.5046299695968628, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5615/10000, Loss: 1.6240864992141724, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5616/10000, Loss: 1.5070691108703613, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5617/10000, Loss: 1.5631282329559326, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5618/10000, Loss: 1.6162326335906982, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5619/10000, Loss: 1.4792492389678955, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5620/10000, Loss: 1.5825910568237305, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5621/10000, Loss: 1.5867397785186768, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5622/10000, Loss: 1.5026071071624756, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5623/10000, Loss: 1.5477067232131958, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5624/10000, Loss: 1.5690977573394775, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5625/10000, Loss: 1.5608023405075073, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5626/10000, Loss: 1.5381537675857544, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5627/10000, Loss: 1.5320144891738892, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5628/10000, Loss: 1.5262665748596191, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5629/10000, Loss: 1.5706943273544312, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5630/10000, Loss: 1.5945748090744019, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5631/10000, Loss: 1.6219199895858765, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5632/10000, Loss: 1.594933271408081, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5633/10000, Loss: 1.5436434745788574, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5634/10000, Loss: 1.6978189945220947, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5635/10000, Loss: 1.5114411115646362, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5636/10000, Loss: 1.5333926677703857, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5637/10000, Loss: 1.5974632501602173, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5638/10000, Loss: 1.5866403579711914, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5639/10000, Loss: 1.4967443943023682, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5640/10000, Loss: 1.6324374675750732, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5641/10000, Loss: 1.5106921195983887, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5642/10000, Loss: 1.5425794124603271, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5643/10000, Loss: 1.5352822542190552, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5644/10000, Loss: 1.641098141670227, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5645/10000, Loss: 1.6126387119293213, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5646/10000, Loss: 1.5377897024154663, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5647/10000, Loss: 1.5354915857315063, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5648/10000, Loss: 1.5590660572052002, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5649/10000, Loss: 1.5847440958023071, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5650/10000, Loss: 1.566010594367981, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5651/10000, Loss: 1.653683066368103, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5652/10000, Loss: 1.4979327917099, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5653/10000, Loss: 1.5348012447357178, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5654/10000, Loss: 1.6228272914886475, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5655/10000, Loss: 1.6603899002075195, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5656/10000, Loss: 1.5302989482879639, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5657/10000, Loss: 1.5442392826080322, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5658/10000, Loss: 1.5061349868774414, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5659/10000, Loss: 1.6283447742462158, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5660/10000, Loss: 1.6050132513046265, Train Acc : 0.47564469914040114 , Val Acc : 0.48205128205128206\n",
      "Epoch 5661/10000, Loss: 1.5658860206604004, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5662/10000, Loss: 1.500032663345337, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5663/10000, Loss: 1.6189063787460327, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5664/10000, Loss: 1.5302526950836182, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5665/10000, Loss: 1.5794360637664795, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5666/10000, Loss: 1.5706230401992798, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5667/10000, Loss: 1.5003564357757568, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5668/10000, Loss: 1.4800939559936523, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5669/10000, Loss: 1.5659071207046509, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5670/10000, Loss: 1.543349027633667, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5671/10000, Loss: 1.6153813600540161, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5672/10000, Loss: 1.5982118844985962, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5673/10000, Loss: 1.5734859704971313, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5674/10000, Loss: 1.6064916849136353, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5675/10000, Loss: 1.637282133102417, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5676/10000, Loss: 1.5983803272247314, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5677/10000, Loss: 1.5807291269302368, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5678/10000, Loss: 1.5668617486953735, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5679/10000, Loss: 1.5766358375549316, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5680/10000, Loss: 1.5308657884597778, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5681/10000, Loss: 1.5751644372940063, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5682/10000, Loss: 1.523270845413208, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5683/10000, Loss: 1.6251838207244873, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5684/10000, Loss: 1.6000746488571167, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5685/10000, Loss: 1.562214970588684, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5686/10000, Loss: 1.5833357572555542, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5687/10000, Loss: 1.4855008125305176, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5688/10000, Loss: 1.6005045175552368, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5689/10000, Loss: 1.5398597717285156, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5690/10000, Loss: 1.6177700757980347, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5691/10000, Loss: 1.5911450386047363, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5692/10000, Loss: 1.5436286926269531, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5693/10000, Loss: 1.6338566541671753, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5694/10000, Loss: 1.5618064403533936, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5695/10000, Loss: 1.5969164371490479, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5696/10000, Loss: 1.5185827016830444, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5697/10000, Loss: 1.5590934753417969, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5698/10000, Loss: 1.6195259094238281, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5699/10000, Loss: 1.5625121593475342, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5700/10000, Loss: 1.5504264831542969, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5701/10000, Loss: 1.5998502969741821, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5702/10000, Loss: 1.6335058212280273, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5703/10000, Loss: 1.6064612865447998, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5704/10000, Loss: 1.634868860244751, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5705/10000, Loss: 1.6121587753295898, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5706/10000, Loss: 1.6054096221923828, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5707/10000, Loss: 1.5533405542373657, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5708/10000, Loss: 1.5968017578125, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5709/10000, Loss: 1.5424448251724243, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5710/10000, Loss: 1.5792839527130127, Train Acc : 0.4759630690862783 , Val Acc : 0.48205128205128206\n",
      "Epoch 5711/10000, Loss: 1.5726655721664429, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5712/10000, Loss: 1.5790389776229858, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5713/10000, Loss: 1.558078646659851, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5714/10000, Loss: 1.4966917037963867, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5715/10000, Loss: 1.539322018623352, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5716/10000, Loss: 1.5990928411483765, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5717/10000, Loss: 1.505765438079834, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5718/10000, Loss: 1.544980525970459, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5719/10000, Loss: 1.5128220319747925, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5720/10000, Loss: 1.5233385562896729, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5721/10000, Loss: 1.5614911317825317, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5722/10000, Loss: 1.5032457113265991, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5723/10000, Loss: 1.5272713899612427, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5724/10000, Loss: 1.5249515771865845, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5725/10000, Loss: 1.5358339548110962, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5726/10000, Loss: 1.5621732473373413, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5727/10000, Loss: 1.594835877418518, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5728/10000, Loss: 1.6103235483169556, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5729/10000, Loss: 1.575116753578186, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5730/10000, Loss: 1.5528912544250488, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5731/10000, Loss: 1.5265476703643799, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5732/10000, Loss: 1.511574625968933, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5733/10000, Loss: 1.6128374338150024, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5734/10000, Loss: 1.5424354076385498, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5735/10000, Loss: 1.6024930477142334, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5736/10000, Loss: 1.609954833984375, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5737/10000, Loss: 1.5214755535125732, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5738/10000, Loss: 1.4788461923599243, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5739/10000, Loss: 1.5716338157653809, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5740/10000, Loss: 1.6062716245651245, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5741/10000, Loss: 1.698318362236023, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5742/10000, Loss: 1.5943603515625, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5743/10000, Loss: 1.5241992473602295, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5744/10000, Loss: 1.5552680492401123, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5745/10000, Loss: 1.590875506401062, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5746/10000, Loss: 1.6021103858947754, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5747/10000, Loss: 1.5719399452209473, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5748/10000, Loss: 1.5004661083221436, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5749/10000, Loss: 1.532006025314331, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5750/10000, Loss: 1.5979410409927368, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5751/10000, Loss: 1.584517002105713, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5752/10000, Loss: 1.4960594177246094, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5753/10000, Loss: 1.6135915517807007, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5754/10000, Loss: 1.5054277181625366, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5755/10000, Loss: 1.612585425376892, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5756/10000, Loss: 1.5375832319259644, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5757/10000, Loss: 1.5923681259155273, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5758/10000, Loss: 1.6091434955596924, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5759/10000, Loss: 1.5947974920272827, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5760/10000, Loss: 1.6097486019134521, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5761/10000, Loss: 1.5191590785980225, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5762/10000, Loss: 1.582533597946167, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5763/10000, Loss: 1.5788037776947021, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5764/10000, Loss: 1.6209616661071777, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5765/10000, Loss: 1.5741026401519775, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5766/10000, Loss: 1.5646145343780518, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5767/10000, Loss: 1.551283836364746, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5768/10000, Loss: 1.5905838012695312, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5769/10000, Loss: 1.580212950706482, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5770/10000, Loss: 1.5835847854614258, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5771/10000, Loss: 1.5758655071258545, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5772/10000, Loss: 1.568224310874939, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5773/10000, Loss: 1.6032259464263916, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5774/10000, Loss: 1.538482427597046, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5775/10000, Loss: 1.6269690990447998, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5776/10000, Loss: 1.553619146347046, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5777/10000, Loss: 1.5576913356781006, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5778/10000, Loss: 1.5709539651870728, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5779/10000, Loss: 1.532102346420288, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5780/10000, Loss: 1.5876902341842651, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5781/10000, Loss: 1.6043763160705566, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5782/10000, Loss: 1.545137643814087, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5783/10000, Loss: 1.5882987976074219, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5784/10000, Loss: 1.6055529117584229, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5785/10000, Loss: 1.5342204570770264, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5786/10000, Loss: 1.5925493240356445, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5787/10000, Loss: 1.5089399814605713, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5788/10000, Loss: 1.6003217697143555, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5789/10000, Loss: 1.571502923965454, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5790/10000, Loss: 1.5931299924850464, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5791/10000, Loss: 1.5623112916946411, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5792/10000, Loss: 1.573857307434082, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5793/10000, Loss: 1.6046760082244873, Train Acc : 0.47659980897803245 , Val Acc : 0.48205128205128206\n",
      "Epoch 5794/10000, Loss: 1.6307984590530396, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5795/10000, Loss: 1.541525959968567, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5796/10000, Loss: 1.50804603099823, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5797/10000, Loss: 1.5707205533981323, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5798/10000, Loss: 1.6443549394607544, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5799/10000, Loss: 1.570646047592163, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5800/10000, Loss: 1.4894051551818848, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5801/10000, Loss: 1.5182081460952759, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5802/10000, Loss: 1.5825761556625366, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5803/10000, Loss: 1.5302268266677856, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5804/10000, Loss: 1.5524394512176514, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5805/10000, Loss: 1.5112013816833496, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5806/10000, Loss: 1.5114020109176636, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5807/10000, Loss: 1.5812307596206665, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5808/10000, Loss: 1.5630333423614502, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5809/10000, Loss: 1.698340654373169, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5810/10000, Loss: 1.5729917287826538, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5811/10000, Loss: 1.5070489645004272, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5812/10000, Loss: 1.5590232610702515, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5813/10000, Loss: 1.5737167596817017, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5814/10000, Loss: 1.5955872535705566, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5815/10000, Loss: 1.560174584388733, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5816/10000, Loss: 1.5725728273391724, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5817/10000, Loss: 1.6101431846618652, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5818/10000, Loss: 1.5845290422439575, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5819/10000, Loss: 1.5549906492233276, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5820/10000, Loss: 1.585831642150879, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5821/10000, Loss: 1.5412997007369995, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5822/10000, Loss: 1.5574768781661987, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5823/10000, Loss: 1.5758885145187378, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5824/10000, Loss: 1.5732980966567993, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5825/10000, Loss: 1.5629620552062988, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5826/10000, Loss: 1.5846773386001587, Train Acc : 0.47628143903215536 , Val Acc : 0.48205128205128206\n",
      "Epoch 5827/10000, Loss: 1.5983939170837402, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5828/10000, Loss: 1.5498565435409546, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5829/10000, Loss: 1.5798879861831665, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5830/10000, Loss: 1.5425511598587036, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5831/10000, Loss: 1.6521155834197998, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5832/10000, Loss: 1.647129774093628, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5833/10000, Loss: 1.545161485671997, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5834/10000, Loss: 1.6097334623336792, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5835/10000, Loss: 1.546439290046692, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5836/10000, Loss: 1.5981041193008423, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5837/10000, Loss: 1.5884029865264893, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5838/10000, Loss: 1.5597835779190063, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5839/10000, Loss: 1.5825231075286865, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5840/10000, Loss: 1.6009418964385986, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5841/10000, Loss: 1.617563247680664, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5842/10000, Loss: 1.4936383962631226, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5843/10000, Loss: 1.4889239072799683, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5844/10000, Loss: 1.6580873727798462, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5845/10000, Loss: 1.5173354148864746, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5846/10000, Loss: 1.486274003982544, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5847/10000, Loss: 1.5398712158203125, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5848/10000, Loss: 1.5697683095932007, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5849/10000, Loss: 1.5711586475372314, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5850/10000, Loss: 1.5659414529800415, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5851/10000, Loss: 1.561318278312683, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5852/10000, Loss: 1.5353055000305176, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5853/10000, Loss: 1.5389753580093384, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5854/10000, Loss: 1.5355561971664429, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5855/10000, Loss: 1.5572196245193481, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5856/10000, Loss: 1.6099797487258911, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5857/10000, Loss: 1.6621029376983643, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5858/10000, Loss: 1.531212568283081, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5859/10000, Loss: 1.596500277519226, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5860/10000, Loss: 1.5730862617492676, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5861/10000, Loss: 1.5311635732650757, Train Acc : 0.47819165870741803 , Val Acc : 0.48205128205128206\n",
      "Epoch 5862/10000, Loss: 1.5733085870742798, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5863/10000, Loss: 1.5020294189453125, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5864/10000, Loss: 1.5079798698425293, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5865/10000, Loss: 1.6063144207000732, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5866/10000, Loss: 1.5795845985412598, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5867/10000, Loss: 1.6000511646270752, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5868/10000, Loss: 1.5983009338378906, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5869/10000, Loss: 1.5647895336151123, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5870/10000, Loss: 1.6017060279846191, Train Acc : 0.47819165870741803 , Val Acc : 0.48205128205128206\n",
      "Epoch 5871/10000, Loss: 1.5146172046661377, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5872/10000, Loss: 1.5496697425842285, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5873/10000, Loss: 1.570401668548584, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5874/10000, Loss: 1.5309486389160156, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5875/10000, Loss: 1.5584083795547485, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5876/10000, Loss: 1.5863463878631592, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5877/10000, Loss: 1.585422158241272, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5878/10000, Loss: 1.6417709589004517, Train Acc : 0.4785100286532951 , Val Acc : 0.48205128205128206\n",
      "Epoch 5879/10000, Loss: 1.5864728689193726, Train Acc : 0.47819165870741803 , Val Acc : 0.48205128205128206\n",
      "Epoch 5880/10000, Loss: 1.5644599199295044, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5881/10000, Loss: 1.659374713897705, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5882/10000, Loss: 1.5743894577026367, Train Acc : 0.4769181789239096 , Val Acc : 0.4794871794871795\n",
      "Epoch 5883/10000, Loss: 1.5308842658996582, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5884/10000, Loss: 1.4875760078430176, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5885/10000, Loss: 1.6307036876678467, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5886/10000, Loss: 1.634789228439331, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5887/10000, Loss: 1.5157835483551025, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5888/10000, Loss: 1.6669471263885498, Train Acc : 0.4769181789239096 , Val Acc : 0.48205128205128206\n",
      "Epoch 5889/10000, Loss: 1.4764091968536377, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5890/10000, Loss: 1.6214464902877808, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5891/10000, Loss: 1.611788272857666, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5892/10000, Loss: 1.5827417373657227, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5893/10000, Loss: 1.4899070262908936, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5894/10000, Loss: 1.5978715419769287, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5895/10000, Loss: 1.5285109281539917, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5896/10000, Loss: 1.5973109006881714, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5897/10000, Loss: 1.4724525213241577, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5898/10000, Loss: 1.5818228721618652, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5899/10000, Loss: 1.5460880994796753, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5900/10000, Loss: 1.553767204284668, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5901/10000, Loss: 1.6224992275238037, Train Acc : 0.4785100286532951 , Val Acc : 0.48205128205128206\n",
      "Epoch 5902/10000, Loss: 1.5503520965576172, Train Acc : 0.47723654886978667 , Val Acc : 0.48205128205128206\n",
      "Epoch 5903/10000, Loss: 1.571866750717163, Train Acc : 0.4778732887615409 , Val Acc : 0.4794871794871795\n",
      "Epoch 5904/10000, Loss: 1.6141000986099243, Train Acc : 0.47819165870741803 , Val Acc : 0.48205128205128206\n",
      "Epoch 5905/10000, Loss: 1.5391478538513184, Train Acc : 0.47723654886978667 , Val Acc : 0.4794871794871795\n",
      "Epoch 5906/10000, Loss: 1.5107269287109375, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5907/10000, Loss: 1.6190556287765503, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5908/10000, Loss: 1.6003243923187256, Train Acc : 0.4775549188156638 , Val Acc : 0.48205128205128206\n",
      "Epoch 5909/10000, Loss: 1.5055961608886719, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5910/10000, Loss: 1.6189531087875366, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5911/10000, Loss: 1.526172161102295, Train Acc : 0.47819165870741803 , Val Acc : 0.48205128205128206\n",
      "Epoch 5912/10000, Loss: 1.5145728588104248, Train Acc : 0.4778732887615409 , Val Acc : 0.4794871794871795\n",
      "Epoch 5913/10000, Loss: 1.637326717376709, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5914/10000, Loss: 1.5754958391189575, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5915/10000, Loss: 1.617637276649475, Train Acc : 0.47723654886978667 , Val Acc : 0.4794871794871795\n",
      "Epoch 5916/10000, Loss: 1.576048493385315, Train Acc : 0.4778732887615409 , Val Acc : 0.4794871794871795\n",
      "Epoch 5917/10000, Loss: 1.5340750217437744, Train Acc : 0.4778732887615409 , Val Acc : 0.48205128205128206\n",
      "Epoch 5918/10000, Loss: 1.7216191291809082, Train Acc : 0.4785100286532951 , Val Acc : 0.48205128205128206\n",
      "Epoch 5919/10000, Loss: 1.5236619710922241, Train Acc : 0.47819165870741803 , Val Acc : 0.48205128205128206\n",
      "Epoch 5920/10000, Loss: 1.4705959558486938, Train Acc : 0.4785100286532951 , Val Acc : 0.48205128205128206\n",
      "Epoch 5921/10000, Loss: 1.561301350593567, Train Acc : 0.4785100286532951 , Val Acc : 0.48205128205128206\n",
      "Epoch 5922/10000, Loss: 1.59882652759552, Train Acc : 0.47914676854504934 , Val Acc : 0.48205128205128206\n",
      "Epoch 5923/10000, Loss: 1.5737173557281494, Train Acc : 0.47819165870741803 , Val Acc : 0.48205128205128206\n",
      "Epoch 5924/10000, Loss: 1.522742509841919, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5925/10000, Loss: 1.58572256565094, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5926/10000, Loss: 1.5913655757904053, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5927/10000, Loss: 1.58575439453125, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5928/10000, Loss: 1.5680978298187256, Train Acc : 0.4785100286532951 , Val Acc : 0.48205128205128206\n",
      "Epoch 5929/10000, Loss: 1.543073296546936, Train Acc : 0.47819165870741803 , Val Acc : 0.48205128205128206\n",
      "Epoch 5930/10000, Loss: 1.5983966588974, Train Acc : 0.47882839859917226 , Val Acc : 0.48205128205128206\n",
      "Epoch 5931/10000, Loss: 1.4890738725662231, Train Acc : 0.4785100286532951 , Val Acc : 0.48205128205128206\n",
      "Epoch 5932/10000, Loss: 1.6129066944122314, Train Acc : 0.47882839859917226 , Val Acc : 0.48205128205128206\n",
      "Epoch 5933/10000, Loss: 1.5980074405670166, Train Acc : 0.4778732887615409 , Val Acc : 0.4794871794871795\n",
      "Epoch 5934/10000, Loss: 1.6159664392471313, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5935/10000, Loss: 1.579683780670166, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5936/10000, Loss: 1.5712485313415527, Train Acc : 0.47819165870741803 , Val Acc : 0.48205128205128206\n",
      "Epoch 5937/10000, Loss: 1.484139084815979, Train Acc : 0.47882839859917226 , Val Acc : 0.48205128205128206\n",
      "Epoch 5938/10000, Loss: 1.5963207483291626, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5939/10000, Loss: 1.5317895412445068, Train Acc : 0.4778732887615409 , Val Acc : 0.4794871794871795\n",
      "Epoch 5940/10000, Loss: 1.546086311340332, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5941/10000, Loss: 1.595524787902832, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5942/10000, Loss: 1.5880264043807983, Train Acc : 0.47882839859917226 , Val Acc : 0.48205128205128206\n",
      "Epoch 5943/10000, Loss: 1.5313900709152222, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5944/10000, Loss: 1.589394211769104, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5945/10000, Loss: 1.6209449768066406, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5946/10000, Loss: 1.5133006572723389, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5947/10000, Loss: 1.6692287921905518, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5948/10000, Loss: 1.524534821510315, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5949/10000, Loss: 1.5388789176940918, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5950/10000, Loss: 1.5525959730148315, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5951/10000, Loss: 1.5822789669036865, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5952/10000, Loss: 1.5598220825195312, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5953/10000, Loss: 1.5714083909988403, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5954/10000, Loss: 1.5856819152832031, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5955/10000, Loss: 1.6123466491699219, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5956/10000, Loss: 1.543169617652893, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5957/10000, Loss: 1.585750937461853, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5958/10000, Loss: 1.631602168083191, Train Acc : 0.4778732887615409 , Val Acc : 0.4794871794871795\n",
      "Epoch 5959/10000, Loss: 1.4785850048065186, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5960/10000, Loss: 1.5535333156585693, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5961/10000, Loss: 1.4825072288513184, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5962/10000, Loss: 1.5992693901062012, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5963/10000, Loss: 1.630285382270813, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5964/10000, Loss: 1.5328762531280518, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5965/10000, Loss: 1.5739727020263672, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5966/10000, Loss: 1.6193854808807373, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5967/10000, Loss: 1.5029075145721436, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 5968/10000, Loss: 1.6202462911605835, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5969/10000, Loss: 1.5424034595489502, Train Acc : 0.4785100286532951 , Val Acc : 0.48205128205128206\n",
      "Epoch 5970/10000, Loss: 1.5711891651153564, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 5971/10000, Loss: 1.5342446565628052, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5972/10000, Loss: 1.6037143468856812, Train Acc : 0.4785100286532951 , Val Acc : 0.48205128205128206\n",
      "Epoch 5973/10000, Loss: 1.5337375402450562, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5974/10000, Loss: 1.5868902206420898, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 5975/10000, Loss: 1.5581361055374146, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5976/10000, Loss: 1.6177759170532227, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5977/10000, Loss: 1.521623969078064, Train Acc : 0.4775549188156638 , Val Acc : 0.4794871794871795\n",
      "Epoch 5978/10000, Loss: 1.5430210828781128, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5979/10000, Loss: 1.546953558921814, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5980/10000, Loss: 1.5533392429351807, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5981/10000, Loss: 1.6129499673843384, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5982/10000, Loss: 1.60186767578125, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5983/10000, Loss: 1.6223747730255127, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5984/10000, Loss: 1.5282284021377563, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5985/10000, Loss: 1.4736055135726929, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5986/10000, Loss: 1.5789693593978882, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 5987/10000, Loss: 1.6113075017929077, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 5988/10000, Loss: 1.5324490070343018, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5989/10000, Loss: 1.4899450540542603, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5990/10000, Loss: 1.6690903902053833, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 5991/10000, Loss: 1.6241090297698975, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5992/10000, Loss: 1.6963920593261719, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5993/10000, Loss: 1.434362769126892, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 5994/10000, Loss: 1.5206818580627441, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 5995/10000, Loss: 1.4936370849609375, Train Acc : 0.4778732887615409 , Val Acc : 0.4794871794871795\n",
      "Epoch 5996/10000, Loss: 1.5695159435272217, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 5997/10000, Loss: 1.5331400632858276, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5998/10000, Loss: 1.5030475854873657, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 5999/10000, Loss: 1.6704094409942627, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6000/10000, Loss: 1.653198003768921, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6001/10000, Loss: 1.483923316001892, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 6002/10000, Loss: 1.5266122817993164, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 6003/10000, Loss: 1.5924385786056519, Train Acc : 0.4778732887615409 , Val Acc : 0.4794871794871795\n",
      "Epoch 6004/10000, Loss: 1.5874605178833008, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6005/10000, Loss: 1.631186842918396, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6006/10000, Loss: 1.5732148885726929, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6007/10000, Loss: 1.5615878105163574, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6008/10000, Loss: 1.6441032886505127, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6009/10000, Loss: 1.4938050508499146, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6010/10000, Loss: 1.553295373916626, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6011/10000, Loss: 1.6187769174575806, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6012/10000, Loss: 1.5716756582260132, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6013/10000, Loss: 1.584323763847351, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6014/10000, Loss: 1.544195532798767, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6015/10000, Loss: 1.5643450021743774, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6016/10000, Loss: 1.59932279586792, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6017/10000, Loss: 1.5883384943008423, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6018/10000, Loss: 1.5111788511276245, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6019/10000, Loss: 1.5647691488265991, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6020/10000, Loss: 1.5491338968276978, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6021/10000, Loss: 1.5972965955734253, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6022/10000, Loss: 1.5711677074432373, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6023/10000, Loss: 1.6208301782608032, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6024/10000, Loss: 1.499502182006836, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6025/10000, Loss: 1.5796165466308594, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6026/10000, Loss: 1.5929003953933716, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6027/10000, Loss: 1.5930724143981934, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6028/10000, Loss: 1.6428810358047485, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6029/10000, Loss: 1.4970097541809082, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6030/10000, Loss: 1.5844818353652954, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6031/10000, Loss: 1.5404332876205444, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6032/10000, Loss: 1.525381088256836, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6033/10000, Loss: 1.5900325775146484, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6034/10000, Loss: 1.5797044038772583, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6035/10000, Loss: 1.6417503356933594, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6036/10000, Loss: 1.5061064958572388, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6037/10000, Loss: 1.6764696836471558, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6038/10000, Loss: 1.6077253818511963, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6039/10000, Loss: 1.585991621017456, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6040/10000, Loss: 1.4567148685455322, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6041/10000, Loss: 1.6068670749664307, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6042/10000, Loss: 1.5786572694778442, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6043/10000, Loss: 1.5959776639938354, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6044/10000, Loss: 1.534287691116333, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6045/10000, Loss: 1.5540440082550049, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6046/10000, Loss: 1.502368688583374, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6047/10000, Loss: 1.6428076028823853, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6048/10000, Loss: 1.6446126699447632, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6049/10000, Loss: 1.5974940061569214, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6050/10000, Loss: 1.5689072608947754, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6051/10000, Loss: 1.5732581615447998, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6052/10000, Loss: 1.5463744401931763, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6053/10000, Loss: 1.4998891353607178, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6054/10000, Loss: 1.5669639110565186, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6055/10000, Loss: 1.566523551940918, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6056/10000, Loss: 1.680138349533081, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6057/10000, Loss: 1.612315058708191, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6058/10000, Loss: 1.5373092889785767, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6059/10000, Loss: 1.599209189414978, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6060/10000, Loss: 1.5514839887619019, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6061/10000, Loss: 1.4751337766647339, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6062/10000, Loss: 1.5271284580230713, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6063/10000, Loss: 1.6477336883544922, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6064/10000, Loss: 1.5464781522750854, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6065/10000, Loss: 1.5306516885757446, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6066/10000, Loss: 1.597006916999817, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6067/10000, Loss: 1.5679880380630493, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6068/10000, Loss: 1.6227807998657227, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6069/10000, Loss: 1.523064374923706, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6070/10000, Loss: 1.6199314594268799, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6071/10000, Loss: 1.635015845298767, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6072/10000, Loss: 1.6421855688095093, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6073/10000, Loss: 1.5903692245483398, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6074/10000, Loss: 1.5520405769348145, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6075/10000, Loss: 1.5679631233215332, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6076/10000, Loss: 1.5943576097488403, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6077/10000, Loss: 1.5539692640304565, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6078/10000, Loss: 1.6014798879623413, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6079/10000, Loss: 1.5593810081481934, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6080/10000, Loss: 1.520789623260498, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6081/10000, Loss: 1.5780621767044067, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6082/10000, Loss: 1.6474932432174683, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6083/10000, Loss: 1.4717761278152466, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6084/10000, Loss: 1.6429675817489624, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6085/10000, Loss: 1.534652829170227, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6086/10000, Loss: 1.4728063344955444, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6087/10000, Loss: 1.556235909461975, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6088/10000, Loss: 1.6231614351272583, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6089/10000, Loss: 1.5158554315567017, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6090/10000, Loss: 1.5150694847106934, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6091/10000, Loss: 1.6027806997299194, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6092/10000, Loss: 1.5985273122787476, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6093/10000, Loss: 1.5699458122253418, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6094/10000, Loss: 1.5402895212173462, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6095/10000, Loss: 1.5624926090240479, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6096/10000, Loss: 1.5563286542892456, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6097/10000, Loss: 1.6253867149353027, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6098/10000, Loss: 1.619903564453125, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6099/10000, Loss: 1.5572007894515991, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6100/10000, Loss: 1.4847525358200073, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6101/10000, Loss: 1.625536322593689, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6102/10000, Loss: 1.5356366634368896, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6103/10000, Loss: 1.5918593406677246, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6104/10000, Loss: 1.549179196357727, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6105/10000, Loss: 1.5699682235717773, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6106/10000, Loss: 1.5661673545837402, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6107/10000, Loss: 1.5864249467849731, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6108/10000, Loss: 1.5459681749343872, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6109/10000, Loss: 1.5130187273025513, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6110/10000, Loss: 1.654693365097046, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6111/10000, Loss: 1.4615000486373901, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6112/10000, Loss: 1.5961744785308838, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6113/10000, Loss: 1.4925014972686768, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6114/10000, Loss: 1.641371726989746, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6115/10000, Loss: 1.5603148937225342, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6116/10000, Loss: 1.553468108177185, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6117/10000, Loss: 1.62930428981781, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6118/10000, Loss: 1.4818751811981201, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6119/10000, Loss: 1.590255856513977, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6120/10000, Loss: 1.5359028577804565, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6121/10000, Loss: 1.659997820854187, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6122/10000, Loss: 1.5733776092529297, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6123/10000, Loss: 1.4820785522460938, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6124/10000, Loss: 1.5640168190002441, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6125/10000, Loss: 1.479530692100525, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6126/10000, Loss: 1.6450271606445312, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6127/10000, Loss: 1.5678702592849731, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6128/10000, Loss: 1.520706295967102, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6129/10000, Loss: 1.5885319709777832, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6130/10000, Loss: 1.6074341535568237, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6131/10000, Loss: 1.448211669921875, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6132/10000, Loss: 1.5245752334594727, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6133/10000, Loss: 1.5485625267028809, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6134/10000, Loss: 1.5576170682907104, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6135/10000, Loss: 1.5744575262069702, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6136/10000, Loss: 1.5623459815979004, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6137/10000, Loss: 1.6250627040863037, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6138/10000, Loss: 1.6082302331924438, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6139/10000, Loss: 1.5144625902175903, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6140/10000, Loss: 1.5506521463394165, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6141/10000, Loss: 1.580482840538025, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6142/10000, Loss: 1.5010874271392822, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6143/10000, Loss: 1.5567359924316406, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6144/10000, Loss: 1.5587458610534668, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6145/10000, Loss: 1.5754283666610718, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6146/10000, Loss: 1.5432372093200684, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6147/10000, Loss: 1.5560978651046753, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6148/10000, Loss: 1.6077214479446411, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6149/10000, Loss: 1.596753716468811, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6150/10000, Loss: 1.5934841632843018, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6151/10000, Loss: 1.6122797727584839, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6152/10000, Loss: 1.5081183910369873, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6153/10000, Loss: 1.4904084205627441, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6154/10000, Loss: 1.5571869611740112, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6155/10000, Loss: 1.5925360918045044, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6156/10000, Loss: 1.56987464427948, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6157/10000, Loss: 1.562157392501831, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6158/10000, Loss: 1.5878137350082397, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6159/10000, Loss: 1.631213665008545, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6160/10000, Loss: 1.526686668395996, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6161/10000, Loss: 1.4947172403335571, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6162/10000, Loss: 1.5353034734725952, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6163/10000, Loss: 1.539267897605896, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6164/10000, Loss: 1.528342604637146, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6165/10000, Loss: 1.502816081047058, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6166/10000, Loss: 1.5843074321746826, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6167/10000, Loss: 1.526597499847412, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6168/10000, Loss: 1.5180493593215942, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6169/10000, Loss: 1.537782073020935, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6170/10000, Loss: 1.6285531520843506, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6171/10000, Loss: 1.580870270729065, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6172/10000, Loss: 1.6364396810531616, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6173/10000, Loss: 1.6221579313278198, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6174/10000, Loss: 1.5421150922775269, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6175/10000, Loss: 1.638198971748352, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6176/10000, Loss: 1.4802789688110352, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6177/10000, Loss: 1.627305269241333, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6178/10000, Loss: 1.5920952558517456, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6179/10000, Loss: 1.4901273250579834, Train Acc : 0.4785100286532951 , Val Acc : 0.4794871794871795\n",
      "Epoch 6180/10000, Loss: 1.584587812423706, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6181/10000, Loss: 1.6023242473602295, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6182/10000, Loss: 1.5511391162872314, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6183/10000, Loss: 1.5196316242218018, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6184/10000, Loss: 1.4327614307403564, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6185/10000, Loss: 1.5559170246124268, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6186/10000, Loss: 1.6183035373687744, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6187/10000, Loss: 1.6282217502593994, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6188/10000, Loss: 1.5786323547363281, Train Acc : 0.47819165870741803 , Val Acc : 0.4794871794871795\n",
      "Epoch 6189/10000, Loss: 1.561249852180481, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6190/10000, Loss: 1.6215827465057373, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6191/10000, Loss: 1.5823665857315063, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6192/10000, Loss: 1.5403553247451782, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6193/10000, Loss: 1.6123968362808228, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6194/10000, Loss: 1.598870873451233, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6195/10000, Loss: 1.4856568574905396, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6196/10000, Loss: 1.4940789937973022, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6197/10000, Loss: 1.615973711013794, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6198/10000, Loss: 1.5393311977386475, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6199/10000, Loss: 1.6099470853805542, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6200/10000, Loss: 1.506669521331787, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6201/10000, Loss: 1.5623427629470825, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6202/10000, Loss: 1.5614932775497437, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6203/10000, Loss: 1.6299232244491577, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6204/10000, Loss: 1.6355644464492798, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6205/10000, Loss: 1.532018780708313, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6206/10000, Loss: 1.4924708604812622, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6207/10000, Loss: 1.567387342453003, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6208/10000, Loss: 1.5697379112243652, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6209/10000, Loss: 1.6357649564743042, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6210/10000, Loss: 1.529699444770813, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6211/10000, Loss: 1.6873586177825928, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6212/10000, Loss: 1.5396592617034912, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6213/10000, Loss: 1.626146674156189, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6214/10000, Loss: 1.5535390377044678, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6215/10000, Loss: 1.6388981342315674, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6216/10000, Loss: 1.512988805770874, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6217/10000, Loss: 1.4896239042282104, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6218/10000, Loss: 1.5554001331329346, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6219/10000, Loss: 1.6117172241210938, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6220/10000, Loss: 1.5736238956451416, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6221/10000, Loss: 1.5860320329666138, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6222/10000, Loss: 1.5809741020202637, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6223/10000, Loss: 1.5165436267852783, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6224/10000, Loss: 1.5556490421295166, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6225/10000, Loss: 1.6055583953857422, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6226/10000, Loss: 1.5533851385116577, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6227/10000, Loss: 1.500952959060669, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6228/10000, Loss: 1.566339373588562, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6229/10000, Loss: 1.5561989545822144, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6230/10000, Loss: 1.5615683794021606, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6231/10000, Loss: 1.5216258764266968, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6232/10000, Loss: 1.5321433544158936, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6233/10000, Loss: 1.574476718902588, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6234/10000, Loss: 1.4891493320465088, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6235/10000, Loss: 1.54538094997406, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6236/10000, Loss: 1.6506731510162354, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6237/10000, Loss: 1.6241415739059448, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6238/10000, Loss: 1.557298183441162, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6239/10000, Loss: 1.5682651996612549, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6240/10000, Loss: 1.5302749872207642, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6241/10000, Loss: 1.5150952339172363, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6242/10000, Loss: 1.6196833848953247, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6243/10000, Loss: 1.538554072380066, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6244/10000, Loss: 1.4986448287963867, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6245/10000, Loss: 1.5553196668624878, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6246/10000, Loss: 1.5860862731933594, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6247/10000, Loss: 1.5327873229980469, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6248/10000, Loss: 1.5721029043197632, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6249/10000, Loss: 1.6189624071121216, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6250/10000, Loss: 1.4816924333572388, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6251/10000, Loss: 1.5182372331619263, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6252/10000, Loss: 1.549622654914856, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6253/10000, Loss: 1.5967991352081299, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6254/10000, Loss: 1.5957144498825073, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6255/10000, Loss: 1.5993165969848633, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6256/10000, Loss: 1.540529727935791, Train Acc : 0.47882839859917226 , Val Acc : 0.4794871794871795\n",
      "Epoch 6257/10000, Loss: 1.5511770248413086, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6258/10000, Loss: 1.5063550472259521, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6259/10000, Loss: 1.610744595527649, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6260/10000, Loss: 1.561600685119629, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6261/10000, Loss: 1.5279722213745117, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6262/10000, Loss: 1.5442510843276978, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6263/10000, Loss: 1.6342272758483887, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6264/10000, Loss: 1.5857707262039185, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6265/10000, Loss: 1.660240888595581, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6266/10000, Loss: 1.5919373035430908, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6267/10000, Loss: 1.522606611251831, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6268/10000, Loss: 1.588068962097168, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6269/10000, Loss: 1.5201646089553833, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6270/10000, Loss: 1.5724554061889648, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6271/10000, Loss: 1.5839489698410034, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6272/10000, Loss: 1.614277720451355, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6273/10000, Loss: 1.5777615308761597, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6274/10000, Loss: 1.5785348415374756, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6275/10000, Loss: 1.5782756805419922, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6276/10000, Loss: 1.4748536348342896, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6277/10000, Loss: 1.5994149446487427, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6278/10000, Loss: 1.6548113822937012, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6279/10000, Loss: 1.4720604419708252, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6280/10000, Loss: 1.632773518562317, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6281/10000, Loss: 1.623997449874878, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6282/10000, Loss: 1.5586225986480713, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6283/10000, Loss: 1.6391456127166748, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6284/10000, Loss: 1.5634057521820068, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6285/10000, Loss: 1.5072838068008423, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6286/10000, Loss: 1.5407038927078247, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6287/10000, Loss: 1.5794422626495361, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6288/10000, Loss: 1.5782004594802856, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6289/10000, Loss: 1.5249671936035156, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6290/10000, Loss: 1.6136469841003418, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6291/10000, Loss: 1.5317587852478027, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6292/10000, Loss: 1.5170387029647827, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6293/10000, Loss: 1.5732390880584717, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6294/10000, Loss: 1.6019877195358276, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6295/10000, Loss: 1.510491967201233, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6296/10000, Loss: 1.5701931715011597, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6297/10000, Loss: 1.5640681982040405, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6298/10000, Loss: 1.5674785375595093, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6299/10000, Loss: 1.5478919744491577, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6300/10000, Loss: 1.5725914239883423, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6301/10000, Loss: 1.533354640007019, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6302/10000, Loss: 1.5194776058197021, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6303/10000, Loss: 1.5554174184799194, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6304/10000, Loss: 1.5557045936584473, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6305/10000, Loss: 1.575758457183838, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6306/10000, Loss: 1.6175696849822998, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6307/10000, Loss: 1.505781888961792, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6308/10000, Loss: 1.5520881414413452, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6309/10000, Loss: 1.5165619850158691, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6310/10000, Loss: 1.472689151763916, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6311/10000, Loss: 1.637668490409851, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6312/10000, Loss: 1.5287009477615356, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6313/10000, Loss: 1.6136462688446045, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6314/10000, Loss: 1.5765602588653564, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6315/10000, Loss: 1.6399352550506592, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6316/10000, Loss: 1.5651211738586426, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6317/10000, Loss: 1.6048444509506226, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6318/10000, Loss: 1.6422902345657349, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6319/10000, Loss: 1.540004849433899, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6320/10000, Loss: 1.6012780666351318, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6321/10000, Loss: 1.5752865076065063, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6322/10000, Loss: 1.686055064201355, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6323/10000, Loss: 1.5273884534835815, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6324/10000, Loss: 1.6132636070251465, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6325/10000, Loss: 1.6319631338119507, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6326/10000, Loss: 1.537092924118042, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6327/10000, Loss: 1.5271261930465698, Train Acc : 0.47978350843680356 , Val Acc : 0.47692307692307695\n",
      "Epoch 6328/10000, Loss: 1.5787113904953003, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6329/10000, Loss: 1.553431510925293, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6330/10000, Loss: 1.6863800287246704, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6331/10000, Loss: 1.536991834640503, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6332/10000, Loss: 1.5593500137329102, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6333/10000, Loss: 1.5433107614517212, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6334/10000, Loss: 1.6145936250686646, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6335/10000, Loss: 1.5669867992401123, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6336/10000, Loss: 1.4966723918914795, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6337/10000, Loss: 1.5411643981933594, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6338/10000, Loss: 1.6222764253616333, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6339/10000, Loss: 1.5471653938293457, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6340/10000, Loss: 1.6404883861541748, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6341/10000, Loss: 1.559302568435669, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6342/10000, Loss: 1.618126392364502, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6343/10000, Loss: 1.5183706283569336, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6344/10000, Loss: 1.5229073762893677, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6345/10000, Loss: 1.5656425952911377, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6346/10000, Loss: 1.517582654953003, Train Acc : 0.47914676854504934 , Val Acc : 0.4794871794871795\n",
      "Epoch 6347/10000, Loss: 1.5867469310760498, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6348/10000, Loss: 1.5330710411071777, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6349/10000, Loss: 1.5410453081130981, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6350/10000, Loss: 1.5584006309509277, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6351/10000, Loss: 1.6280723810195923, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6352/10000, Loss: 1.6073509454727173, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6353/10000, Loss: 1.453417420387268, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6354/10000, Loss: 1.5377403497695923, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6355/10000, Loss: 1.6337525844573975, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6356/10000, Loss: 1.5783421993255615, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6357/10000, Loss: 1.5482723712921143, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6358/10000, Loss: 1.4613159894943237, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6359/10000, Loss: 1.629294514656067, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6360/10000, Loss: 1.587012529373169, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6361/10000, Loss: 1.5103161334991455, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6362/10000, Loss: 1.5313713550567627, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6363/10000, Loss: 1.6500742435455322, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6364/10000, Loss: 1.6325095891952515, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6365/10000, Loss: 1.534400224685669, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6366/10000, Loss: 1.585667371749878, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6367/10000, Loss: 1.5475395917892456, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6368/10000, Loss: 1.5828250646591187, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6369/10000, Loss: 1.5130412578582764, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6370/10000, Loss: 1.5147308111190796, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6371/10000, Loss: 1.5765827894210815, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6372/10000, Loss: 1.6271231174468994, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6373/10000, Loss: 1.545851230621338, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6374/10000, Loss: 1.5205224752426147, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6375/10000, Loss: 1.4994488954544067, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6376/10000, Loss: 1.5895729064941406, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6377/10000, Loss: 1.5900661945343018, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6378/10000, Loss: 1.6139041185379028, Train Acc : 0.47978350843680356 , Val Acc : 0.47692307692307695\n",
      "Epoch 6379/10000, Loss: 1.605154275894165, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6380/10000, Loss: 1.577951192855835, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6381/10000, Loss: 1.5378178358078003, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6382/10000, Loss: 1.513255000114441, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6383/10000, Loss: 1.5358927249908447, Train Acc : 0.47978350843680356 , Val Acc : 0.47692307692307695\n",
      "Epoch 6384/10000, Loss: 1.544252872467041, Train Acc : 0.47978350843680356 , Val Acc : 0.47692307692307695\n",
      "Epoch 6385/10000, Loss: 1.595528244972229, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6386/10000, Loss: 1.605159044265747, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6387/10000, Loss: 1.5901274681091309, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6388/10000, Loss: 1.5846562385559082, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6389/10000, Loss: 1.5127906799316406, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6390/10000, Loss: 1.5939629077911377, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6391/10000, Loss: 1.516710638999939, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6392/10000, Loss: 1.6279340982437134, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6393/10000, Loss: 1.5407938957214355, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6394/10000, Loss: 1.649758219718933, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6395/10000, Loss: 1.580924153327942, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6396/10000, Loss: 1.607483983039856, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6397/10000, Loss: 1.5755983591079712, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6398/10000, Loss: 1.5111061334609985, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6399/10000, Loss: 1.6174262762069702, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6400/10000, Loss: 1.575051188468933, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6401/10000, Loss: 1.5609214305877686, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6402/10000, Loss: 1.6019519567489624, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6403/10000, Loss: 1.5190757513046265, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6404/10000, Loss: 1.6360012292861938, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6405/10000, Loss: 1.610491394996643, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6406/10000, Loss: 1.5591188669204712, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6407/10000, Loss: 1.5501829385757446, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6408/10000, Loss: 1.5538525581359863, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6409/10000, Loss: 1.5118778944015503, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6410/10000, Loss: 1.5895901918411255, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6411/10000, Loss: 1.5933434963226318, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6412/10000, Loss: 1.5359408855438232, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6413/10000, Loss: 1.5679636001586914, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6414/10000, Loss: 1.5520751476287842, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6415/10000, Loss: 1.6051287651062012, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6416/10000, Loss: 1.557132601737976, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6417/10000, Loss: 1.5783741474151611, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6418/10000, Loss: 1.6084245443344116, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6419/10000, Loss: 1.5947548151016235, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6420/10000, Loss: 1.5453455448150635, Train Acc : 0.4794651384909265 , Val Acc : 0.4794871794871795\n",
      "Epoch 6421/10000, Loss: 1.5647648572921753, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6422/10000, Loss: 1.6200941801071167, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6423/10000, Loss: 1.571053385734558, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6424/10000, Loss: 1.5458685159683228, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6425/10000, Loss: 1.5081307888031006, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6426/10000, Loss: 1.57900869846344, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6427/10000, Loss: 1.5298833847045898, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6428/10000, Loss: 1.6680171489715576, Train Acc : 0.47978350843680356 , Val Acc : 0.47692307692307695\n",
      "Epoch 6429/10000, Loss: 1.5499471426010132, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6430/10000, Loss: 1.4651128053665161, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6431/10000, Loss: 1.607538104057312, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6432/10000, Loss: 1.6548312902450562, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6433/10000, Loss: 1.591809868812561, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6434/10000, Loss: 1.5393891334533691, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6435/10000, Loss: 1.5485016107559204, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6436/10000, Loss: 1.4905377626419067, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6437/10000, Loss: 1.5479354858398438, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6438/10000, Loss: 1.5342037677764893, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6439/10000, Loss: 1.5555517673492432, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6440/10000, Loss: 1.607331395149231, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6441/10000, Loss: 1.5636823177337646, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6442/10000, Loss: 1.5082087516784668, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6443/10000, Loss: 1.6240967512130737, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6444/10000, Loss: 1.4696379899978638, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6445/10000, Loss: 1.623555302619934, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6446/10000, Loss: 1.4882601499557495, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6447/10000, Loss: 1.488745927810669, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6448/10000, Loss: 1.5114799737930298, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6449/10000, Loss: 1.5775068998336792, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6450/10000, Loss: 1.5662466287612915, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6451/10000, Loss: 1.588417410850525, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6452/10000, Loss: 1.574938416481018, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6453/10000, Loss: 1.5671465396881104, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6454/10000, Loss: 1.4884452819824219, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6455/10000, Loss: 1.5555095672607422, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6456/10000, Loss: 1.5498979091644287, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6457/10000, Loss: 1.544813632965088, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6458/10000, Loss: 1.6524591445922852, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6459/10000, Loss: 1.54426109790802, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6460/10000, Loss: 1.5606979131698608, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6461/10000, Loss: 1.544191598892212, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6462/10000, Loss: 1.5725473165512085, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6463/10000, Loss: 1.530484676361084, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6464/10000, Loss: 1.5429348945617676, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6465/10000, Loss: 1.4835623502731323, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6466/10000, Loss: 1.4298241138458252, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6467/10000, Loss: 1.5811718702316284, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6468/10000, Loss: 1.5743134021759033, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6469/10000, Loss: 1.6013209819793701, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6470/10000, Loss: 1.6138075590133667, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6471/10000, Loss: 1.6062278747558594, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6472/10000, Loss: 1.5084800720214844, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6473/10000, Loss: 1.5017482042312622, Train Acc : 0.47978350843680356 , Val Acc : 0.4794871794871795\n",
      "Epoch 6474/10000, Loss: 1.6231446266174316, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6475/10000, Loss: 1.5180275440216064, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6476/10000, Loss: 1.5997298955917358, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6477/10000, Loss: 1.5660513639450073, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6478/10000, Loss: 1.5661091804504395, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6479/10000, Loss: 1.5756608247756958, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6480/10000, Loss: 1.6044882535934448, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6481/10000, Loss: 1.6081923246383667, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6482/10000, Loss: 1.4809876680374146, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6483/10000, Loss: 1.6199380159378052, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6484/10000, Loss: 1.5454274415969849, Train Acc : 0.4801018783826807 , Val Acc : 0.4794871794871795\n",
      "Epoch 6485/10000, Loss: 1.5774959325790405, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6486/10000, Loss: 1.543267011642456, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6487/10000, Loss: 1.5871529579162598, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6488/10000, Loss: 1.5039526224136353, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6489/10000, Loss: 1.547694206237793, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6490/10000, Loss: 1.5550106763839722, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6491/10000, Loss: 1.6294314861297607, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6492/10000, Loss: 1.6187775135040283, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6493/10000, Loss: 1.5244760513305664, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6494/10000, Loss: 1.5655187368392944, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6495/10000, Loss: 1.61159348487854, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6496/10000, Loss: 1.5660662651062012, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6497/10000, Loss: 1.5837140083312988, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6498/10000, Loss: 1.5926179885864258, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6499/10000, Loss: 1.5555363893508911, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6500/10000, Loss: 1.4257259368896484, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6501/10000, Loss: 1.5219095945358276, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6502/10000, Loss: 1.5075300931930542, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6503/10000, Loss: 1.4984910488128662, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6504/10000, Loss: 1.6207587718963623, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6505/10000, Loss: 1.5311548709869385, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6506/10000, Loss: 1.5437711477279663, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6507/10000, Loss: 1.4628582000732422, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6508/10000, Loss: 1.5600430965423584, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6509/10000, Loss: 1.6266155242919922, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6510/10000, Loss: 1.5364800691604614, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6511/10000, Loss: 1.5463169813156128, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6512/10000, Loss: 1.6153852939605713, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6513/10000, Loss: 1.5691478252410889, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6514/10000, Loss: 1.5984790325164795, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6515/10000, Loss: 1.480155348777771, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6516/10000, Loss: 1.4786208868026733, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6517/10000, Loss: 1.5354301929473877, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6518/10000, Loss: 1.5357844829559326, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6519/10000, Loss: 1.5180195569992065, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6520/10000, Loss: 1.557187795639038, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6521/10000, Loss: 1.5358353853225708, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6522/10000, Loss: 1.6278789043426514, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6523/10000, Loss: 1.521746277809143, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6524/10000, Loss: 1.5665283203125, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6525/10000, Loss: 1.576981782913208, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6526/10000, Loss: 1.5656120777130127, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6527/10000, Loss: 1.6111832857131958, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6528/10000, Loss: 1.5473554134368896, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6529/10000, Loss: 1.6103920936584473, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6530/10000, Loss: 1.5146644115447998, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6531/10000, Loss: 1.5922249555587769, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6532/10000, Loss: 1.4758225679397583, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6533/10000, Loss: 1.56891930103302, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6534/10000, Loss: 1.572403073310852, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6535/10000, Loss: 1.5396405458450317, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6536/10000, Loss: 1.5472019910812378, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6537/10000, Loss: 1.5265880823135376, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6538/10000, Loss: 1.584806203842163, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6539/10000, Loss: 1.5468254089355469, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6540/10000, Loss: 1.5541555881500244, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6541/10000, Loss: 1.5721156597137451, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6542/10000, Loss: 1.6167969703674316, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6543/10000, Loss: 1.6044782400131226, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6544/10000, Loss: 1.5492842197418213, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6545/10000, Loss: 1.5015499591827393, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6546/10000, Loss: 1.5411149263381958, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6547/10000, Loss: 1.497826099395752, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6548/10000, Loss: 1.5808862447738647, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6549/10000, Loss: 1.5705817937850952, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6550/10000, Loss: 1.5493208169937134, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6551/10000, Loss: 1.5088145732879639, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6552/10000, Loss: 1.5723801851272583, Train Acc : 0.4801018783826807 , Val Acc : 0.47692307692307695\n",
      "Epoch 6553/10000, Loss: 1.617380976676941, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6554/10000, Loss: 1.5754692554473877, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6555/10000, Loss: 1.5760554075241089, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6556/10000, Loss: 1.6337242126464844, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6557/10000, Loss: 1.6891497373580933, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6558/10000, Loss: 1.598733901977539, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6559/10000, Loss: 1.4790194034576416, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6560/10000, Loss: 1.6266475915908813, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6561/10000, Loss: 1.5753798484802246, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6562/10000, Loss: 1.5704177618026733, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6563/10000, Loss: 1.6150282621383667, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6564/10000, Loss: 1.5439116954803467, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6565/10000, Loss: 1.593892216682434, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6566/10000, Loss: 1.5285674333572388, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6567/10000, Loss: 1.529186725616455, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6568/10000, Loss: 1.6149271726608276, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6569/10000, Loss: 1.5307034254074097, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6570/10000, Loss: 1.5862857103347778, Train Acc : 0.481056988220312 , Val Acc : 0.4794871794871795\n",
      "Epoch 6571/10000, Loss: 1.6220968961715698, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6572/10000, Loss: 1.4828616380691528, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6573/10000, Loss: 1.5371350049972534, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6574/10000, Loss: 1.583045244216919, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6575/10000, Loss: 1.5535551309585571, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6576/10000, Loss: 1.504145860671997, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6577/10000, Loss: 1.4492295980453491, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6578/10000, Loss: 1.6430915594100952, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6579/10000, Loss: 1.5412845611572266, Train Acc : 0.48073861827443487 , Val Acc : 0.4794871794871795\n",
      "Epoch 6580/10000, Loss: 1.6070365905761719, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6581/10000, Loss: 1.5520726442337036, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6582/10000, Loss: 1.5799788236618042, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6583/10000, Loss: 1.6114764213562012, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6584/10000, Loss: 1.54696524143219, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6585/10000, Loss: 1.5289534330368042, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6586/10000, Loss: 1.561383843421936, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6587/10000, Loss: 1.5882039070129395, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6588/10000, Loss: 1.6117993593215942, Train Acc : 0.4804202483285578 , Val Acc : 0.4794871794871795\n",
      "Epoch 6589/10000, Loss: 1.5518227815628052, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6590/10000, Loss: 1.5833064317703247, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6591/10000, Loss: 1.547562837600708, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6592/10000, Loss: 1.5579806566238403, Train Acc : 0.4804202483285578 , Val Acc : 0.47692307692307695\n",
      "Epoch 6593/10000, Loss: 1.5795748233795166, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6594/10000, Loss: 1.6079350709915161, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6595/10000, Loss: 1.5537121295928955, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6596/10000, Loss: 1.5134434700012207, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6597/10000, Loss: 1.546621322631836, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6598/10000, Loss: 1.559032678604126, Train Acc : 0.481056988220312 , Val Acc : 0.4794871794871795\n",
      "Epoch 6599/10000, Loss: 1.518949031829834, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6600/10000, Loss: 1.5224337577819824, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6601/10000, Loss: 1.5751450061798096, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6602/10000, Loss: 1.5967062711715698, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6603/10000, Loss: 1.516233205795288, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6604/10000, Loss: 1.513954520225525, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6605/10000, Loss: 1.5188522338867188, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6606/10000, Loss: 1.6122795343399048, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6607/10000, Loss: 1.5639792680740356, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6608/10000, Loss: 1.4887456893920898, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6609/10000, Loss: 1.514801025390625, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6610/10000, Loss: 1.5573110580444336, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6611/10000, Loss: 1.6019086837768555, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6612/10000, Loss: 1.608918309211731, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6613/10000, Loss: 1.597779393196106, Train Acc : 0.4813753581661891 , Val Acc : 0.4794871794871795\n",
      "Epoch 6614/10000, Loss: 1.5429073572158813, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6615/10000, Loss: 1.5439543724060059, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6616/10000, Loss: 1.562936782836914, Train Acc : 0.4813753581661891 , Val Acc : 0.4794871794871795\n",
      "Epoch 6617/10000, Loss: 1.5228159427642822, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6618/10000, Loss: 1.562890887260437, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6619/10000, Loss: 1.5826414823532104, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6620/10000, Loss: 1.5789175033569336, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6621/10000, Loss: 1.48195481300354, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6622/10000, Loss: 1.5378726720809937, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6623/10000, Loss: 1.6424822807312012, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6624/10000, Loss: 1.507745385169983, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6625/10000, Loss: 1.5057529211044312, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6626/10000, Loss: 1.577654480934143, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6627/10000, Loss: 1.580742597579956, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6628/10000, Loss: 1.5808817148208618, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6629/10000, Loss: 1.5679008960723877, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6630/10000, Loss: 1.5702000856399536, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6631/10000, Loss: 1.5987757444381714, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6632/10000, Loss: 1.5681095123291016, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6633/10000, Loss: 1.5394326448440552, Train Acc : 0.48169372811206623 , Val Acc : 0.4794871794871795\n",
      "Epoch 6634/10000, Loss: 1.6329047679901123, Train Acc : 0.48169372811206623 , Val Acc : 0.4794871794871795\n",
      "Epoch 6635/10000, Loss: 1.4277653694152832, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6636/10000, Loss: 1.5870416164398193, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6637/10000, Loss: 1.6173081398010254, Train Acc : 0.481056988220312 , Val Acc : 0.4794871794871795\n",
      "Epoch 6638/10000, Loss: 1.536779522895813, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6639/10000, Loss: 1.4994248151779175, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6640/10000, Loss: 1.5403624773025513, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6641/10000, Loss: 1.578386664390564, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6642/10000, Loss: 1.6087024211883545, Train Acc : 0.48169372811206623 , Val Acc : 0.4794871794871795\n",
      "Epoch 6643/10000, Loss: 1.5372451543807983, Train Acc : 0.48169372811206623 , Val Acc : 0.4794871794871795\n",
      "Epoch 6644/10000, Loss: 1.590950608253479, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6645/10000, Loss: 1.646064043045044, Train Acc : 0.48169372811206623 , Val Acc : 0.4794871794871795\n",
      "Epoch 6646/10000, Loss: 1.541417121887207, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6647/10000, Loss: 1.5959552526474, Train Acc : 0.481056988220312 , Val Acc : 0.47692307692307695\n",
      "Epoch 6648/10000, Loss: 1.459118127822876, Train Acc : 0.48073861827443487 , Val Acc : 0.47692307692307695\n",
      "Epoch 6649/10000, Loss: 1.542854905128479, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6650/10000, Loss: 1.5268266201019287, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6651/10000, Loss: 1.5613237619400024, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6652/10000, Loss: 1.6279982328414917, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6653/10000, Loss: 1.50717031955719, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6654/10000, Loss: 1.6054900884628296, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6655/10000, Loss: 1.5715925693511963, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6656/10000, Loss: 1.5421347618103027, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6657/10000, Loss: 1.6332411766052246, Train Acc : 0.48169372811206623 , Val Acc : 0.4794871794871795\n",
      "Epoch 6658/10000, Loss: 1.533101201057434, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6659/10000, Loss: 1.4950789213180542, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6660/10000, Loss: 1.6276588439941406, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6661/10000, Loss: 1.5012662410736084, Train Acc : 0.4813753581661891 , Val Acc : 0.4794871794871795\n",
      "Epoch 6662/10000, Loss: 1.511872410774231, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6663/10000, Loss: 1.547802448272705, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6664/10000, Loss: 1.478089690208435, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6665/10000, Loss: 1.5665327310562134, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6666/10000, Loss: 1.5424844026565552, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6667/10000, Loss: 1.5387969017028809, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6668/10000, Loss: 1.5793522596359253, Train Acc : 0.48169372811206623 , Val Acc : 0.4794871794871795\n",
      "Epoch 6669/10000, Loss: 1.5701508522033691, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6670/10000, Loss: 1.6248607635498047, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6671/10000, Loss: 1.5607945919036865, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6672/10000, Loss: 1.4754328727722168, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6673/10000, Loss: 1.5878467559814453, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6674/10000, Loss: 1.571886420249939, Train Acc : 0.48169372811206623 , Val Acc : 0.4794871794871795\n",
      "Epoch 6675/10000, Loss: 1.5430899858474731, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6676/10000, Loss: 1.5793704986572266, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6677/10000, Loss: 1.5638209581375122, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6678/10000, Loss: 1.5716321468353271, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6679/10000, Loss: 1.5855153799057007, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6680/10000, Loss: 1.5881010293960571, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6681/10000, Loss: 1.5442525148391724, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6682/10000, Loss: 1.6480450630187988, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6683/10000, Loss: 1.487982988357544, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6684/10000, Loss: 1.5380311012268066, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6685/10000, Loss: 1.573087453842163, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6686/10000, Loss: 1.5943537950515747, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6687/10000, Loss: 1.4967433214187622, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6688/10000, Loss: 1.5398941040039062, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6689/10000, Loss: 1.5727986097335815, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6690/10000, Loss: 1.5292905569076538, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6691/10000, Loss: 1.5482841730117798, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6692/10000, Loss: 1.645888090133667, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6693/10000, Loss: 1.5492383241653442, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6694/10000, Loss: 1.5756416320800781, Train Acc : 0.48264883794969754 , Val Acc : 0.47692307692307695\n",
      "Epoch 6695/10000, Loss: 1.533393383026123, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6696/10000, Loss: 1.5392661094665527, Train Acc : 0.4813753581661891 , Val Acc : 0.47692307692307695\n",
      "Epoch 6697/10000, Loss: 1.5557883977890015, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6698/10000, Loss: 1.5195425748825073, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6699/10000, Loss: 1.6195621490478516, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6700/10000, Loss: 1.6075189113616943, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6701/10000, Loss: 1.5809029340744019, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6702/10000, Loss: 1.5902127027511597, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6703/10000, Loss: 1.455843210220337, Train Acc : 0.4813753581661891 , Val Acc : 0.4794871794871795\n",
      "Epoch 6704/10000, Loss: 1.5430792570114136, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6705/10000, Loss: 1.6048327684402466, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6706/10000, Loss: 1.546918511390686, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6707/10000, Loss: 1.471514105796814, Train Acc : 0.4813753581661891 , Val Acc : 0.4794871794871795\n",
      "Epoch 6708/10000, Loss: 1.5846225023269653, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6709/10000, Loss: 1.6172112226486206, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6710/10000, Loss: 1.5828227996826172, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6711/10000, Loss: 1.5667731761932373, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6712/10000, Loss: 1.5012590885162354, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6713/10000, Loss: 1.5272295475006104, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6714/10000, Loss: 1.5987452268600464, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6715/10000, Loss: 1.6056478023529053, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6716/10000, Loss: 1.6496696472167969, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6717/10000, Loss: 1.557261347770691, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6718/10000, Loss: 1.5040192604064941, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6719/10000, Loss: 1.5445911884307861, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6720/10000, Loss: 1.5678268671035767, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6721/10000, Loss: 1.4521739482879639, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6722/10000, Loss: 1.6392617225646973, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6723/10000, Loss: 1.540758490562439, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6724/10000, Loss: 1.5801643133163452, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6725/10000, Loss: 1.5207581520080566, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6726/10000, Loss: 1.562130331993103, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6727/10000, Loss: 1.5177940130233765, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6728/10000, Loss: 1.5606846809387207, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6729/10000, Loss: 1.5877246856689453, Train Acc : 0.48264883794969754 , Val Acc : 0.47692307692307695\n",
      "Epoch 6730/10000, Loss: 1.5673691034317017, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6731/10000, Loss: 1.5751529932022095, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6732/10000, Loss: 1.5470448732376099, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6733/10000, Loss: 1.5392550230026245, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6734/10000, Loss: 1.5551735162734985, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6735/10000, Loss: 1.5808112621307373, Train Acc : 0.48169372811206623 , Val Acc : 0.47692307692307695\n",
      "Epoch 6736/10000, Loss: 1.6498842239379883, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6737/10000, Loss: 1.4926257133483887, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6738/10000, Loss: 1.546815276145935, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6739/10000, Loss: 1.5443490743637085, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6740/10000, Loss: 1.589525580406189, Train Acc : 0.48169372811206623 , Val Acc : 0.4794871794871795\n",
      "Epoch 6741/10000, Loss: 1.5763728618621826, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6742/10000, Loss: 1.5589823722839355, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6743/10000, Loss: 1.6490150690078735, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6744/10000, Loss: 1.5481808185577393, Train Acc : 0.48264883794969754 , Val Acc : 0.47692307692307695\n",
      "Epoch 6745/10000, Loss: 1.6071754693984985, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6746/10000, Loss: 1.5075494050979614, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6747/10000, Loss: 1.6083955764770508, Train Acc : 0.48264883794969754 , Val Acc : 0.47692307692307695\n",
      "Epoch 6748/10000, Loss: 1.5621510744094849, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6749/10000, Loss: 1.5566463470458984, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6750/10000, Loss: 1.5455584526062012, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6751/10000, Loss: 1.6441504955291748, Train Acc : 0.4820120980579433 , Val Acc : 0.47692307692307695\n",
      "Epoch 6752/10000, Loss: 1.6100796461105347, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6753/10000, Loss: 1.5264114141464233, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6754/10000, Loss: 1.5909302234649658, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6755/10000, Loss: 1.618195652961731, Train Acc : 0.4829672078955747 , Val Acc : 0.47692307692307695\n",
      "Epoch 6756/10000, Loss: 1.5046744346618652, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6757/10000, Loss: 1.516152024269104, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6758/10000, Loss: 1.5638169050216675, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6759/10000, Loss: 1.5007860660552979, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6760/10000, Loss: 1.63373863697052, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6761/10000, Loss: 1.544010043144226, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6762/10000, Loss: 1.5228912830352783, Train Acc : 0.48233046800382046 , Val Acc : 0.47692307692307695\n",
      "Epoch 6763/10000, Loss: 1.6083507537841797, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6764/10000, Loss: 1.4862679243087769, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6765/10000, Loss: 1.590049147605896, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6766/10000, Loss: 1.47698974609375, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6767/10000, Loss: 1.6084067821502686, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6768/10000, Loss: 1.5797289609909058, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6769/10000, Loss: 1.589524507522583, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6770/10000, Loss: 1.6221200227737427, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6771/10000, Loss: 1.6054694652557373, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6772/10000, Loss: 1.533707618713379, Train Acc : 0.4829672078955747 , Val Acc : 0.47692307692307695\n",
      "Epoch 6773/10000, Loss: 1.522060513496399, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6774/10000, Loss: 1.5648378133773804, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6775/10000, Loss: 1.5559273958206177, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6776/10000, Loss: 1.5767099857330322, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6777/10000, Loss: 1.546584129333496, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6778/10000, Loss: 1.6979196071624756, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6779/10000, Loss: 1.622944951057434, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6780/10000, Loss: 1.5167049169540405, Train Acc : 0.4820120980579433 , Val Acc : 0.4794871794871795\n",
      "Epoch 6781/10000, Loss: 1.4710386991500854, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6782/10000, Loss: 1.561821699142456, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6783/10000, Loss: 1.61272132396698, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6784/10000, Loss: 1.5496773719787598, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6785/10000, Loss: 1.5342743396759033, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6786/10000, Loss: 1.623294711112976, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6787/10000, Loss: 1.510835886001587, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6788/10000, Loss: 1.5480570793151855, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6789/10000, Loss: 1.5494238138198853, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6790/10000, Loss: 1.5458072423934937, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6791/10000, Loss: 1.5172325372695923, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6792/10000, Loss: 1.4999980926513672, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6793/10000, Loss: 1.6157732009887695, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6794/10000, Loss: 1.5603907108306885, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6795/10000, Loss: 1.5606553554534912, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6796/10000, Loss: 1.598394751548767, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6797/10000, Loss: 1.580270528793335, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6798/10000, Loss: 1.5766099691390991, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6799/10000, Loss: 1.5899477005004883, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6800/10000, Loss: 1.5356557369232178, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6801/10000, Loss: 1.5436887741088867, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6802/10000, Loss: 1.5322043895721436, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6803/10000, Loss: 1.538519263267517, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6804/10000, Loss: 1.5475103855133057, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6805/10000, Loss: 1.499314308166504, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6806/10000, Loss: 1.5178306102752686, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6807/10000, Loss: 1.596403956413269, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6808/10000, Loss: 1.5821425914764404, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6809/10000, Loss: 1.5672506093978882, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6810/10000, Loss: 1.6298160552978516, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6811/10000, Loss: 1.5563455820083618, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6812/10000, Loss: 1.5475918054580688, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6813/10000, Loss: 1.5550729036331177, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6814/10000, Loss: 1.539984107017517, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6815/10000, Loss: 1.57192063331604, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6816/10000, Loss: 1.5469244718551636, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6817/10000, Loss: 1.5342154502868652, Train Acc : 0.48233046800382046 , Val Acc : 0.4794871794871795\n",
      "Epoch 6818/10000, Loss: 1.6244139671325684, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6819/10000, Loss: 1.4965096712112427, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6820/10000, Loss: 1.589678168296814, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6821/10000, Loss: 1.5501450300216675, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6822/10000, Loss: 1.5428876876831055, Train Acc : 0.4829672078955747 , Val Acc : 0.47692307692307695\n",
      "Epoch 6823/10000, Loss: 1.5618247985839844, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6824/10000, Loss: 1.6207237243652344, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6825/10000, Loss: 1.6122349500656128, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6826/10000, Loss: 1.5809425115585327, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6827/10000, Loss: 1.5335332155227661, Train Acc : 0.48264883794969754 , Val Acc : 0.47692307692307695\n",
      "Epoch 6828/10000, Loss: 1.5746759176254272, Train Acc : 0.48328557784145176 , Val Acc : 0.48205128205128206\n",
      "Epoch 6829/10000, Loss: 1.6334136724472046, Train Acc : 0.48264883794969754 , Val Acc : 0.47692307692307695\n",
      "Epoch 6830/10000, Loss: 1.5078028440475464, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6831/10000, Loss: 1.6080095767974854, Train Acc : 0.4836039477873289 , Val Acc : 0.47692307692307695\n",
      "Epoch 6832/10000, Loss: 1.5565588474273682, Train Acc : 0.4836039477873289 , Val Acc : 0.47692307692307695\n",
      "Epoch 6833/10000, Loss: 1.4876118898391724, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6834/10000, Loss: 1.6240216493606567, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6835/10000, Loss: 1.517276644706726, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6836/10000, Loss: 1.526415467262268, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6837/10000, Loss: 1.575677514076233, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6838/10000, Loss: 1.5521297454833984, Train Acc : 0.4829672078955747 , Val Acc : 0.47692307692307695\n",
      "Epoch 6839/10000, Loss: 1.5736205577850342, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6840/10000, Loss: 1.4542639255523682, Train Acc : 0.483922317733206 , Val Acc : 0.4794871794871795\n",
      "Epoch 6841/10000, Loss: 1.5580865144729614, Train Acc : 0.4836039477873289 , Val Acc : 0.47692307692307695\n",
      "Epoch 6842/10000, Loss: 1.6147568225860596, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6843/10000, Loss: 1.516629934310913, Train Acc : 0.48264883794969754 , Val Acc : 0.4794871794871795\n",
      "Epoch 6844/10000, Loss: 1.601473093032837, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6845/10000, Loss: 1.4737695455551147, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6846/10000, Loss: 1.4971766471862793, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6847/10000, Loss: 1.5897482633590698, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6848/10000, Loss: 1.5161024332046509, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6849/10000, Loss: 1.5185531377792358, Train Acc : 0.483922317733206 , Val Acc : 0.47692307692307695\n",
      "Epoch 6850/10000, Loss: 1.5616494417190552, Train Acc : 0.483922317733206 , Val Acc : 0.47692307692307695\n",
      "Epoch 6851/10000, Loss: 1.6377280950546265, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6852/10000, Loss: 1.6479783058166504, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6853/10000, Loss: 1.5441193580627441, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6854/10000, Loss: 1.5227993726730347, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6855/10000, Loss: 1.445664882659912, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6856/10000, Loss: 1.5632693767547607, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6857/10000, Loss: 1.441815972328186, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6858/10000, Loss: 1.5362696647644043, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6859/10000, Loss: 1.5838676691055298, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6860/10000, Loss: 1.5404061079025269, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6861/10000, Loss: 1.5506292581558228, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6862/10000, Loss: 1.4933688640594482, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6863/10000, Loss: 1.564524531364441, Train Acc : 0.483922317733206 , Val Acc : 0.4794871794871795\n",
      "Epoch 6864/10000, Loss: 1.561046838760376, Train Acc : 0.483922317733206 , Val Acc : 0.4794871794871795\n",
      "Epoch 6865/10000, Loss: 1.5351823568344116, Train Acc : 0.483922317733206 , Val Acc : 0.4794871794871795\n",
      "Epoch 6866/10000, Loss: 1.5336339473724365, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6867/10000, Loss: 1.5386251211166382, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6868/10000, Loss: 1.535066843032837, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6869/10000, Loss: 1.45700204372406, Train Acc : 0.483922317733206 , Val Acc : 0.4794871794871795\n",
      "Epoch 6870/10000, Loss: 1.5565482378005981, Train Acc : 0.48424068767908307 , Val Acc : 0.4794871794871795\n",
      "Epoch 6871/10000, Loss: 1.528448224067688, Train Acc : 0.483922317733206 , Val Acc : 0.4794871794871795\n",
      "Epoch 6872/10000, Loss: 1.5614032745361328, Train Acc : 0.48424068767908307 , Val Acc : 0.4794871794871795\n",
      "Epoch 6873/10000, Loss: 1.522866129875183, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6874/10000, Loss: 1.5498738288879395, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6875/10000, Loss: 1.5663950443267822, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6876/10000, Loss: 1.5167468786239624, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6877/10000, Loss: 1.4768882989883423, Train Acc : 0.4829672078955747 , Val Acc : 0.4794871794871795\n",
      "Epoch 6878/10000, Loss: 1.5233526229858398, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6879/10000, Loss: 1.5787248611450195, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6880/10000, Loss: 1.5770845413208008, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6881/10000, Loss: 1.583465814590454, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6882/10000, Loss: 1.5991606712341309, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6883/10000, Loss: 1.5328707695007324, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6884/10000, Loss: 1.606201410293579, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6885/10000, Loss: 1.5754503011703491, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6886/10000, Loss: 1.654085636138916, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6887/10000, Loss: 1.631812572479248, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6888/10000, Loss: 1.5922363996505737, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6889/10000, Loss: 1.501327395439148, Train Acc : 0.48424068767908307 , Val Acc : 0.4794871794871795\n",
      "Epoch 6890/10000, Loss: 1.6093332767486572, Train Acc : 0.483922317733206 , Val Acc : 0.4794871794871795\n",
      "Epoch 6891/10000, Loss: 1.5555216073989868, Train Acc : 0.48424068767908307 , Val Acc : 0.4794871794871795\n",
      "Epoch 6892/10000, Loss: 1.5290664434432983, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6893/10000, Loss: 1.4896326065063477, Train Acc : 0.483922317733206 , Val Acc : 0.4794871794871795\n",
      "Epoch 6894/10000, Loss: 1.5164889097213745, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6895/10000, Loss: 1.5711733102798462, Train Acc : 0.48328557784145176 , Val Acc : 0.48205128205128206\n",
      "Epoch 6896/10000, Loss: 1.6617388725280762, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6897/10000, Loss: 1.5857075452804565, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6898/10000, Loss: 1.5670688152313232, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6899/10000, Loss: 1.585126519203186, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6900/10000, Loss: 1.4839255809783936, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6901/10000, Loss: 1.5353442430496216, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6902/10000, Loss: 1.6166025400161743, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6903/10000, Loss: 1.478248953819275, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6904/10000, Loss: 1.6115444898605347, Train Acc : 0.4836039477873289 , Val Acc : 0.4794871794871795\n",
      "Epoch 6905/10000, Loss: 1.6526391506195068, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6906/10000, Loss: 1.6358190774917603, Train Acc : 0.4836039477873289 , Val Acc : 0.47692307692307695\n",
      "Epoch 6907/10000, Loss: 1.5323740243911743, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6908/10000, Loss: 1.5610383749008179, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6909/10000, Loss: 1.593413233757019, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6910/10000, Loss: 1.527266025543213, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6911/10000, Loss: 1.5754404067993164, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6912/10000, Loss: 1.6103148460388184, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6913/10000, Loss: 1.4894405603408813, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6914/10000, Loss: 1.5369219779968262, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6915/10000, Loss: 1.5221208333969116, Train Acc : 0.48328557784145176 , Val Acc : 0.4794871794871795\n",
      "Epoch 6916/10000, Loss: 1.5416158437728882, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6917/10000, Loss: 1.5648150444030762, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6918/10000, Loss: 1.5179516077041626, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6919/10000, Loss: 1.5309364795684814, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6920/10000, Loss: 1.5039122104644775, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6921/10000, Loss: 1.5950263738632202, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6922/10000, Loss: 1.6369975805282593, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6923/10000, Loss: 1.5471113920211792, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6924/10000, Loss: 1.5738087892532349, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6925/10000, Loss: 1.6112362146377563, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6926/10000, Loss: 1.5910624265670776, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6927/10000, Loss: 1.5448405742645264, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6928/10000, Loss: 1.572235345840454, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6929/10000, Loss: 1.5494086742401123, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6930/10000, Loss: 1.5834662914276123, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6931/10000, Loss: 1.6981483697891235, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6932/10000, Loss: 1.484876275062561, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6933/10000, Loss: 1.501880407333374, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6934/10000, Loss: 1.5315892696380615, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6935/10000, Loss: 1.6057441234588623, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6936/10000, Loss: 1.5940923690795898, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6937/10000, Loss: 1.5599184036254883, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6938/10000, Loss: 1.6205713748931885, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6939/10000, Loss: 1.504436731338501, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6940/10000, Loss: 1.5695617198944092, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6941/10000, Loss: 1.575066328048706, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6942/10000, Loss: 1.5141440629959106, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6943/10000, Loss: 1.5124112367630005, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6944/10000, Loss: 1.6458631753921509, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6945/10000, Loss: 1.608396053314209, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6946/10000, Loss: 1.5920555591583252, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6947/10000, Loss: 1.5113341808319092, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 6948/10000, Loss: 1.539679765701294, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6949/10000, Loss: 1.4835667610168457, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6950/10000, Loss: 1.568874716758728, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6951/10000, Loss: 1.435370922088623, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6952/10000, Loss: 1.4952598810195923, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6953/10000, Loss: 1.6167094707489014, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6954/10000, Loss: 1.6020379066467285, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6955/10000, Loss: 1.5828698873519897, Train Acc : 0.48328557784145176 , Val Acc : 0.48205128205128206\n",
      "Epoch 6956/10000, Loss: 1.6277799606323242, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6957/10000, Loss: 1.5111840963363647, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6958/10000, Loss: 1.5788170099258423, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6959/10000, Loss: 1.4924736022949219, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6960/10000, Loss: 1.5141834020614624, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6961/10000, Loss: 1.637891411781311, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6962/10000, Loss: 1.571759581565857, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6963/10000, Loss: 1.620776891708374, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6964/10000, Loss: 1.6088552474975586, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6965/10000, Loss: 1.5785579681396484, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6966/10000, Loss: 1.5436547994613647, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6967/10000, Loss: 1.5480858087539673, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6968/10000, Loss: 1.5385067462921143, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6969/10000, Loss: 1.5774517059326172, Train Acc : 0.4836039477873289 , Val Acc : 0.48205128205128206\n",
      "Epoch 6970/10000, Loss: 1.5183236598968506, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6971/10000, Loss: 1.499118447303772, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6972/10000, Loss: 1.5059102773666382, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6973/10000, Loss: 1.656806230545044, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6974/10000, Loss: 1.4785562753677368, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 6975/10000, Loss: 1.6317098140716553, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6976/10000, Loss: 1.4693825244903564, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6977/10000, Loss: 1.644390344619751, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6978/10000, Loss: 1.5408912897109985, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 6979/10000, Loss: 1.4973496198654175, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6980/10000, Loss: 1.522403359413147, Train Acc : 0.4845590576249602 , Val Acc : 0.4794871794871795\n",
      "Epoch 6981/10000, Loss: 1.5529308319091797, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6982/10000, Loss: 1.6044776439666748, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6983/10000, Loss: 1.5429062843322754, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 6984/10000, Loss: 1.6079142093658447, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 6985/10000, Loss: 1.589552879333496, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 6986/10000, Loss: 1.570592999458313, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 6987/10000, Loss: 1.5509849786758423, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6988/10000, Loss: 1.5781065225601196, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6989/10000, Loss: 1.5916571617126465, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 6990/10000, Loss: 1.558074951171875, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 6991/10000, Loss: 1.6287728548049927, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6992/10000, Loss: 1.5898113250732422, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6993/10000, Loss: 1.5685656070709229, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6994/10000, Loss: 1.5673315525054932, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6995/10000, Loss: 1.529882550239563, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 6996/10000, Loss: 1.5905948877334595, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 6997/10000, Loss: 1.51157808303833, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 6998/10000, Loss: 1.5328150987625122, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 6999/10000, Loss: 1.525400996208191, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7000/10000, Loss: 1.504428505897522, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7001/10000, Loss: 1.5617847442626953, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7002/10000, Loss: 1.6196656227111816, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7003/10000, Loss: 1.6123408079147339, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7004/10000, Loss: 1.509358286857605, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7005/10000, Loss: 1.566212773323059, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7006/10000, Loss: 1.558322548866272, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7007/10000, Loss: 1.5744065046310425, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7008/10000, Loss: 1.5896855592727661, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7009/10000, Loss: 1.5927037000656128, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7010/10000, Loss: 1.5906376838684082, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7011/10000, Loss: 1.578169822692871, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7012/10000, Loss: 1.5454788208007812, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7013/10000, Loss: 1.5473127365112305, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7014/10000, Loss: 1.5877765417099, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7015/10000, Loss: 1.524401068687439, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7016/10000, Loss: 1.5785022974014282, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7017/10000, Loss: 1.5270423889160156, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7018/10000, Loss: 1.6447937488555908, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7019/10000, Loss: 1.5937905311584473, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7020/10000, Loss: 1.5280084609985352, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7021/10000, Loss: 1.5579239130020142, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7022/10000, Loss: 1.5597914457321167, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7023/10000, Loss: 1.683980107307434, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7024/10000, Loss: 1.6125099658966064, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7025/10000, Loss: 1.5078949928283691, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7026/10000, Loss: 1.5607961416244507, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7027/10000, Loss: 1.611863613128662, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7028/10000, Loss: 1.6252551078796387, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7029/10000, Loss: 1.5384818315505981, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7030/10000, Loss: 1.5441428422927856, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7031/10000, Loss: 1.454628825187683, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 7032/10000, Loss: 1.5000128746032715, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7033/10000, Loss: 1.516963243484497, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7034/10000, Loss: 1.5356138944625854, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7035/10000, Loss: 1.6004668474197388, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7036/10000, Loss: 1.5064979791641235, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7037/10000, Loss: 1.5918225049972534, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7038/10000, Loss: 1.4721276760101318, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7039/10000, Loss: 1.5578680038452148, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7040/10000, Loss: 1.5580450296401978, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7041/10000, Loss: 1.5250450372695923, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7042/10000, Loss: 1.5252957344055176, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7043/10000, Loss: 1.5964770317077637, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7044/10000, Loss: 1.4721333980560303, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7045/10000, Loss: 1.5350701808929443, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7046/10000, Loss: 1.5876381397247314, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7047/10000, Loss: 1.654244303703308, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7048/10000, Loss: 1.6105154752731323, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7049/10000, Loss: 1.548213243484497, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7050/10000, Loss: 1.5498945713043213, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7051/10000, Loss: 1.51520574092865, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7052/10000, Loss: 1.5312563180923462, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7053/10000, Loss: 1.5198476314544678, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7054/10000, Loss: 1.488940954208374, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7055/10000, Loss: 1.53067147731781, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7056/10000, Loss: 1.4984474182128906, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7057/10000, Loss: 1.4718403816223145, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7058/10000, Loss: 1.5792088508605957, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7059/10000, Loss: 1.5584020614624023, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7060/10000, Loss: 1.5815414190292358, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7061/10000, Loss: 1.611960530281067, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7062/10000, Loss: 1.5387061834335327, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7063/10000, Loss: 1.5092326402664185, Train Acc : 0.483922317733206 , Val Acc : 0.48205128205128206\n",
      "Epoch 7064/10000, Loss: 1.4526323080062866, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7065/10000, Loss: 1.5012274980545044, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7066/10000, Loss: 1.5401335954666138, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7067/10000, Loss: 1.5172126293182373, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7068/10000, Loss: 1.471323013305664, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7069/10000, Loss: 1.5475891828536987, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7070/10000, Loss: 1.5914469957351685, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7071/10000, Loss: 1.4838809967041016, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7072/10000, Loss: 1.5610917806625366, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7073/10000, Loss: 1.5605921745300293, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7074/10000, Loss: 1.572801947593689, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7075/10000, Loss: 1.5996605157852173, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7076/10000, Loss: 1.5941612720489502, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7077/10000, Loss: 1.5481985807418823, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7078/10000, Loss: 1.6503841876983643, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7079/10000, Loss: 1.4350969791412354, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7080/10000, Loss: 1.541558027267456, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7081/10000, Loss: 1.4981049299240112, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7082/10000, Loss: 1.4734290838241577, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7083/10000, Loss: 1.5683647394180298, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7084/10000, Loss: 1.6089165210723877, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7085/10000, Loss: 1.6366872787475586, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7086/10000, Loss: 1.5448204278945923, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7087/10000, Loss: 1.5177733898162842, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7088/10000, Loss: 1.5568349361419678, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7089/10000, Loss: 1.6403918266296387, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7090/10000, Loss: 1.501419186592102, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7091/10000, Loss: 1.5239945650100708, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7092/10000, Loss: 1.5385479927062988, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7093/10000, Loss: 1.6254856586456299, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7094/10000, Loss: 1.5225168466567993, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7095/10000, Loss: 1.587250828742981, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7096/10000, Loss: 1.5189448595046997, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7097/10000, Loss: 1.541332483291626, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7098/10000, Loss: 1.4844180345535278, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7099/10000, Loss: 1.5361549854278564, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7100/10000, Loss: 1.538056492805481, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7101/10000, Loss: 1.6202448606491089, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7102/10000, Loss: 1.5131208896636963, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7103/10000, Loss: 1.5683590173721313, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7104/10000, Loss: 1.637150764465332, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7105/10000, Loss: 1.506922960281372, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7106/10000, Loss: 1.578216552734375, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7107/10000, Loss: 1.5129224061965942, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7108/10000, Loss: 1.4954233169555664, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7109/10000, Loss: 1.4692498445510864, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7110/10000, Loss: 1.6040756702423096, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7111/10000, Loss: 1.452925443649292, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7112/10000, Loss: 1.5825523138046265, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7113/10000, Loss: 1.457504391670227, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7114/10000, Loss: 1.6067191362380981, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7115/10000, Loss: 1.6035282611846924, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7116/10000, Loss: 1.5042762756347656, Train Acc : 0.48424068767908307 , Val Acc : 0.48205128205128206\n",
      "Epoch 7117/10000, Loss: 1.5076367855072021, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7118/10000, Loss: 1.6232314109802246, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7119/10000, Loss: 1.5058386325836182, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7120/10000, Loss: 1.556161880493164, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7121/10000, Loss: 1.491316556930542, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7122/10000, Loss: 1.5525660514831543, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7123/10000, Loss: 1.5141143798828125, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7124/10000, Loss: 1.6153430938720703, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7125/10000, Loss: 1.5223859548568726, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7126/10000, Loss: 1.566758155822754, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7127/10000, Loss: 1.634528398513794, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7128/10000, Loss: 1.5922095775604248, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7129/10000, Loss: 1.5237460136413574, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7130/10000, Loss: 1.6817091703414917, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7131/10000, Loss: 1.599164366722107, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7132/10000, Loss: 1.6495634317398071, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7133/10000, Loss: 1.5823644399642944, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7134/10000, Loss: 1.5796573162078857, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7135/10000, Loss: 1.5115635395050049, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7136/10000, Loss: 1.6327089071273804, Train Acc : 0.48519579751671443 , Val Acc : 0.4794871794871795\n",
      "Epoch 7137/10000, Loss: 1.5000889301300049, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7138/10000, Loss: 1.7188836336135864, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7139/10000, Loss: 1.5500950813293457, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7140/10000, Loss: 1.49986732006073, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7141/10000, Loss: 1.551659345626831, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7142/10000, Loss: 1.5433040857315063, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7143/10000, Loss: 1.5339218378067017, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7144/10000, Loss: 1.5888093709945679, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7145/10000, Loss: 1.5628467798233032, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7146/10000, Loss: 1.5152060985565186, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7147/10000, Loss: 1.5687199831008911, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7148/10000, Loss: 1.55384361743927, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7149/10000, Loss: 1.4967533349990845, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7150/10000, Loss: 1.4465625286102295, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7151/10000, Loss: 1.4319580793380737, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7152/10000, Loss: 1.5299293994903564, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7153/10000, Loss: 1.539419174194336, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7154/10000, Loss: 1.5064138174057007, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7155/10000, Loss: 1.5322312116622925, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7156/10000, Loss: 1.5817533731460571, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7157/10000, Loss: 1.4790688753128052, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7158/10000, Loss: 1.6022224426269531, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7159/10000, Loss: 1.5207751989364624, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7160/10000, Loss: 1.4359734058380127, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7161/10000, Loss: 1.5858772993087769, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7162/10000, Loss: 1.5071394443511963, Train Acc : 0.4845590576249602 , Val Acc : 0.4794871794871795\n",
      "Epoch 7163/10000, Loss: 1.5971808433532715, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7164/10000, Loss: 1.5427788496017456, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7165/10000, Loss: 1.522810459136963, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7166/10000, Loss: 1.5556796789169312, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7167/10000, Loss: 1.5253727436065674, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7168/10000, Loss: 1.5809295177459717, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7169/10000, Loss: 1.6199991703033447, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7170/10000, Loss: 1.5760257244110107, Train Acc : 0.4845590576249602 , Val Acc : 0.48205128205128206\n",
      "Epoch 7171/10000, Loss: 1.588771939277649, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7172/10000, Loss: 1.5218874216079712, Train Acc : 0.4855141674625915 , Val Acc : 0.4794871794871795\n",
      "Epoch 7173/10000, Loss: 1.4929457902908325, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7174/10000, Loss: 1.5951282978057861, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7175/10000, Loss: 1.5736331939697266, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7176/10000, Loss: 1.6525626182556152, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7177/10000, Loss: 1.5898571014404297, Train Acc : 0.48519579751671443 , Val Acc : 0.48205128205128206\n",
      "Epoch 7178/10000, Loss: 1.5628292560577393, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7179/10000, Loss: 1.6445856094360352, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7180/10000, Loss: 1.59127676486969, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7181/10000, Loss: 1.5238593816757202, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7182/10000, Loss: 1.5202949047088623, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7183/10000, Loss: 1.4962389469146729, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7184/10000, Loss: 1.605995774269104, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7185/10000, Loss: 1.5061118602752686, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7186/10000, Loss: 1.583662748336792, Train Acc : 0.4855141674625915 , Val Acc : 0.4794871794871795\n",
      "Epoch 7187/10000, Loss: 1.5389243364334106, Train Acc : 0.4855141674625915 , Val Acc : 0.4794871794871795\n",
      "Epoch 7188/10000, Loss: 1.5627158880233765, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7189/10000, Loss: 1.5016694068908691, Train Acc : 0.4855141674625915 , Val Acc : 0.4794871794871795\n",
      "Epoch 7190/10000, Loss: 1.5378371477127075, Train Acc : 0.4848774275708373 , Val Acc : 0.48205128205128206\n",
      "Epoch 7191/10000, Loss: 1.5552136898040771, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7192/10000, Loss: 1.5474543571472168, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7193/10000, Loss: 1.4826195240020752, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7194/10000, Loss: 1.5639996528625488, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7195/10000, Loss: 1.5227118730545044, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7196/10000, Loss: 1.552014708518982, Train Acc : 0.4848774275708373 , Val Acc : 0.4794871794871795\n",
      "Epoch 7197/10000, Loss: 1.5248916149139404, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7198/10000, Loss: 1.6135145425796509, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7199/10000, Loss: 1.7318435907363892, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7200/10000, Loss: 1.5413378477096558, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7201/10000, Loss: 1.5333904027938843, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7202/10000, Loss: 1.4992843866348267, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7203/10000, Loss: 1.4192516803741455, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7204/10000, Loss: 1.5064365863800049, Train Acc : 0.4855141674625915 , Val Acc : 0.4794871794871795\n",
      "Epoch 7205/10000, Loss: 1.6035423278808594, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7206/10000, Loss: 1.5107812881469727, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7207/10000, Loss: 1.5970220565795898, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7208/10000, Loss: 1.6076856851577759, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7209/10000, Loss: 1.6012576818466187, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7210/10000, Loss: 1.4356372356414795, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7211/10000, Loss: 1.5552339553833008, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7212/10000, Loss: 1.5728591680526733, Train Acc : 0.4855141674625915 , Val Acc : 0.4794871794871795\n",
      "Epoch 7213/10000, Loss: 1.6433929204940796, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7214/10000, Loss: 1.6812477111816406, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7215/10000, Loss: 1.5881855487823486, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7216/10000, Loss: 1.527779221534729, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7217/10000, Loss: 1.5330750942230225, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7218/10000, Loss: 1.4565409421920776, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7219/10000, Loss: 1.5736470222473145, Train Acc : 0.4855141674625915 , Val Acc : 0.48205128205128206\n",
      "Epoch 7220/10000, Loss: 1.521772861480713, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7221/10000, Loss: 1.5997686386108398, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7222/10000, Loss: 1.5716372728347778, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7223/10000, Loss: 1.5415799617767334, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7224/10000, Loss: 1.5002633333206177, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7225/10000, Loss: 1.5996220111846924, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7226/10000, Loss: 1.6035419702529907, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7227/10000, Loss: 1.5871034860610962, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7228/10000, Loss: 1.566706895828247, Train Acc : 0.48678764724609996 , Val Acc : 0.48205128205128206\n",
      "Epoch 7229/10000, Loss: 1.6226686239242554, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7230/10000, Loss: 1.5278059244155884, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7231/10000, Loss: 1.5519013404846191, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7232/10000, Loss: 1.5527584552764893, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7233/10000, Loss: 1.5188909769058228, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7234/10000, Loss: 1.5838528871536255, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7235/10000, Loss: 1.5893069505691528, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7236/10000, Loss: 1.559211015701294, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7237/10000, Loss: 1.5772528648376465, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7238/10000, Loss: 1.6131563186645508, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7239/10000, Loss: 1.5737780332565308, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7240/10000, Loss: 1.567134976387024, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7241/10000, Loss: 1.6031755208969116, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7242/10000, Loss: 1.5980217456817627, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7243/10000, Loss: 1.6848326921463013, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7244/10000, Loss: 1.5431897640228271, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7245/10000, Loss: 1.5793838500976562, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7246/10000, Loss: 1.6143989562988281, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7247/10000, Loss: 1.6256623268127441, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7248/10000, Loss: 1.6573864221572876, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7249/10000, Loss: 1.515159010887146, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7250/10000, Loss: 1.616835594177246, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7251/10000, Loss: 1.5783790349960327, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7252/10000, Loss: 1.577873706817627, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7253/10000, Loss: 1.6016952991485596, Train Acc : 0.48583253740846866 , Val Acc : 0.4794871794871795\n",
      "Epoch 7254/10000, Loss: 1.6063331365585327, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7255/10000, Loss: 1.479791283607483, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7256/10000, Loss: 1.6292319297790527, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7257/10000, Loss: 1.5495647192001343, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7258/10000, Loss: 1.4751795530319214, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7259/10000, Loss: 1.586132287979126, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7260/10000, Loss: 1.5803767442703247, Train Acc : 0.48678764724609996 , Val Acc : 0.48205128205128206\n",
      "Epoch 7261/10000, Loss: 1.5403975248336792, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7262/10000, Loss: 1.5656685829162598, Train Acc : 0.48615090735434574 , Val Acc : 0.48205128205128206\n",
      "Epoch 7263/10000, Loss: 1.5481497049331665, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7264/10000, Loss: 1.5489400625228882, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7265/10000, Loss: 1.4838829040527344, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7266/10000, Loss: 1.5945717096328735, Train Acc : 0.48583253740846866 , Val Acc : 0.48205128205128206\n",
      "Epoch 7267/10000, Loss: 1.5025060176849365, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7268/10000, Loss: 1.5730149745941162, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7269/10000, Loss: 1.5820376873016357, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7270/10000, Loss: 1.5108987092971802, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7271/10000, Loss: 1.5643926858901978, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7272/10000, Loss: 1.5575119256973267, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7273/10000, Loss: 1.5821173191070557, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7274/10000, Loss: 1.584983468055725, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7275/10000, Loss: 1.4992225170135498, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7276/10000, Loss: 1.6133766174316406, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7277/10000, Loss: 1.6044528484344482, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7278/10000, Loss: 1.438873291015625, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7279/10000, Loss: 1.550438404083252, Train Acc : 0.48678764724609996 , Val Acc : 0.48205128205128206\n",
      "Epoch 7280/10000, Loss: 1.6077814102172852, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7281/10000, Loss: 1.5268120765686035, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7282/10000, Loss: 1.600996732711792, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7283/10000, Loss: 1.5407774448394775, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7284/10000, Loss: 1.5247560739517212, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7285/10000, Loss: 1.6220639944076538, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7286/10000, Loss: 1.5121177434921265, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7287/10000, Loss: 1.5733152627944946, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7288/10000, Loss: 1.619439721107483, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7289/10000, Loss: 1.5401976108551025, Train Acc : 0.4864692773002229 , Val Acc : 0.48205128205128206\n",
      "Epoch 7290/10000, Loss: 1.6169403791427612, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7291/10000, Loss: 1.5104058980941772, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7292/10000, Loss: 1.6639795303344727, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7293/10000, Loss: 1.5315839052200317, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7294/10000, Loss: 1.5195107460021973, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7295/10000, Loss: 1.471167802810669, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7296/10000, Loss: 1.5396027565002441, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7297/10000, Loss: 1.6259584426879883, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7298/10000, Loss: 1.532906413078308, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7299/10000, Loss: 1.5395872592926025, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7300/10000, Loss: 1.535773754119873, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7301/10000, Loss: 1.6816215515136719, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7302/10000, Loss: 1.5884010791778564, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7303/10000, Loss: 1.5255953073501587, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7304/10000, Loss: 1.5774635076522827, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7305/10000, Loss: 1.5345251560211182, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7306/10000, Loss: 1.4872474670410156, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7307/10000, Loss: 1.558484435081482, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7308/10000, Loss: 1.5156883001327515, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7309/10000, Loss: 1.4794881343841553, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7310/10000, Loss: 1.5684343576431274, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7311/10000, Loss: 1.5163079500198364, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7312/10000, Loss: 1.5565497875213623, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7313/10000, Loss: 1.552803874015808, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7314/10000, Loss: 1.605012059211731, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7315/10000, Loss: 1.559079647064209, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7316/10000, Loss: 1.5654876232147217, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7317/10000, Loss: 1.5469063520431519, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7318/10000, Loss: 1.5264815092086792, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7319/10000, Loss: 1.6072990894317627, Train Acc : 0.48615090735434574 , Val Acc : 0.4794871794871795\n",
      "Epoch 7320/10000, Loss: 1.5216212272644043, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7321/10000, Loss: 1.49683678150177, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7322/10000, Loss: 1.6036465167999268, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7323/10000, Loss: 1.4917124509811401, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7324/10000, Loss: 1.6170449256896973, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7325/10000, Loss: 1.5450170040130615, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7326/10000, Loss: 1.5860449075698853, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7327/10000, Loss: 1.524336338043213, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7328/10000, Loss: 1.5960043668746948, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7329/10000, Loss: 1.505294680595398, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7330/10000, Loss: 1.532169222831726, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7331/10000, Loss: 1.578182578086853, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7332/10000, Loss: 1.5707955360412598, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7333/10000, Loss: 1.5430490970611572, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7334/10000, Loss: 1.575615644454956, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7335/10000, Loss: 1.5053038597106934, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7336/10000, Loss: 1.5994561910629272, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7337/10000, Loss: 1.5632890462875366, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7338/10000, Loss: 1.5759191513061523, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7339/10000, Loss: 1.5974217653274536, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7340/10000, Loss: 1.5161247253417969, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7341/10000, Loss: 1.4899457693099976, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7342/10000, Loss: 1.5853410959243774, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7343/10000, Loss: 1.553482174873352, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7344/10000, Loss: 1.5340886116027832, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7345/10000, Loss: 1.6005243062973022, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7346/10000, Loss: 1.511559247970581, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7347/10000, Loss: 1.5541743040084839, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7348/10000, Loss: 1.5144163370132446, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7349/10000, Loss: 1.4793967008590698, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7350/10000, Loss: 1.4658845663070679, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7351/10000, Loss: 1.5570517778396606, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7352/10000, Loss: 1.5602993965148926, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7353/10000, Loss: 1.5911270380020142, Train Acc : 0.4864692773002229 , Val Acc : 0.4794871794871795\n",
      "Epoch 7354/10000, Loss: 1.516788363456726, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7355/10000, Loss: 1.5484428405761719, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7356/10000, Loss: 1.5149110555648804, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7357/10000, Loss: 1.5372835397720337, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7358/10000, Loss: 1.5265153646469116, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7359/10000, Loss: 1.4783337116241455, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7360/10000, Loss: 1.551538348197937, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7361/10000, Loss: 1.4975364208221436, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7362/10000, Loss: 1.6273488998413086, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7363/10000, Loss: 1.641714096069336, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7364/10000, Loss: 1.5934022665023804, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7365/10000, Loss: 1.5669347047805786, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7366/10000, Loss: 1.5795358419418335, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7367/10000, Loss: 1.499712347984314, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7368/10000, Loss: 1.5853036642074585, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7369/10000, Loss: 1.4919772148132324, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7370/10000, Loss: 1.596054196357727, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7371/10000, Loss: 1.5091272592544556, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7372/10000, Loss: 1.4675284624099731, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7373/10000, Loss: 1.6604409217834473, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7374/10000, Loss: 1.5436936616897583, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7375/10000, Loss: 1.5567547082901, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7376/10000, Loss: 1.576615571975708, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7377/10000, Loss: 1.5090376138687134, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7378/10000, Loss: 1.6182239055633545, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7379/10000, Loss: 1.550565242767334, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7380/10000, Loss: 1.4911378622055054, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7381/10000, Loss: 1.5668985843658447, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7382/10000, Loss: 1.5570427179336548, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7383/10000, Loss: 1.5558381080627441, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7384/10000, Loss: 1.5105667114257812, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7385/10000, Loss: 1.4860635995864868, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7386/10000, Loss: 1.5217543840408325, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7387/10000, Loss: 1.6362930536270142, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7388/10000, Loss: 1.6169594526290894, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7389/10000, Loss: 1.6049113273620605, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7390/10000, Loss: 1.4764339923858643, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7391/10000, Loss: 1.4756138324737549, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7392/10000, Loss: 1.5804204940795898, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7393/10000, Loss: 1.5425702333450317, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7394/10000, Loss: 1.5688345432281494, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7395/10000, Loss: 1.5571250915527344, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7396/10000, Loss: 1.5801467895507812, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7397/10000, Loss: 1.5528684854507446, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7398/10000, Loss: 1.5937408208847046, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7399/10000, Loss: 1.587621808052063, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7400/10000, Loss: 1.6022573709487915, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7401/10000, Loss: 1.5926282405853271, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7402/10000, Loss: 1.4942212104797363, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7403/10000, Loss: 1.5883840322494507, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7404/10000, Loss: 1.585442304611206, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7405/10000, Loss: 1.6044895648956299, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7406/10000, Loss: 1.539857268333435, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7407/10000, Loss: 1.5343818664550781, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7408/10000, Loss: 1.5182863473892212, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7409/10000, Loss: 1.5332472324371338, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7410/10000, Loss: 1.520328164100647, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7411/10000, Loss: 1.5367275476455688, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7412/10000, Loss: 1.5593630075454712, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7413/10000, Loss: 1.533793568611145, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7414/10000, Loss: 1.585538387298584, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7415/10000, Loss: 1.4335153102874756, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7416/10000, Loss: 1.5660172700881958, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7417/10000, Loss: 1.5997198820114136, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7418/10000, Loss: 1.5651311874389648, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7419/10000, Loss: 1.535288691520691, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7420/10000, Loss: 1.560486912727356, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7421/10000, Loss: 1.5433766841888428, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7422/10000, Loss: 1.5938928127288818, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7423/10000, Loss: 1.5257757902145386, Train Acc : 0.4874243871378542 , Val Acc : 0.4794871794871795\n",
      "Epoch 7424/10000, Loss: 1.620919108390808, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7425/10000, Loss: 1.5708028078079224, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7426/10000, Loss: 1.513426423072815, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7427/10000, Loss: 1.5539089441299438, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7428/10000, Loss: 1.6714178323745728, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7429/10000, Loss: 1.5826982259750366, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7430/10000, Loss: 1.6019691228866577, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7431/10000, Loss: 1.493334412574768, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7432/10000, Loss: 1.4669122695922852, Train Acc : 0.48678764724609996 , Val Acc : 0.4794871794871795\n",
      "Epoch 7433/10000, Loss: 1.5574991703033447, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7434/10000, Loss: 1.5058238506317139, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7435/10000, Loss: 1.524627447128296, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7436/10000, Loss: 1.5972496271133423, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7437/10000, Loss: 1.556704044342041, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7438/10000, Loss: 1.501233696937561, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7439/10000, Loss: 1.5711873769760132, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7440/10000, Loss: 1.45548677444458, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7441/10000, Loss: 1.4865278005599976, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7442/10000, Loss: 1.545705795288086, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7443/10000, Loss: 1.6088907718658447, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7444/10000, Loss: 1.501489520072937, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7445/10000, Loss: 1.6782649755477905, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7446/10000, Loss: 1.573058843612671, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7447/10000, Loss: 1.5806691646575928, Train Acc : 0.48774275708373127 , Val Acc : 0.4794871794871795\n",
      "Epoch 7448/10000, Loss: 1.5165488719940186, Train Acc : 0.4871060171919771 , Val Acc : 0.4794871794871795\n",
      "Epoch 7449/10000, Loss: 1.5647176504135132, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7450/10000, Loss: 1.5924121141433716, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7451/10000, Loss: 1.5107097625732422, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7452/10000, Loss: 1.5141916275024414, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7453/10000, Loss: 1.5632599592208862, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7454/10000, Loss: 1.5805628299713135, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7455/10000, Loss: 1.5703165531158447, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7456/10000, Loss: 1.590695858001709, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7457/10000, Loss: 1.5196634531021118, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7458/10000, Loss: 1.5748201608657837, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7459/10000, Loss: 1.5648630857467651, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7460/10000, Loss: 1.5466995239257812, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7461/10000, Loss: 1.5452003479003906, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7462/10000, Loss: 1.4971473217010498, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7463/10000, Loss: 1.513175129890442, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7464/10000, Loss: 1.5407694578170776, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7465/10000, Loss: 1.5452302694320679, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7466/10000, Loss: 1.5569581985473633, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7467/10000, Loss: 1.5821144580841064, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7468/10000, Loss: 1.615828037261963, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7469/10000, Loss: 1.5700546503067017, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7470/10000, Loss: 1.539445161819458, Train Acc : 0.48933460681311686 , Val Acc : 0.4794871794871795\n",
      "Epoch 7471/10000, Loss: 1.5662548542022705, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7472/10000, Loss: 1.6629403829574585, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7473/10000, Loss: 1.628150224685669, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7474/10000, Loss: 1.5281705856323242, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7475/10000, Loss: 1.5742558240890503, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7476/10000, Loss: 1.585802435874939, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7477/10000, Loss: 1.5236138105392456, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7478/10000, Loss: 1.550661563873291, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7479/10000, Loss: 1.560411810874939, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7480/10000, Loss: 1.6128950119018555, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7481/10000, Loss: 1.5628244876861572, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7482/10000, Loss: 1.5917956829071045, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7483/10000, Loss: 1.5761109590530396, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7484/10000, Loss: 1.6099729537963867, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7485/10000, Loss: 1.608399748802185, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7486/10000, Loss: 1.5028356313705444, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7487/10000, Loss: 1.584100365638733, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7488/10000, Loss: 1.6011682748794556, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7489/10000, Loss: 1.618003487586975, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7490/10000, Loss: 1.6211884021759033, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7491/10000, Loss: 1.6267493963241577, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7492/10000, Loss: 1.5217547416687012, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7493/10000, Loss: 1.5113105773925781, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7494/10000, Loss: 1.5905207395553589, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7495/10000, Loss: 1.4787609577178955, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7496/10000, Loss: 1.4258946180343628, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7497/10000, Loss: 1.5277206897735596, Train Acc : 0.4880611270296084 , Val Acc : 0.48205128205128206\n",
      "Epoch 7498/10000, Loss: 1.6007163524627686, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7499/10000, Loss: 1.5456736087799072, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7500/10000, Loss: 1.5204001665115356, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7501/10000, Loss: 1.5224021673202515, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7502/10000, Loss: 1.5793828964233398, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7503/10000, Loss: 1.5750831365585327, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7504/10000, Loss: 1.5523021221160889, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7505/10000, Loss: 1.5159509181976318, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7506/10000, Loss: 1.5377198457717896, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7507/10000, Loss: 1.5743083953857422, Train Acc : 0.4880611270296084 , Val Acc : 0.4794871794871795\n",
      "Epoch 7508/10000, Loss: 1.5639863014221191, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7509/10000, Loss: 1.5861454010009766, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7510/10000, Loss: 1.5074223279953003, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7511/10000, Loss: 1.593489170074463, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7512/10000, Loss: 1.6163591146469116, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7513/10000, Loss: 1.5620360374450684, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7514/10000, Loss: 1.5758072137832642, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7515/10000, Loss: 1.5180091857910156, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7516/10000, Loss: 1.5390312671661377, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7517/10000, Loss: 1.5822080373764038, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7518/10000, Loss: 1.5367838144302368, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7519/10000, Loss: 1.5603718757629395, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7520/10000, Loss: 1.6409895420074463, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7521/10000, Loss: 1.6082700490951538, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7522/10000, Loss: 1.5201843976974487, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7523/10000, Loss: 1.4973794221878052, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7524/10000, Loss: 1.5704160928726196, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7525/10000, Loss: 1.5528411865234375, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7526/10000, Loss: 1.4778310060501099, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7527/10000, Loss: 1.6485555171966553, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7528/10000, Loss: 1.4950835704803467, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7529/10000, Loss: 1.518186330795288, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7530/10000, Loss: 1.4759068489074707, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7531/10000, Loss: 1.4644924402236938, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7532/10000, Loss: 1.4824568033218384, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7533/10000, Loss: 1.6109832525253296, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7534/10000, Loss: 1.603698492050171, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7535/10000, Loss: 1.5150532722473145, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7536/10000, Loss: 1.528141736984253, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7537/10000, Loss: 1.4920648336410522, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7538/10000, Loss: 1.552743911743164, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7539/10000, Loss: 1.5415380001068115, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7540/10000, Loss: 1.6218498945236206, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7541/10000, Loss: 1.5017220973968506, Train Acc : 0.4890162368672397 , Val Acc : 0.4794871794871795\n",
      "Epoch 7542/10000, Loss: 1.5774556398391724, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7543/10000, Loss: 1.5943182706832886, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7544/10000, Loss: 1.574469804763794, Train Acc : 0.48869786692136263 , Val Acc : 0.4794871794871795\n",
      "Epoch 7545/10000, Loss: 1.585752010345459, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7546/10000, Loss: 1.5110816955566406, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7547/10000, Loss: 1.4752429723739624, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7548/10000, Loss: 1.6396167278289795, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7549/10000, Loss: 1.5927109718322754, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7550/10000, Loss: 1.5683622360229492, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7551/10000, Loss: 1.5674949884414673, Train Acc : 0.4880611270296084 , Val Acc : 0.48205128205128206\n",
      "Epoch 7552/10000, Loss: 1.5576255321502686, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7553/10000, Loss: 1.6214942932128906, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7554/10000, Loss: 1.5431604385375977, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7555/10000, Loss: 1.5737007856369019, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7556/10000, Loss: 1.5818917751312256, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7557/10000, Loss: 1.5673621892929077, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7558/10000, Loss: 1.528080940246582, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7559/10000, Loss: 1.5724403858184814, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7560/10000, Loss: 1.5321998596191406, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7561/10000, Loss: 1.4655768871307373, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7562/10000, Loss: 1.4792732000350952, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7563/10000, Loss: 1.5880531072616577, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7564/10000, Loss: 1.447446584701538, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7565/10000, Loss: 1.6271653175354004, Train Acc : 0.4883794969754855 , Val Acc : 0.4794871794871795\n",
      "Epoch 7566/10000, Loss: 1.6386351585388184, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7567/10000, Loss: 1.511765718460083, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7568/10000, Loss: 1.6135998964309692, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7569/10000, Loss: 1.5380125045776367, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7570/10000, Loss: 1.5919063091278076, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7571/10000, Loss: 1.5663307905197144, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7572/10000, Loss: 1.5650519132614136, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7573/10000, Loss: 1.5197854042053223, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7574/10000, Loss: 1.5742911100387573, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7575/10000, Loss: 1.6219332218170166, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7576/10000, Loss: 1.5360571146011353, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7577/10000, Loss: 1.5688235759735107, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7578/10000, Loss: 1.4639307260513306, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7579/10000, Loss: 1.581472396850586, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7580/10000, Loss: 1.5284134149551392, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7581/10000, Loss: 1.5477142333984375, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7582/10000, Loss: 1.647192120552063, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7583/10000, Loss: 1.5590378046035767, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7584/10000, Loss: 1.5090497732162476, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7585/10000, Loss: 1.4926841259002686, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7586/10000, Loss: 1.5703518390655518, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7587/10000, Loss: 1.5523524284362793, Train Acc : 0.4880611270296084 , Val Acc : 0.48205128205128206\n",
      "Epoch 7588/10000, Loss: 1.6071345806121826, Train Acc : 0.4880611270296084 , Val Acc : 0.48205128205128206\n",
      "Epoch 7589/10000, Loss: 1.6026569604873657, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7590/10000, Loss: 1.5855724811553955, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7591/10000, Loss: 1.5307061672210693, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7592/10000, Loss: 1.6176586151123047, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7593/10000, Loss: 1.6015522480010986, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7594/10000, Loss: 1.6935303211212158, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7595/10000, Loss: 1.5562995672225952, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7596/10000, Loss: 1.5468661785125732, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7597/10000, Loss: 1.5514484643936157, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7598/10000, Loss: 1.629713535308838, Train Acc : 0.4880611270296084 , Val Acc : 0.48205128205128206\n",
      "Epoch 7599/10000, Loss: 1.5181301832199097, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7600/10000, Loss: 1.4927637577056885, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7601/10000, Loss: 1.6190574169158936, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7602/10000, Loss: 1.5889701843261719, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7603/10000, Loss: 1.4751626253128052, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7604/10000, Loss: 1.5027530193328857, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7605/10000, Loss: 1.5977461338043213, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7606/10000, Loss: 1.5968387126922607, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7607/10000, Loss: 1.599082589149475, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7608/10000, Loss: 1.5509065389633179, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7609/10000, Loss: 1.5345655679702759, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7610/10000, Loss: 1.4772311449050903, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7611/10000, Loss: 1.5166711807250977, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7612/10000, Loss: 1.5449426174163818, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7613/10000, Loss: 1.5380311012268066, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7614/10000, Loss: 1.5467463731765747, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7615/10000, Loss: 1.4958945512771606, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7616/10000, Loss: 1.4921280145645142, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7617/10000, Loss: 1.6076973676681519, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7618/10000, Loss: 1.6177198886871338, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7619/10000, Loss: 1.5033364295959473, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7620/10000, Loss: 1.5291038751602173, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7621/10000, Loss: 1.493333101272583, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7622/10000, Loss: 1.5356965065002441, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7623/10000, Loss: 1.6138023138046265, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7624/10000, Loss: 1.6362884044647217, Train Acc : 0.4883794969754855 , Val Acc : 0.48205128205128206\n",
      "Epoch 7625/10000, Loss: 1.4817063808441162, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7626/10000, Loss: 1.5939592123031616, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7627/10000, Loss: 1.634139895439148, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7628/10000, Loss: 1.5717486143112183, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7629/10000, Loss: 1.562711477279663, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7630/10000, Loss: 1.5201561450958252, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7631/10000, Loss: 1.4791465997695923, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7632/10000, Loss: 1.567137360572815, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7633/10000, Loss: 1.5180319547653198, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7634/10000, Loss: 1.5366816520690918, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7635/10000, Loss: 1.5878130197525024, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7636/10000, Loss: 1.620587706565857, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7637/10000, Loss: 1.4644324779510498, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7638/10000, Loss: 1.570210576057434, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7639/10000, Loss: 1.5523757934570312, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7640/10000, Loss: 1.5299632549285889, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7641/10000, Loss: 1.5916736125946045, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7642/10000, Loss: 1.5417248010635376, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7643/10000, Loss: 1.5241440534591675, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7644/10000, Loss: 1.5383833646774292, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7645/10000, Loss: 1.5219796895980835, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7646/10000, Loss: 1.5789817571640015, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7647/10000, Loss: 1.5686049461364746, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7648/10000, Loss: 1.5999962091445923, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7649/10000, Loss: 1.5355569124221802, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7650/10000, Loss: 1.4854682683944702, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7651/10000, Loss: 1.5163534879684448, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7652/10000, Loss: 1.57392418384552, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7653/10000, Loss: 1.510594129562378, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7654/10000, Loss: 1.571176528930664, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7655/10000, Loss: 1.6242386102676392, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7656/10000, Loss: 1.5960190296173096, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7657/10000, Loss: 1.582843542098999, Train Acc : 0.48869786692136263 , Val Acc : 0.48205128205128206\n",
      "Epoch 7658/10000, Loss: 1.5043734312057495, Train Acc : 0.4890162368672397 , Val Acc : 0.48205128205128206\n",
      "Epoch 7659/10000, Loss: 1.6274349689483643, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7660/10000, Loss: 1.5054244995117188, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7661/10000, Loss: 1.4676262140274048, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7662/10000, Loss: 1.5168949365615845, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7663/10000, Loss: 1.5229439735412598, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7664/10000, Loss: 1.5306726694107056, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7665/10000, Loss: 1.513444423675537, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7666/10000, Loss: 1.5981391668319702, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7667/10000, Loss: 1.5115842819213867, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7668/10000, Loss: 1.5788025856018066, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7669/10000, Loss: 1.5445204973220825, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7670/10000, Loss: 1.6370177268981934, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7671/10000, Loss: 1.5221362113952637, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7672/10000, Loss: 1.524294137954712, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7673/10000, Loss: 1.4960756301879883, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7674/10000, Loss: 1.507699966430664, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7675/10000, Loss: 1.5854288339614868, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7676/10000, Loss: 1.5944836139678955, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7677/10000, Loss: 1.5519195795059204, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7678/10000, Loss: 1.5055413246154785, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7679/10000, Loss: 1.533133625984192, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7680/10000, Loss: 1.5278457403182983, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7681/10000, Loss: 1.5617755651474, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7682/10000, Loss: 1.5570259094238281, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7683/10000, Loss: 1.5376451015472412, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7684/10000, Loss: 1.4504762887954712, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7685/10000, Loss: 1.4638335704803467, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7686/10000, Loss: 1.542862057685852, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7687/10000, Loss: 1.6234742403030396, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7688/10000, Loss: 1.5058799982070923, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7689/10000, Loss: 1.5005290508270264, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7690/10000, Loss: 1.4870789051055908, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7691/10000, Loss: 1.5180137157440186, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7692/10000, Loss: 1.6060688495635986, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7693/10000, Loss: 1.5673542022705078, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7694/10000, Loss: 1.543907880783081, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7695/10000, Loss: 1.5922553539276123, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7696/10000, Loss: 1.5636736154556274, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7697/10000, Loss: 1.6444340944290161, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7698/10000, Loss: 1.5280786752700806, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7699/10000, Loss: 1.5846465826034546, Train Acc : 0.48933460681311686 , Val Acc : 0.48205128205128206\n",
      "Epoch 7700/10000, Loss: 1.5317672491073608, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7701/10000, Loss: 1.5500777959823608, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7702/10000, Loss: 1.4959059953689575, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7703/10000, Loss: 1.5071989297866821, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7704/10000, Loss: 1.6005655527114868, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7705/10000, Loss: 1.5762723684310913, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7706/10000, Loss: 1.4995673894882202, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7707/10000, Loss: 1.5682601928710938, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7708/10000, Loss: 1.5982143878936768, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7709/10000, Loss: 1.5402278900146484, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7710/10000, Loss: 1.484584093093872, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7711/10000, Loss: 1.5449917316436768, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7712/10000, Loss: 1.6287081241607666, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7713/10000, Loss: 1.559658408164978, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7714/10000, Loss: 1.529942274093628, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7715/10000, Loss: 1.4808692932128906, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7716/10000, Loss: 1.5116863250732422, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7717/10000, Loss: 1.598581075668335, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7718/10000, Loss: 1.4778378009796143, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7719/10000, Loss: 1.496916651725769, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7720/10000, Loss: 1.5057636499404907, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7721/10000, Loss: 1.6249639987945557, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7722/10000, Loss: 1.4975342750549316, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7723/10000, Loss: 1.4835585355758667, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7724/10000, Loss: 1.5331475734710693, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7725/10000, Loss: 1.5588047504425049, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7726/10000, Loss: 1.5190515518188477, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7727/10000, Loss: 1.6079142093658447, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7728/10000, Loss: 1.5728788375854492, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7729/10000, Loss: 1.5217680931091309, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7730/10000, Loss: 1.5162765979766846, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7731/10000, Loss: 1.6274323463439941, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7732/10000, Loss: 1.549487590789795, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7733/10000, Loss: 1.4733424186706543, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7734/10000, Loss: 1.6148251295089722, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7735/10000, Loss: 1.5603793859481812, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7736/10000, Loss: 1.6454318761825562, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7737/10000, Loss: 1.5844202041625977, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7738/10000, Loss: 1.5493502616882324, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7739/10000, Loss: 1.4528149366378784, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7740/10000, Loss: 1.577222228050232, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7741/10000, Loss: 1.5530024766921997, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7742/10000, Loss: 1.5534287691116333, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7743/10000, Loss: 1.4842898845672607, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7744/10000, Loss: 1.5502744913101196, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7745/10000, Loss: 1.4872652292251587, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7746/10000, Loss: 1.532663106918335, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7747/10000, Loss: 1.5346711874008179, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7748/10000, Loss: 1.5690391063690186, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7749/10000, Loss: 1.5564582347869873, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7750/10000, Loss: 1.53532874584198, Train Acc : 0.4899713467048711 , Val Acc : 0.48205128205128206\n",
      "Epoch 7751/10000, Loss: 1.6403836011886597, Train Acc : 0.4899713467048711 , Val Acc : 0.4846153846153846\n",
      "Epoch 7752/10000, Loss: 1.560296893119812, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7753/10000, Loss: 1.5755208730697632, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7754/10000, Loss: 1.6087242364883423, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7755/10000, Loss: 1.6234772205352783, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7756/10000, Loss: 1.6024150848388672, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7757/10000, Loss: 1.6062606573104858, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7758/10000, Loss: 1.5701091289520264, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7759/10000, Loss: 1.4586281776428223, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7760/10000, Loss: 1.5754441022872925, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7761/10000, Loss: 1.5964168310165405, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7762/10000, Loss: 1.58869469165802, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7763/10000, Loss: 1.561754584312439, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7764/10000, Loss: 1.5317188501358032, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7765/10000, Loss: 1.4549260139465332, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7766/10000, Loss: 1.62606680393219, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7767/10000, Loss: 1.6674870252609253, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7768/10000, Loss: 1.5876414775848389, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7769/10000, Loss: 1.664361596107483, Train Acc : 0.48965297675899394 , Val Acc : 0.48205128205128206\n",
      "Epoch 7770/10000, Loss: 1.6760200262069702, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7771/10000, Loss: 1.54449462890625, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7772/10000, Loss: 1.5357201099395752, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7773/10000, Loss: 1.5430233478546143, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7774/10000, Loss: 1.493407130241394, Train Acc : 0.4906080865966253 , Val Acc : 0.48205128205128206\n",
      "Epoch 7775/10000, Loss: 1.5916996002197266, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7776/10000, Loss: 1.5265343189239502, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7777/10000, Loss: 1.5696696043014526, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7778/10000, Loss: 1.6552624702453613, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7779/10000, Loss: 1.6230913400650024, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7780/10000, Loss: 1.574644923210144, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7781/10000, Loss: 1.5383810997009277, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7782/10000, Loss: 1.5409201383590698, Train Acc : 0.48965297675899394 , Val Acc : 0.4846153846153846\n",
      "Epoch 7783/10000, Loss: 1.647828459739685, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7784/10000, Loss: 1.5420769453048706, Train Acc : 0.4899713467048711 , Val Acc : 0.4846153846153846\n",
      "Epoch 7785/10000, Loss: 1.642682671546936, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7786/10000, Loss: 1.5159642696380615, Train Acc : 0.48965297675899394 , Val Acc : 0.4846153846153846\n",
      "Epoch 7787/10000, Loss: 1.5572974681854248, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7788/10000, Loss: 1.6147072315216064, Train Acc : 0.49028971665074816 , Val Acc : 0.4846153846153846\n",
      "Epoch 7789/10000, Loss: 1.5495924949645996, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7790/10000, Loss: 1.5544278621673584, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7791/10000, Loss: 1.59962797164917, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7792/10000, Loss: 1.5081368684768677, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7793/10000, Loss: 1.6365654468536377, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7794/10000, Loss: 1.5193885564804077, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7795/10000, Loss: 1.4599530696868896, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7796/10000, Loss: 1.5933289527893066, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7797/10000, Loss: 1.6013803482055664, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7798/10000, Loss: 1.5833823680877686, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7799/10000, Loss: 1.5802083015441895, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7800/10000, Loss: 1.621889591217041, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7801/10000, Loss: 1.6069875955581665, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7802/10000, Loss: 1.5780832767486572, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7803/10000, Loss: 1.5659003257751465, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7804/10000, Loss: 1.5846967697143555, Train Acc : 0.49028971665074816 , Val Acc : 0.4846153846153846\n",
      "Epoch 7805/10000, Loss: 1.5660970211029053, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7806/10000, Loss: 1.5256160497665405, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7807/10000, Loss: 1.508763313293457, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7808/10000, Loss: 1.5100364685058594, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7809/10000, Loss: 1.5679597854614258, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7810/10000, Loss: 1.5593950748443604, Train Acc : 0.49028971665074816 , Val Acc : 0.48205128205128206\n",
      "Epoch 7811/10000, Loss: 1.6013636589050293, Train Acc : 0.4899713467048711 , Val Acc : 0.4846153846153846\n",
      "Epoch 7812/10000, Loss: 1.4714852571487427, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7813/10000, Loss: 1.5471123456954956, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7814/10000, Loss: 1.5744869709014893, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7815/10000, Loss: 1.5403430461883545, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7816/10000, Loss: 1.5557252168655396, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7817/10000, Loss: 1.5405093431472778, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7818/10000, Loss: 1.547286033630371, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7819/10000, Loss: 1.5759902000427246, Train Acc : 0.49028971665074816 , Val Acc : 0.4846153846153846\n",
      "Epoch 7820/10000, Loss: 1.540008544921875, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7821/10000, Loss: 1.5741245746612549, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7822/10000, Loss: 1.5765256881713867, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7823/10000, Loss: 1.495266079902649, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7824/10000, Loss: 1.5962097644805908, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7825/10000, Loss: 1.592734694480896, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7826/10000, Loss: 1.552633285522461, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7827/10000, Loss: 1.5464410781860352, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7828/10000, Loss: 1.6393498182296753, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7829/10000, Loss: 1.5202094316482544, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7830/10000, Loss: 1.5767178535461426, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7831/10000, Loss: 1.600119948387146, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7832/10000, Loss: 1.5690704584121704, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7833/10000, Loss: 1.558394432067871, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7834/10000, Loss: 1.5678962469100952, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7835/10000, Loss: 1.5762693881988525, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7836/10000, Loss: 1.4213181734085083, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7837/10000, Loss: 1.542342185974121, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7838/10000, Loss: 1.5307449102401733, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7839/10000, Loss: 1.5901356935501099, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7840/10000, Loss: 1.4763109683990479, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7841/10000, Loss: 1.587486982345581, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7842/10000, Loss: 1.5554462671279907, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7843/10000, Loss: 1.4931081533432007, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7844/10000, Loss: 1.5289608240127563, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7845/10000, Loss: 1.5393708944320679, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7846/10000, Loss: 1.5883426666259766, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7847/10000, Loss: 1.5688176155090332, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7848/10000, Loss: 1.5671972036361694, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7849/10000, Loss: 1.4741485118865967, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7850/10000, Loss: 1.4785484075546265, Train Acc : 0.4915631964342566 , Val Acc : 0.48205128205128206\n",
      "Epoch 7851/10000, Loss: 1.5611903667449951, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7852/10000, Loss: 1.5232632160186768, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7853/10000, Loss: 1.618022084236145, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7854/10000, Loss: 1.6527748107910156, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7855/10000, Loss: 1.5585497617721558, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7856/10000, Loss: 1.6596453189849854, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7857/10000, Loss: 1.600508689880371, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7858/10000, Loss: 1.5855895280838013, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7859/10000, Loss: 1.5755428075790405, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7860/10000, Loss: 1.546911358833313, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7861/10000, Loss: 1.5300949811935425, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7862/10000, Loss: 1.5569859743118286, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7863/10000, Loss: 1.6039563417434692, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7864/10000, Loss: 1.49991774559021, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7865/10000, Loss: 1.5376996994018555, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7866/10000, Loss: 1.5083897113800049, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7867/10000, Loss: 1.5947415828704834, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7868/10000, Loss: 1.546554684638977, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7869/10000, Loss: 1.6189197301864624, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7870/10000, Loss: 1.4828529357910156, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7871/10000, Loss: 1.512023687362671, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7872/10000, Loss: 1.5514416694641113, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7873/10000, Loss: 1.5162839889526367, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7874/10000, Loss: 1.5975946187973022, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7875/10000, Loss: 1.5681917667388916, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7876/10000, Loss: 1.5846216678619385, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7877/10000, Loss: 1.479788899421692, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7878/10000, Loss: 1.644588828086853, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7879/10000, Loss: 1.5481537580490112, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7880/10000, Loss: 1.5492780208587646, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7881/10000, Loss: 1.5624926090240479, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7882/10000, Loss: 1.5378557443618774, Train Acc : 0.4906080865966253 , Val Acc : 0.4846153846153846\n",
      "Epoch 7883/10000, Loss: 1.5919945240020752, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7884/10000, Loss: 1.5202858448028564, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7885/10000, Loss: 1.4584726095199585, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7886/10000, Loss: 1.6675666570663452, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7887/10000, Loss: 1.6012319326400757, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7888/10000, Loss: 1.6582647562026978, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7889/10000, Loss: 1.5906490087509155, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7890/10000, Loss: 1.5821484327316284, Train Acc : 0.49219993632601083 , Val Acc : 0.48205128205128206\n",
      "Epoch 7891/10000, Loss: 1.618183970451355, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7892/10000, Loss: 1.5197906494140625, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7893/10000, Loss: 1.6482391357421875, Train Acc : 0.49124482648837947 , Val Acc : 0.48205128205128206\n",
      "Epoch 7894/10000, Loss: 1.5483598709106445, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7895/10000, Loss: 1.5504405498504639, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7896/10000, Loss: 1.5612225532531738, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7897/10000, Loss: 1.502838373184204, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7898/10000, Loss: 1.5493417978286743, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7899/10000, Loss: 1.5462830066680908, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7900/10000, Loss: 1.5238795280456543, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7901/10000, Loss: 1.4958598613739014, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7902/10000, Loss: 1.5562589168548584, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7903/10000, Loss: 1.4861303567886353, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7904/10000, Loss: 1.4853880405426025, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7905/10000, Loss: 1.515152096748352, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7906/10000, Loss: 1.574408769607544, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7907/10000, Loss: 1.652368187904358, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7908/10000, Loss: 1.5914182662963867, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7909/10000, Loss: 1.6563804149627686, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7910/10000, Loss: 1.5353118181228638, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7911/10000, Loss: 1.5458381175994873, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7912/10000, Loss: 1.5604017972946167, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7913/10000, Loss: 1.6171871423721313, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7914/10000, Loss: 1.4882097244262695, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7915/10000, Loss: 1.6051905155181885, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7916/10000, Loss: 1.5619288682937622, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7917/10000, Loss: 1.5203912258148193, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7918/10000, Loss: 1.5413802862167358, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7919/10000, Loss: 1.5663032531738281, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7920/10000, Loss: 1.496124029159546, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7921/10000, Loss: 1.500237226486206, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7922/10000, Loss: 1.505013346672058, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7923/10000, Loss: 1.6067533493041992, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7924/10000, Loss: 1.6162073612213135, Train Acc : 0.4909264565425024 , Val Acc : 0.48205128205128206\n",
      "Epoch 7925/10000, Loss: 1.5688140392303467, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7926/10000, Loss: 1.5305910110473633, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 7927/10000, Loss: 1.6311323642730713, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7928/10000, Loss: 1.5814814567565918, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7929/10000, Loss: 1.5328633785247803, Train Acc : 0.4909264565425024 , Val Acc : 0.4846153846153846\n",
      "Epoch 7930/10000, Loss: 1.5619275569915771, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7931/10000, Loss: 1.4974794387817383, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7932/10000, Loss: 1.51865816116333, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7933/10000, Loss: 1.5517605543136597, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 7934/10000, Loss: 1.5414403676986694, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7935/10000, Loss: 1.5461252927780151, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7936/10000, Loss: 1.4723119735717773, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7937/10000, Loss: 1.5072050094604492, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7938/10000, Loss: 1.566999077796936, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7939/10000, Loss: 1.6266120672225952, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7940/10000, Loss: 1.5826897621154785, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7941/10000, Loss: 1.5369224548339844, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7942/10000, Loss: 1.577345609664917, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7943/10000, Loss: 1.6163794994354248, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7944/10000, Loss: 1.4816639423370361, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7945/10000, Loss: 1.647088646888733, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7946/10000, Loss: 1.5882588624954224, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7947/10000, Loss: 1.55514395236969, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7948/10000, Loss: 1.5194700956344604, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7949/10000, Loss: 1.5629916191101074, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7950/10000, Loss: 1.6270729303359985, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7951/10000, Loss: 1.5020304918289185, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 7952/10000, Loss: 1.5258606672286987, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7953/10000, Loss: 1.4740763902664185, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7954/10000, Loss: 1.4744163751602173, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7955/10000, Loss: 1.5271201133728027, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7956/10000, Loss: 1.544495701789856, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7957/10000, Loss: 1.6435483694076538, Train Acc : 0.4915631964342566 , Val Acc : 0.48205128205128206\n",
      "Epoch 7958/10000, Loss: 1.5007282495498657, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7959/10000, Loss: 1.5581856966018677, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 7960/10000, Loss: 1.4824448823928833, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7961/10000, Loss: 1.5206797122955322, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 7962/10000, Loss: 1.5122445821762085, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 7963/10000, Loss: 1.5485138893127441, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7964/10000, Loss: 1.596960186958313, Train Acc : 0.4915631964342566 , Val Acc : 0.48205128205128206\n",
      "Epoch 7965/10000, Loss: 1.6312357187271118, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7966/10000, Loss: 1.614964246749878, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7967/10000, Loss: 1.6499052047729492, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7968/10000, Loss: 1.5774036645889282, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7969/10000, Loss: 1.5400525331497192, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7970/10000, Loss: 1.6013933420181274, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7971/10000, Loss: 1.617424726486206, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 7972/10000, Loss: 1.5329735279083252, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7973/10000, Loss: 1.561387300491333, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7974/10000, Loss: 1.6319836378097534, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7975/10000, Loss: 1.5358625650405884, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7976/10000, Loss: 1.5121219158172607, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7977/10000, Loss: 1.5742202997207642, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7978/10000, Loss: 1.514702558517456, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7979/10000, Loss: 1.5789090394973755, Train Acc : 0.49124482648837947 , Val Acc : 0.4846153846153846\n",
      "Epoch 7980/10000, Loss: 1.5809433460235596, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7981/10000, Loss: 1.6031724214553833, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7982/10000, Loss: 1.619248390197754, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7983/10000, Loss: 1.4643083810806274, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7984/10000, Loss: 1.5793373584747314, Train Acc : 0.49219993632601083 , Val Acc : 0.48205128205128206\n",
      "Epoch 7985/10000, Loss: 1.5315320491790771, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7986/10000, Loss: 1.5729717016220093, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 7987/10000, Loss: 1.5853488445281982, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7988/10000, Loss: 1.5603268146514893, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7989/10000, Loss: 1.5041011571884155, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7990/10000, Loss: 1.4758065938949585, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7991/10000, Loss: 1.5596373081207275, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 7992/10000, Loss: 1.5319443941116333, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 7993/10000, Loss: 1.578659176826477, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7994/10000, Loss: 1.558322787284851, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7995/10000, Loss: 1.5717841386795044, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7996/10000, Loss: 1.537397027015686, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7997/10000, Loss: 1.4875373840332031, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 7998/10000, Loss: 1.4353264570236206, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 7999/10000, Loss: 1.4716416597366333, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8000/10000, Loss: 1.6130328178405762, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8001/10000, Loss: 1.554212212562561, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8002/10000, Loss: 1.529572606086731, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8003/10000, Loss: 1.5241615772247314, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8004/10000, Loss: 1.5023002624511719, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8005/10000, Loss: 1.5366758108139038, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8006/10000, Loss: 1.5950427055358887, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8007/10000, Loss: 1.512618064880371, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 8008/10000, Loss: 1.612668752670288, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8009/10000, Loss: 1.5108596086502075, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8010/10000, Loss: 1.530558466911316, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8011/10000, Loss: 1.5171151161193848, Train Acc : 0.49219993632601083 , Val Acc : 0.48205128205128206\n",
      "Epoch 8012/10000, Loss: 1.5996607542037964, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8013/10000, Loss: 1.631078839302063, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8014/10000, Loss: 1.564818263053894, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8015/10000, Loss: 1.5107163190841675, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8016/10000, Loss: 1.6093906164169312, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8017/10000, Loss: 1.5534902811050415, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8018/10000, Loss: 1.4581239223480225, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8019/10000, Loss: 1.5369375944137573, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8020/10000, Loss: 1.585947871208191, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 8021/10000, Loss: 1.4532301425933838, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 8022/10000, Loss: 1.5975446701049805, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8023/10000, Loss: 1.5451395511627197, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8024/10000, Loss: 1.6279443502426147, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 8025/10000, Loss: 1.5344947576522827, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8026/10000, Loss: 1.5104775428771973, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8027/10000, Loss: 1.537001371383667, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8028/10000, Loss: 1.5592823028564453, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8029/10000, Loss: 1.5139753818511963, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8030/10000, Loss: 1.5474897623062134, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8031/10000, Loss: 1.5592366456985474, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8032/10000, Loss: 1.5350970029830933, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8033/10000, Loss: 1.5396171808242798, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8034/10000, Loss: 1.5129212141036987, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8035/10000, Loss: 1.6184226274490356, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8036/10000, Loss: 1.5471277236938477, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 8037/10000, Loss: 1.5848411321640015, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8038/10000, Loss: 1.5957084894180298, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8039/10000, Loss: 1.5291249752044678, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8040/10000, Loss: 1.5020419359207153, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8041/10000, Loss: 1.5243040323257446, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8042/10000, Loss: 1.5062094926834106, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8043/10000, Loss: 1.5584360361099243, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8044/10000, Loss: 1.6428085565567017, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8045/10000, Loss: 1.5188201665878296, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8046/10000, Loss: 1.472355842590332, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8047/10000, Loss: 1.7294005155563354, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8048/10000, Loss: 1.5227320194244385, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8049/10000, Loss: 1.559249997138977, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8050/10000, Loss: 1.508241891860962, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8051/10000, Loss: 1.555262565612793, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8052/10000, Loss: 1.5762906074523926, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8053/10000, Loss: 1.5682859420776367, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8054/10000, Loss: 1.4914252758026123, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8055/10000, Loss: 1.589214563369751, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8056/10000, Loss: 1.5319664478302002, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8057/10000, Loss: 1.559831976890564, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8058/10000, Loss: 1.605357050895691, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8059/10000, Loss: 1.5231012105941772, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8060/10000, Loss: 1.5473875999450684, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8061/10000, Loss: 1.577104091644287, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8062/10000, Loss: 1.4540646076202393, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8063/10000, Loss: 1.5348457098007202, Train Acc : 0.4925183062718879 , Val Acc : 0.48205128205128206\n",
      "Epoch 8064/10000, Loss: 1.608465552330017, Train Acc : 0.49283667621776506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8065/10000, Loss: 1.6047955751419067, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8066/10000, Loss: 1.5956478118896484, Train Acc : 0.49219993632601083 , Val Acc : 0.48205128205128206\n",
      "Epoch 8067/10000, Loss: 1.629963994026184, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8068/10000, Loss: 1.5723545551300049, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8069/10000, Loss: 1.6517661809921265, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8070/10000, Loss: 1.5606520175933838, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8071/10000, Loss: 1.4525339603424072, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8072/10000, Loss: 1.5372825860977173, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8073/10000, Loss: 1.567624807357788, Train Acc : 0.49283667621776506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8074/10000, Loss: 1.5347776412963867, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8075/10000, Loss: 1.6095107793807983, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8076/10000, Loss: 1.499237298965454, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 8077/10000, Loss: 1.5062274932861328, Train Acc : 0.4918815663801337 , Val Acc : 0.48205128205128206\n",
      "Epoch 8078/10000, Loss: 1.67251455783844, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8079/10000, Loss: 1.5806641578674316, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8080/10000, Loss: 1.562082052230835, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8081/10000, Loss: 1.5181300640106201, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8082/10000, Loss: 1.5577036142349243, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8083/10000, Loss: 1.5287481546401978, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8084/10000, Loss: 1.5540729761123657, Train Acc : 0.4915631964342566 , Val Acc : 0.4846153846153846\n",
      "Epoch 8085/10000, Loss: 1.5453397035598755, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8086/10000, Loss: 1.587401032447815, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8087/10000, Loss: 1.616815209388733, Train Acc : 0.49283667621776506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8088/10000, Loss: 1.5565025806427002, Train Acc : 0.49219993632601083 , Val Acc : 0.48205128205128206\n",
      "Epoch 8089/10000, Loss: 1.4951552152633667, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8090/10000, Loss: 1.5098851919174194, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8091/10000, Loss: 1.5344231128692627, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8092/10000, Loss: 1.4999524354934692, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8093/10000, Loss: 1.5796736478805542, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8094/10000, Loss: 1.6086516380310059, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8095/10000, Loss: 1.522859811782837, Train Acc : 0.4918815663801337 , Val Acc : 0.4846153846153846\n",
      "Epoch 8096/10000, Loss: 1.5471397638320923, Train Acc : 0.49219993632601083 , Val Acc : 0.48205128205128206\n",
      "Epoch 8097/10000, Loss: 1.580828070640564, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8098/10000, Loss: 1.5687317848205566, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8099/10000, Loss: 1.632496953010559, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8100/10000, Loss: 1.5134210586547852, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8101/10000, Loss: 1.5742155313491821, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8102/10000, Loss: 1.5390872955322266, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8103/10000, Loss: 1.5386911630630493, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8104/10000, Loss: 1.5372459888458252, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8105/10000, Loss: 1.580485463142395, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8106/10000, Loss: 1.5371663570404053, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8107/10000, Loss: 1.491014838218689, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8108/10000, Loss: 1.5206352472305298, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8109/10000, Loss: 1.6098673343658447, Train Acc : 0.49219993632601083 , Val Acc : 0.4846153846153846\n",
      "Epoch 8110/10000, Loss: 1.516347885131836, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8111/10000, Loss: 1.5896570682525635, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8112/10000, Loss: 1.537559986114502, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8113/10000, Loss: 1.4752544164657593, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8114/10000, Loss: 1.6537566184997559, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8115/10000, Loss: 1.521048903465271, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8116/10000, Loss: 1.5707439184188843, Train Acc : 0.49283667621776506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8117/10000, Loss: 1.5509305000305176, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8118/10000, Loss: 1.4865928888320923, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8119/10000, Loss: 1.5250803232192993, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8120/10000, Loss: 1.5263296365737915, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8121/10000, Loss: 1.5621699094772339, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8122/10000, Loss: 1.5658596754074097, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8123/10000, Loss: 1.5428812503814697, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8124/10000, Loss: 1.5146023035049438, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8125/10000, Loss: 1.553504467010498, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8126/10000, Loss: 1.517830491065979, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8127/10000, Loss: 1.552618145942688, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8128/10000, Loss: 1.5525805950164795, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8129/10000, Loss: 1.452675700187683, Train Acc : 0.49283667621776506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8130/10000, Loss: 1.6366288661956787, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8131/10000, Loss: 1.577223300933838, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8132/10000, Loss: 1.5009218454360962, Train Acc : 0.49283667621776506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8133/10000, Loss: 1.4970160722732544, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8134/10000, Loss: 1.5099704265594482, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8135/10000, Loss: 1.580093502998352, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8136/10000, Loss: 1.5522563457489014, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8137/10000, Loss: 1.6036326885223389, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8138/10000, Loss: 1.521935224533081, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8139/10000, Loss: 1.5300925970077515, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8140/10000, Loss: 1.5304853916168213, Train Acc : 0.49283667621776506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8141/10000, Loss: 1.548048496246338, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8142/10000, Loss: 1.5099585056304932, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8143/10000, Loss: 1.5091136693954468, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8144/10000, Loss: 1.5154303312301636, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8145/10000, Loss: 1.5974278450012207, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8146/10000, Loss: 1.5383507013320923, Train Acc : 0.4934734161095193 , Val Acc : 0.4794871794871795\n",
      "Epoch 8147/10000, Loss: 1.5038491487503052, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8148/10000, Loss: 1.5603302717208862, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8149/10000, Loss: 1.442838430404663, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8150/10000, Loss: 1.6627215147018433, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8151/10000, Loss: 1.5819218158721924, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8152/10000, Loss: 1.5571293830871582, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8153/10000, Loss: 1.5239614248275757, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8154/10000, Loss: 1.5289291143417358, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8155/10000, Loss: 1.515127420425415, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8156/10000, Loss: 1.5931320190429688, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8157/10000, Loss: 1.5487860441207886, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8158/10000, Loss: 1.433038592338562, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8159/10000, Loss: 1.5236413478851318, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8160/10000, Loss: 1.551771640777588, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8161/10000, Loss: 1.5710505247116089, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8162/10000, Loss: 1.5222455263137817, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8163/10000, Loss: 1.6293598413467407, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8164/10000, Loss: 1.541335940361023, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8165/10000, Loss: 1.4956978559494019, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8166/10000, Loss: 1.5655418634414673, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8167/10000, Loss: 1.4659278392791748, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8168/10000, Loss: 1.6077059507369995, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8169/10000, Loss: 1.532447338104248, Train Acc : 0.4925183062718879 , Val Acc : 0.4846153846153846\n",
      "Epoch 8170/10000, Loss: 1.5704028606414795, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8171/10000, Loss: 1.5646488666534424, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8172/10000, Loss: 1.6305863857269287, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8173/10000, Loss: 1.615655541419983, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8174/10000, Loss: 1.6015866994857788, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8175/10000, Loss: 1.5362309217453003, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8176/10000, Loss: 1.5240147113800049, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8177/10000, Loss: 1.544142723083496, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8178/10000, Loss: 1.5177643299102783, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8179/10000, Loss: 1.499396562576294, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8180/10000, Loss: 1.4846974611282349, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8181/10000, Loss: 1.4809050559997559, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8182/10000, Loss: 1.5400097370147705, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8183/10000, Loss: 1.5463688373565674, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8184/10000, Loss: 1.5555474758148193, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8185/10000, Loss: 1.530434250831604, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8186/10000, Loss: 1.6039202213287354, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8187/10000, Loss: 1.5245550870895386, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8188/10000, Loss: 1.6026575565338135, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8189/10000, Loss: 1.5221612453460693, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8190/10000, Loss: 1.5359183549880981, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8191/10000, Loss: 1.5526834726333618, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8192/10000, Loss: 1.5222105979919434, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8193/10000, Loss: 1.5529851913452148, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8194/10000, Loss: 1.60231614112854, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8195/10000, Loss: 1.517670750617981, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8196/10000, Loss: 1.5655744075775146, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8197/10000, Loss: 1.5251375436782837, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8198/10000, Loss: 1.5632147789001465, Train Acc : 0.49379178605539636 , Val Acc : 0.4794871794871795\n",
      "Epoch 8199/10000, Loss: 1.547238826751709, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8200/10000, Loss: 1.5778651237487793, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8201/10000, Loss: 1.5037232637405396, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8202/10000, Loss: 1.6151096820831299, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8203/10000, Loss: 1.549729585647583, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8204/10000, Loss: 1.6085917949676514, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8205/10000, Loss: 1.5696940422058105, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8206/10000, Loss: 1.5484718084335327, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8207/10000, Loss: 1.5213664770126343, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8208/10000, Loss: 1.5101810693740845, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8209/10000, Loss: 1.5567508935928345, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8210/10000, Loss: 1.4956687688827515, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8211/10000, Loss: 1.5910459756851196, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8212/10000, Loss: 1.5595910549163818, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8213/10000, Loss: 1.5592584609985352, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8214/10000, Loss: 1.5399681329727173, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8215/10000, Loss: 1.5465946197509766, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8216/10000, Loss: 1.5718424320220947, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8217/10000, Loss: 1.5231789350509644, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8218/10000, Loss: 1.5413790941238403, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8219/10000, Loss: 1.4855403900146484, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8220/10000, Loss: 1.4661504030227661, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8221/10000, Loss: 1.5608420372009277, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8222/10000, Loss: 1.6023080348968506, Train Acc : 0.49283667621776506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8223/10000, Loss: 1.559526801109314, Train Acc : 0.49315504616364214 , Val Acc : 0.48205128205128206\n",
      "Epoch 8224/10000, Loss: 1.5754404067993164, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8225/10000, Loss: 1.5435326099395752, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8226/10000, Loss: 1.6259806156158447, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8227/10000, Loss: 1.5711660385131836, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8228/10000, Loss: 1.6098805665969849, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8229/10000, Loss: 1.5584633350372314, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8230/10000, Loss: 1.5810847282409668, Train Acc : 0.4941101560012735 , Val Acc : 0.4794871794871795\n",
      "Epoch 8231/10000, Loss: 1.5725303888320923, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8232/10000, Loss: 1.5009651184082031, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8233/10000, Loss: 1.5327776670455933, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8234/10000, Loss: 1.4600108861923218, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8235/10000, Loss: 1.4966188669204712, Train Acc : 0.49379178605539636 , Val Acc : 0.4794871794871795\n",
      "Epoch 8236/10000, Loss: 1.552482008934021, Train Acc : 0.49379178605539636 , Val Acc : 0.4794871794871795\n",
      "Epoch 8237/10000, Loss: 1.5679188966751099, Train Acc : 0.4941101560012735 , Val Acc : 0.4794871794871795\n",
      "Epoch 8238/10000, Loss: 1.5885804891586304, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8239/10000, Loss: 1.5478076934814453, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8240/10000, Loss: 1.6370830535888672, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8241/10000, Loss: 1.544744849205017, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8242/10000, Loss: 1.6013227701187134, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8243/10000, Loss: 1.6776094436645508, Train Acc : 0.49315504616364214 , Val Acc : 0.4846153846153846\n",
      "Epoch 8244/10000, Loss: 1.5197837352752686, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8245/10000, Loss: 1.4889651536941528, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8246/10000, Loss: 1.6056900024414062, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8247/10000, Loss: 1.490615963935852, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8248/10000, Loss: 1.5292505025863647, Train Acc : 0.49379178605539636 , Val Acc : 0.4794871794871795\n",
      "Epoch 8249/10000, Loss: 1.5255286693572998, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8250/10000, Loss: 1.5533092021942139, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8251/10000, Loss: 1.5040873289108276, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8252/10000, Loss: 1.5206276178359985, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8253/10000, Loss: 1.5783848762512207, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8254/10000, Loss: 1.6421051025390625, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8255/10000, Loss: 1.539543867111206, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8256/10000, Loss: 1.5585565567016602, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8257/10000, Loss: 1.5598348379135132, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8258/10000, Loss: 1.533218502998352, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8259/10000, Loss: 1.4812180995941162, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8260/10000, Loss: 1.540673017501831, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8261/10000, Loss: 1.5295445919036865, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8262/10000, Loss: 1.5505179166793823, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8263/10000, Loss: 1.5273067951202393, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8264/10000, Loss: 1.5186725854873657, Train Acc : 0.4941101560012735 , Val Acc : 0.4794871794871795\n",
      "Epoch 8265/10000, Loss: 1.5426198244094849, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8266/10000, Loss: 1.5125044584274292, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8267/10000, Loss: 1.5261975526809692, Train Acc : 0.4941101560012735 , Val Acc : 0.4794871794871795\n",
      "Epoch 8268/10000, Loss: 1.5565181970596313, Train Acc : 0.4941101560012735 , Val Acc : 0.4794871794871795\n",
      "Epoch 8269/10000, Loss: 1.4549050331115723, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8270/10000, Loss: 1.5271962881088257, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8271/10000, Loss: 1.553117036819458, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8272/10000, Loss: 1.5454802513122559, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8273/10000, Loss: 1.5370275974273682, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8274/10000, Loss: 1.5048736333847046, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8275/10000, Loss: 1.5051037073135376, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8276/10000, Loss: 1.570642352104187, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8277/10000, Loss: 1.6177082061767578, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8278/10000, Loss: 1.540866732597351, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8279/10000, Loss: 1.4964011907577515, Train Acc : 0.4934734161095193 , Val Acc : 0.4846153846153846\n",
      "Epoch 8280/10000, Loss: 1.5252493619918823, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8281/10000, Loss: 1.4992003440856934, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8282/10000, Loss: 1.6330245733261108, Train Acc : 0.4944285259471506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8283/10000, Loss: 1.604038953781128, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8284/10000, Loss: 1.4350240230560303, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8285/10000, Loss: 1.6506621837615967, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8286/10000, Loss: 1.5265296697616577, Train Acc : 0.4944285259471506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8287/10000, Loss: 1.47175931930542, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8288/10000, Loss: 1.5609723329544067, Train Acc : 0.49474689589302767 , Val Acc : 0.4846153846153846\n",
      "Epoch 8289/10000, Loss: 1.584951400756836, Train Acc : 0.4944285259471506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8290/10000, Loss: 1.4997011423110962, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8291/10000, Loss: 1.5816932916641235, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8292/10000, Loss: 1.549547553062439, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8293/10000, Loss: 1.505631923675537, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8294/10000, Loss: 1.6260441541671753, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8295/10000, Loss: 1.602908730506897, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8296/10000, Loss: 1.6123710870742798, Train Acc : 0.49379178605539636 , Val Acc : 0.4846153846153846\n",
      "Epoch 8297/10000, Loss: 1.6268516778945923, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8298/10000, Loss: 1.5402584075927734, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8299/10000, Loss: 1.5685983896255493, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8300/10000, Loss: 1.5712850093841553, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8301/10000, Loss: 1.5604609251022339, Train Acc : 0.4941101560012735 , Val Acc : 0.4794871794871795\n",
      "Epoch 8302/10000, Loss: 1.4297062158584595, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8303/10000, Loss: 1.5593128204345703, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8304/10000, Loss: 1.570986270904541, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8305/10000, Loss: 1.5183850526809692, Train Acc : 0.49379178605539636 , Val Acc : 0.4794871794871795\n",
      "Epoch 8306/10000, Loss: 1.5620520114898682, Train Acc : 0.4941101560012735 , Val Acc : 0.4794871794871795\n",
      "Epoch 8307/10000, Loss: 1.5788555145263672, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8308/10000, Loss: 1.6039466857910156, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8309/10000, Loss: 1.5383614301681519, Train Acc : 0.4944285259471506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8310/10000, Loss: 1.4800031185150146, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8311/10000, Loss: 1.6547895669937134, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8312/10000, Loss: 1.5092711448669434, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8313/10000, Loss: 1.4694640636444092, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8314/10000, Loss: 1.523125410079956, Train Acc : 0.49379178605539636 , Val Acc : 0.4794871794871795\n",
      "Epoch 8315/10000, Loss: 1.5750974416732788, Train Acc : 0.4950652658389048 , Val Acc : 0.4846153846153846\n",
      "Epoch 8316/10000, Loss: 1.5304324626922607, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8317/10000, Loss: 1.5928367376327515, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8318/10000, Loss: 1.5422358512878418, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8319/10000, Loss: 1.5735547542572021, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8320/10000, Loss: 1.5923020839691162, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8321/10000, Loss: 1.5586957931518555, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8322/10000, Loss: 1.488724946975708, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8323/10000, Loss: 1.5273033380508423, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8324/10000, Loss: 1.467070460319519, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8325/10000, Loss: 1.6755658388137817, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8326/10000, Loss: 1.5400158166885376, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8327/10000, Loss: 1.520313024520874, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8328/10000, Loss: 1.6051207780838013, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8329/10000, Loss: 1.5949188470840454, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8330/10000, Loss: 1.553856372833252, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8331/10000, Loss: 1.5688719749450684, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8332/10000, Loss: 1.5851936340332031, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8333/10000, Loss: 1.4833533763885498, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8334/10000, Loss: 1.536141037940979, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8335/10000, Loss: 1.509978175163269, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8336/10000, Loss: 1.4840691089630127, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8337/10000, Loss: 1.5529428720474243, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8338/10000, Loss: 1.5244901180267334, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8339/10000, Loss: 1.5099189281463623, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8340/10000, Loss: 1.4958158731460571, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8341/10000, Loss: 1.538378357887268, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8342/10000, Loss: 1.4717618227005005, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8343/10000, Loss: 1.5951906442642212, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8344/10000, Loss: 1.5525085926055908, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8345/10000, Loss: 1.5448683500289917, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8346/10000, Loss: 1.612903118133545, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8347/10000, Loss: 1.614127278327942, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8348/10000, Loss: 1.6121723651885986, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8349/10000, Loss: 1.6225944757461548, Train Acc : 0.4950652658389048 , Val Acc : 0.4846153846153846\n",
      "Epoch 8350/10000, Loss: 1.527453064918518, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8351/10000, Loss: 1.555128574371338, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8352/10000, Loss: 1.624428391456604, Train Acc : 0.4950652658389048 , Val Acc : 0.4846153846153846\n",
      "Epoch 8353/10000, Loss: 1.5349571704864502, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8354/10000, Loss: 1.5224089622497559, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8355/10000, Loss: 1.4367892742156982, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8356/10000, Loss: 1.6069411039352417, Train Acc : 0.4950652658389048 , Val Acc : 0.4846153846153846\n",
      "Epoch 8357/10000, Loss: 1.5016796588897705, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8358/10000, Loss: 1.6042362451553345, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8359/10000, Loss: 1.5051217079162598, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8360/10000, Loss: 1.536369800567627, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8361/10000, Loss: 1.6279903650283813, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8362/10000, Loss: 1.4758052825927734, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8363/10000, Loss: 1.5101134777069092, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8364/10000, Loss: 1.5232547521591187, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8365/10000, Loss: 1.5576270818710327, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8366/10000, Loss: 1.5364704132080078, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8367/10000, Loss: 1.5501244068145752, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8368/10000, Loss: 1.5341603755950928, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8369/10000, Loss: 1.5689613819122314, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8370/10000, Loss: 1.63434636592865, Train Acc : 0.4950652658389048 , Val Acc : 0.4846153846153846\n",
      "Epoch 8371/10000, Loss: 1.5316274166107178, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8372/10000, Loss: 1.5396437644958496, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8373/10000, Loss: 1.5353548526763916, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8374/10000, Loss: 1.5187201499938965, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8375/10000, Loss: 1.5500372648239136, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8376/10000, Loss: 1.6247979402542114, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8377/10000, Loss: 1.4525184631347656, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8378/10000, Loss: 1.5197216272354126, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8379/10000, Loss: 1.4651310443878174, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8380/10000, Loss: 1.545954942703247, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8381/10000, Loss: 1.5344593524932861, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8382/10000, Loss: 1.6014961004257202, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8383/10000, Loss: 1.5923652648925781, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8384/10000, Loss: 1.5329151153564453, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8385/10000, Loss: 1.5754890441894531, Train Acc : 0.4953836357847819 , Val Acc : 0.4846153846153846\n",
      "Epoch 8386/10000, Loss: 1.6136449575424194, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8387/10000, Loss: 1.533787727355957, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8388/10000, Loss: 1.4727224111557007, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8389/10000, Loss: 1.5278358459472656, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8390/10000, Loss: 1.6012332439422607, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8391/10000, Loss: 1.5981589555740356, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8392/10000, Loss: 1.571138620376587, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8393/10000, Loss: 1.4958109855651855, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8394/10000, Loss: 1.5988523960113525, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8395/10000, Loss: 1.4755504131317139, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8396/10000, Loss: 1.511191487312317, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8397/10000, Loss: 1.497184157371521, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8398/10000, Loss: 1.5946013927459717, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8399/10000, Loss: 1.6389710903167725, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8400/10000, Loss: 1.6203664541244507, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8401/10000, Loss: 1.5925514698028564, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8402/10000, Loss: 1.5667604207992554, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8403/10000, Loss: 1.5836272239685059, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8404/10000, Loss: 1.6386733055114746, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8405/10000, Loss: 1.522085189819336, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8406/10000, Loss: 1.5057302713394165, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8407/10000, Loss: 1.544490098953247, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8408/10000, Loss: 1.4815757274627686, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8409/10000, Loss: 1.5394375324249268, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8410/10000, Loss: 1.5746194124221802, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8411/10000, Loss: 1.574270486831665, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8412/10000, Loss: 1.5695269107818604, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8413/10000, Loss: 1.4710859060287476, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8414/10000, Loss: 1.560455322265625, Train Acc : 0.4950652658389048 , Val Acc : 0.4846153846153846\n",
      "Epoch 8415/10000, Loss: 1.5681370496749878, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8416/10000, Loss: 1.5763963460922241, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8417/10000, Loss: 1.4900718927383423, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8418/10000, Loss: 1.5706591606140137, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8419/10000, Loss: 1.519498348236084, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8420/10000, Loss: 1.5040709972381592, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8421/10000, Loss: 1.6066533327102661, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8422/10000, Loss: 1.5104913711547852, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8423/10000, Loss: 1.5431969165802002, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8424/10000, Loss: 1.4630017280578613, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8425/10000, Loss: 1.5164825916290283, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8426/10000, Loss: 1.5952093601226807, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8427/10000, Loss: 1.549978256225586, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8428/10000, Loss: 1.6158250570297241, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8429/10000, Loss: 1.5776523351669312, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8430/10000, Loss: 1.565670371055603, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8431/10000, Loss: 1.4763401746749878, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8432/10000, Loss: 1.5012692213058472, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8433/10000, Loss: 1.5909485816955566, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8434/10000, Loss: 1.6398695707321167, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8435/10000, Loss: 1.646261215209961, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8436/10000, Loss: 1.4710471630096436, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8437/10000, Loss: 1.6487090587615967, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8438/10000, Loss: 1.6065834760665894, Train Acc : 0.49474689589302767 , Val Acc : 0.4846153846153846\n",
      "Epoch 8439/10000, Loss: 1.5399781465530396, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8440/10000, Loss: 1.5202562808990479, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8441/10000, Loss: 1.541463851928711, Train Acc : 0.4944285259471506 , Val Acc : 0.4846153846153846\n",
      "Epoch 8442/10000, Loss: 1.4390404224395752, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8443/10000, Loss: 1.4932401180267334, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8444/10000, Loss: 1.6246002912521362, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8445/10000, Loss: 1.6124597787857056, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8446/10000, Loss: 1.5473726987838745, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8447/10000, Loss: 1.5866518020629883, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8448/10000, Loss: 1.5583148002624512, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8449/10000, Loss: 1.5996512174606323, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8450/10000, Loss: 1.4510997533798218, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8451/10000, Loss: 1.6425237655639648, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8452/10000, Loss: 1.4969737529754639, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8453/10000, Loss: 1.5964405536651611, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8454/10000, Loss: 1.5154203176498413, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8455/10000, Loss: 1.5708216428756714, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8456/10000, Loss: 1.4774513244628906, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8457/10000, Loss: 1.5207290649414062, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8458/10000, Loss: 1.505922555923462, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8459/10000, Loss: 1.5365692377090454, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8460/10000, Loss: 1.6257045269012451, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8461/10000, Loss: 1.6030436754226685, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8462/10000, Loss: 1.532019019126892, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8463/10000, Loss: 1.5219976902008057, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8464/10000, Loss: 1.5177451372146606, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8465/10000, Loss: 1.5520752668380737, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8466/10000, Loss: 1.536948561668396, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8467/10000, Loss: 1.548946738243103, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8468/10000, Loss: 1.525728702545166, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8469/10000, Loss: 1.4907002449035645, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8470/10000, Loss: 1.5279980897903442, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8471/10000, Loss: 1.5996952056884766, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8472/10000, Loss: 1.605065107345581, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8473/10000, Loss: 1.550307273864746, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8474/10000, Loss: 1.5867986679077148, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8475/10000, Loss: 1.5518622398376465, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8476/10000, Loss: 1.5938560962677002, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8477/10000, Loss: 1.6254265308380127, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8478/10000, Loss: 1.537825107574463, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8479/10000, Loss: 1.5202356576919556, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8480/10000, Loss: 1.5671203136444092, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8481/10000, Loss: 1.4889557361602783, Train Acc : 0.49474689589302767 , Val Acc : 0.4846153846153846\n",
      "Epoch 8482/10000, Loss: 1.4854182004928589, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8483/10000, Loss: 1.5511614084243774, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8484/10000, Loss: 1.5814167261123657, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8485/10000, Loss: 1.5299161672592163, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8486/10000, Loss: 1.5952390432357788, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8487/10000, Loss: 1.493719220161438, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8488/10000, Loss: 1.5583513975143433, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8489/10000, Loss: 1.5687100887298584, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8490/10000, Loss: 1.5974220037460327, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8491/10000, Loss: 1.5640982389450073, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8492/10000, Loss: 1.4922456741333008, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8493/10000, Loss: 1.5112721920013428, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8494/10000, Loss: 1.6402391195297241, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8495/10000, Loss: 1.4994540214538574, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8496/10000, Loss: 1.5786290168762207, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8497/10000, Loss: 1.5915197134017944, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8498/10000, Loss: 1.5326083898544312, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8499/10000, Loss: 1.5440179109573364, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8500/10000, Loss: 1.5292785167694092, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8501/10000, Loss: 1.4634850025177002, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8502/10000, Loss: 1.431014895439148, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8503/10000, Loss: 1.5192502737045288, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8504/10000, Loss: 1.599888563156128, Train Acc : 0.4941101560012735 , Val Acc : 0.4846153846153846\n",
      "Epoch 8505/10000, Loss: 1.589015245437622, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8506/10000, Loss: 1.6145507097244263, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8507/10000, Loss: 1.597698450088501, Train Acc : 0.4953836357847819 , Val Acc : 0.4846153846153846\n",
      "Epoch 8508/10000, Loss: 1.5436962842941284, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8509/10000, Loss: 1.5812422037124634, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8510/10000, Loss: 1.5052040815353394, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8511/10000, Loss: 1.4592173099517822, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8512/10000, Loss: 1.557213544845581, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8513/10000, Loss: 1.4779250621795654, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8514/10000, Loss: 1.6299793720245361, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8515/10000, Loss: 1.5568183660507202, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8516/10000, Loss: 1.5794132947921753, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8517/10000, Loss: 1.6489869356155396, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8518/10000, Loss: 1.5576748847961426, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8519/10000, Loss: 1.5328407287597656, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8520/10000, Loss: 1.5415233373641968, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8521/10000, Loss: 1.6118097305297852, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8522/10000, Loss: 1.526688814163208, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8523/10000, Loss: 1.4385743141174316, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8524/10000, Loss: 1.546962857246399, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8525/10000, Loss: 1.517205834388733, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8526/10000, Loss: 1.5450527667999268, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8527/10000, Loss: 1.5722122192382812, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8528/10000, Loss: 1.5712862014770508, Train Acc : 0.4950652658389048 , Val Acc : 0.4846153846153846\n",
      "Epoch 8529/10000, Loss: 1.5198757648468018, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8530/10000, Loss: 1.5732897520065308, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8531/10000, Loss: 1.5628281831741333, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8532/10000, Loss: 1.5481685400009155, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8533/10000, Loss: 1.603135585784912, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8534/10000, Loss: 1.5352476835250854, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8535/10000, Loss: 1.492169737815857, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8536/10000, Loss: 1.566460371017456, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8537/10000, Loss: 1.476836085319519, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8538/10000, Loss: 1.5228216648101807, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8539/10000, Loss: 1.5612702369689941, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8540/10000, Loss: 1.5487339496612549, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8541/10000, Loss: 1.5690721273422241, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8542/10000, Loss: 1.5425300598144531, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8543/10000, Loss: 1.6064479351043701, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8544/10000, Loss: 1.4947274923324585, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8545/10000, Loss: 1.5373551845550537, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8546/10000, Loss: 1.5329383611679077, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8547/10000, Loss: 1.5629714727401733, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8548/10000, Loss: 1.5998618602752686, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8549/10000, Loss: 1.5322359800338745, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8550/10000, Loss: 1.617445468902588, Train Acc : 0.4950652658389048 , Val Acc : 0.4846153846153846\n",
      "Epoch 8551/10000, Loss: 1.530341386795044, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8552/10000, Loss: 1.564981460571289, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8553/10000, Loss: 1.6069937944412231, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8554/10000, Loss: 1.4791686534881592, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8555/10000, Loss: 1.6439658403396606, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8556/10000, Loss: 1.5374860763549805, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8557/10000, Loss: 1.476987600326538, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8558/10000, Loss: 1.5565541982650757, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8559/10000, Loss: 1.6071467399597168, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8560/10000, Loss: 1.5966678857803345, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8561/10000, Loss: 1.4830833673477173, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8562/10000, Loss: 1.5624139308929443, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8563/10000, Loss: 1.6149839162826538, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8564/10000, Loss: 1.573490858078003, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8565/10000, Loss: 1.5949395895004272, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8566/10000, Loss: 1.587285041809082, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8567/10000, Loss: 1.581071138381958, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8568/10000, Loss: 1.5600849390029907, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8569/10000, Loss: 1.5188626050949097, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8570/10000, Loss: 1.4647176265716553, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8571/10000, Loss: 1.6508238315582275, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8572/10000, Loss: 1.489364743232727, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8573/10000, Loss: 1.6017721891403198, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8574/10000, Loss: 1.5655103921890259, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8575/10000, Loss: 1.5182558298110962, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8576/10000, Loss: 1.5885759592056274, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8577/10000, Loss: 1.4868899583816528, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8578/10000, Loss: 1.5804044008255005, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8579/10000, Loss: 1.4861112833023071, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8580/10000, Loss: 1.486646294593811, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8581/10000, Loss: 1.5836251974105835, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8582/10000, Loss: 1.512861728668213, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8583/10000, Loss: 1.553425669670105, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8584/10000, Loss: 1.4940917491912842, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8585/10000, Loss: 1.5422098636627197, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8586/10000, Loss: 1.5722745656967163, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8587/10000, Loss: 1.6086145639419556, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8588/10000, Loss: 1.5186668634414673, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8589/10000, Loss: 1.5843819379806519, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8590/10000, Loss: 1.5518078804016113, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8591/10000, Loss: 1.5828711986541748, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8592/10000, Loss: 1.5728384256362915, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8593/10000, Loss: 1.6051185131072998, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8594/10000, Loss: 1.6013023853302002, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8595/10000, Loss: 1.5726076364517212, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8596/10000, Loss: 1.4575227499008179, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8597/10000, Loss: 1.4484202861785889, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8598/10000, Loss: 1.4648674726486206, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8599/10000, Loss: 1.5896576642990112, Train Acc : 0.4944285259471506 , Val Acc : 0.4794871794871795\n",
      "Epoch 8600/10000, Loss: 1.5659505128860474, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8601/10000, Loss: 1.603110671043396, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8602/10000, Loss: 1.528357744216919, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8603/10000, Loss: 1.5870281457901, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8604/10000, Loss: 1.5657252073287964, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8605/10000, Loss: 1.5514723062515259, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8606/10000, Loss: 1.5736439228057861, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8607/10000, Loss: 1.5653802156448364, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8608/10000, Loss: 1.4955501556396484, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8609/10000, Loss: 1.4952561855316162, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8610/10000, Loss: 1.5054928064346313, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8611/10000, Loss: 1.5636693239212036, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8612/10000, Loss: 1.529664397239685, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8613/10000, Loss: 1.5517712831497192, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8614/10000, Loss: 1.545098900794983, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8615/10000, Loss: 1.5481047630310059, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8616/10000, Loss: 1.5679571628570557, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8617/10000, Loss: 1.5743240118026733, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8618/10000, Loss: 1.5678130388259888, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8619/10000, Loss: 1.4441394805908203, Train Acc : 0.4941101560012735 , Val Acc : 0.4794871794871795\n",
      "Epoch 8620/10000, Loss: 1.6080836057662964, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8621/10000, Loss: 1.5493797063827515, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8622/10000, Loss: 1.4993518590927124, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8623/10000, Loss: 1.6123946905136108, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8624/10000, Loss: 1.5862504243850708, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8625/10000, Loss: 1.5616554021835327, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8626/10000, Loss: 1.5055351257324219, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8627/10000, Loss: 1.4672211408615112, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8628/10000, Loss: 1.5419589281082153, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8629/10000, Loss: 1.5151405334472656, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8630/10000, Loss: 1.529266357421875, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8631/10000, Loss: 1.571058750152588, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8632/10000, Loss: 1.543883204460144, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8633/10000, Loss: 1.5233376026153564, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8634/10000, Loss: 1.5824087858200073, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8635/10000, Loss: 1.569818139076233, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8636/10000, Loss: 1.5660604238510132, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8637/10000, Loss: 1.5574620962142944, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8638/10000, Loss: 1.6255518198013306, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8639/10000, Loss: 1.5412002801895142, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8640/10000, Loss: 1.5057222843170166, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8641/10000, Loss: 1.5943578481674194, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8642/10000, Loss: 1.5310546159744263, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8643/10000, Loss: 1.4486818313598633, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8644/10000, Loss: 1.619076132774353, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8645/10000, Loss: 1.6279728412628174, Train Acc : 0.4950652658389048 , Val Acc : 0.4794871794871795\n",
      "Epoch 8646/10000, Loss: 1.4951709508895874, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8647/10000, Loss: 1.5844186544418335, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8648/10000, Loss: 1.532416820526123, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8649/10000, Loss: 1.500909447669983, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8650/10000, Loss: 1.4665025472640991, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8651/10000, Loss: 1.52283775806427, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8652/10000, Loss: 1.5549870729446411, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8653/10000, Loss: 1.572348952293396, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8654/10000, Loss: 1.5533535480499268, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8655/10000, Loss: 1.5302032232284546, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8656/10000, Loss: 1.599926233291626, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8657/10000, Loss: 1.571899175643921, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8658/10000, Loss: 1.5180550813674927, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8659/10000, Loss: 1.5919456481933594, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8660/10000, Loss: 1.550469994544983, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8661/10000, Loss: 1.5217502117156982, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8662/10000, Loss: 1.4794893264770508, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8663/10000, Loss: 1.578366994857788, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8664/10000, Loss: 1.619950771331787, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8665/10000, Loss: 1.5360560417175293, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8666/10000, Loss: 1.4891340732574463, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8667/10000, Loss: 1.5158365964889526, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8668/10000, Loss: 1.573629379272461, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8669/10000, Loss: 1.6163581609725952, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8670/10000, Loss: 1.5814547538757324, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8671/10000, Loss: 1.5677138566970825, Train Acc : 0.49474689589302767 , Val Acc : 0.4794871794871795\n",
      "Epoch 8672/10000, Loss: 1.5220497846603394, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8673/10000, Loss: 1.5513191223144531, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8674/10000, Loss: 1.559567928314209, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8675/10000, Loss: 1.5321626663208008, Train Acc : 0.4953836357847819 , Val Acc : 0.4794871794871795\n",
      "Epoch 8676/10000, Loss: 1.6064683198928833, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8677/10000, Loss: 1.4921412467956543, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8678/10000, Loss: 1.5504590272903442, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8679/10000, Loss: 1.60947847366333, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8680/10000, Loss: 1.601881980895996, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8681/10000, Loss: 1.563062071800232, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8682/10000, Loss: 1.4452378749847412, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8683/10000, Loss: 1.6266275644302368, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8684/10000, Loss: 1.4518963098526, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8685/10000, Loss: 1.5087990760803223, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8686/10000, Loss: 1.6282684803009033, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8687/10000, Loss: 1.4768115282058716, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8688/10000, Loss: 1.536359429359436, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8689/10000, Loss: 1.6143218278884888, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8690/10000, Loss: 1.6161351203918457, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8691/10000, Loss: 1.5405941009521484, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8692/10000, Loss: 1.529924988746643, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8693/10000, Loss: 1.6185847520828247, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8694/10000, Loss: 1.6823288202285767, Train Acc : 0.49570200573065903 , Val Acc : 0.4794871794871795\n",
      "Epoch 8695/10000, Loss: 1.5662239789962769, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8696/10000, Loss: 1.496425986289978, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8697/10000, Loss: 1.576555609703064, Train Acc : 0.49570200573065903 , Val Acc : 0.4794871794871795\n",
      "Epoch 8698/10000, Loss: 1.5308886766433716, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8699/10000, Loss: 1.5590773820877075, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8700/10000, Loss: 1.4867541790008545, Train Acc : 0.4934734161095193 , Val Acc : 0.48205128205128206\n",
      "Epoch 8701/10000, Loss: 1.5947812795639038, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8702/10000, Loss: 1.5726054906845093, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8703/10000, Loss: 1.5460113286972046, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8704/10000, Loss: 1.5381308794021606, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8705/10000, Loss: 1.5800944566726685, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8706/10000, Loss: 1.5166577100753784, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8707/10000, Loss: 1.55044424533844, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8708/10000, Loss: 1.4665229320526123, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8709/10000, Loss: 1.6281412839889526, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8710/10000, Loss: 1.5867589712142944, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8711/10000, Loss: 1.557965636253357, Train Acc : 0.49570200573065903 , Val Acc : 0.4794871794871795\n",
      "Epoch 8712/10000, Loss: 1.4662877321243286, Train Acc : 0.49570200573065903 , Val Acc : 0.4794871794871795\n",
      "Epoch 8713/10000, Loss: 1.6037776470184326, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8714/10000, Loss: 1.4926669597625732, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8715/10000, Loss: 1.5044974088668823, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8716/10000, Loss: 1.5476409196853638, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8717/10000, Loss: 1.5663981437683105, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8718/10000, Loss: 1.6722142696380615, Train Acc : 0.4941101560012735 , Val Acc : 0.48205128205128206\n",
      "Epoch 8719/10000, Loss: 1.5648763179779053, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8720/10000, Loss: 1.4650439023971558, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8721/10000, Loss: 1.640363097190857, Train Acc : 0.49570200573065903 , Val Acc : 0.4794871794871795\n",
      "Epoch 8722/10000, Loss: 1.4588043689727783, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8723/10000, Loss: 1.5422242879867554, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8724/10000, Loss: 1.478122353553772, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8725/10000, Loss: 1.5679575204849243, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8726/10000, Loss: 1.537698745727539, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8727/10000, Loss: 1.5491008758544922, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8728/10000, Loss: 1.5779407024383545, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8729/10000, Loss: 1.5711214542388916, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8730/10000, Loss: 1.5889532566070557, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8731/10000, Loss: 1.5236457586288452, Train Acc : 0.49665711556829034 , Val Acc : 0.4794871794871795\n",
      "Epoch 8732/10000, Loss: 1.5936964750289917, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8733/10000, Loss: 1.6002753973007202, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8734/10000, Loss: 1.5502201318740845, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8735/10000, Loss: 1.5155702829360962, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8736/10000, Loss: 1.5479625463485718, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8737/10000, Loss: 1.4862910509109497, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8738/10000, Loss: 1.5342390537261963, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8739/10000, Loss: 1.5438319444656372, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8740/10000, Loss: 1.4285178184509277, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8741/10000, Loss: 1.460553526878357, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8742/10000, Loss: 1.6092138290405273, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8743/10000, Loss: 1.5562305450439453, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8744/10000, Loss: 1.4751853942871094, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8745/10000, Loss: 1.5329384803771973, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8746/10000, Loss: 1.6311320066452026, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8747/10000, Loss: 1.5459896326065063, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8748/10000, Loss: 1.6004326343536377, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8749/10000, Loss: 1.5434647798538208, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8750/10000, Loss: 1.5747138261795044, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8751/10000, Loss: 1.5737102031707764, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8752/10000, Loss: 1.6102399826049805, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8753/10000, Loss: 1.5155521631240845, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8754/10000, Loss: 1.5934867858886719, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8755/10000, Loss: 1.4483590126037598, Train Acc : 0.4960203756765361 , Val Acc : 0.4794871794871795\n",
      "Epoch 8756/10000, Loss: 1.6164299249649048, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8757/10000, Loss: 1.5577880144119263, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8758/10000, Loss: 1.5673116445541382, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8759/10000, Loss: 1.4988274574279785, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8760/10000, Loss: 1.5045318603515625, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8761/10000, Loss: 1.5689194202423096, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8762/10000, Loss: 1.5628700256347656, Train Acc : 0.49379178605539636 , Val Acc : 0.48205128205128206\n",
      "Epoch 8763/10000, Loss: 1.5173540115356445, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8764/10000, Loss: 1.5468380451202393, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8765/10000, Loss: 1.5047532320022583, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8766/10000, Loss: 1.5296974182128906, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8767/10000, Loss: 1.4839423894882202, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8768/10000, Loss: 1.5072871446609497, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8769/10000, Loss: 1.550804853439331, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8770/10000, Loss: 1.5153404474258423, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8771/10000, Loss: 1.4862271547317505, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8772/10000, Loss: 1.6267011165618896, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8773/10000, Loss: 1.4775705337524414, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8774/10000, Loss: 1.4752302169799805, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8775/10000, Loss: 1.4847021102905273, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8776/10000, Loss: 1.4868807792663574, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8777/10000, Loss: 1.582514762878418, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8778/10000, Loss: 1.5284889936447144, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8779/10000, Loss: 1.569115400314331, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8780/10000, Loss: 1.4961216449737549, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8781/10000, Loss: 1.5373780727386475, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8782/10000, Loss: 1.5754274129867554, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8783/10000, Loss: 1.5595093965530396, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8784/10000, Loss: 1.4219552278518677, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8785/10000, Loss: 1.5895788669586182, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8786/10000, Loss: 1.6275113821029663, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8787/10000, Loss: 1.5182480812072754, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8788/10000, Loss: 1.5448970794677734, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8789/10000, Loss: 1.5837202072143555, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8790/10000, Loss: 1.6258940696716309, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8791/10000, Loss: 1.5619803667068481, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8792/10000, Loss: 1.5728172063827515, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8793/10000, Loss: 1.5343070030212402, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8794/10000, Loss: 1.563456654548645, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8795/10000, Loss: 1.6290961503982544, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8796/10000, Loss: 1.5345308780670166, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8797/10000, Loss: 1.5744285583496094, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8798/10000, Loss: 1.6085504293441772, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8799/10000, Loss: 1.5748084783554077, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8800/10000, Loss: 1.5241698026657104, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8801/10000, Loss: 1.5805511474609375, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8802/10000, Loss: 1.5240790843963623, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8803/10000, Loss: 1.5802561044692993, Train Acc : 0.4944285259471506 , Val Acc : 0.48205128205128206\n",
      "Epoch 8804/10000, Loss: 1.5992577075958252, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8805/10000, Loss: 1.5191384553909302, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8806/10000, Loss: 1.571756362915039, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8807/10000, Loss: 1.5502210855484009, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8808/10000, Loss: 1.6131126880645752, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8809/10000, Loss: 1.560350775718689, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8810/10000, Loss: 1.5604747533798218, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8811/10000, Loss: 1.527609944343567, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8812/10000, Loss: 1.4522656202316284, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8813/10000, Loss: 1.5262572765350342, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8814/10000, Loss: 1.5945594310760498, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8815/10000, Loss: 1.6263468265533447, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8816/10000, Loss: 1.5480966567993164, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8817/10000, Loss: 1.6262632608413696, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8818/10000, Loss: 1.5575597286224365, Train Acc : 0.49474689589302767 , Val Acc : 0.48205128205128206\n",
      "Epoch 8819/10000, Loss: 1.5215743780136108, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8820/10000, Loss: 1.6006437540054321, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8821/10000, Loss: 1.5171867609024048, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8822/10000, Loss: 1.5242770910263062, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8823/10000, Loss: 1.5469235181808472, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8824/10000, Loss: 1.564449667930603, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8825/10000, Loss: 1.551406979560852, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8826/10000, Loss: 1.4415390491485596, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8827/10000, Loss: 1.5762169361114502, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8828/10000, Loss: 1.5206626653671265, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8829/10000, Loss: 1.5165398120880127, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8830/10000, Loss: 1.5492933988571167, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8831/10000, Loss: 1.604085922241211, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8832/10000, Loss: 1.5328431129455566, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8833/10000, Loss: 1.5765724182128906, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8834/10000, Loss: 1.5922287702560425, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8835/10000, Loss: 1.5830765962600708, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8836/10000, Loss: 1.5081803798675537, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8837/10000, Loss: 1.6150944232940674, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8838/10000, Loss: 1.5246363878250122, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8839/10000, Loss: 1.4940935373306274, Train Acc : 0.4960203756765361 , Val Acc : 0.48205128205128206\n",
      "Epoch 8840/10000, Loss: 1.5436623096466064, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8841/10000, Loss: 1.5773544311523438, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8842/10000, Loss: 1.5294488668441772, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8843/10000, Loss: 1.5951942205429077, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8844/10000, Loss: 1.647904634475708, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8845/10000, Loss: 1.5433614253997803, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8846/10000, Loss: 1.5313695669174194, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8847/10000, Loss: 1.5746757984161377, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8848/10000, Loss: 1.600071907043457, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8849/10000, Loss: 1.5647326707839966, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8850/10000, Loss: 1.5658241510391235, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8851/10000, Loss: 1.519960880279541, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8852/10000, Loss: 1.556715488433838, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8853/10000, Loss: 1.4702353477478027, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8854/10000, Loss: 1.626456379890442, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8855/10000, Loss: 1.582006812095642, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8856/10000, Loss: 1.5604915618896484, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8857/10000, Loss: 1.6305981874465942, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8858/10000, Loss: 1.6595616340637207, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8859/10000, Loss: 1.5766140222549438, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8860/10000, Loss: 1.609897255897522, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8861/10000, Loss: 1.4404500722885132, Train Acc : 0.4950652658389048 , Val Acc : 0.48205128205128206\n",
      "Epoch 8862/10000, Loss: 1.5655131340026855, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8863/10000, Loss: 1.564656376838684, Train Acc : 0.49570200573065903 , Val Acc : 0.48205128205128206\n",
      "Epoch 8864/10000, Loss: 1.5580161809921265, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8865/10000, Loss: 1.4853702783584595, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8866/10000, Loss: 1.5454809665679932, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8867/10000, Loss: 1.5552536249160767, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8868/10000, Loss: 1.5237164497375488, Train Acc : 0.4953836357847819 , Val Acc : 0.48205128205128206\n",
      "Epoch 8869/10000, Loss: 1.4956355094909668, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8870/10000, Loss: 1.576382040977478, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8871/10000, Loss: 1.4718550443649292, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8872/10000, Loss: 1.5339665412902832, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8873/10000, Loss: 1.5245718955993652, Train Acc : 0.49633874562241326 , Val Acc : 0.48205128205128206\n",
      "Epoch 8874/10000, Loss: 1.5882424116134644, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8875/10000, Loss: 1.5629385709762573, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8876/10000, Loss: 1.5387847423553467, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8877/10000, Loss: 1.5114209651947021, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8878/10000, Loss: 1.5051625967025757, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8879/10000, Loss: 1.5933424234390259, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8880/10000, Loss: 1.5150500535964966, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8881/10000, Loss: 1.5429911613464355, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8882/10000, Loss: 1.5267465114593506, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8883/10000, Loss: 1.5460765361785889, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8884/10000, Loss: 1.5988909006118774, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8885/10000, Loss: 1.5690110921859741, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8886/10000, Loss: 1.4543030261993408, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8887/10000, Loss: 1.5600090026855469, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8888/10000, Loss: 1.5046541690826416, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8889/10000, Loss: 1.4888525009155273, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8890/10000, Loss: 1.469386339187622, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8891/10000, Loss: 1.563040018081665, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8892/10000, Loss: 1.5711451768875122, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8893/10000, Loss: 1.5814632177352905, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8894/10000, Loss: 1.5749543905258179, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8895/10000, Loss: 1.5205713510513306, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8896/10000, Loss: 1.4905186891555786, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8897/10000, Loss: 1.447770118713379, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8898/10000, Loss: 1.5480775833129883, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8899/10000, Loss: 1.5013943910598755, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8900/10000, Loss: 1.595243215560913, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8901/10000, Loss: 1.5165656805038452, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8902/10000, Loss: 1.5229648351669312, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8903/10000, Loss: 1.4804903268814087, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8904/10000, Loss: 1.5658899545669556, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8905/10000, Loss: 1.5094932317733765, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8906/10000, Loss: 1.6037275791168213, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8907/10000, Loss: 1.5456215143203735, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8908/10000, Loss: 1.5399799346923828, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8909/10000, Loss: 1.5997085571289062, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8910/10000, Loss: 1.553496241569519, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8911/10000, Loss: 1.482928991317749, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8912/10000, Loss: 1.5476175546646118, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8913/10000, Loss: 1.671621322631836, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8914/10000, Loss: 1.610579490661621, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8915/10000, Loss: 1.5562047958374023, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8916/10000, Loss: 1.5772933959960938, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8917/10000, Loss: 1.5330018997192383, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8918/10000, Loss: 1.5599100589752197, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8919/10000, Loss: 1.4584776163101196, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8920/10000, Loss: 1.487175464630127, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8921/10000, Loss: 1.487921118736267, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8922/10000, Loss: 1.5831236839294434, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8923/10000, Loss: 1.601157307624817, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8924/10000, Loss: 1.5177093744277954, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8925/10000, Loss: 1.5517834424972534, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8926/10000, Loss: 1.5819224119186401, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8927/10000, Loss: 1.6172090768814087, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8928/10000, Loss: 1.622327446937561, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8929/10000, Loss: 1.5004693269729614, Train Acc : 0.49665711556829034 , Val Acc : 0.48205128205128206\n",
      "Epoch 8930/10000, Loss: 1.5447503328323364, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8931/10000, Loss: 1.542510986328125, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8932/10000, Loss: 1.5009503364562988, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8933/10000, Loss: 1.5583879947662354, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8934/10000, Loss: 1.4596740007400513, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8935/10000, Loss: 1.4937976598739624, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8936/10000, Loss: 1.559542179107666, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8937/10000, Loss: 1.6724039316177368, Train Acc : 0.49729385546004456 , Val Acc : 0.48205128205128206\n",
      "Epoch 8938/10000, Loss: 1.6022961139678955, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8939/10000, Loss: 1.660779356956482, Train Acc : 0.4969754855141675 , Val Acc : 0.48205128205128206\n",
      "Epoch 8940/10000, Loss: 1.4594252109527588, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8941/10000, Loss: 1.4367820024490356, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8942/10000, Loss: 1.5058175325393677, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8943/10000, Loss: 1.5341001749038696, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8944/10000, Loss: 1.536419153213501, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8945/10000, Loss: 1.4964734315872192, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8946/10000, Loss: 1.5479001998901367, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8947/10000, Loss: 1.5983139276504517, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8948/10000, Loss: 1.6155085563659668, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8949/10000, Loss: 1.6288608312606812, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8950/10000, Loss: 1.5584907531738281, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8951/10000, Loss: 1.493742823600769, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8952/10000, Loss: 1.6239330768585205, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8953/10000, Loss: 1.635240912437439, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8954/10000, Loss: 1.5052589178085327, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8955/10000, Loss: 1.5345321893692017, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8956/10000, Loss: 1.5230084657669067, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8957/10000, Loss: 1.5629997253417969, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8958/10000, Loss: 1.6108942031860352, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8959/10000, Loss: 1.574577808380127, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8960/10000, Loss: 1.4797172546386719, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8961/10000, Loss: 1.5353566408157349, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8962/10000, Loss: 1.595638632774353, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8963/10000, Loss: 1.5193843841552734, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8964/10000, Loss: 1.5413049459457397, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8965/10000, Loss: 1.5818067789077759, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8966/10000, Loss: 1.5861722230911255, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8967/10000, Loss: 1.6694623231887817, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8968/10000, Loss: 1.660105586051941, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 8969/10000, Loss: 1.4992311000823975, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8970/10000, Loss: 1.5399225950241089, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8971/10000, Loss: 1.6017167568206787, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8972/10000, Loss: 1.495179295539856, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8973/10000, Loss: 1.6531121730804443, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8974/10000, Loss: 1.558797001838684, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8975/10000, Loss: 1.5016793012619019, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8976/10000, Loss: 1.5647177696228027, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8977/10000, Loss: 1.537338376045227, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8978/10000, Loss: 1.5474865436553955, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8979/10000, Loss: 1.5804553031921387, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8980/10000, Loss: 1.5385555028915405, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8981/10000, Loss: 1.4886436462402344, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8982/10000, Loss: 1.6232059001922607, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8983/10000, Loss: 1.544950008392334, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8984/10000, Loss: 1.5702483654022217, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8985/10000, Loss: 1.477120280265808, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8986/10000, Loss: 1.5012403726577759, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8987/10000, Loss: 1.6219635009765625, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8988/10000, Loss: 1.5179494619369507, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8989/10000, Loss: 1.6000354290008545, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 8990/10000, Loss: 1.5454018115997314, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8991/10000, Loss: 1.546697974205017, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8992/10000, Loss: 1.6211345195770264, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8993/10000, Loss: 1.6183830499649048, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 8994/10000, Loss: 1.5758285522460938, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8995/10000, Loss: 1.6216305494308472, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 8996/10000, Loss: 1.5824540853500366, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 8997/10000, Loss: 1.575323462486267, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8998/10000, Loss: 1.5398880243301392, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 8999/10000, Loss: 1.5393249988555908, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9000/10000, Loss: 1.5887272357940674, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9001/10000, Loss: 1.6457687616348267, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9002/10000, Loss: 1.5701348781585693, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9003/10000, Loss: 1.5061298608779907, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9004/10000, Loss: 1.5056283473968506, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 9005/10000, Loss: 1.514214277267456, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9006/10000, Loss: 1.4647271633148193, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9007/10000, Loss: 1.5515716075897217, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9008/10000, Loss: 1.5157562494277954, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 9009/10000, Loss: 1.5656567811965942, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 9010/10000, Loss: 1.5483198165893555, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9011/10000, Loss: 1.5286986827850342, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9012/10000, Loss: 1.5855642557144165, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9013/10000, Loss: 1.5726171731948853, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9014/10000, Loss: 1.4984965324401855, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9015/10000, Loss: 1.6260184049606323, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9016/10000, Loss: 1.5815706253051758, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9017/10000, Loss: 1.5803321599960327, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9018/10000, Loss: 1.5148338079452515, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9019/10000, Loss: 1.4770950078964233, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9020/10000, Loss: 1.55722975730896, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9021/10000, Loss: 1.5497108697891235, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9022/10000, Loss: 1.5243109464645386, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9023/10000, Loss: 1.5193474292755127, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9024/10000, Loss: 1.4922471046447754, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9025/10000, Loss: 1.5092562437057495, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9026/10000, Loss: 1.5327284336090088, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9027/10000, Loss: 1.5468298196792603, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9028/10000, Loss: 1.5576105117797852, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9029/10000, Loss: 1.5901241302490234, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9030/10000, Loss: 1.5003252029418945, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9031/10000, Loss: 1.4707826375961304, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9032/10000, Loss: 1.651487946510315, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9033/10000, Loss: 1.532728910446167, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9034/10000, Loss: 1.5822491645812988, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9035/10000, Loss: 1.5328915119171143, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9036/10000, Loss: 1.477879524230957, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9037/10000, Loss: 1.565744400024414, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9038/10000, Loss: 1.551627516746521, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 9039/10000, Loss: 1.533923864364624, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9040/10000, Loss: 1.6430487632751465, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9041/10000, Loss: 1.5590386390686035, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9042/10000, Loss: 1.5336570739746094, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9043/10000, Loss: 1.5597699880599976, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9044/10000, Loss: 1.4984902143478394, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9045/10000, Loss: 1.5157508850097656, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9046/10000, Loss: 1.493214726448059, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9047/10000, Loss: 1.5827836990356445, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9048/10000, Loss: 1.485171914100647, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9049/10000, Loss: 1.5342228412628174, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9050/10000, Loss: 1.507256031036377, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9051/10000, Loss: 1.46840500831604, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9052/10000, Loss: 1.540177583694458, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9053/10000, Loss: 1.5084998607635498, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9054/10000, Loss: 1.679900050163269, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9055/10000, Loss: 1.4850412607192993, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9056/10000, Loss: 1.526257038116455, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9057/10000, Loss: 1.6277167797088623, Train Acc : 0.4976122254059217 , Val Acc : 0.48205128205128206\n",
      "Epoch 9058/10000, Loss: 1.5085132122039795, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9059/10000, Loss: 1.5466974973678589, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9060/10000, Loss: 1.5031706094741821, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 9061/10000, Loss: 1.5267616510391235, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9062/10000, Loss: 1.567725419998169, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9063/10000, Loss: 1.5198193788528442, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9064/10000, Loss: 1.4306505918502808, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9065/10000, Loss: 1.5123683214187622, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9066/10000, Loss: 1.5691800117492676, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9067/10000, Loss: 1.565955638885498, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9068/10000, Loss: 1.5417715311050415, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9069/10000, Loss: 1.582327961921692, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9070/10000, Loss: 1.5070780515670776, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9071/10000, Loss: 1.5563589334487915, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9072/10000, Loss: 1.5487921237945557, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9073/10000, Loss: 1.5746898651123047, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9074/10000, Loss: 1.5167927742004395, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9075/10000, Loss: 1.5951666831970215, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9076/10000, Loss: 1.5365097522735596, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9077/10000, Loss: 1.533806562423706, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9078/10000, Loss: 1.5417118072509766, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9079/10000, Loss: 1.584685206413269, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9080/10000, Loss: 1.616522192955017, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9081/10000, Loss: 1.6413627862930298, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9082/10000, Loss: 1.5310256481170654, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9083/10000, Loss: 1.6134934425354004, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9084/10000, Loss: 1.5801409482955933, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9085/10000, Loss: 1.5044013261795044, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9086/10000, Loss: 1.550995111465454, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9087/10000, Loss: 1.5683441162109375, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9088/10000, Loss: 1.4903619289398193, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9089/10000, Loss: 1.5471428632736206, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9090/10000, Loss: 1.5908485651016235, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9091/10000, Loss: 1.5218675136566162, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9092/10000, Loss: 1.535096526145935, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9093/10000, Loss: 1.4924043416976929, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9094/10000, Loss: 1.610816240310669, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9095/10000, Loss: 1.5171765089035034, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9096/10000, Loss: 1.6517685651779175, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9097/10000, Loss: 1.5514488220214844, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9098/10000, Loss: 1.4814293384552002, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9099/10000, Loss: 1.5272608995437622, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9100/10000, Loss: 1.58388090133667, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9101/10000, Loss: 1.6205308437347412, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9102/10000, Loss: 1.5828301906585693, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9103/10000, Loss: 1.587185263633728, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9104/10000, Loss: 1.5973774194717407, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9105/10000, Loss: 1.5775712728500366, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9106/10000, Loss: 1.4734036922454834, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9107/10000, Loss: 1.465942621231079, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9108/10000, Loss: 1.522606372833252, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9109/10000, Loss: 1.6041005849838257, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9110/10000, Loss: 1.5333869457244873, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9111/10000, Loss: 1.5351810455322266, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9112/10000, Loss: 1.671750783920288, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9113/10000, Loss: 1.4664993286132812, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9114/10000, Loss: 1.5631541013717651, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9115/10000, Loss: 1.5339665412902832, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9116/10000, Loss: 1.4978278875350952, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9117/10000, Loss: 1.5793845653533936, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9118/10000, Loss: 1.4976712465286255, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9119/10000, Loss: 1.6021486520767212, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9120/10000, Loss: 1.5788052082061768, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9121/10000, Loss: 1.568521499633789, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9122/10000, Loss: 1.5684181451797485, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9123/10000, Loss: 1.515762209892273, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9124/10000, Loss: 1.5153770446777344, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9125/10000, Loss: 1.5661015510559082, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9126/10000, Loss: 1.404442548751831, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9127/10000, Loss: 1.6120665073394775, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9128/10000, Loss: 1.5613561868667603, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9129/10000, Loss: 1.4953597784042358, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9130/10000, Loss: 1.4863190650939941, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9131/10000, Loss: 1.549821138381958, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9132/10000, Loss: 1.5573643445968628, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9133/10000, Loss: 1.5920699834823608, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9134/10000, Loss: 1.513237714767456, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9135/10000, Loss: 1.5914361476898193, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9136/10000, Loss: 1.548484444618225, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9137/10000, Loss: 1.6267344951629639, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9138/10000, Loss: 1.639586091041565, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9139/10000, Loss: 1.5472571849822998, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9140/10000, Loss: 1.5408179759979248, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9141/10000, Loss: 1.5423774719238281, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9142/10000, Loss: 1.5855821371078491, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9143/10000, Loss: 1.5705209970474243, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9144/10000, Loss: 1.498735785484314, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9145/10000, Loss: 1.5434776544570923, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9146/10000, Loss: 1.556854009628296, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9147/10000, Loss: 1.5271165370941162, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9148/10000, Loss: 1.515228033065796, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9149/10000, Loss: 1.5131248235702515, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9150/10000, Loss: 1.6044279336929321, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9151/10000, Loss: 1.5869773626327515, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9152/10000, Loss: 1.621886134147644, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9153/10000, Loss: 1.613000750541687, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9154/10000, Loss: 1.5575248003005981, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9155/10000, Loss: 1.5037004947662354, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9156/10000, Loss: 1.5613811016082764, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9157/10000, Loss: 1.603559136390686, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9158/10000, Loss: 1.5185527801513672, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9159/10000, Loss: 1.5577847957611084, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9160/10000, Loss: 1.5036836862564087, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9161/10000, Loss: 1.568278431892395, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9162/10000, Loss: 1.500554084777832, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9163/10000, Loss: 1.5618457794189453, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9164/10000, Loss: 1.5883063077926636, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9165/10000, Loss: 1.5508785247802734, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9166/10000, Loss: 1.6064738035202026, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9167/10000, Loss: 1.4794385433197021, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9168/10000, Loss: 1.4970879554748535, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9169/10000, Loss: 1.5332716703414917, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9170/10000, Loss: 1.4258679151535034, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9171/10000, Loss: 1.5122010707855225, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9172/10000, Loss: 1.5815249681472778, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9173/10000, Loss: 1.601149320602417, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9174/10000, Loss: 1.6090421676635742, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9175/10000, Loss: 1.5432260036468506, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9176/10000, Loss: 1.567055344581604, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9177/10000, Loss: 1.538676381111145, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9178/10000, Loss: 1.5587323904037476, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9179/10000, Loss: 1.4782401323318481, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9180/10000, Loss: 1.5275722742080688, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9181/10000, Loss: 1.53106689453125, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9182/10000, Loss: 1.508318305015564, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9183/10000, Loss: 1.5818864107131958, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9184/10000, Loss: 1.528982400894165, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9185/10000, Loss: 1.5074124336242676, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9186/10000, Loss: 1.5692282915115356, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9187/10000, Loss: 1.5179178714752197, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9188/10000, Loss: 1.573993444442749, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9189/10000, Loss: 1.5658830404281616, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9190/10000, Loss: 1.529530644416809, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9191/10000, Loss: 1.519281268119812, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9192/10000, Loss: 1.5427428483963013, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9193/10000, Loss: 1.562214970588684, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9194/10000, Loss: 1.5907999277114868, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9195/10000, Loss: 1.5545192956924438, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9196/10000, Loss: 1.6282788515090942, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9197/10000, Loss: 1.476961612701416, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9198/10000, Loss: 1.567241907119751, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9199/10000, Loss: 1.595801830291748, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9200/10000, Loss: 1.5621143579483032, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9201/10000, Loss: 1.5212591886520386, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9202/10000, Loss: 1.5985722541809082, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9203/10000, Loss: 1.530220866203308, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9204/10000, Loss: 1.645264744758606, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9205/10000, Loss: 1.5116262435913086, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9206/10000, Loss: 1.5697740316390991, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9207/10000, Loss: 1.55621337890625, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9208/10000, Loss: 1.5248136520385742, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9209/10000, Loss: 1.5990958213806152, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9210/10000, Loss: 1.5819802284240723, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9211/10000, Loss: 1.562484622001648, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9212/10000, Loss: 1.574972152709961, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9213/10000, Loss: 1.56244695186615, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9214/10000, Loss: 1.5170902013778687, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9215/10000, Loss: 1.571960210800171, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9216/10000, Loss: 1.6013567447662354, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9217/10000, Loss: 1.5414739847183228, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9218/10000, Loss: 1.607248306274414, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9219/10000, Loss: 1.4710890054702759, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9220/10000, Loss: 1.6110866069793701, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9221/10000, Loss: 1.5687949657440186, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9222/10000, Loss: 1.6476097106933594, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9223/10000, Loss: 1.570129156112671, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9224/10000, Loss: 1.5688812732696533, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9225/10000, Loss: 1.5550947189331055, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9226/10000, Loss: 1.4602079391479492, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9227/10000, Loss: 1.6427456140518188, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9228/10000, Loss: 1.526970624923706, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9229/10000, Loss: 1.4918581247329712, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9230/10000, Loss: 1.4770219326019287, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9231/10000, Loss: 1.5489946603775024, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9232/10000, Loss: 1.5762346982955933, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9233/10000, Loss: 1.5771681070327759, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9234/10000, Loss: 1.4803931713104248, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9235/10000, Loss: 1.5320398807525635, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9236/10000, Loss: 1.5110501050949097, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9237/10000, Loss: 1.535466194152832, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9238/10000, Loss: 1.5663470029830933, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9239/10000, Loss: 1.587537407875061, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9240/10000, Loss: 1.5206795930862427, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9241/10000, Loss: 1.5705634355545044, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9242/10000, Loss: 1.5885539054870605, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9243/10000, Loss: 1.6021831035614014, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9244/10000, Loss: 1.55974543094635, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9245/10000, Loss: 1.5450886487960815, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9246/10000, Loss: 1.6256344318389893, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9247/10000, Loss: 1.5178958177566528, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9248/10000, Loss: 1.4877293109893799, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9249/10000, Loss: 1.5471043586730957, Train Acc : 0.5004775549188156 , Val Acc : 0.48205128205128206\n",
      "Epoch 9250/10000, Loss: 1.6036841869354248, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9251/10000, Loss: 1.543864130973816, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9252/10000, Loss: 1.4684269428253174, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9253/10000, Loss: 1.5215325355529785, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9254/10000, Loss: 1.5285756587982178, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9255/10000, Loss: 1.6352306604385376, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9256/10000, Loss: 1.5847777128219604, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9257/10000, Loss: 1.5137232542037964, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9258/10000, Loss: 1.556398868560791, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9259/10000, Loss: 1.6166843175888062, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9260/10000, Loss: 1.5840840339660645, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9261/10000, Loss: 1.4990671873092651, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9262/10000, Loss: 1.5590265989303589, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9263/10000, Loss: 1.5089850425720215, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9264/10000, Loss: 1.5707449913024902, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9265/10000, Loss: 1.545148253440857, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9266/10000, Loss: 1.5063987970352173, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9267/10000, Loss: 1.5596294403076172, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9268/10000, Loss: 1.5455377101898193, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9269/10000, Loss: 1.5855506658554077, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9270/10000, Loss: 1.4894202947616577, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9271/10000, Loss: 1.5288300514221191, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9272/10000, Loss: 1.6055760383605957, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9273/10000, Loss: 1.5016695261001587, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9274/10000, Loss: 1.5233397483825684, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9275/10000, Loss: 1.6041433811187744, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9276/10000, Loss: 1.5712337493896484, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9277/10000, Loss: 1.5524343252182007, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9278/10000, Loss: 1.6119537353515625, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9279/10000, Loss: 1.5126163959503174, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9280/10000, Loss: 1.5012283325195312, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9281/10000, Loss: 1.4797680377960205, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9282/10000, Loss: 1.4724009037017822, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9283/10000, Loss: 1.5891362428665161, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9284/10000, Loss: 1.4529190063476562, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9285/10000, Loss: 1.6134583950042725, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9286/10000, Loss: 1.5334601402282715, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9287/10000, Loss: 1.5887119770050049, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9288/10000, Loss: 1.4829776287078857, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9289/10000, Loss: 1.4387253522872925, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9290/10000, Loss: 1.4823832511901855, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9291/10000, Loss: 1.5454421043395996, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9292/10000, Loss: 1.6189266443252563, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9293/10000, Loss: 1.3881465196609497, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9294/10000, Loss: 1.4930698871612549, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9295/10000, Loss: 1.5503015518188477, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9296/10000, Loss: 1.5009987354278564, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9297/10000, Loss: 1.575289011001587, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9298/10000, Loss: 1.5444785356521606, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9299/10000, Loss: 1.494879961013794, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9300/10000, Loss: 1.55039381980896, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9301/10000, Loss: 1.5480096340179443, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9302/10000, Loss: 1.5182417631149292, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9303/10000, Loss: 1.5448088645935059, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9304/10000, Loss: 1.49173104763031, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9305/10000, Loss: 1.4971524477005005, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9306/10000, Loss: 1.5471563339233398, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9307/10000, Loss: 1.5361099243164062, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9308/10000, Loss: 1.4445244073867798, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9309/10000, Loss: 1.5698623657226562, Train Acc : 0.5004775549188156 , Val Acc : 0.48205128205128206\n",
      "Epoch 9310/10000, Loss: 1.490441918373108, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9311/10000, Loss: 1.516767144203186, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9312/10000, Loss: 1.5245295763015747, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9313/10000, Loss: 1.517194390296936, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9314/10000, Loss: 1.6148719787597656, Train Acc : 0.5004775549188156 , Val Acc : 0.48205128205128206\n",
      "Epoch 9315/10000, Loss: 1.499847412109375, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9316/10000, Loss: 1.5589990615844727, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9317/10000, Loss: 1.5552213191986084, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9318/10000, Loss: 1.528541922569275, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9319/10000, Loss: 1.5509675741195679, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9320/10000, Loss: 1.5068107843399048, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9321/10000, Loss: 1.4941473007202148, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9322/10000, Loss: 1.5235912799835205, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9323/10000, Loss: 1.4423409700393677, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9324/10000, Loss: 1.5376064777374268, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9325/10000, Loss: 1.5937483310699463, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9326/10000, Loss: 1.522460699081421, Train Acc : 0.5001591849729385 , Val Acc : 0.48205128205128206\n",
      "Epoch 9327/10000, Loss: 1.546704888343811, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9328/10000, Loss: 1.5218204259872437, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9329/10000, Loss: 1.5040487051010132, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9330/10000, Loss: 1.582778811454773, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9331/10000, Loss: 1.5172518491744995, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9332/10000, Loss: 1.6102759838104248, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9333/10000, Loss: 1.5279544591903687, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9334/10000, Loss: 1.6472465991973877, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9335/10000, Loss: 1.635744333267212, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9336/10000, Loss: 1.5241323709487915, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9337/10000, Loss: 1.5101799964904785, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9338/10000, Loss: 1.5385322570800781, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9339/10000, Loss: 1.5273873805999756, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9340/10000, Loss: 1.5594263076782227, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9341/10000, Loss: 1.548482060432434, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9342/10000, Loss: 1.5371373891830444, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9343/10000, Loss: 1.5609934329986572, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9344/10000, Loss: 1.5482885837554932, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9345/10000, Loss: 1.6524826288223267, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9346/10000, Loss: 1.4638946056365967, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9347/10000, Loss: 1.5337135791778564, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9348/10000, Loss: 1.5836191177368164, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9349/10000, Loss: 1.5182864665985107, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9350/10000, Loss: 1.6344226598739624, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9351/10000, Loss: 1.603527545928955, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9352/10000, Loss: 1.5701465606689453, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9353/10000, Loss: 1.5573011636734009, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9354/10000, Loss: 1.5827115774154663, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9355/10000, Loss: 1.4902746677398682, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9356/10000, Loss: 1.6219340562820435, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9357/10000, Loss: 1.5501233339309692, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9358/10000, Loss: 1.5292080640792847, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9359/10000, Loss: 1.6414518356323242, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9360/10000, Loss: 1.5457144975662231, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9361/10000, Loss: 1.5770549774169922, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9362/10000, Loss: 1.466307282447815, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9363/10000, Loss: 1.4880322217941284, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9364/10000, Loss: 1.571790337562561, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9365/10000, Loss: 1.5689191818237305, Train Acc : 0.49984081502706146 , Val Acc : 0.48205128205128206\n",
      "Epoch 9366/10000, Loss: 1.582432746887207, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9367/10000, Loss: 1.6054426431655884, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9368/10000, Loss: 1.5077885389328003, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9369/10000, Loss: 1.5971990823745728, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9370/10000, Loss: 1.5347089767456055, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9371/10000, Loss: 1.4799903631210327, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9372/10000, Loss: 1.5503532886505127, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9373/10000, Loss: 1.5600049495697021, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9374/10000, Loss: 1.5672905445098877, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9375/10000, Loss: 1.4654442071914673, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9376/10000, Loss: 1.4729349613189697, Train Acc : 0.49984081502706146 , Val Acc : 0.4846153846153846\n",
      "Epoch 9377/10000, Loss: 1.5651626586914062, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9378/10000, Loss: 1.5484868288040161, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9379/10000, Loss: 1.5368658304214478, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9380/10000, Loss: 1.558032512664795, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9381/10000, Loss: 1.6245195865631104, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9382/10000, Loss: 1.4830660820007324, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9383/10000, Loss: 1.5532640218734741, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9384/10000, Loss: 1.5521626472473145, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9385/10000, Loss: 1.6130201816558838, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9386/10000, Loss: 1.5956206321716309, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9387/10000, Loss: 1.5266038179397583, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9388/10000, Loss: 1.6043936014175415, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9389/10000, Loss: 1.4733277559280396, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9390/10000, Loss: 1.430184006690979, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9391/10000, Loss: 1.5537421703338623, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9392/10000, Loss: 1.5574692487716675, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9393/10000, Loss: 1.6236393451690674, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9394/10000, Loss: 1.5248677730560303, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9395/10000, Loss: 1.591320514678955, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9396/10000, Loss: 1.5145368576049805, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9397/10000, Loss: 1.4901134967803955, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9398/10000, Loss: 1.5873409509658813, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9399/10000, Loss: 1.511962652206421, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9400/10000, Loss: 1.5180940628051758, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9401/10000, Loss: 1.5774627923965454, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9402/10000, Loss: 1.5316699743270874, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9403/10000, Loss: 1.5437825918197632, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9404/10000, Loss: 1.592272162437439, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9405/10000, Loss: 1.5035743713378906, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9406/10000, Loss: 1.5466302633285522, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9407/10000, Loss: 1.5206915140151978, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9408/10000, Loss: 1.5529730319976807, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9409/10000, Loss: 1.5090806484222412, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9410/10000, Loss: 1.524675965309143, Train Acc : 0.49984081502706146 , Val Acc : 0.4846153846153846\n",
      "Epoch 9411/10000, Loss: 1.4601480960845947, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9412/10000, Loss: 1.509375810623169, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9413/10000, Loss: 1.536742091178894, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9414/10000, Loss: 1.5784634351730347, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9415/10000, Loss: 1.5296244621276855, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9416/10000, Loss: 1.5615490674972534, Train Acc : 0.49984081502706146 , Val Acc : 0.4846153846153846\n",
      "Epoch 9417/10000, Loss: 1.5601328611373901, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9418/10000, Loss: 1.5191881656646729, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9419/10000, Loss: 1.500067949295044, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9420/10000, Loss: 1.5686157941818237, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9421/10000, Loss: 1.4891186952590942, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9422/10000, Loss: 1.5117219686508179, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9423/10000, Loss: 1.5128852128982544, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9424/10000, Loss: 1.5083330869674683, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9425/10000, Loss: 1.5345394611358643, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9426/10000, Loss: 1.6462291479110718, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9427/10000, Loss: 1.5665804147720337, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9428/10000, Loss: 1.6013119220733643, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9429/10000, Loss: 1.5029503107070923, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9430/10000, Loss: 1.598496437072754, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9431/10000, Loss: 1.511925458908081, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9432/10000, Loss: 1.5312728881835938, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9433/10000, Loss: 1.5699864625930786, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9434/10000, Loss: 1.6384916305541992, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9435/10000, Loss: 1.5519388914108276, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9436/10000, Loss: 1.4825080633163452, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9437/10000, Loss: 1.5749167203903198, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9438/10000, Loss: 1.4197185039520264, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9439/10000, Loss: 1.5400266647338867, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9440/10000, Loss: 1.4630271196365356, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9441/10000, Loss: 1.6172513961791992, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9442/10000, Loss: 1.5814510583877563, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9443/10000, Loss: 1.508882999420166, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9444/10000, Loss: 1.5280696153640747, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9445/10000, Loss: 1.546249508857727, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9446/10000, Loss: 1.603560209274292, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9447/10000, Loss: 1.6005525588989258, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9448/10000, Loss: 1.5720068216323853, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9449/10000, Loss: 1.5576695203781128, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9450/10000, Loss: 1.5861796140670776, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9451/10000, Loss: 1.5094797611236572, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9452/10000, Loss: 1.5611883401870728, Train Acc : 0.49984081502706146 , Val Acc : 0.4846153846153846\n",
      "Epoch 9453/10000, Loss: 1.5312005281448364, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9454/10000, Loss: 1.5173072814941406, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9455/10000, Loss: 1.4494967460632324, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9456/10000, Loss: 1.5675688982009888, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9457/10000, Loss: 1.4917519092559814, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9458/10000, Loss: 1.631866455078125, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9459/10000, Loss: 1.5233370065689087, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9460/10000, Loss: 1.5607478618621826, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9461/10000, Loss: 1.5985969305038452, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9462/10000, Loss: 1.542528510093689, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9463/10000, Loss: 1.5581687688827515, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9464/10000, Loss: 1.680969476699829, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9465/10000, Loss: 1.5330226421356201, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9466/10000, Loss: 1.4953291416168213, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9467/10000, Loss: 1.5964136123657227, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9468/10000, Loss: 1.585189938545227, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9469/10000, Loss: 1.5562293529510498, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9470/10000, Loss: 1.5526537895202637, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9471/10000, Loss: 1.5866531133651733, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9472/10000, Loss: 1.5921381711959839, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9473/10000, Loss: 1.5229461193084717, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9474/10000, Loss: 1.6722097396850586, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9475/10000, Loss: 1.5509779453277588, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9476/10000, Loss: 1.4520641565322876, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9477/10000, Loss: 1.4511890411376953, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9478/10000, Loss: 1.6490471363067627, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9479/10000, Loss: 1.4461642503738403, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9480/10000, Loss: 1.5616881847381592, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9481/10000, Loss: 1.5420507192611694, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9482/10000, Loss: 1.5135893821716309, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9483/10000, Loss: 1.5106844902038574, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9484/10000, Loss: 1.4944928884506226, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9485/10000, Loss: 1.5725860595703125, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9486/10000, Loss: 1.5099109411239624, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9487/10000, Loss: 1.5889439582824707, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9488/10000, Loss: 1.531382441520691, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9489/10000, Loss: 1.539155125617981, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9490/10000, Loss: 1.5637925863265991, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9491/10000, Loss: 1.5053212642669678, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9492/10000, Loss: 1.5480003356933594, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9493/10000, Loss: 1.595069169998169, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9494/10000, Loss: 1.4567673206329346, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9495/10000, Loss: 1.6358733177185059, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9496/10000, Loss: 1.511054277420044, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9497/10000, Loss: 1.5898807048797607, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9498/10000, Loss: 1.5766839981079102, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9499/10000, Loss: 1.58584725856781, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9500/10000, Loss: 1.5567988157272339, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9501/10000, Loss: 1.5503703355789185, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9502/10000, Loss: 1.5859410762786865, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9503/10000, Loss: 1.6636109352111816, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9504/10000, Loss: 1.5135924816131592, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9505/10000, Loss: 1.4862178564071655, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9506/10000, Loss: 1.5269789695739746, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9507/10000, Loss: 1.6192777156829834, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9508/10000, Loss: 1.5107884407043457, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9509/10000, Loss: 1.5678296089172363, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9510/10000, Loss: 1.589120864868164, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9511/10000, Loss: 1.4847831726074219, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9512/10000, Loss: 1.623347282409668, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9513/10000, Loss: 1.571197509765625, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9514/10000, Loss: 1.563635230064392, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9515/10000, Loss: 1.556634545326233, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9516/10000, Loss: 1.4810658693313599, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9517/10000, Loss: 1.5747016668319702, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9518/10000, Loss: 1.5430958271026611, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9519/10000, Loss: 1.496472954750061, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9520/10000, Loss: 1.559876561164856, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9521/10000, Loss: 1.5785751342773438, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9522/10000, Loss: 1.5644341707229614, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9523/10000, Loss: 1.6197028160095215, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9524/10000, Loss: 1.6261444091796875, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9525/10000, Loss: 1.4727178812026978, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9526/10000, Loss: 1.5211539268493652, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9527/10000, Loss: 1.5234928131103516, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9528/10000, Loss: 1.5205085277557373, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9529/10000, Loss: 1.4678055047988892, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9530/10000, Loss: 1.582233190536499, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9531/10000, Loss: 1.4411087036132812, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9532/10000, Loss: 1.5465372800827026, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9533/10000, Loss: 1.5103615522384644, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9534/10000, Loss: 1.5938383340835571, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9535/10000, Loss: 1.4843145608901978, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9536/10000, Loss: 1.5257316827774048, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9537/10000, Loss: 1.588619351387024, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9538/10000, Loss: 1.4235481023788452, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9539/10000, Loss: 1.4732221364974976, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9540/10000, Loss: 1.5864951610565186, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9541/10000, Loss: 1.627848744392395, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9542/10000, Loss: 1.6180322170257568, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9543/10000, Loss: 1.530137062072754, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9544/10000, Loss: 1.5431623458862305, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9545/10000, Loss: 1.4942207336425781, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9546/10000, Loss: 1.5789802074432373, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9547/10000, Loss: 1.5564906597137451, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9548/10000, Loss: 1.5144779682159424, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9549/10000, Loss: 1.5024518966674805, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9550/10000, Loss: 1.499651312828064, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9551/10000, Loss: 1.4734410047531128, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9552/10000, Loss: 1.6266742944717407, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9553/10000, Loss: 1.497660756111145, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9554/10000, Loss: 1.5046051740646362, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9555/10000, Loss: 1.5767240524291992, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9556/10000, Loss: 1.454506516456604, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9557/10000, Loss: 1.4368085861206055, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9558/10000, Loss: 1.5027347803115845, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9559/10000, Loss: 1.5066962242126465, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9560/10000, Loss: 1.589477777481079, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9561/10000, Loss: 1.5540748834609985, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9562/10000, Loss: 1.6438359022140503, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9563/10000, Loss: 1.5721544027328491, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9564/10000, Loss: 1.6217162609100342, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9565/10000, Loss: 1.5868988037109375, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9566/10000, Loss: 1.6050503253936768, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9567/10000, Loss: 1.511665940284729, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9568/10000, Loss: 1.5975923538208008, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9569/10000, Loss: 1.5468175411224365, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9570/10000, Loss: 1.6265889406204224, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9571/10000, Loss: 1.5785636901855469, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9572/10000, Loss: 1.5902488231658936, Train Acc : 0.5001591849729385 , Val Acc : 0.4846153846153846\n",
      "Epoch 9573/10000, Loss: 1.6659445762634277, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9574/10000, Loss: 1.5928457975387573, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9575/10000, Loss: 1.5603824853897095, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9576/10000, Loss: 1.5748510360717773, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9577/10000, Loss: 1.5138486623764038, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9578/10000, Loss: 1.4932148456573486, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9579/10000, Loss: 1.5040392875671387, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9580/10000, Loss: 1.4110954999923706, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9581/10000, Loss: 1.5956445932388306, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9582/10000, Loss: 1.5006330013275146, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9583/10000, Loss: 1.531935691833496, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9584/10000, Loss: 1.482221245765686, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9585/10000, Loss: 1.5331796407699585, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9586/10000, Loss: 1.5758435726165771, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9587/10000, Loss: 1.5236316919326782, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9588/10000, Loss: 1.5693070888519287, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9589/10000, Loss: 1.4182054996490479, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9590/10000, Loss: 1.5737247467041016, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9591/10000, Loss: 1.6000843048095703, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9592/10000, Loss: 1.4504128694534302, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9593/10000, Loss: 1.567516565322876, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9594/10000, Loss: 1.6396381855010986, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9595/10000, Loss: 1.4841433763504028, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9596/10000, Loss: 1.5971839427947998, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9597/10000, Loss: 1.6234722137451172, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9598/10000, Loss: 1.4920575618743896, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9599/10000, Loss: 1.5227235555648804, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9600/10000, Loss: 1.5052647590637207, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9601/10000, Loss: 1.5790045261383057, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9602/10000, Loss: 1.446560263633728, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9603/10000, Loss: 1.5830720663070679, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9604/10000, Loss: 1.5555319786071777, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9605/10000, Loss: 1.4822843074798584, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9606/10000, Loss: 1.5622780323028564, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9607/10000, Loss: 1.5837514400482178, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9608/10000, Loss: 1.586661458015442, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9609/10000, Loss: 1.5672169923782349, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9610/10000, Loss: 1.517095685005188, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9611/10000, Loss: 1.575634479522705, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9612/10000, Loss: 1.5650475025177002, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9613/10000, Loss: 1.5393757820129395, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9614/10000, Loss: 1.5617212057113647, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9615/10000, Loss: 1.571923851966858, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9616/10000, Loss: 1.5970500707626343, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9617/10000, Loss: 1.5181784629821777, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9618/10000, Loss: 1.4986876249313354, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9619/10000, Loss: 1.505504846572876, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9620/10000, Loss: 1.6346015930175781, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9621/10000, Loss: 1.4986259937286377, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9622/10000, Loss: 1.509106993675232, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9623/10000, Loss: 1.5064749717712402, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9624/10000, Loss: 1.5623968839645386, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9625/10000, Loss: 1.4782991409301758, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9626/10000, Loss: 1.5472769737243652, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9627/10000, Loss: 1.5555851459503174, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9628/10000, Loss: 1.536474585533142, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9629/10000, Loss: 1.508497714996338, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9630/10000, Loss: 1.5620399713516235, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9631/10000, Loss: 1.527593970298767, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9632/10000, Loss: 1.631476640701294, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9633/10000, Loss: 1.5422900915145874, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9634/10000, Loss: 1.5909401178359985, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9635/10000, Loss: 1.593010663986206, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9636/10000, Loss: 1.5981439352035522, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9637/10000, Loss: 1.5891863107681274, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9638/10000, Loss: 1.5657422542572021, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9639/10000, Loss: 1.6427421569824219, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9640/10000, Loss: 1.5358854532241821, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9641/10000, Loss: 1.554062843322754, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9642/10000, Loss: 1.5760767459869385, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9643/10000, Loss: 1.6237176656723022, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9644/10000, Loss: 1.5651415586471558, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9645/10000, Loss: 1.5606346130371094, Train Acc : 0.49920407513530723 , Val Acc : 0.48717948717948717\n",
      "Epoch 9646/10000, Loss: 1.4162191152572632, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9647/10000, Loss: 1.4655052423477173, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9648/10000, Loss: 1.558013916015625, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9649/10000, Loss: 1.5379672050476074, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9650/10000, Loss: 1.5567270517349243, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9651/10000, Loss: 1.5913879871368408, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9652/10000, Loss: 1.500078558921814, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9653/10000, Loss: 1.5622905492782593, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 9654/10000, Loss: 1.5765702724456787, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9655/10000, Loss: 1.5602221488952637, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 9656/10000, Loss: 1.5458310842514038, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9657/10000, Loss: 1.478653907775879, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9658/10000, Loss: 1.5104392766952515, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9659/10000, Loss: 1.4870003461837769, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9660/10000, Loss: 1.5346174240112305, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9661/10000, Loss: 1.5977646112442017, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9662/10000, Loss: 1.5949060916900635, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9663/10000, Loss: 1.5581579208374023, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9664/10000, Loss: 1.5853787660598755, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9665/10000, Loss: 1.4868308305740356, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9666/10000, Loss: 1.4976824522018433, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9667/10000, Loss: 1.4596487283706665, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9668/10000, Loss: 1.5689678192138672, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9669/10000, Loss: 1.6162753105163574, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9670/10000, Loss: 1.4677221775054932, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9671/10000, Loss: 1.5825107097625732, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9672/10000, Loss: 1.524205207824707, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9673/10000, Loss: 1.5329205989837646, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9674/10000, Loss: 1.4643679857254028, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9675/10000, Loss: 1.5645231008529663, Train Acc : 0.49824896529767587 , Val Acc : 0.48205128205128206\n",
      "Epoch 9676/10000, Loss: 1.4372749328613281, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9677/10000, Loss: 1.5399863719940186, Train Acc : 0.49920407513530723 , Val Acc : 0.48205128205128206\n",
      "Epoch 9678/10000, Loss: 1.495468020439148, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 9679/10000, Loss: 1.5476014614105225, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9680/10000, Loss: 1.5970826148986816, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9681/10000, Loss: 1.641848087310791, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9682/10000, Loss: 1.5211677551269531, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9683/10000, Loss: 1.5547573566436768, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9684/10000, Loss: 1.6136009693145752, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9685/10000, Loss: 1.500998616218567, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9686/10000, Loss: 1.5280280113220215, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9687/10000, Loss: 1.566802740097046, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9688/10000, Loss: 1.5533332824707031, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9689/10000, Loss: 1.4631253480911255, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9690/10000, Loss: 1.543265461921692, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9691/10000, Loss: 1.504056692123413, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9692/10000, Loss: 1.4919273853302002, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9693/10000, Loss: 1.4263421297073364, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9694/10000, Loss: 1.4907402992248535, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9695/10000, Loss: 1.6058377027511597, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9696/10000, Loss: 1.5379250049591064, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9697/10000, Loss: 1.5439937114715576, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9698/10000, Loss: 1.544818639755249, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9699/10000, Loss: 1.5031813383102417, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9700/10000, Loss: 1.5761487483978271, Train Acc : 0.4988857051894301 , Val Acc : 0.48205128205128206\n",
      "Epoch 9701/10000, Loss: 1.5401837825775146, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9702/10000, Loss: 1.516045331954956, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9703/10000, Loss: 1.492807388305664, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9704/10000, Loss: 1.4997107982635498, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9705/10000, Loss: 1.544158697128296, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9706/10000, Loss: 1.506615400314331, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9707/10000, Loss: 1.5619885921478271, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9708/10000, Loss: 1.5089534521102905, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9709/10000, Loss: 1.5710551738739014, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9710/10000, Loss: 1.6012166738510132, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9711/10000, Loss: 1.5120129585266113, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9712/10000, Loss: 1.548994779586792, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9713/10000, Loss: 1.5564205646514893, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9714/10000, Loss: 1.5473690032958984, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9715/10000, Loss: 1.591257929801941, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9716/10000, Loss: 1.5042259693145752, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9717/10000, Loss: 1.600928783416748, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 9718/10000, Loss: 1.5100288391113281, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9719/10000, Loss: 1.5932121276855469, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9720/10000, Loss: 1.5487250089645386, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9721/10000, Loss: 1.532189965248108, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9722/10000, Loss: 1.4842779636383057, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9723/10000, Loss: 1.5836588144302368, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9724/10000, Loss: 1.5833048820495605, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9725/10000, Loss: 1.5451117753982544, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9726/10000, Loss: 1.5375083684921265, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9727/10000, Loss: 1.500388264656067, Train Acc : 0.4979305953517988 , Val Acc : 0.48205128205128206\n",
      "Epoch 9728/10000, Loss: 1.4752823114395142, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9729/10000, Loss: 1.4958457946777344, Train Acc : 0.49984081502706146 , Val Acc : 0.4846153846153846\n",
      "Epoch 9730/10000, Loss: 1.588330864906311, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9731/10000, Loss: 1.555577039718628, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9732/10000, Loss: 1.556698203086853, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9733/10000, Loss: 1.5184965133666992, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9734/10000, Loss: 1.5605385303497314, Train Acc : 0.498567335243553 , Val Acc : 0.48205128205128206\n",
      "Epoch 9735/10000, Loss: 1.4932124614715576, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9736/10000, Loss: 1.4883196353912354, Train Acc : 0.4995224450811843 , Val Acc : 0.48205128205128206\n",
      "Epoch 9737/10000, Loss: 1.5651345252990723, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9738/10000, Loss: 1.5646705627441406, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9739/10000, Loss: 1.4719489812850952, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9740/10000, Loss: 1.5143609046936035, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9741/10000, Loss: 1.5721633434295654, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9742/10000, Loss: 1.583537220954895, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9743/10000, Loss: 1.562534213066101, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9744/10000, Loss: 1.513811469078064, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9745/10000, Loss: 1.5613629817962646, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9746/10000, Loss: 1.496955156326294, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9747/10000, Loss: 1.553591012954712, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9748/10000, Loss: 1.5055854320526123, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9749/10000, Loss: 1.6044232845306396, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9750/10000, Loss: 1.485105037689209, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9751/10000, Loss: 1.6886276006698608, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9752/10000, Loss: 1.5513499975204468, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9753/10000, Loss: 1.4955625534057617, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9754/10000, Loss: 1.6298784017562866, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9755/10000, Loss: 1.588728666305542, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9756/10000, Loss: 1.5711265802383423, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9757/10000, Loss: 1.5238548517227173, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9758/10000, Loss: 1.581612467765808, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9759/10000, Loss: 1.528099775314331, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9760/10000, Loss: 1.5708564519882202, Train Acc : 0.498567335243553 , Val Acc : 0.4897435897435897\n",
      "Epoch 9761/10000, Loss: 1.4855726957321167, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9762/10000, Loss: 1.5099955797195435, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9763/10000, Loss: 1.5519245862960815, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9764/10000, Loss: 1.5865988731384277, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9765/10000, Loss: 1.5707439184188843, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9766/10000, Loss: 1.594096064567566, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9767/10000, Loss: 1.543397068977356, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9768/10000, Loss: 1.5352073907852173, Train Acc : 0.49920407513530723 , Val Acc : 0.48717948717948717\n",
      "Epoch 9769/10000, Loss: 1.542870283126831, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9770/10000, Loss: 1.414000153541565, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9771/10000, Loss: 1.5122994184494019, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9772/10000, Loss: 1.5604740381240845, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9773/10000, Loss: 1.487156867980957, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9774/10000, Loss: 1.5657840967178345, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9775/10000, Loss: 1.4966039657592773, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9776/10000, Loss: 1.5253113508224487, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9777/10000, Loss: 1.5665005445480347, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9778/10000, Loss: 1.5177706480026245, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9779/10000, Loss: 1.537593126296997, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9780/10000, Loss: 1.5838863849639893, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9781/10000, Loss: 1.5762826204299927, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9782/10000, Loss: 1.6009795665740967, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9783/10000, Loss: 1.5619652271270752, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9784/10000, Loss: 1.509860873222351, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9785/10000, Loss: 1.488966464996338, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9786/10000, Loss: 1.5954008102416992, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9787/10000, Loss: 1.5980353355407715, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9788/10000, Loss: 1.5278480052947998, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9789/10000, Loss: 1.5786826610565186, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9790/10000, Loss: 1.5086599588394165, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9791/10000, Loss: 1.5552756786346436, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9792/10000, Loss: 1.507907509803772, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9793/10000, Loss: 1.5201939344406128, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9794/10000, Loss: 1.6159247159957886, Train Acc : 0.4995224450811843 , Val Acc : 0.48717948717948717\n",
      "Epoch 9795/10000, Loss: 1.4864612817764282, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9796/10000, Loss: 1.5656089782714844, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9797/10000, Loss: 1.4707969427108765, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9798/10000, Loss: 1.4714218378067017, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9799/10000, Loss: 1.4907281398773193, Train Acc : 0.49920407513530723 , Val Acc : 0.48717948717948717\n",
      "Epoch 9800/10000, Loss: 1.533095121383667, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9801/10000, Loss: 1.5292116403579712, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9802/10000, Loss: 1.6376807689666748, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9803/10000, Loss: 1.4543265104293823, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9804/10000, Loss: 1.6515611410140991, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9805/10000, Loss: 1.4848977327346802, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9806/10000, Loss: 1.598578691482544, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9807/10000, Loss: 1.554519534111023, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9808/10000, Loss: 1.541165828704834, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9809/10000, Loss: 1.5183465480804443, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9810/10000, Loss: 1.5662999153137207, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9811/10000, Loss: 1.6685607433319092, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9812/10000, Loss: 1.5497896671295166, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9813/10000, Loss: 1.6167409420013428, Train Acc : 0.4995224450811843 , Val Acc : 0.4846153846153846\n",
      "Epoch 9814/10000, Loss: 1.6078215837478638, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9815/10000, Loss: 1.4863296747207642, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9816/10000, Loss: 1.5515327453613281, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9817/10000, Loss: 1.5114555358886719, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9818/10000, Loss: 1.5876145362854004, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9819/10000, Loss: 1.4926929473876953, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9820/10000, Loss: 1.5012571811676025, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9821/10000, Loss: 1.5214482545852661, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9822/10000, Loss: 1.520600438117981, Train Acc : 0.49920407513530723 , Val Acc : 0.48717948717948717\n",
      "Epoch 9823/10000, Loss: 1.5912013053894043, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9824/10000, Loss: 1.618887186050415, Train Acc : 0.49920407513530723 , Val Acc : 0.48717948717948717\n",
      "Epoch 9825/10000, Loss: 1.5033528804779053, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9826/10000, Loss: 1.4381009340286255, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9827/10000, Loss: 1.4570510387420654, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9828/10000, Loss: 1.5647486448287964, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9829/10000, Loss: 1.531755805015564, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9830/10000, Loss: 1.5046701431274414, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9831/10000, Loss: 1.481173038482666, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9832/10000, Loss: 1.5639393329620361, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9833/10000, Loss: 1.5405387878417969, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9834/10000, Loss: 1.5764120817184448, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9835/10000, Loss: 1.5028822422027588, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9836/10000, Loss: 1.6533925533294678, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9837/10000, Loss: 1.5230458974838257, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9838/10000, Loss: 1.5180197954177856, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9839/10000, Loss: 1.4792762994766235, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9840/10000, Loss: 1.6018229722976685, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9841/10000, Loss: 1.613304853439331, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9842/10000, Loss: 1.525902271270752, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9843/10000, Loss: 1.5278342962265015, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9844/10000, Loss: 1.5367637872695923, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9845/10000, Loss: 1.4280035495758057, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9846/10000, Loss: 1.5667445659637451, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9847/10000, Loss: 1.554093360900879, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9848/10000, Loss: 1.4593476057052612, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9849/10000, Loss: 1.5819708108901978, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9850/10000, Loss: 1.5613224506378174, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9851/10000, Loss: 1.4966752529144287, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9852/10000, Loss: 1.522565245628357, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9853/10000, Loss: 1.5367684364318848, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9854/10000, Loss: 1.5854463577270508, Train Acc : 0.49984081502706146 , Val Acc : 0.4846153846153846\n",
      "Epoch 9855/10000, Loss: 1.514512062072754, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9856/10000, Loss: 1.4770454168319702, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9857/10000, Loss: 1.498737096786499, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9858/10000, Loss: 1.4185436964035034, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9859/10000, Loss: 1.5383802652359009, Train Acc : 0.49920407513530723 , Val Acc : 0.48717948717948717\n",
      "Epoch 9860/10000, Loss: 1.5320122241973877, Train Acc : 0.4995224450811843 , Val Acc : 0.48717948717948717\n",
      "Epoch 9861/10000, Loss: 1.5137571096420288, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9862/10000, Loss: 1.4493211507797241, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9863/10000, Loss: 1.5118814706802368, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9864/10000, Loss: 1.531604290008545, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9865/10000, Loss: 1.5002295970916748, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9866/10000, Loss: 1.5245863199234009, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9867/10000, Loss: 1.4927386045455933, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9868/10000, Loss: 1.502951741218567, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9869/10000, Loss: 1.5590026378631592, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9870/10000, Loss: 1.5671465396881104, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9871/10000, Loss: 1.5648247003555298, Train Acc : 0.4995224450811843 , Val Acc : 0.48717948717948717\n",
      "Epoch 9872/10000, Loss: 1.5919158458709717, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9873/10000, Loss: 1.5958491563796997, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9874/10000, Loss: 1.6178042888641357, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9875/10000, Loss: 1.5493465662002563, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9876/10000, Loss: 1.5534600019454956, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9877/10000, Loss: 1.5397579669952393, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9878/10000, Loss: 1.5773975849151611, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9879/10000, Loss: 1.5137070417404175, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9880/10000, Loss: 1.4820908308029175, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9881/10000, Loss: 1.5538479089736938, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9882/10000, Loss: 1.6166309118270874, Train Acc : 0.4988857051894301 , Val Acc : 0.4846153846153846\n",
      "Epoch 9883/10000, Loss: 1.5388352870941162, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9884/10000, Loss: 1.5647001266479492, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9885/10000, Loss: 1.5634303092956543, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9886/10000, Loss: 1.6058372259140015, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9887/10000, Loss: 1.5442008972167969, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9888/10000, Loss: 1.4488707780838013, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9889/10000, Loss: 1.5434777736663818, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9890/10000, Loss: 1.6151992082595825, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9891/10000, Loss: 1.5252645015716553, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9892/10000, Loss: 1.5677443742752075, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9893/10000, Loss: 1.6018928289413452, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9894/10000, Loss: 1.5018121004104614, Train Acc : 0.49920407513530723 , Val Acc : 0.4846153846153846\n",
      "Epoch 9895/10000, Loss: 1.570829153060913, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9896/10000, Loss: 1.5671164989471436, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9897/10000, Loss: 1.5964586734771729, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9898/10000, Loss: 1.6376383304595947, Train Acc : 0.49920407513530723 , Val Acc : 0.48717948717948717\n",
      "Epoch 9899/10000, Loss: 1.6297407150268555, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9900/10000, Loss: 1.6228926181793213, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9901/10000, Loss: 1.5541869401931763, Train Acc : 0.49729385546004456 , Val Acc : 0.48717948717948717\n",
      "Epoch 9902/10000, Loss: 1.5086750984191895, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9903/10000, Loss: 1.604993462562561, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9904/10000, Loss: 1.5774186849594116, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9905/10000, Loss: 1.5936886072158813, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9906/10000, Loss: 1.5516616106033325, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9907/10000, Loss: 1.5600848197937012, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9908/10000, Loss: 1.5615806579589844, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9909/10000, Loss: 1.5584887266159058, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9910/10000, Loss: 1.5884665250778198, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9911/10000, Loss: 1.4159839153289795, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9912/10000, Loss: 1.5149863958358765, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9913/10000, Loss: 1.541798710823059, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9914/10000, Loss: 1.4645988941192627, Train Acc : 0.4976122254059217 , Val Acc : 0.48717948717948717\n",
      "Epoch 9915/10000, Loss: 1.4599970579147339, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9916/10000, Loss: 1.5238697528839111, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9917/10000, Loss: 1.5552881956100464, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9918/10000, Loss: 1.6542474031448364, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9919/10000, Loss: 1.4907256364822388, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9920/10000, Loss: 1.5378999710083008, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9921/10000, Loss: 1.608672022819519, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9922/10000, Loss: 1.5375545024871826, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9923/10000, Loss: 1.586916208267212, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9924/10000, Loss: 1.543920874595642, Train Acc : 0.49824896529767587 , Val Acc : 0.4846153846153846\n",
      "Epoch 9925/10000, Loss: 1.504935622215271, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9926/10000, Loss: 1.5628175735473633, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9927/10000, Loss: 1.5981470346450806, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9928/10000, Loss: 1.513651967048645, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9929/10000, Loss: 1.6316447257995605, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9930/10000, Loss: 1.609695315361023, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9931/10000, Loss: 1.5232713222503662, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9932/10000, Loss: 1.5458765029907227, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9933/10000, Loss: 1.5217760801315308, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9934/10000, Loss: 1.447579264640808, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9935/10000, Loss: 1.5576058626174927, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9936/10000, Loss: 1.5555468797683716, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9937/10000, Loss: 1.6255542039871216, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9938/10000, Loss: 1.5757331848144531, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9939/10000, Loss: 1.5413148403167725, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9940/10000, Loss: 1.5299313068389893, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9941/10000, Loss: 1.542954444885254, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9942/10000, Loss: 1.5021575689315796, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9943/10000, Loss: 1.5657047033309937, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9944/10000, Loss: 1.5144586563110352, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9945/10000, Loss: 1.5994887351989746, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9946/10000, Loss: 1.5945708751678467, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9947/10000, Loss: 1.5720206499099731, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9948/10000, Loss: 1.5188229084014893, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9949/10000, Loss: 1.5464847087860107, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9950/10000, Loss: 1.5922091007232666, Train Acc : 0.498567335243553 , Val Acc : 0.4846153846153846\n",
      "Epoch 9951/10000, Loss: 1.5645830631256104, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9952/10000, Loss: 1.5246484279632568, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9953/10000, Loss: 1.5159480571746826, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9954/10000, Loss: 1.5575108528137207, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9955/10000, Loss: 1.612614631652832, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9956/10000, Loss: 1.550390362739563, Train Acc : 0.4979305953517988 , Val Acc : 0.4846153846153846\n",
      "Epoch 9957/10000, Loss: 1.618528127670288, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9958/10000, Loss: 1.6232973337173462, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9959/10000, Loss: 1.5214035511016846, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9960/10000, Loss: 1.5399421453475952, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9961/10000, Loss: 1.5538233518600464, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9962/10000, Loss: 1.46201491355896, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9963/10000, Loss: 1.4685519933700562, Train Acc : 0.4976122254059217 , Val Acc : 0.48717948717948717\n",
      "Epoch 9964/10000, Loss: 1.536834955215454, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9965/10000, Loss: 1.513819932937622, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9966/10000, Loss: 1.5277283191680908, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9967/10000, Loss: 1.4779719114303589, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9968/10000, Loss: 1.5929850339889526, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9969/10000, Loss: 1.6278561353683472, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9970/10000, Loss: 1.519293189048767, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9971/10000, Loss: 1.5615676641464233, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9972/10000, Loss: 1.5521202087402344, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9973/10000, Loss: 1.4866294860839844, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9974/10000, Loss: 1.4903490543365479, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9975/10000, Loss: 1.606982707977295, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9976/10000, Loss: 1.5156886577606201, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9977/10000, Loss: 1.5846112966537476, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9978/10000, Loss: 1.5622467994689941, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9979/10000, Loss: 1.4701011180877686, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9980/10000, Loss: 1.5489686727523804, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9981/10000, Loss: 1.4881231784820557, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9982/10000, Loss: 1.581892967224121, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9983/10000, Loss: 1.4847776889801025, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9984/10000, Loss: 1.5348070859909058, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9985/10000, Loss: 1.5359176397323608, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9986/10000, Loss: 1.614560604095459, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9987/10000, Loss: 1.642228364944458, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9988/10000, Loss: 1.5831153392791748, Train Acc : 0.4976122254059217 , Val Acc : 0.48717948717948717\n",
      "Epoch 9989/10000, Loss: 1.5419690608978271, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9990/10000, Loss: 1.5037763118743896, Train Acc : 0.49729385546004456 , Val Acc : 0.48717948717948717\n",
      "Epoch 9991/10000, Loss: 1.510905146598816, Train Acc : 0.4976122254059217 , Val Acc : 0.4846153846153846\n",
      "Epoch 9992/10000, Loss: 1.5486128330230713, Train Acc : 0.498567335243553 , Val Acc : 0.48717948717948717\n",
      "Epoch 9993/10000, Loss: 1.6191935539245605, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9994/10000, Loss: 1.6034605503082275, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9995/10000, Loss: 1.5409495830535889, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9996/10000, Loss: 1.4984626770019531, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 9997/10000, Loss: 1.4505200386047363, Train Acc : 0.49824896529767587 , Val Acc : 0.48717948717948717\n",
      "Epoch 9998/10000, Loss: 1.562130093574524, Train Acc : 0.4988857051894301 , Val Acc : 0.48717948717948717\n",
      "Epoch 9999/10000, Loss: 1.5468881130218506, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Epoch 10000/10000, Loss: 1.5764656066894531, Train Acc : 0.4979305953517988 , Val Acc : 0.48717948717948717\n",
      "Best Validation Accuracy: 0.4897435897435897\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10000\n",
    "train_data_loader = DataLoader(train_dataset_embedded, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset_embedded, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "classification_head = MLPHead().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(classification_head.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "train_acc = list()\n",
    "val_acc = list()\n",
    "best_acc = 0\n",
    "for e in range(epochs):\n",
    "    train_correct = 0\n",
    "    for batch in train_data_loader:\n",
    "        audio_embeds, labels = batch\n",
    "        audio_embeds = audio_embeds.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classification_head(audio_embeds)\n",
    "        est_classification = torch.argmax(outputs, dim=1)\n",
    "        train_correct += torch.sum(est_classification == labels).item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc.append(train_correct/len(train_dataset))\n",
    "    with torch.no_grad():\n",
    "        val_correct = 0\n",
    "        for batch in val_data_loader:\n",
    "            audio_embeds, labels = batch\n",
    "            audio_embeds = audio_embeds.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = classification_head(audio_embeds)\n",
    "            est_classification = torch.argmax(outputs, dim=1)\n",
    "            val_correct += torch.sum(est_classification == labels).item()\n",
    "        val_acc.append(val_correct/len(val_dataset))\n",
    "        if val_acc[-1] > best_acc:\n",
    "            best_acc = val_acc[-1]\n",
    "            best_model ={\n",
    "                \"clap_model\": clap_model.state_dict(),\n",
    "                \"mlp_head\": classification_head.state_dict(),\n",
    "                \"val_acc\": val_acc[-1],\n",
    "            }\n",
    "    print(f\"Epoch {e+1}/{epochs}, Loss: {loss.item()}, Train Acc : {train_acc[-1]} , Val Acc : {val_acc[-1]}\")\n",
    "\n",
    "\n",
    "torch.save(best_model, os.path.join(r\"CLAP\\models\\freeze_clap_train_mlp\",\"classification_head_best.pt\"))\n",
    "plt.plot(range(epochs), train_acc, label='Train Accuracy')\n",
    "plt.plot(range(epochs), val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "print(\"Best Validation Accuracy:\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r\"CLAP\\models\\freeze_clap_train_mlp\\classification_head_best.pt\"\n",
    "loaded_model = torch.load(model_path,weights_only=False)\n",
    "clap_model.load_state_dict(loaded_model['clap_model'])\n",
    "classification_head.load_state_dict(loaded_model['mlp_head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc : 0.4899497487437186\n",
      "Val Acc : 0.4897435897435897\n"
     ]
    }
   ],
   "source": [
    "test_data_loader = DataLoader(test_dataset_embedded, batch_size=128, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_correct = 0\n",
    "    for batch in test_data_loader:\n",
    "        audio_embeds, labels = batch\n",
    "        audio_embeds = audio_embeds.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = classification_head(audio_embeds)\n",
    "        est_classification = torch.argmax(outputs, dim=1)\n",
    "        test_correct += torch.sum(est_classification == labels).item()\n",
    "    test_acc = test_correct/len(test_dataset)\n",
    "print(f\"Test Acc : {test_acc}\")\n",
    "print(f\"Val Acc : {loaded_model['val_acc']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CLAP and MLP together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with LR: 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.6657702541351318, Train Acc: 0.9000318369945877, Val Acc: 0.7282051282051282\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 1.2223918676376342, Train Acc: 0.9856733524355301, Val Acc: 0.735897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 1.0716734743118286, Train Acc: 0.9888570518943012, Val Acc: 0.7410256410256411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 1.059475450515747, Train Acc: 0.9898121617319325, Val Acc: 0.7461538461538462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 1.0574294853210449, Train Acc: 0.9894937917860553, Val Acc: 0.7512820512820513\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 1.0568529176712036, Train Acc: 0.9885386819484241, Val Acc: 0.7512820512820513\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 1.0548970460891725, Train Acc: 0.9907672715695638, Val Acc: 0.7487179487179487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 1.0544779682159424, Train Acc: 0.9901305316778096, Val Acc: 0.7538461538461538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 1.0552094984054565, Train Acc: 0.9907672715695638, Val Acc: 0.7435897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 1.0545235538482667, Train Acc: 0.9894937917860553, Val Acc: 0.7410256410256411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 1.053626413345337, Train Acc: 0.9917223814071952, Val Acc: 0.7410256410256411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 1.05373694896698, Train Acc: 0.9898121617319325, Val Acc: 0.7461538461538462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 1.054529414176941, Train Acc: 0.9907672715695638, Val Acc: 0.7512820512820513\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 1.0535404109954833, Train Acc: 0.991085641515441, Val Acc: 0.7538461538461538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 1.052899250984192, Train Acc: 0.9907672715695638, Val Acc: 0.7564102564102564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 1.053914222717285, Train Acc: 0.9898121617319325, Val Acc: 0.7538461538461538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 1.0524463224411011, Train Acc: 0.9920407513530722, Val Acc: 0.7487179487179487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 1.0539927387237549, Train Acc: 0.9898121617319325, Val Acc: 0.7512820512820513\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 1.0522625589370727, Train Acc: 0.9920407513530722, Val Acc: 0.7512820512820513\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 1.0522158861160278, Train Acc: 0.9917223814071952, Val Acc: 0.7435897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 1.0516876745224, Train Acc: 0.9929958611907036, Val Acc: 0.7538461538461538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 1.0506817817687988, Train Acc: 0.994269340974212, Val Acc: 0.7461538461538462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 1.05208655834198, Train Acc: 0.9920407513530722, Val Acc: 0.7384615384615385\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 1.0542024326324464, Train Acc: 0.9894937917860553, Val Acc: 0.7307692307692307\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 1.052820987701416, Train Acc: 0.991085641515441, Val Acc: 0.7435897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 1.053552770614624, Train Acc: 0.991085641515441, Val Acc: 0.7487179487179487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 1.0525987482070922, Train Acc: 0.991085641515441, Val Acc: 0.7487179487179487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 1.0529799413681031, Train Acc: 0.9904489016236867, Val Acc: 0.735897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 1.0503799533843994, Train Acc: 0.994269340974212, Val Acc: 0.7487179487179487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 1.0516993188858033, Train Acc: 0.9929958611907036, Val Acc: 0.7410256410256411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 1.0517750072479248, Train Acc: 0.9926774912448265, Val Acc: 0.7410256410256411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 1.0532979106903075, Train Acc: 0.9904489016236867, Val Acc: 0.7461538461538462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 1.0520238208770751, Train Acc: 0.9920407513530722, Val Acc: 0.7461538461538462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 1.0508270931243897, Train Acc: 0.9933142311365807, Val Acc: 0.7435897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 1.0525107049942017, Train Acc: 0.9907672715695638, Val Acc: 0.7435897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 1.0512076663970946, Train Acc: 0.9920407513530722, Val Acc: 0.7384615384615385\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 1.0521705341339112, Train Acc: 0.9923591212989494, Val Acc: 0.7410256410256411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 1.0512993764877319, Train Acc: 0.9923591212989494, Val Acc: 0.7487179487179487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 1.0519452381134033, Train Acc: 0.9920407513530722, Val Acc: 0.7461538461538462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 1.0509571743011474, Train Acc: 0.9933142311365807, Val Acc: 0.7564102564102564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 1.0514341735839843, Train Acc: 0.9926774912448265, Val Acc: 0.7435897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 1.0520552921295165, Train Acc: 0.9914040114613181, Val Acc: 0.7487179487179487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 1.05287672996521, Train Acc: 0.9920407513530722, Val Acc: 0.7487179487179487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 1.0509853124618531, Train Acc: 0.9933142311365807, Val Acc: 0.7307692307692307\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 1.0505009269714356, Train Acc: 0.993950971028335, Val Acc: 0.7282051282051282\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 1.0510488939285278, Train Acc: 0.9923591212989494, Val Acc: 0.7435897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 1.0507187747955322, Train Acc: 0.9933142311365807, Val Acc: 0.7410256410256411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 1.051751275062561, Train Acc: 0.9923591212989494, Val Acc: 0.7410256410256411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 1.0507590055465699, Train Acc: 0.9933142311365807, Val Acc: 0.7435897435897436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batches: 100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n",
      "Val Batches: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 1.0498077964782715, Train Acc: 0.9933142311365807, Val Acc: 0.7512820512820513\n",
      "\n",
      "Best Validation Accuracy for LR: 1e-06 is 0.7564102564102564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "lrs = [1e-6]\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "# Data loaders\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "best_models = dict()\n",
    "# Criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Accuracy lists\n",
    "acc_list = {\"train\": [], \"val\": []}\n",
    "\n",
    "# Training loop\n",
    "for lr in lrs:\n",
    "    # Load the model and processor\n",
    "    processor = ClapProcessor.from_pretrained(CLAP_ARCH)\n",
    "    clap_model = ClapModel.from_pretrained(CLAP_ARCH).to(DEVICE)\n",
    "    clap_model.load_state_dict(torch.load(clap_model_path, weights_only=False)['model_state_dict'])\n",
    "\n",
    "    # Initialize the MLP head\n",
    "    classification_head = MLPHead().to(DEVICE)\n",
    "    for param in clap_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Unfreeze audio projection heads\n",
    "    for param in clap_model.audio_projection.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        [\n",
    "            {\"params\": clap_model.parameters(), \"lr\": lr},\n",
    "            {\"params\": classification_head.parameters(), \"lr\": 1e-3},\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Training with LR: {lr}\")\n",
    "    best_acc = 0\n",
    "    for e in range(epochs):\n",
    "        clap_model.train()\n",
    "        classification_head.train()\n",
    "        train_correct = 0\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_data_loader, desc=\"Train Batches\"):\n",
    "            audio = batch[0]\n",
    "            train_labels = list(batch[1])\n",
    "            unique_labels = train_labels[:1]  # Not needed for inference\n",
    "            inputs = processor(\n",
    "                text=unique_labels,\n",
    "                audios=audio.numpy(),\n",
    "                return_tensors=\"pt\",\n",
    "                sampling_rate=48000,\n",
    "                padding=True,\n",
    "            )\n",
    "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "            outputs = clap_model(**inputs)\n",
    "            audio_embeds = outputs.audio_embeds\n",
    "            outputs = classification_head(audio_embeds)\n",
    "            est_classification = torch.argmax(outputs, dim=1)\n",
    "            train_correct += torch.sum(\n",
    "                est_classification\n",
    "                == torch.tensor([label_to_index[label] for label in train_labels]).to(\n",
    "                    DEVICE\n",
    "                )\n",
    "            ).item()\n",
    "            loss = criterion(\n",
    "                outputs,\n",
    "                torch.tensor([label_to_index[label] for label in train_labels]).to(\n",
    "                    DEVICE\n",
    "                ),\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_acc = train_correct / len(train_dataset)\n",
    "        acc_list[\"train\"].append(train_acc)\n",
    "\n",
    "        clap_model.eval()\n",
    "        classification_head.eval()\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_data_loader, desc=\"Val Batches\"):\n",
    "                audio = batch[0]\n",
    "                val_labels = list(batch[1])\n",
    "                unique_labels = val_labels[:1]\n",
    "                inputs = processor(\n",
    "                    text=unique_labels,\n",
    "                    audios=audio.numpy(),\n",
    "                    return_tensors=\"pt\",\n",
    "                    sampling_rate=48000,\n",
    "                    padding=True,\n",
    "                )\n",
    "                inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "                outputs = clap_model(**inputs)\n",
    "                audio_embeds = outputs.audio_embeds\n",
    "                outputs = classification_head(audio_embeds)\n",
    "                est_classification = torch.argmax(outputs, dim=1)\n",
    "                val_correct += torch.sum(\n",
    "                    est_classification\n",
    "                    == torch.tensor([label_to_index[label] for label in val_labels]).to(\n",
    "                        DEVICE\n",
    "                    )\n",
    "                ).item()\n",
    "        val_acc = val_correct / len(val_dataset)\n",
    "        acc_list[\"val\"].append(val_acc)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_models[lr] ={\n",
    "                \"clap_model\": clap_model.state_dict(),\n",
    "                \"mlp_head\": classification_head.state_dict(),\n",
    "                \"val_acc\": val_acc,\n",
    "            }\n",
    "        print(\n",
    "            f\"Epoch {e+1}/{epochs}, Loss: {total_loss / len(train_data_loader)}, Train Acc: {train_acc}, Val Acc: {val_acc}\\n\"\n",
    "        )\n",
    "\n",
    "    # Print final accuracies\n",
    "    for key in best_models:\n",
    "        print(f\"Best Validation Accuracy for LR: {key} is {best_models[key]['val_acc']}\")\n",
    "    # print(\"Final Training Accuracy:\", acc_list[\"train\"][-1])\n",
    "    # print(\"Final Validation Accuracy:\", acc_list[\"val\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7564102564102564\n"
     ]
    }
   ],
   "source": [
    "path = r\"CLAP\\models\\fine_tuned_clap_mlp_train_together\"\n",
    "for lr,model in best_models.items():\n",
    "    torch.save(model,os.path.join(path,f\"model_dict_lr_{lr}_v2.pt\"))\n",
    "    print(model['val_acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r\"CLAP\\models\\fine_tuned_clap_mlp_train_together\\model_dict_lr_1e-06_v2.pt\"\n",
    "loaded_model = torch.load(model_path,weights_only=False)\n",
    "clap_model.load_state_dict(loaded_model['clap_model'])\n",
    "classification_head.load_state_dict(loaded_model['mlp_head'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Batches: 100%|██████████| 4/4 [00:08<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.7537688442211056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "test_correct = 0\n",
    "\n",
    "confusion_matrix = torch.zeros(6,6)\n",
    "all_labels = list()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_data_loader,desc=\"Test Batches\"):\n",
    "        audio = batch[0]\n",
    "        test_labels = list(batch[1])\n",
    "        all_labels.extend(test_labels)\n",
    "        inputs = processor(\n",
    "            text=test_labels[:1],\n",
    "            audios=audio.numpy(),\n",
    "            return_tensors=\"pt\",\n",
    "            sampling_rate=48000,\n",
    "            padding=True,\n",
    "        )\n",
    "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "        outputs = clap_model(**inputs)\n",
    "        audio_embeds = outputs.audio_embeds\n",
    "        outputs = classification_head(audio_embeds)\n",
    "        est_classification = torch.argmax(outputs, dim=1)\n",
    "        correct_label_index = torch.tensor([label_to_index[label] for label in test_labels])\n",
    "        is_correct = est_classification.cpu() == correct_label_index\n",
    "        for est,correct in zip(est_classification,correct_label_index):\n",
    "            confusion_matrix[correct][est] += 1\n",
    "        test_correct += torch.sum(is_correct).item()\n",
    "    test_acc = test_correct / len(test_dataset)\n",
    "    print(f\"Test Acc: {test_acc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "confusion_matrix = 100*confusion_matrix/confusion_matrix.sum(dim=1).reshape(-1,1)\n",
    "plt.imshow(confusion_matrix)\n",
    "plt.colorbar()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Ground Truth\")\n",
    "plt.xticks(ticks=np.arange(len(label_to_index)), labels=label_to_index.keys())\n",
    "plt.yticks(ticks=np.arange(len(label_to_index)), labels=label_to_index.keys())\n",
    "# Annotate each cell with the numeric value\n",
    "for i in range(confusion_matrix.shape[0]):\n",
    "    for j in range(confusion_matrix.shape[1]):\n",
    "        plt.text(j, i, f\"{round(confusion_matrix[i, j].item(),2)}%\", ha='center', va='center', color='white')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label anger :  65.00%\n",
      "Label surprise :  88.10%\n",
      "Label fear :  57.69%\n",
      "Label sadness :  67.69%\n",
      "Label love :  61.90%\n",
      "Label joy :  87.37%\n"
     ]
    }
   ],
   "source": [
    "for label,counter in Counter(all_labels).items():\n",
    "    print(f\"Label {label} : {100*correct_per_label[label]/counter : .2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
