{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "working_dir = os.path.join(os.getcwd().split(\"Text2BGAudio\")[0],'Text2BGAudio')\n",
    "sys.path.append(working_dir)\n",
    "os.chdir(working_dir)\n",
    "from datasets import load_dataset\n",
    "from transformers import ClapModel, ClapProcessor\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter,defaultdict\n",
    "from tqdm import tqdm\n",
    "from Dataset_Creation import audio_dataset\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(DEVICE))\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Device Name: CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddedDataset(Dataset):\n",
    "    def __init__(self, embedded_data):\n",
    "        self.embedded_data = embedded_data\n",
    "    def __len__(self):\n",
    "        return len(self.embedded_data)\n",
    "    def __getitem__(self, idx):\n",
    "        x,y= self.embedded_data[idx]\n",
    "        return x,y\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "class MLPHead(torch.nn.Module):\n",
    "    def __init__(self, input_dim=512, output_dim=6, hidden_dim=256):\n",
    "        super(MLPHead, self).__init__()\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, output_dim),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index  = {'Angry' : 0, 'Joy' : 1, 'Love' : 2, 'Sad' : 3, 'Scary' : 4, 'Surprise' : 5}\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "\n",
    "def create_embedded_ds(ds_path,model_path,return_indexed=True):\n",
    "    embedded_ds_path = ds_path.split('.')[0] + \"_embedded.pt\"\n",
    "    if os.path.isfile(embedded_ds_path):\n",
    "        print(f\"Loading Embedded Dataset {os.path.basename(embedded_ds_path)}\")\n",
    "        embedded_data = torch.load(embedded_ds_path,weights_only=False)\n",
    "    else:\n",
    "        print(f\"Creating Embedded Dataset {os.path.basename(embedded_ds_path)}\")\n",
    "        dataset = audio_dataset.AudioDataset(ds_path)\n",
    "        data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "        model_name = \"laion/larger_clap_music\"\n",
    "        model = ClapModel.from_pretrained(model_name).to(DEVICE)\n",
    "        processor = ClapProcessor.from_pretrained(model_name)\n",
    "        model.load_state_dict(torch.load(model_path,weights_only=False)['model_state_dict'])\n",
    "\n",
    "        embedded_data =list()\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(data_loader,desc=\"Batches\"):\n",
    "                audio = batch[0]\n",
    "                labels = list(batch[1])\n",
    "                unique_labels = list(set(labels))\n",
    "                inputs = processor(\n",
    "                    text=unique_labels,\n",
    "                    audios=audio.numpy(),\n",
    "                    return_tensors=\"pt\",\n",
    "                    sampling_rate=48000,\n",
    "                    padding=True,\n",
    "                )\n",
    "                inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "                outputs = model(**inputs)\n",
    "                audio_embeds = outputs.audio_embeds\n",
    "                embedded_data.extend([(audio_embed.cpu().detach(), label) for audio_embed, label in zip(audio_embeds, labels)])\n",
    "        torch.save(embedded_data,embedded_ds_path)\n",
    "    if return_indexed:\n",
    "        embedded_data_indexed = [(audio_embed.cpu().detach(), label_to_index[label]) for audio_embed, label in embedded_data]\n",
    "        return EmbeddedDataset(embedded_data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embedded Dataset music_dataset_train_size7507_embedded.pt\n",
      "Creating Embedded Dataset music_dataset_test_size39_embedded.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = r\"CLAP\\models\\clap_fine_tunned_BatchSize_32_LR_1e-05_Epochs_50_LOSS_27.06.pt\"\n",
    "train_dataset_path = r\"_Data\\Music\\music_dataset_train_size7507.pt\"\n",
    "val_dataset_path = r\"_Data\\Music\\music_dataset_test_size39.pt\"\n",
    "train_dataset = create_embedded_ds(train_dataset_path,model_path)\n",
    "val_dataset = create_embedded_ds(val_dataset_path,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.1938018798828125, Train Acc : 0.7485013986945518 , Val Acc : 0.6923076923076923\n",
      "Epoch 2/100, Loss: 1.2446573972702026, Train Acc : 0.815771946183562 , Val Acc : 0.6666666666666666\n",
      "Epoch 3/100, Loss: 1.156229853630066, Train Acc : 0.8242973224990009 , Val Acc : 0.6666666666666666\n",
      "Epoch 4/100, Loss: 1.2113853693008423, Train Acc : 0.8266950845877181 , Val Acc : 0.6666666666666666\n",
      "Epoch 5/100, Loss: 1.2848998308181763, Train Acc : 0.8290928466764353 , Val Acc : 0.6666666666666666\n",
      "Epoch 6/100, Loss: 1.0612423419952393, Train Acc : 0.8320234447848674 , Val Acc : 0.6666666666666666\n",
      "Epoch 7/100, Loss: 1.1632806062698364, Train Acc : 0.8348208338883708 , Val Acc : 0.6923076923076923\n",
      "Epoch 8/100, Loss: 1.1985416412353516, Train Acc : 0.835753296922872 , Val Acc : 0.6923076923076923\n",
      "Epoch 9/100, Loss: 1.054551124572754, Train Acc : 0.8380178500066604 , Val Acc : 0.6923076923076923\n",
      "Epoch 10/100, Loss: 1.2772855758666992, Train Acc : 0.8390835220460903 , Val Acc : 0.6153846153846154\n",
      "Epoch 11/100, Loss: 1.087523102760315, Train Acc : 0.8428133741840949 , Val Acc : 0.6923076923076923\n",
      "Epoch 12/100, Loss: 1.2540901899337769, Train Acc : 0.8418809111495937 , Val Acc : 0.6666666666666666\n",
      "Epoch 13/100, Loss: 1.062145471572876, Train Acc : 0.8432130011988811 , Val Acc : 0.6923076923076923\n",
      "Epoch 14/100, Loss: 1.1841586828231812, Train Acc : 0.8449447182629546 , Val Acc : 0.6923076923076923\n",
      "Epoch 15/100, Loss: 1.1139631271362305, Train Acc : 0.8456107632875982 , Val Acc : 0.6923076923076923\n",
      "Epoch 16/100, Loss: 1.2265228033065796, Train Acc : 0.8482749433861729 , Val Acc : 0.6923076923076923\n",
      "Epoch 17/100, Loss: 1.134687900543213, Train Acc : 0.8500066604502464 , Val Acc : 0.5897435897435898\n",
      "Epoch 18/100, Loss: 1.2390211820602417, Train Acc : 0.8508059144798188 , Val Acc : 0.6666666666666666\n",
      "Epoch 19/100, Loss: 1.2095636129379272, Train Acc : 0.8509391234847475 , Val Acc : 0.5897435897435898\n",
      "Epoch 20/100, Loss: 1.2009488344192505, Train Acc : 0.8518715865192487 , Val Acc : 0.5641025641025641\n",
      "Epoch 21/100, Loss: 1.237380027770996, Train Acc : 0.8541361396030371 , Val Acc : 0.6410256410256411\n",
      "Epoch 22/100, Loss: 1.1601064205169678, Train Acc : 0.8549353936326096 , Val Acc : 0.6153846153846154\n",
      "Epoch 23/100, Loss: 1.1255228519439697, Train Acc : 0.8553350206473957 , Val Acc : 0.6153846153846154\n",
      "Epoch 24/100, Loss: 1.2223678827285767, Train Acc : 0.8575995737311842 , Val Acc : 0.6153846153846154\n",
      "Epoch 25/100, Loss: 1.230022668838501, Train Acc : 0.857199946716398 , Val Acc : 0.6923076923076923\n",
      "Epoch 26/100, Loss: 1.1621190309524536, Train Acc : 0.8606633808445451 , Val Acc : 0.6153846153846154\n",
      "Epoch 27/100, Loss: 1.2484227418899536, Train Acc : 0.859730917810044 , Val Acc : 0.5641025641025641\n",
      "Epoch 28/100, Loss: 1.2533243894577026, Train Acc : 0.8623950979086186 , Val Acc : 0.5641025641025641\n",
      "Epoch 29/100, Loss: 1.167040467262268, Train Acc : 0.8633275609431198 , Val Acc : 0.6153846153846154\n",
      "Epoch 30/100, Loss: 1.1516666412353516, Train Acc : 0.8642600239776209 , Val Acc : 0.6410256410256411\n",
      "Epoch 31/100, Loss: 1.1713002920150757, Train Acc : 0.8643932329825497 , Val Acc : 0.6153846153846154\n",
      "Epoch 32/100, Loss: 1.2393200397491455, Train Acc : 0.8654589050219795 , Val Acc : 0.6153846153846154\n",
      "Epoch 33/100, Loss: 1.2678524255752563, Train Acc : 0.867190622086053 , Val Acc : 0.6153846153846154\n",
      "Epoch 34/100, Loss: 1.1281265020370483, Train Acc : 0.8683895031304116 , Val Acc : 0.6153846153846154\n",
      "Epoch 35/100, Loss: 1.152752161026001, Train Acc : 0.8682562941254829 , Val Acc : 0.6153846153846154\n",
      "Epoch 36/100, Loss: 1.1512845754623413, Train Acc : 0.8706540562142001 , Val Acc : 0.6410256410256411\n",
      "Epoch 37/100, Loss: 1.145400047302246, Train Acc : 0.8703876382043426 , Val Acc : 0.5897435897435898\n",
      "Epoch 38/100, Loss: 1.0961029529571533, Train Acc : 0.8707872652191289 , Val Acc : 0.5897435897435898\n",
      "Epoch 39/100, Loss: 1.1664021015167236, Train Acc : 0.8719861462634874 , Val Acc : 0.6410256410256411\n",
      "Epoch 40/100, Loss: 1.0869590044021606, Train Acc : 0.873717863327561 , Val Acc : 0.6153846153846154\n",
      "Epoch 41/100, Loss: 1.1482692956924438, Train Acc : 0.8734514453177035 , Val Acc : 0.6153846153846154\n",
      "Epoch 42/100, Loss: 1.252537727355957, Train Acc : 0.8734514453177035 , Val Acc : 0.6153846153846154\n",
      "Epoch 43/100, Loss: 1.146589756011963, Train Acc : 0.8754495803916345 , Val Acc : 0.6153846153846154\n",
      "Epoch 44/100, Loss: 1.2116377353668213, Train Acc : 0.875183162381777 , Val Acc : 0.6153846153846154\n",
      "Epoch 45/100, Loss: 1.2936638593673706, Train Acc : 0.8762488344212068 , Val Acc : 0.5897435897435898\n",
      "Epoch 46/100, Loss: 1.1467539072036743, Train Acc : 0.8767816704409218 , Val Acc : 0.6410256410256411\n",
      "Epoch 47/100, Loss: 1.1863739490509033, Train Acc : 0.8787798055148528 , Val Acc : 0.6410256410256411\n",
      "Epoch 48/100, Loss: 1.2091412544250488, Train Acc : 0.8794458505394964 , Val Acc : 0.5897435897435898\n",
      "Epoch 49/100, Loss: 1.1361078023910522, Train Acc : 0.8799786865592114 , Val Acc : 0.6410256410256411\n",
      "Epoch 50/100, Loss: 1.155699372291565, Train Acc : 0.8799786865592114 , Val Acc : 0.5897435897435898\n",
      "Epoch 51/100, Loss: 1.110277533531189, Train Acc : 0.8803783135739977 , Val Acc : 0.5897435897435898\n",
      "Epoch 52/100, Loss: 1.2835508584976196, Train Acc : 0.8818436126282136 , Val Acc : 0.6410256410256411\n",
      "Epoch 53/100, Loss: 1.2442009449005127, Train Acc : 0.882642866657786 , Val Acc : 0.6153846153846154\n",
      "Epoch 54/100, Loss: 1.1183415651321411, Train Acc : 0.8843745837218596 , Val Acc : 0.6410256410256411\n",
      "Epoch 55/100, Loss: 1.0787172317504883, Train Acc : 0.8823764486479286 , Val Acc : 0.6410256410256411\n",
      "Epoch 56/100, Loss: 1.2583644390106201, Train Acc : 0.8841081657120021 , Val Acc : 0.6410256410256411\n",
      "Epoch 57/100, Loss: 1.2378253936767578, Train Acc : 0.8838417477021446 , Val Acc : 0.6153846153846154\n",
      "Epoch 58/100, Loss: 1.229736089706421, Train Acc : 0.8854402557612895 , Val Acc : 0.6153846153846154\n",
      "Epoch 59/100, Loss: 1.1503506898880005, Train Acc : 0.8867723458105768 , Val Acc : 0.6410256410256411\n",
      "Epoch 60/100, Loss: 1.049942970275879, Train Acc : 0.8869055548155055 , Val Acc : 0.6410256410256411\n",
      "Epoch 61/100, Loss: 1.1261085271835327, Train Acc : 0.8869055548155055 , Val Acc : 0.6410256410256411\n",
      "Epoch 62/100, Loss: 1.1969926357269287, Train Acc : 0.8879712268549353 , Val Acc : 0.6410256410256411\n",
      "Epoch 63/100, Loss: 1.4453221559524536, Train Acc : 0.8883708538697216 , Val Acc : 0.6410256410256411\n",
      "Epoch 64/100, Loss: 1.1505368947982788, Train Acc : 0.8886372718795791 , Val Acc : 0.6410256410256411\n",
      "Epoch 65/100, Loss: 1.2616755962371826, Train Acc : 0.8905021979485813 , Val Acc : 0.6666666666666666\n",
      "Epoch 66/100, Loss: 1.0967611074447632, Train Acc : 0.8903689889436526 , Val Acc : 0.6666666666666666\n",
      "Epoch 67/100, Loss: 1.062669038772583, Train Acc : 0.8914346609830824 , Val Acc : 0.6410256410256411\n",
      "Epoch 68/100, Loss: 1.1446641683578491, Train Acc : 0.8923671240175836 , Val Acc : 0.6666666666666666\n",
      "Epoch 69/100, Loss: 1.152064323425293, Train Acc : 0.8906354069535101 , Val Acc : 0.6410256410256411\n",
      "Epoch 70/100, Loss: 1.174824595451355, Train Acc : 0.8918342879978687 , Val Acc : 0.6410256410256411\n",
      "Epoch 71/100, Loss: 1.2559009790420532, Train Acc : 0.8939656320767284 , Val Acc : 0.6410256410256411\n",
      "Epoch 72/100, Loss: 1.274521827697754, Train Acc : 0.8940988410816572 , Val Acc : 0.6666666666666666\n",
      "Epoch 73/100, Loss: 1.1024094820022583, Train Acc : 0.8940988410816572 , Val Acc : 0.6410256410256411\n",
      "Epoch 74/100, Loss: 1.1062885522842407, Train Acc : 0.895164513121087 , Val Acc : 0.6666666666666666\n",
      "Epoch 75/100, Loss: 1.0438305139541626, Train Acc : 0.8943652590915145 , Val Acc : 0.6410256410256411\n",
      "Epoch 76/100, Loss: 1.1836074590682983, Train Acc : 0.8954309311309444 , Val Acc : 0.6666666666666666\n",
      "Epoch 77/100, Loss: 1.2285706996917725, Train Acc : 0.8952977221260158 , Val Acc : 0.6666666666666666\n",
      "Epoch 78/100, Loss: 1.128656029701233, Train Acc : 0.8974290662048755 , Val Acc : 0.6410256410256411\n",
      "Epoch 79/100, Loss: 1.205268144607544, Train Acc : 0.897162648195018 , Val Acc : 0.6410256410256411\n",
      "Epoch 80/100, Loss: 1.054365634918213, Train Acc : 0.8978286932196616 , Val Acc : 0.6410256410256411\n",
      "Epoch 81/100, Loss: 1.2005161046981812, Train Acc : 0.8982283202344479 , Val Acc : 0.6410256410256411\n",
      "Epoch 82/100, Loss: 1.1297425031661987, Train Acc : 0.8983615292393766 , Val Acc : 0.6410256410256411\n",
      "Epoch 83/100, Loss: 1.2174971103668213, Train Acc : 0.8982283202344479 , Val Acc : 0.6410256410256411\n",
      "Epoch 84/100, Loss: 1.1583586931228638, Train Acc : 0.8992939922738777 , Val Acc : 0.6666666666666666\n",
      "Epoch 85/100, Loss: 1.3548409938812256, Train Acc : 0.8996936192886639 , Val Acc : 0.6410256410256411\n",
      "Epoch 86/100, Loss: 1.094826340675354, Train Acc : 0.9010257093379512 , Val Acc : 0.6410256410256411\n",
      "Epoch 87/100, Loss: 1.150787591934204, Train Acc : 0.9008925003330225 , Val Acc : 0.6410256410256411\n",
      "Epoch 88/100, Loss: 1.0521020889282227, Train Acc : 0.8999600372985214 , Val Acc : 0.6410256410256411\n",
      "Epoch 89/100, Loss: 1.1067702770233154, Train Acc : 0.9010257093379512 , Val Acc : 0.6410256410256411\n",
      "Epoch 90/100, Loss: 1.2939602136611938, Train Acc : 0.9010257093379512 , Val Acc : 0.6410256410256411\n",
      "Epoch 91/100, Loss: 1.0946048498153687, Train Acc : 0.9007592913280937 , Val Acc : 0.6410256410256411\n",
      "Epoch 92/100, Loss: 1.1512597799301147, Train Acc : 0.9018249633675236 , Val Acc : 0.6410256410256411\n",
      "Epoch 93/100, Loss: 1.0677838325500488, Train Acc : 0.9015585453576662 , Val Acc : 0.6666666666666666\n",
      "Epoch 94/100, Loss: 1.2043499946594238, Train Acc : 0.9018249633675236 , Val Acc : 0.6410256410256411\n",
      "Epoch 95/100, Loss: 1.2038520574569702, Train Acc : 0.9032902624217397 , Val Acc : 0.6666666666666666\n",
      "Epoch 96/100, Loss: 1.0816761255264282, Train Acc : 0.9024910083921673 , Val Acc : 0.6410256410256411\n",
      "Epoch 97/100, Loss: 1.1510281562805176, Train Acc : 0.9042227254562408 , Val Acc : 0.6410256410256411\n",
      "Epoch 98/100, Loss: 1.0585460662841797, Train Acc : 0.903157053416811 , Val Acc : 0.6410256410256411\n",
      "Epoch 99/100, Loss: 1.1137539148330688, Train Acc : 0.9034234714266685 , Val Acc : 0.6410256410256411\n",
      "Epoch 100/100, Loss: 1.1563808917999268, Train Acc : 0.9042227254562408 , Val Acc : 0.6410256410256411\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=True)\n",
    "\n",
    "classification_head = MLPHead().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(classification_head.parameters(), lr=5e-4)\n",
    "\n",
    "train_acc = list()\n",
    "val_acc = list()\n",
    "for e in range(epochs):\n",
    "    train_correct = 0\n",
    "    for batch in train_data_loader:\n",
    "        audio_embeds, labels = batch\n",
    "        audio_embeds = audio_embeds.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = classification_head(audio_embeds)\n",
    "        est_classification = torch.argmax(outputs, dim=1)\n",
    "        train_correct += torch.sum(est_classification == labels).item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc.append(train_correct/len(train_dataset))\n",
    "    with torch.no_grad():\n",
    "        val_correct = 0\n",
    "        for batch in val_data_loader:\n",
    "            audio_embeds, labels = batch\n",
    "            # audio_embeds = F.normalize(audio_embeds, p=2, dim=1)\n",
    "            audio_embeds = audio_embeds.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = classification_head(audio_embeds)\n",
    "            est_classification = torch.argmax(outputs, dim=1)\n",
    "            val_correct += torch.sum(est_classification == labels).item()\n",
    "        val_acc.append(val_correct/len(val_dataset))\n",
    "    print(f\"Epoch {e+1}/{epochs}, Loss: {loss.item()}, Train Acc : {train_acc[-1]} , Val Acc : {val_acc[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
